Tracking of Multiple Worms and Fish for Biological Studies
Ebraheem Fontaine1, Alan H. Barr2, and Joel W. Burdick1
1 Department of Mechanical Engineering, California Institute of Technology, US ebraheem,jwb@robotics.caltech.edu,
2 Department of Computer Science, California Institute of Technology, US barr@cs.caltech.edu,
Abstract. This paper addresses the problem of tracking multiple undulating creatures through interactions and partial occlusions from a top view. Detailed posture estimation of biological model organisms is essential for a wide variety of research. We present a visual tracking algorithm that incorporates both a contour model and a region model based on level sets. Both visual cues are naturally integrated into the observation model of an Iterated Kalman Filter (IKF). We use generative geometric models to parameterize the animal's shape deformations and motion. The priors provided by these parametrized models improve tracking accuracy in the presence of incorrect foreground segmentation and partial occlusions, while allowing us to measure physical quantities directly relevant to experimental goals. For illustration, the method is used to track the position and shape of multiple nematodes and larval zebrafish.
1 Introduction
Capturing the detailed motion and behavior of biological organisms plays an important role in a wide variety of research disciplines. Many studies in genetics, developmental biology, and neuroscience rely on the analysis of video sequences. Techniques from computer vision can potentially have a large impact in this area by providing accurate and efficient screening of complex organismal phenotypes and behavior modes that are dominated by motion. In this paper, we address the problems of tracking the planar motion of multiple nematodes (C. elegans) and larval zebrafish (Danio rerio), which are widely used model organisms in biology [1, 2]. The experimental lighting conditions in our video sequences are such that high contrast is often achieved between the organism and background. This facilitates accurate foreground segmentation and localization of individual organisms in the lateral direction due to the existence of strong edges.
However, many of the behaviors most interesting for biological research occur when the animals closely interact, such as mating of nematodes or collisions
We are thankful to the Beckman Institute of California Institute of Technology for providing funding of this project

between zebrafish larvae. In these cases, there is often insufficient edge infor-

mation to localize the organisms during partial occlusions (see Fig. 1). Thus,

this problem argues for a region-based approach that will drive our models to

contain the maximum number of foreground pixels. However, to achieve precise

estimation of the organism's posture, contours should be utilized also. To ad-

dress this need, we present a tracking algorithm that incorporates a level-set

based image segmentation functional and a contour tracker into the framework

of the Iterated Kalman Filter (IKF). The algorithm uses the solution given by

the region-based measurements as an initial condition that is refined using the

contour measurements.

Frame 54

Fig. 1: Left: Raw image of mating C. elegans. Right: Despite accurate foreground segmentation, it is difficult to localize the smaller worm in the axial direction with only edge information (i.e. both configuration are plausible). Therefore a region-based method should be employed.
Recently, several automated systems have been developed for tracking multiple C. elegans nematode [3­5]. In [3] and [5], the authors both use a region-based approach that achieves robust tracking, but they do not take advantage of contour information to refine the pose estimation and achieve greater accuracy. The authors in [4] proposed an edge-based tracker that achieved high accuracy, however, manual intervention was required when the head and tail of the worms remained occluded for more than a few frames. No methods to date have addressed the problem of tracking multiple zebrafish larvae. The proposed algorithm takes advantage of multiple cues and incorporates a model representation that is applicable across different species.
Tracking moving objects with changing shape continues to be an active area of research. Geometric active contours formulated in the level-set framework has emerged as a general and robust method because its implicit representation naturally deals with topological changes (e.g. when a worm coils its body) that earlier explicit representations [6] could not. Previous level-set based trackers that use a dynamic state space framework include [7­11]. By using a state space model that includes a model of the moving object's dynamics, the temporal coherence of the level sets guides the tracking process, instead of using the solution from the previous image frame as the initial guess for the current frame. In terms of Bayesian inference, this corresponds to a prior probability distribution on system state. The region-based portion of our algorithm is most closely related to the

work of [7, 8, 11] who formulate tracking as a problem of Bayesian inference and incorporate a prior model using a linear combination of principle shapes learned from a training sequence.
With the animal tracking application in mind, we construct generative geometrical models whose finite parameterizations are adapted to the given problem. By specifying the degrees of freedom and deformations of our model, the state estimation process allows us to perform inference on physical quantities that are of interest to experimental goals. In addition, the generative models allow us to naturally decouple the organism's shape from its posture and apply it to diverse motions across different organisms.

2 Preliminaries
This section first reviews our tracking methodology, and aspects of prior theory that are needed to develop our approach. Then, we review the popular Chan and Vese model for image segmentation [12] and show how it is incorporated into our region-based tracking scheme. We then develop an example of this method using nematodes and zebrafish that includes a contour based measurement model which is used to refine the state estimate given by the region-based approach.

2.1 Model-Based Image Tracking

We construct models for animal tracking using a generative modeling approach

[13]. A generative model is constructed by applying a continuous transformation

to a shape, known as a generator. Mathematically, the generator is represented by the parametric function G(q) : l  m, and the continuous transformation by T (x; r) : m× k  n, where x  m is a point in space to be transformed, and r  k is a parameter that defines the transformation. The resulting generative

model is

F (p) = T (G(q) ; r) : l+k  n

(1)

where F is the surface defined by our model and p = q r T is the joint param-

eterization. Examples of generative models for C. elegans and Danio rerio are

given in Section 3.

The state of the animal consists of the parameters that describe its pose (i.e.

the translation of a body fixed frame with respect to a reference frame and angles

associated with the orientation of appendages), although other parameters can

be included. The visual tracking problem involves sequentially estimating the

state, p, via measurements, z, in a discrete time dynamic state space model

pk = f(pk-1, k-1)

(2)

zk = h(pk, k)

(3)

where k and k are noise processes. We assume that f(p, ) is available to describe the animal's motion between frames (e.g., see section 3.1), and the

measurements consist of either 2D images or 1D edge-feature points for the re-

gion and contour methods, respectively. To systematically derive the tracking

equations for the region-based approach, the generative model defined by (1) is transformed into the image domain by rendering it using an appropriate camera model, IF (p) = Render(F (p)) : n  2. The image IF (p) determines the regions inside and outside the rendered model and is used to construct a signed distance function (SDF), . The observation equation, h(p, ), is then based on the Chan and Vese model which uses the implicit representation of . For the contour-based approach, the observation function is the concatenation of edge-feature points normal to the model contour. Correspondence is achieved using statistical measures and an exclusion heuristic based on current estimates of other models. See the ensuing sections for details. Under the assumptions of white and Gaussian noise, the IKF is used as our nonlinear estimation technique. A specific example of the approach is given in Section 3.2.

2.2 Region-Based Tracking

As shown in [14], a single iteration of the update equation in an IKF is equivalent
to a single Gauss-Newton iteration of a nonlinear least squares problem. To establish this equivalence, assume that the state estimate p^  n and observation z  m come from the multivariate normal distributions

p^  N (p, P), z  N (h(p), R).

(4)

From Bayes Rule, the MAP estimate of p is found by maximizing P(p|z) P(z|p)P(p) with respect to z. Maximizing the posterior distrubution is equivalent to minimizing the negative log of the function P(z|p)P(p),

1 E(p) =

(z - h(p))T R-1(z - h(p)) + (p^ - p)T P-1(p^ - p)

2

(5)

after dropping a constant. The minimization of (5) is equivalent to a nonlinear

least squares problem with an error functional of the form:

E(p)

=

1 2

f (p)

2.

(6)

The Gauss-Newton method for minimizing (6) defines a sequence of approximations pi that converges to a local minimum of (6) for problems where ||f (p)|| is locally convex at the solution. Using matrix algebra and utilizing the matrix inversion lemma, the Gauss-Newton sequence becomes equivalent to

pi+1 = p^k + Ki z - h(pi) - Hi(p^k - pi) ,

(7)

which is the IKF update equation for the kth time step. Hi is the Jacobian matrix of h(pi) and Ki = PHiT (HiPHiT + R)-1 is the Kalman gain. Thus, the update equation of an iterated Kalman Filter is equivalent to a nonlinear least
squares problem of the form in (6).
Next, we use this result to incorporate a level set image functional into the
Kalman Filter update framework. In order to determine the boundary that di-
vides the image into foreground and background regions (i.e, the image boundary
that divides the tracked animal's body from the background), a contour  is embedded into the zero level set of a signed distance function  :   on the image domain   2:

 = {(x, y)   | (x, y) = 0}.

(8)

By minimizing an energy functional,  is deformed implicitly by evolving the function . While many different image-based energy functionals have been proposed, we focus on the popular Chan and Vese model [12], which can be solved using level set methods [15]. It has the form:

Ecv() = (I - c1)2H() + (I - c2)2(1 - H()) dx dy + |H()| dx dy, (9)


where the first and second terms try to increase the grayscale homogeneity of

the image I inside and outside  and the third term penalizes the contour

length. H(·) is the Heaviside function, and the constants, c1 and c2 are defined

as c1() =

 I(x,y)H()dx dy  H()dx dy

and

c2()

=

 I(x,y)(1-H())dx dy  (1-H())dx dy

which

respectively

represent the average grayscale intensity inside and outside the contour.

When prior knowledge about the object being detected is available,  can be

explicitly parameterized by the model parameters. This approach is utilized by

Tsai et al. to accurately segment MRI scans of the left ventricle and prostate

gland [16]. They redefine the Chan and Vese model as Ecv(c1, c2, (w, z)) and perform gradient descent directly on the shape parameters, w, and the pose

parameters, z. We also define  as a function of the shape and pose parame-

ters, however, instead of using PCA to model the shape deformations, we use a

generative model (1) that encodes all variables appropriate to scientific goals.

We assume that our segmenting contour  and associated  are parameter-

ized by a state vector p. Following [16], we eliminate the "length" term in the

Chan and Vese model because the underlying model-based parameterization of

 prevents it from growing arbitrarily. Then (9) becomes

Ecv(p) = (I - c1)2H((p)) + (I - c2)2(1 - H((p))) dx dy.


(10)

To show how the Chan-Vese segmentation model can formally fit into an IKF

framework, we define the observation function of the state space model (3) as:

h(p) =

c1

(p)  0 .

c2 (p) < 0

(11)

Note that the c1, c2 are functions of , which in turn is a function of p, and so h(·) is differentiable. For implementation on images with a finite number of
pixels, we convert (10) to a discrete representation:

Ecv(p) =

(I(xi, yj) - h(xi, yj ; p))2

ij

= (I - h(p)) 2.

(12) (13)

where I(xi, yj) is the image intensity at the pixel with coordinates (xi, yj). Note that the Chan-Vese model tries to minimize the difference in pixel intensity between the observed image and a binary-valued image, defined by the observation

function h of (11), across the image domain . Assuming that the covariance

of z (in (3)) assumes the value R = I, the identity matrix, and rewriting the

squared Mahalanobis distance as

y-p

2 

(y - p)T -1(y - p), we can rewrite

error function (5) of the MAP estimate as:

1 E(p) =
2

z - h(p)

2 R

+

p^ - p

2 P

1 =
2

Ecv +

p^ - p

2 P

.

(14) (15)

That is, the error function takes the nonlinear least squares form of (6), whose

iterative minimization is equivalent to the IKF update equation. Thus, we have

shown that the Chan and Vese segmentation model can be implemented as the

observation term of an iterated Kalman filter when one defines the observation

function according to (11). The second term in (15),

p^ - p

2 P

,

is

equivalent

to

a "shape prior" or "knowledge-driven" term. It draws the current state towards

the prediction and weights it according to the statistical certainty, while the first

term modifies the state based solely on image intensity.

2.3 Contour Update
Let p^k and Pk be the updated state and covariance at time step k due to the Chan and Vese Model region model described above. The final state estimate is achieved by applying the Kalman update equation to these estimates, pi+1 = p^k + Ki z - hc(pi) - Hic(p^k - pi) , using the contour observation model, hc(p) and iterating until convergence.
Implementation of the IKF update equation requires linearization of (11), which can be better approximated using the statistical linearization methods of Sigma-Point Kalman Filters (SPKF) (see [17] and the references therein). We follow the approach of [18] by using iteration in addition to the statistical linearization. The iteration is stopped when either the residual norm is less than a preset threshold, it increases for consecutive iterations, or the update reaches a maximum number of iterations.
The tracking approach presented here has several advantages. First, the region-based observation model makes a global measurement of the error by utilizing the distribution of intensity values across the entire image to make a local search for the solution. Second, by utilizing the statistical linearization methods, we eliminate the need to directly calculate the Jacobian matrices associated with our process and observation equations. Finally, the contour update allows us to refine our state estimate using the dominant edges present in our high contrast images.

3 The Worm and Fish State Space Models
Sections 3 and 3.1 describe the equations for a single organism. Tracking K organisms is achieved by concatenating the state variables K times. The motion

of C. elegans and Danio rerio on a typical microscope slide is largely planar,

so we restrict our modeling of the organisms to two dimensions and assume

orthographic projection in the camera model. To a good approximation, they

also maintain constant length and width during locomotion. Therefore, we model

the organism's centerline as a planar, inextensible curve. The centerline shape

can be effectively described by the bend angle as a function of distance along its

length. This function, (u), becomes the generator of our model and is finitely

parameterized using a linear combination of known basis functions, kj (u):

N

(u) = jjk(u).

(16)

j=1

Although other choices are possible, the current implementation uses second and fourth order (k = {2, 4}) periodic B-spline basis with N = 8 for the worm and fish, respectively. The organism's centerline is constructed by integrating the unit
tangent vector e1 to the centerline curve, and the width is created by expanding the surface in the direction of the normal vector e2. This transformation creates our parameterized generative model F (p):

e1(u) =

cos((u^)) sin((u^))

,

e2(u) =

- sin((u)) cos((u))

(17)

u

F (p) = 

e1(u^)du^ + v R(u)e2(u) + T

0

(18)

where  is a constant scaling term with units pixels  mm-1, T is a global translation vector to the model's center of mass, p =  T T , L is the organ-

ism's

length,

u



[-

L 2

,

L 2

],

v



[-1, 1]

are

the

mesh

parameters,

and

R(u)

is

a continuous function for the organism's width as a function of distance along

its length. Currently, R(u) is defined as a fourth order periodic B-spline using

20 control points and is calculated offline using a semi-automatic initialization

routine described in [19]. For our experiments, the scaling term  is calculated

from a test image using a stage micrometer.

F (p)

~e2(u)

y T~
x

~e1(u)

£(u)

~e2(u)

y

~e1(u)

£(u)

T~ x

F (p)

Fig. 2: Illustration of C. Elegans and Danio rerio geometric models. The models are deformed by changing the bend angle (u) and the location of its body coordinate frame T

3.1 Motion Model

The motion model assumes that the organism undergoes axial progression along its length with a constant wave velocity, 1, corrupted by acceleration noise, 2. Thus, the state vector and process noise vector for a single organism are:

p =  T 1 T

 =  T 2 T

(19)

The equations of motion calculate the predicted state vector after the organ-

ism

has

undergone

a

total

axial

displacement

of

0

=

1t

+

2

t2 2

,

where

t

is

the inverse of the camera frame rate. These equations take the form:

pk = f(pk-1, k-1)

 k   (u)-1(u + 0)k-1   k-1 

Txk Tyk

=TTxykk--11

+ +

0 00 0

csions((((u^u^))kk--11))ddu^u^+

Txk-1 Tyk-1

  

1k

1k-1

2k-1 t

(20)

Here, (u) is a N dimensional row vector of B-spline bases, and (u) =

(u1 )

· ·

is a s x N matrix of B-spline bases evaluated at s sampled grid points

(us )

in u. The predicted shape parameters are calculated by projecting onto this

basis in the domain of displacement u + 0, calculating the new (u + 0), and

projecting back onto the original basis, (u). Likewise, the predicted translation

is calculated by integrating the tangent vector over the axial displacement.

3.2 Observation Model

Although the Chan and Vese model can be applied directly to grayscale images,

we apply it to binary images that are calculated using a simple background

subtraction model. Because microscope lighting effects may cause regions of the

worm and fish to be nearly camouflaged in the background, we determine the

pixels belonging to the worm by background subtraction instead of relying on the

image functional to partition the image based on the distribution of grayscale

intensities. This approach is primarily used to provide improved tracking of

multiple organisms, as we do not currently constrain the shape priors to pre-

vent intersection of different worms or fish because this occurs frequently in the

intended applications.

The binary image serves as the data observation at the kth frame, zk = Ik. An

overview of the worm observation model is illustrated in Figure 3. The rendered

image of each organism model defined by (18) is joined to create the total image

IF (p) =

K i=1

Render(F (pi)).

Once

the

boundary

locations



have

been

found,

the values of c1 and c2 can be calculated directly. We first determine the domains:

I = (xi, yi) | IF (p)(xi, yi) = 1, (xi, yi) /  O = (xi, yi) | IF (p)(xi, yi) = 0 ,

(21) (22)

which determine the sets of pixels inside and outside the worm boundary, respectively. The observation model h(p) is then calculated as follows:

h(p) =

c1 = c2 =

N i

Ik (xi ,yi )

N

M i

Ik (xi ,yi )

M

(xi, yi)  I (xi, yi)  O.



(23)

We assume that the image pixels are corrupted by additive noise with unit variance, k  N (0, I). Using this model, the observation dimension is equal to the number of pixels in the image. To decrease the computational cost of
calculating the Kalman gain, we make two modifications. First, Ik is trimmed to the smallest window that contains the closed boundaries that belong to the
organism. We also subsample the images Ik and IF (p) using a standard Gaussian pyramid with unit variance. The observation update is then performed at a level
2 of the pyramid where level 0 is the original resolution (see Fig. 3a).
The contour observation model is illustrated in Fig. 3b, and it consists of the model boundary points qi = xi yi projected onto their outward normal vectors, ni = nix nyi . To find corresponding edge-feature points, we follow the approach of [20] by applying a 1D edge detector filter to Ik in the normal direction at each of the boundary points in the model. The nearest neighbor detected edge points,
ri, are also projected onto ni so that the error minimized by the IKF has the form nT(q - r). For worm tracking, we also make two additions to this contour
model. A closed B-Spline curve is fit to the boundaries of Ik and locations of high negative curvature are calculated. These feature points correspond to head
and tail locations and are matched with our model if they pass a Mahalanobis
test and have a similar normal vector orientation. Also, due to their cylindri-
cal shape, the worms never share a visible boundary while they interact (i.e.
their centerlines are almost never coincident and parallel in any region). This
constraint is incorporated by rejecting any detected edge points for one worm
where the measurement lines cross over the model location of other worms. This
idea is also modeled in [3] using a 'worm overlap energy' and is a simpler notion
of the exclusion principle presented in [21].

4 Experimental Results
We demonstrate our tracking algorithm on 4 worm sequences and 1 fish sequence. All videos are acquired using a stereographic microscope outfitted with either a 30 Hz camera at 720x480 or 640x480 resolution for the worms or a 3000 Hz, 1024x1024 camera for the fish. The fish sequence was cropped to 550x775 to only include the region where swimming occurs. For each sequence, the model pose parameters are manually initialized by clicking points along the centerline of each organism to match the configuration at the first frame. The algorithm is written in MATLABTM, uses the state estimation toolbox of [22], and operates in a batch off-line mode.
In the multiple worm sequences, the hermaphrodite (larger worm) is partially paralyzed to keep the mating behavior within the camera's field of view.

10

20

30

40

10 20(a) 30 40

(b)

Fig. 3: Overview of observation models, h(pk, k) used in the proposed tracker: (a) Illustration of the observation model for region-based tracking. Initial condition (red) and final solution (green) are plotted over the subsampled data image, Ik. Contours represent the zero level set of (pk); (b) Observation model for contour-based tracking. Edge features are detected along 1D measurement lines. Model locations are labeled as occluded (yellow stars) if no match is detected. High curvature points (red squares) are matched with head/tail locations.

Research into the genetic basis of mating behavior mainly involves studying the male motion. Mating consists of two behavior modes that are dominated by motion: backing and turning. Quantifying the body posture of the male during backing and turning is an important metric for understanding the genetic and neuronal basis of mating. For instance, certain mutants either cannot turn, or hesitate a lot before turning. Fig. 4 shows four sequences where our algorithm is able to successfully track both worms while the male backs and turns. The first row illustrates the failed tracking result when just the contour observation model is utilized. Because the male model is only using the lower edge information to localize itself, the tracker cannot detect when it crawls underneath the hermaphrodite. However, by incorporating the region-based module, we can successfully handle the partial occlusion. Fig. 5 illustrates the specific curvature profile (curvature normalized by body length) of the male worm from the video sequence in Fig. 4c. The direction of propagation of the curvature isocontours indicates which way the worm is traveling and, hence, can be used to detect reversals. This particular worm undergoes four different reversals to reorient itself for mating that is indicated by a change in slope of the isocontours.
In Fig. 4f, three zebrafish are successfully tracked during partial occlusions and collisions that result from one larvae exhibiting an escape response (C-start) that is initiated by touching the fish with a horse hair. Automatic quantification of the swimming behavior across multiple fish is important for many scientific questions such as, automatic phenotyping and schooling behavior. Our approach allows us to quickly construct specific curvature profiles (see Fig. 5), which compactly illustrates the motion over time. Key measurements such as frequency,

wave speed, and peak muscle strains can be calculated from this plot. The escape response is illustrated by the initial closely spaced tailbeat cycles, which become more spaced out after 30ms when the animal has evaded danger.
5 Future Work
We presented a model-based tracking algorithm that formally incorporates the robust segmentation method of level sets and contours within the nonlinear IKF estimation framework. This approach has tracked worms during mating and fish during swimming collisions by utilizing the flexibility of generative models, and created an accurate behavioral quantification method for numerous future biological studies. Although we are able to acheive good tracking results, we feel it is mainly due to incorporating high-level and low-level cues, and not due to the choice of nonlinear estimator. Because the Kalman filter only performs a local search, estimators that perform a more global search may have superior performance in certain scenarios. Specifically, we are interested in incorporating our parameterized models and contour tracking with the particle filtering implementation of Chan and Vese's model presented in [11]. In addition, certain lighting and/or experimental conditions will make appearance-based tracking a more favorable approach. The work of Khan et. al. on bee tracking [23] provides a viable approach to estimate the extra parameters associated with appearance in an effective manner.
References
1. Kaletta, T., Hengartner, M.O.: Finding function in novel targets: C. elegans as a model organism. Nature Reviews Drug Discovery 5 (2006) 387­399
2. Grunwald, D.J., Eisen, J.S.: Headwaters of the zebrafish - emergence of a new model vertebrate. Nature Reviews Genetics 3 (2002) 717­724
3. Roussel, N., Morton, C., Finger, F., Roysam, B.: A computational model for c. elegans locomotory behavior: Application to multi-worm tracking. IEEE Trans. Biomed. Eng. to appear (2007)
4. Fontaine, E., Burdick, J.W., Barr, A.: Automated tracking of multiple c. elegans. In: IEEE EMBS. (2006)
5. Huang, K.M., Cosman, P., Schafer, W.: Automated tracking of multiple c. elegans with articulated models. In: IEEE ISBI. (2007)
6. Terzopoulos, D., Szeliski, R.: Tracking with Kalman snakes. In: Active Vision. MIT Press (1992) 3­20
7. Cremers, D.: Dynamical statistical shape priors for level set based tracking. PAMI 28(8) (2006) 1262­1273
8. Dambreville, S., Rathi, Y., Tannenbaum, A.: Tracking deformable objects with unscented kalman filtering and geometric active contours. In: ACC. (2006)
9. Jackson, J., Yezzi, A., Soatto, S.: Tracking deformable moving objects under severe occlusions. In: IEEE CDC. (2004)
10. Niethammer, M., Tannenbaum, A.: Dynamic geodesic snakes for visual tracking. In: CVPR. (2004)

Frame 1

Frame 55

Frame 70

(a) Using only edge information, tracking of the male worm fails when it is partially occluded.

Frame 1

Frame 55

Frame 70

Frame 336

Frame 403

Frame 460

(b) Tracking using region and edge based cues successfully handles the partial occlusion.

Frame 1

Frame 78

Frame 269

Frame 308

Frame 338

Frame 470

(c) The implicit representation of  handles the changing topology of the image contour in the second and fourth still frames when the male worm curls its body.

Frame 1

Frame 90

Frame 243

Frame 470

Frame 794

Frame 1120

(d) TrackiFnrgamme 1u1tant male that Fpreamrfeo6r1ms backing alonFgramheer1m40aphrodite butFhraemseit2a1t5es and fails to complete a turn.

(e) This mutant hesitates but successfully completes a turn.

Frame 1

Frame 27

Frame 35

Frame 46

Frame 80

(f) Tracking larval zebrafish during the escape response behavior which is initiated on the green fish by prodding with a horse hair
Fig. 4: Tracking results of four different C. elegans mating sequences and one zebrafish sequence. Model estimate of male and hermaphrodite appear in white and cyan, respectively (a)-(e)

time (s) time (ms)

25 10

15

20 70

8

15 60

6

10 4

10

50 5

2

0 40

0

5 Forward

-5 30
-10 20
-15

-2 -4 -6

Backward

-20 10

-8

00 0.2 0.4 0.6 0.8 1 -25

00 0.2 0.4 0.6 0.8 1 -10

Fig. 5: (Left) Specific curvature profile of male C. elegans vs. time during mating behavior from video sequence 4c. (Right) Specific curvature profile of zebrafish larvae escape response from green fish.
11. Rathi, Y., Vaswani, N., Tannenbaum, A., Yezzi, A.: Particle filtering for geometric active contours with application to tracking moving and deforming objects. In: CVPR. (2005)
12. Chan, T., Vese, L.: Active contours without edges. IEEE Trans. Image Processing 10(2) (2001) 266­277
13. Snyder, J.M., Kajiya, J.T.: Generative modeling: A symbolic system for geometric modeling. In: SIGGRAPH. (1992) 369­378
14. Bell, B.M., Cathey, F.W.: The iterated kalman filter update as a gauss-newton method. IEEE Trans. on Automatic Control 38(2) (1993) 294­297
15. Osher, S., Fedkiw, R.: Level Set Methods and Dynamic Implicit Surfaces. SpringerVerlag (2003)
16. Tsai, A., Yezzi, A., Wells, W., Tempany, C., Tucker, D., Fan, A., Grimson, W., Willsky, A.: Model-based curve evolution technique for image segmentation. In: CVPR. (2001)
17. van der Merwe, R., Wan, E.: Sigma-point kalman filters for probabilistic inference in dynamic state-space models. In: Proc. of the Workshop on Advances in Machine Learning. (2003)
18. Sibley, G., Sukhatme, G., Matthies, L.: The iterated sigma point kalman filter with applications to long range stereo. In: Robotics Science and Systems. (2006)
19. Fontaine, E., Lentink, D., Kranenbarg, S., Mller, U., van Leeuwen, J., Barr, A., Burdick, J.W.: Automated visual tracking for studying the ontogeny of zebrafish swimming. (submitted)
20. Blake, A., Isard, M.: Active Contours. Springer (1998) 21. MacCormick, J., Blake, A.: A probabilistic exclusion principle for tracking multiple
objects. In: ICCV. (1999) 22. van der Merwe, R., Wan, E.: Rebel:recursive bayesian estimation library.
http://choosh.bme.ogi.edu/rebel/ (2004) Matlab R Toolkit. 23. Khan, Z., Balch, T., Dellart, F.: A rao-blackwellized particle filter for eigentracking.
In: CVPR. (2004)

