An Evaluation of the DTEACh Robolab Summer Institute for 2004 ­ Assessment of Instructional and Hands-on Learning Correlated with MBTI types

Dan Jensen US Air Force Academy Dept of Engr Mechanics Dan.jensen@usafa.af.mil

Kris Wood & Rich Crawford Univ. of Texas, Austin Dept. of Mechanical Engr.

Kathleen Crowe Technology Coordinator Pflugerville Independent School District

1. Overview of the Institute During a 2 week period the summer of 2004, the University of Texas at Austin (UTA) hosted the DTEACh ROBOLAB Automation and Control Institute. The institute is sponsored by National Instruments; the maker of the ROBOLAB software. During the institute, a group of 28 K-12 teachers spent 2 weeks at UTA learning how they could integrate Lego® Mindstorm products, which are controlled by the ROBOLAB software, into their classrooms. Each K-12 teacher received a Lego® Mindstorm kit and the ROBOLAB software. Approximately ½ of the teachers had previous experience using ROBOLAB in their classrooms. One goal of the institute is to provide a way to integrate technology into K-12 classrooms in a manner that incorporates extensive active learning. The Lego Mindstorm framework provides an extensive hands-on environment for accomplishing this goal. The incorporation of hands-on, active learning techniques like this have been shown in the past to provide a tremendously enhanced learning environment 1-9.
Over the course of the two week institute, a series of building/programming projects were completed using the Legos® and ROBOLAB. These projects were arranged in order of increasing complexity and were normally done in teams of two. Typically, the projects were broken into three parts: 1) "lecture" time was devoted to introducing the hardware and software tools needed for that project, 2) the K-12 teachers worked on the "implementation" and 3) each team was given time to "demonstrate" their project and to share specific difficulties and successes. The content lectures (item 1 above) were given by UTA professors who have extensive knowledge in the area of design as well as with the Lego® products and the ROBOLAB software. The implementation (item 2 above) was facilitated by approximately seven Lego® / ROBOLAB experts who went from group to group helping to resolve special issues related to that project. Also, staff from National Instruments were there daily to ensure that logistics ran smoothly.
In addition, various "special lectures" were given by a number of experts. These lectures were intended to provide the K-12 teachers with additional resources for implementing this technology into their classrooms. Specifically, special lectures were given by personal from TUFTs University (on their extensive Lego® /ROBOLAB web site), by a Lego® representative and by a mentor K-12 teacher, Kathleen Crowe who has extensive knowledge regarding implementation of this technology into K-12 classrooms.
2. Assessment Plan Assessment was accomplished using surveys given at the end of each day. This daily survey had two parts. The first part asked the K-12 teachers to identify, in writing, the best and worst things

1

from that day's activities. The second part asked for quantitative responses to six questions. The first three questions covered instructional content and the last three covered laboratory content. Figure 1 below shows the 6 quantitative questions along with the numerical scale used in the rating.

Circle the number that best represents your answer to the following statements 0=disagree 1=very slightly agree 2=somewhat agree 3=mostly agree 4=totally agree

1) Today's instruction was clear.

01

2

3

4

2) Today's instruction was relevant.

01

2

3

4

3) Today's instruction was motivating.

01

2

3

4

4) Today's laboratory work was clear.

01

2

3

4

5) Today's laboratory work was relevant.

01

2

3

4

6) Today's laboratory work was motivating.

01

2

3

4

Figure 1 ­ Quantitative Section of Daily Survey

3. Assessment Results
3.1 Overall Assessment Results Overall results from the quantitative part of the daily surveys were extremely positive. As can be seen in Table 1 the average of all quantitative responses was 3.89 / 4.0. Recall that 4.0 indicates that responders "totally agree" with the statements (see Figure 1). Note from Figure 1 that the questions 1-3 relate to the "instruction" and questions 4-6 relate to the "laboratory" portion of the institute. Table 1 shows that, while both the instruction and laboratory portions received high ratings, the laboratories ratings were somewhat higher than those for the instruction. Although the differences in responses seem relatively minor (3.86 for the instruction and 3.92 for the laboratory) due to the large number of data points (>2000) and the small standard deviations, these differences in ranking lead to significant percentile ranking for these two different content areas. These percentile rankings assume a Gaussian distribution of the data. The average
"Proceedings of the 2005 American Society for Engineering Education Annual Conference & Exposition Copyright © 2005, American Society for Engineering Education"

instruction rating correlates to a 39th percentile rating (meaning that average instruction rating is better than 39 % of the total ratings) while the laboratory rating corresponds to a 61st percentile
ranking (meaning that average laboratory rating is better than 61 % of the total ratings). Another
interesting result can be seen by noting that question 2 and 5 have the highest ratings of the 6 questions at 71st percentile and 77th percentile respectively. As questions 2 and 5 are both related
to the "relevancy" of the content, it appears that the relevancy of both the instruction and the labs
is clearly seen by the participants. Note that the lowest percentile is for question 1 which relates to the clarity of the instruction. Although this percentile rating is low (20th percentile) recall that
the actual rating still has an average of 3.79 indicating that, although they rated this category
below the others, participants still "mostly agreed / totally agreed" that the instruction was clear.

Table 1 - Overview of the Quantitative Assessment Results from the Daily Survey

Q1 Q2 Q3 Q4 Q5 Q6 Avg. Q1-3 Avg. Q4-6 Avg. Q1-6

Overall Average (all days) 3.79 3.95 3.83 3.87 3.97 3.91

3.86

3.92

3.89

Std Dev (all days)

0.18 0.04 0.13 0.17 0.05 0.09

0.12

0.10

0.11

# Std Devs off Avg.

0.56 -0.53 -0.16 0.72 0.25 -0.27 0.27

0.00

0.00

Percentiles

20 71 30 44 77 60

39

61 50

3.2 Quantitative Assessment Corresponding to Different MBTI Types
In an attempt to determine if the ROBOLAB Institute's content and presentation are effective
across different personality types, we have correlated the assessment data with different
personality types. In order to accomplish this, we have used the Myers Briggs Type Indicator (MBTI)10, 11. MBTI types have been used extensively in the psychological field to provide insight into how an individual prefers to interact with their environment 12. More recently, the MBTI type has been used in educational research to provide insight into how people learn 13, 14.
The goal is to create a learning environment that facilitates effective learning for all MBTI types.
Figure 2 below gives an overview of the MBTI designations.

Manner in Which a Person Interacts With Others

E Focuses outwardly. Gains energy from others. Focuses inwardly. Gains energy from cognition I

EXTROVERSION

INTROVERSION

Manner in Which a Person Processes Information

S

Focus is on the five senses and experience.

Focus is on possibilities, use, big picture. N

SENSING

INTUITION

Manner in Which a Person Evaluates Information

T Focuses on objective facts and causes & effect. Focuses on subjective meaning and values. F

THINKING

FEELING

Manner in Which a Person Comes to Conclusions

J

Focus is on timely, planned decisions.

Focus on process oriented decision-making. P

JUDGEMENT

PERCEPTION

Figure 2: Overview of MBTI

"Proceedings of the 2005 American Society for Engineering Education Annual Conference & Exposition Copyright © 2005, American Society for Engineering Education"

Tables 2 and 3 show the quantitative rankings (Table 2) and associated percentiles (Table 3) when they are broken down by MBTI types. Recall that there are four designation letters per MBTI type: I vs. E, S vs. N, T vs. F, and P vs. J. Quantitative ratings are tabulated separately for each of the two letter options.

Table 2 ­ Rankings Categorized by MBTI Type

Q1 Q2 Q3 Q4 Q5 Q6 avg 1-3

avg 4-6

avg

Type-I 3.79 3.94 3.80 3.85 3.95 3.94

3.84

3.92

3.88

Type-E 3.79 3.97 3.88 3.89 3.98 3.87

3.88

3.91

3.90

Type-N 3.81 3.97 3.88 3.90 3.97 3.95

3.89

3.94

3.91

Type-S 3.74 3.90 3.70 3.80 3.95 3.82

3.78

3.85

3.82

Type-F 3.81 3.95 3.87 3.87 3.98 3.91

3.88

3.92

3.90

Type-T 3.77 3.94 3.77 3.86 3.95 3.91

3.82

3.91

3.87

Type-J 3.82 3.95 3.82 3.86 3.97 3.91

3.86

3.91

3.89

Type-P 3.70 3.95 3.85 3.89 3.96 3.92

3.84

3.92

3.88

0=disagree 1=very slightly agree 2=somewhat agree 3=mostly agree 4=totally agree

Q1 = Today's instruction was clear.

Q2 = Today's instruction was relevant.

Q3 = Today's instruction was motivating.

Q4 = Today's laboratory work was clear.

Q5 = Today's laboratory work was relevant.

Q6 = Today's laboratory work was motivating.

Table 3 ­ Percentile Ranking Categorized by MBTI Type

Q1 Q2 Q3 Q4 Q5 Q6

Type-I

20 67 21 38 73 70

Type-E 20 77 47 52 81 43

Type-N 25 76 47 54 78 72

Type-S 10 77 5 31 73 26

Type-F 25 73 42 44 79 59

Type-T 24 67 24 42 71 60

Type-J 27 72 26 41 77 60

Type-P 5 72 39 53 76 61

Q1 = Today's instruction was clear.

Q2 = Today's instruction was relevant.

Q3 = Today's instruction was motivating.

Q4 = Today's laboratory work was clear.

Q5 = Today's laboratory work was relevant.

Q6 = Today's laboratory work was motivating.

avg 1-3 34.00 44.00 50.00 18.00 47.00 28.00 41.00 33.00

avg 4-6 61.00 60.00 68.00 39.00 62.00 48.00 60.00 64.00

avg 48.00 54.00 59.00 27.00 54.00 43.00 50.00 48.00

The correlations between MBTI types and ratings for the different questions provide some surprising results. In this light, it may prove helpful to provide a slightly more detailed

"Proceedings of the 2005 American Society for Engineering Education Annual Conference & Exposition Copyright © 2005, American Society for Engineering Education"

description of some of the characteristics of the instruction and the laboratories. First, it is noteworthy that this content is quite challenging. It was not uncommon for participants to need considerable assistance from the institute staff in order to successfully complete a project. Second, the instruction involved a good deal of interaction. Participants were constantly asking and being asked questions regarding their understanding and implementation of the concepts being covered. Participants also interacted with each other often during the instruction periods. Finally, the laboratories consisted of a combination of hands-on Lego® building and ROBOLAB programming. The programming portion required extensive abstract thought process.
With these facts in mind, comparing the Type-I and Type-E rows in Tables 2 and 3 a number of observations can be made. First, note again that the overall ratings are very good (3.88 for TypeI and 3.90 for Type-E). Of particular note are the large differences in percentile ratings for Type-I and Type-E for question 3 and 6. Type-I rates the motivation derived from the instruction in the 21st percentile. This is considerably lower than the Type-E rating of 47th percentile for the same question. Normally, one would expect that introverts (Type-I) would prefer an instructional environment where interaction is not required. However, we propose that the Type-I rated this lower due to considerable interaction inherent in our instructional environment. Next note that the Type-E rated the motivation provided by the laboratory (43rd percentile for question 6) considerably lower than the Type-I rating (70th percentile). We postulate that this is due to the fact that the difficulty of the tasks involved necessitated very focused communication between partners in the lab. This focused communication is more difficult for Type-E than for Type-I.
Comparison of the Type-S and Type-N data in Tables 2 and 3 shows that the Type ­S ratings for the clarity and motivation associated with the instruction is low (10th percentile and 5th percentile respectively for questions 1 and 3). This is an expected result as Type-S tends to learn best in a hands-on environment. What is unexpected is the low rating Type-S gives to the motivation derived from the laboratory content (26th percentile for question 6). Possibly this is due to the difficulty of the tasks and the resulting frustration from the significant effort required for success. The sensor types (Type-S) may have assumed that since they prefer hands-on and are normally competent in that area that they would experience relatively painless success. Many of the TypeS participants communicated frustration when time ran out before a task could be completed.
When comparing Type-F and Type-T, one result that stands out is the low rating that Type-T gives to motivation derived for the instruction. Type-T rating is 24th percentile while Type-F ratings were 42nd percentile. This is likely due to the fact that sometime the instructional content was not presented in a step-by-step manner. Type-Ts prefer to think and learn in this procedural manner. Comments from participants indicating this were especially prevalent when the content involved learning programming. A number of times the participants specifically asked for a more procedural approach to this content. Evaluation of the Type J and Type P rows reveals that the most significant difference is with respect to question 1: clarity of instruction. The Type-P rates this content in the 5th percentile while the Type-J rates it in the 27th percentile. Keeping in mind that the actual rating by the Type-P for question 1 is 3.70 (which correlates to mostly/totally agree that the instruction is clear), the 5th percentile rating is the lowest percentile rating that occurred. This is most likely due to the fact that Type-Ps prefer to have a complete set of data before proceeding in a decision making or learning process. The instruction in the
"Proceedings of the 2005 American Society for Engineering Education Annual Conference & Exposition Copyright © 2005, American Society for Engineering Education"

ROBOLAB institute was intentionally brief enough that not all the relevant questions were answered during the instruction time. It was assumed that part of the learning would take place during the laboratory portion of the project. This process is intrinsically frustrating to the TypeP. This prognosis is bolstered by the fact that the Type-Ts had the lowest occurrence of positive written feedback regarding their accomplishments of all the MBTI Types.

3.3 Written Assessment Corresponding to Different MBTI Types Along with the quantitative portion of the daily surveys, written feedback was also requested. Specifically, participants were asked to record the best and worst parts of the institute for that particular day. These written comments were compiled and were grouped into a number of common areas. These areas can be thought of as "features of the Institute" that participants were inclined to write comments for. These features include:
· Information Technology (IT), · Hands-on content or building (HO/Build), · Time related issues like sufficient time to complete a task (time), · Teamwork including sharing of ideas and project results (Team) · Help from the Institute staff (Help) · Successful accomplishment of a project (Accomplishment) · Content that helped participants plan for implementation back in the K-12 classes
(Implementation).

The percentage of participants of a certain MBTI letter who made a positive comment regarding that particular area were tabulated. If a participant made a negative comment regarding a particular area, that comment was considered to cancel one of the positive comments. These results are shown in Table 4.

Table 4 ­ Percentages of Participants Providing Positive Written Comments

on a Particular Feature of the Institute

IT HO/BUILD TIME TEAMS HELP ACCOMPLISHMENT IMPLEMENTATION Average

Type-E 26 14 10 33 16

14

11 18

Type-I 17

22

-2 28 16

12

15 16

Type-N 20

19

3 28 13

10

11 15

Type-S 22

18

2 35 24

22

20 21

Type-F 18

20

3 30 18

15

10 16

Type-T 24

17

3 29 13

10

19 16

Type-J 20

21

2 33 17

17

17 18

Type-P 22

12

4 20 12

2

4 11

Average 21

18

3 29 16

13

14 16

Although there is no specific evidence that the number of positive or negative comments made by participants is a good measure of the effectiveness of a particular type of comment, because the participants were specifically asked for a "best" and "worst" part of that day's content, there is likely some correlation to content effectiveness. Note first that the content feature that received the most positive comments was the "Team" aspect. This included opportunities to work on programming, Lego Construction as well as demonstrating the finished product to the group. The area that received the least number of positive comments was "Time". A large

"Proceedings of the 2005 American Society for Engineering Education Annual Conference & Exposition Copyright © 2005, American Society for Engineering Education"

number of people expressed frustration at the inability to complete a project due to time constraints.
In terms of the MBTI breakout of the data, note that the Type-S has the highest average for positive comments at 21. As this entire institute is based on hands-on implementation of the Lego Mindstorm and Robolab, this results is not surprising. As can be seen by the Type-S's 22 positive comments regarding "accomplishment and their 20 positive comments regarding "Implementation", they felt a significant sense of accomplishment from the projects and believed that they were going to be able to implement this material in their own classes. The N-types did not express this same level of certainty regarding these issues (10 positive responses for "accomplishment" and 11 for "Implementation"). Notice from Table 2 that the Type-N rated the content more highly (3.91) than did the Type-S (3.82), from the comments summarized in Table 4, it appears that they did not perceive sense of accomplishment or believe that implementation was workable at the level that the Type-S did.
4. Conclusions and Recommendations
Two critical goals for the institute were 1) to communicate the content effectively and 2) to communicate it well to all learning styles (in this case represented by different MBTI types). With respect to the first goal, the ratings as shown in Table 2 along with the preponderance of written comments show demonstrate the overall effectiveness of the institute. Overall the participants gave the content (instruction and laboratory) a 3.9 / 4.0. Positive written comments (Table 4) outnumbered negative ones in 55 out of 56 cases; the only exception being the type-I comments regarding not having sufficient time to accomplish a task. In terms of our second goal, these positive comments outnumbered the negative comments for all MBTI types, with the single exception mentioned above. Although there were significant differences in the responses from different MBTI types (see Tables 2-4), in general all types rated the material highly and believed that were benefiting from it.
Several recommendations come from this work. From Table 3 we see that all MBTI types indicate that there is potential to increase the clarity and motivational nature of the instruction. In addition, from table 4, it appears that a significant number of participants believed that additional time was needed to complete the tasks. MBTI specific recommendations include adding hands-on content to the lectures in order to increase the Type-S rating for motivation. This should be done while keeping the significant interactive parts of the lectures so that the high ratings for the Type-E does not decline.
Biographical Information
DR. DAN JENSEN is a Professor of Engineering Mechanics at the U.S. Air Force Academy. He received his B.S., M.S. and Ph.D. from the University of Colorado at Boulder. He has worked for Texas Instruments, Lockheed Martin, NASA, University of the Pacific, Lawrence Berkeley National Lab and MacNeal-Schwendler Corp. His research includes development of innovative design methodologies and enhancement of engineering education.
DR. KRISTIN WOOD is the Cullen Trust Endowed Professor in Engineering at The University of Texas, Department of Mechanical Engineering. The objective of his research is to develop design strategies,
"Proceedings of the 2005 American Society for Engineering Education Annual Conference & Exposition Copyright © 2005, American Society for Engineering Education"

representations, and languages that will result in more comprehensive design tools, innovative manufacturing techniques, and design teaching aids at the college, pre-college, and industrial levels.
DR. RICHARD H. CRAWFORD is a Professor of Mechanical Engineering and Director of the Design Projects Program at The University of Texas at Austin. His research interests include a broad range of topics in computeraided mechanical design, design theory and methodology, and solid freeform fabrication.
REFERENCES 1. Bonwell, C.C. Active Learning and Learning Styles. in Active Learning Workshops Conference, Content
available at http://www.active-learning-site.com/vark.htm. 1998. 2. Borchert, R., D.D. Jensen, and D. Yates. Hands-on and Visualization Modules for Enhancement of
Learning in Mechanics: Development and Assessment in the Context of Myers Briggs Types and VARK Learning Styles. in Proceedings of the ASEE Annual Conference and Exposition. 1999. Charlotte, NC. 3. Catalano, G.D. and K.L. Tonso, The Sunrayce '95 Idea: Adding Hands-on Design to an Engineering Curriculum. Journal of Engineering Education, 1996: p. 193-199. 4. Jensen, D.D. and M. Bowe. Hands-On Experiences to Enhance Learning of Design: Effectiveness in a Reverse Engineering / Redesign Context When Correlated with MBTI and VARK Types. in Proceedings of the ASEE Annual Conference and Exposition. 1999. Charlotte, NC. 5. Jensen, D.D., J.J. Wood, and K.L. Wood, Hands-on Activities, Interactive Multimedia and Improved Team Dynamics for Enhancing Mechanical Engineering Curricula. International Journal of Engineering Education, 2003. 19(No. 6): p. 874-884. 6. Kresta, S.M., Hands-on Demonstrations: An Alternative to Full Scale Lab Experiments. Journal of Engineering Education, 1998: p. 7-9. 7. Self, B., J.J. Wood, and D. Hansen. Teaching Undergraduate Kinetics Using Lego® Mindstorms Race Car Competition. in Proceedings of the ASEE Annual Conference and Exposition. 2004. Salt Lake City, UT. 8. Wood, J.J., et al., Enhancing Machine Design by Creating a Basic Hands-On Environment with Mechanical Breadboards. International Journal of Mechanical Engineering Education, 2001. 9. Wood, J.J. and K.L. Wood. The Tinkerer's Pendulum for Machine System's Education: Creating a Basic Hands-On Environment with Mechanical Breadboards. in Proceedings of the ASEE Annual Conference and Exposition. 2000. St. Louis, MO. 10. URL, Human Metrics - Jung Myers Briggs Typology, www.humanmerics.com. 2005. 11. Jung, C.G., Psychological Types, Volume 6 of the Collected Works of C.G. Jung. 1971, Princeton University Press. 12. McCaulley, M.H., Psychological Types in Engineering: Implications for Teaching. Journal of Engineering Education, 1976. 66(7): p. 729-736. 13. McCaulley, M.H., The MBTI and Individual Pathways in Engineering Design. Engineering Education, 1990. 80: p. 537-542. 14. Jensen, D.D. and K.L. Wood. Incorporating Learning Styles to Enhance Mechanical Engineering Curricula by Restructuring Courses, Increasing Hands-on Activities, & Improving Team Dynamics. in ASME Publication and Presentation for the Award for the Most Innovative Curriculum for the Year 2000, Presented at the ASME Annual Conference. 2000. Orlando, FL.
"Proceedings of the 2005 American Society for Engineering Education Annual Conference & Exposition Copyright © 2005, American Society for Engineering Education"

