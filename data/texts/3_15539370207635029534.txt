Path-Adaptive A* for Incremental Heuristic Search in Unknown Terrain∗

Carlos Hern´andez

Departamento de Ingenier´ıa Inform´atica

Pedro Meseguer
Institut d’Investigaci´o

Universidad Cat´olica de la Ssma. Concepci´on

en Intel.lig`encia Artiﬁcial, CSIC

Concepci´on, Chile
chernan@ucsc.cl

Campus UAB, 08193 Bellaterra, Spain

pedro@iiia.csic.es

Xiaoxun Sun Sven Koenig

Computer Science Department
University of Southern California
Los Angeles, CA 90089-0781, USA

{xiaoxuns,skoenig}@usc.edu

Abstract

Adaptive A* is an incremental version of A* that up-
dates the h-values of the previous A* search to make
them more informed and thus future A* searches more
focused. In this paper, we show how the A* searches
performed by Adaptive A* can reuse part of the path
of the previous search and terminate before they ex-
pand a goal state, resulting in Path-Adaptive A*. We
demonstrate experimentally that Path-Adaptive A* ex-
pands fewer states per search and runs faster than Adap-
tive A* when solving path-planning problems in ini-
tially unknown terrain.

Introduction

Consider agents that have to navigate from given start co-
ordinates to given goal coordinates in initially unknown ter-
rain and can sense obstacles only around themselves, such as
computer-controlled characters in real-time computer games
(Bulitko and Lee 2006) and robots (Stentz 1994). Plan-
ning with the freespace assumption is a popular approach
to solve such tasks (Koenig, Tovey, and Smirnov 2003): The
agent repeatedly ﬁnds and then follows a cost-minimal un-
blocked path from its current coordinates to the goal coordi-
nates, taking into account the obstacles that it has sensed al-
ready but assuming that no additional obstacles are present.
It repeats the process when it senses obstacles on its path
while it follows the path. Thus, the agent has to search re-
peatedly. Incremental search can be used to speed up these
similar searches. Adaptive A*, for example, is an incremen-
tal version of A* that updates the h-values of the previous

∗We would like to thank Nathan Sturtevant from the Univer-
sity of Alberta for making maps from World of Warcraft available
to us. This material is based upon work supported by, or in part
by, projects under contract TIN2006-15387-C03-01 and Fondecyt-
Chile #11080063, the U.S. Army Research Laboratory and the U.S.
Army Research Ofﬁce under contract W911NF-08-1-0468 and by
NSF under contract 0413196. The views and conclusions con-
tained in this document are those of the authors and should not
be interpreted as representing the ofﬁcial policies, either expressed
or implied, of the sponsoring organizations, agencies, companies
or the U.S. government.
Copyright c° 2009, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

A* search to make them more informed and thus future A*
searches more focused (Koenig and Likhachev 2005). Our
key observation is that part of the current cost-minimal path
remains cost-minimal when the agent senses obstacles on
the path, namely the obstacle-free sufﬁx of the path. We
show how the next A* search can reuse this part of the
path and terminate before it expands a goal state, resulting
in Path-Adaptive A*. We demonstrate experimentally that
Path-Adaptive A* expands fewer states per search and runs
faster than Adaptive A* when solving navigation problems
in initially unknown terrain.

Notation

S is the ﬁnite set of states (vertices). A ⊂ S × S is the ﬁnite
set of actions (edges). Executing action a = (s, s′) moves
from state s ∈ S to state s′ ∈ S with cost c(s, s′) > 0.
Succ(s) := {s′ ∈ S|(s, s′) ∈ A} is the set of succes-
sor states of state s ∈ S. Assume that we are given a
cost-minimal path Path(s0, sn) = (s0, . . . , sn) from state
s0 ∈ S to state sn ∈ S. Then, nextstate(si) = si+1 is
the state after state si on the path. (nextstate(sn) = null.)
backstate(si) = si−1 is the state before state si on the path.
(backstate(s0) = null.) We also use the standard terminol-
ogy and notation from A* (Pearl 1985). In addition, d(s, s′)
denotes the cost of a cost-minimal path from state s ∈ S to
state s′ ∈ S. H(s, s′) denotes the user-provided H-value,
a lower approximation of d(s, s′) that satisﬁes the triangle
inequality.

For our application, the states correspond to the cells of a
gridworld. The agent always senses whether the adjacent
cells in the main four compass directions are blocked. The
actions correspond to moving from a cell to an adjacent cell
in the main four compass directions. The cost is inﬁnity if
at least one cell is known to be blocked and one otherwise.
The h-values H(s, s′) are the Manhattan distances. sstart de-
notes the initial cell of the agent (and is updated as the agent
moves) and sgoal denotes its goal cell.

Adaptive A*

Adaptive A* (AA*) is an incremental version of A*, based
on a principle ﬁrst described in (Holte et al. 1996), that
solves a series of searches in the same state space with

sgoal

sstart

sstart

s'start

S’

p

r

s’start

p’=nextstate(p)

sgoal

x

sstart

s’start

x

s’start

Figure 1: Top-left:
the agent follows Path(sstart, sgoal);
is at s′
top-right:
the agent
start when it discovers that
Path(sstart, sgoal) is blocked; bottom-left: the agent performs
an A* search until it expands state x ∈ Path(sstart, sgoal);
bottom-right: the agent follows Path(s′
start, sgoal), the con-
catenation of Path(s′

start, x) and Path(x, sgoal).

the same goal state potentially faster than A* (Koenig and
Likhachev 2005). The start state can change and the costs
of one or more actions can increase from search to search.
AA* with the initial h-values h(s) := H(s, sgoal) ﬁnds cost-
minimal paths. AA* performs standard A* searches but up-
dates the h-values after an A* search to make them more
informed and thus future A* searches more focused. As-
sume, for example, that AA* performed an A* search from
state sstart to state sgoal. It then updates the h-values of all
states s expanded during the A* search (that is, the states in
the closed list) by assigning h(s) := f (sgoal) − g(s). The
updated h-values again satisfy the triangle inequality.

Path-Adaptive A*

Path-Adaptive A* (Path-AA*) applies AA* to solve navi-
gation problems in initially unknown terrain using planning
with the freespace assumption. The agent repeatedly ﬁnds
and then follows a cost-minimal path from its current state
to the goal state. If the agent senses that the cost of at least
one action on the path increased while it follows the path,
then it repeats the process. Our key observation is that part
of its path remains a cost-minimal path, namely the sufﬁx
of the path without action cost changes. The A* searches
of Path-AA* reuse this part of the path and thus terminate
before they expand a goal state.

Formally, we deﬁne the reusable path as follows: Assume
that the agent follows Path(sstart, sgoal) and is at s′
start when
it discovers that the cost of at least one action on the path in-
creased. Assume that the cost of action (s, r) on the path
increased but the costs of no actions on Path(r, sgoal) in-
creased. Then, Path(r, sgoal) is the reusable path.

Figure 2: Optimized tie breaking.

the A* search from state s′
start to state x and the part of the
reusable path from state x to state sgoal, see Figure 1. It then
updates the h-values of all states s expanded during the A*
search by assigning h(s) := f (x) − g(s).

Path-AA* is correct: Consider a state s that is on a cost-
minimal path from sstart to sgoal found during a previous
A* search. That A* search expanded state s and AA*
thus updated its h-value to h(s) = f (sgoal) − g(s) =
d(sstart, sgoal) − d(sstart, s) = d(s, sgoal). Both states x and
x′ are on a cost-minimal path found during a previous A*
search. Now assume that the current A* search from s′
start
to sgoal is about to expand state x with f-value f (x).
It
holds that f (x) = g(x) + h(x) = g(x) + d(x, sgoal) =
g(x) + d(x, x′) + d(x′, sgoal) = g(x′) + h(x′) = f (x′). The
sequence of f-values of the states expanded by an A* search
with h-values that satisfy the triangle inequality is monoton-
ically non-decreasing (Pearl 1985). Thus, the A* search can
expand state x′ next with f-value f (x′) = f (x). By induc-
tion, it can expand all states on the reusable path from x to
sgoal in sequence and would terminate when it is about to
expand state sgoal with f-value f (sgoal) = f (x). AA* would
then update the h-values of the expanded states s on the
reusable path from x to sgoal by assigning h(s) := d(x, sgoal)
since these states are again on a cost-minimal path. This up-
date would not change their h-values and thus could be omit-
ted. AA* would update the h-values of all other expanded
states s by assigning h(s) := f (sgoal) − g(s) = f (x) − g(s),
resulting in exactly the operations performed by Path-AA*.

Optimization of Tie Breaking

How the A* searches performed by Path-AA* break ties
among states with the same f-value determines how many
states they expand and thus how fast they are. Our objec-
tive is to make them expand a state on the reusable path
as quickly as possible. The ﬁrst A* search of Path-AA*
breaks ties in favor of larger g-values, which is known
to be a good tie-breaking strategy for A*. The follow-
ing A* searches break ties in favor of states s whose es-
timated distance ed(s) to the reusable path is smallest, as
given by the user-provided H-values. Path-AA* initially
sets p := r and p′ := nextstate(p). It then computes the
estimated distance ed(s) := min(H(s, p), H(s, p′)) and, if
H(s, p) > H(s, p′), advances p and p′ by assigning p := p′
and p′ := nextstate(p), see Figure 2.

When the next A* search is about to expand a state x on the
reusable path Path(r, sgoal) it terminates. Path-AA* updates
the cost-minimal path by concatenating the path found by

Figure 3 shows an example that illustrates the advantage of
breaking ties using our optimization over breaking ties in fa-
vor of larger g-values. The agent started in cell C1 and then

A

B

C

A

B

C

2

6

1

5

2

6

1

5

1

2

3

4

5

6

2

6

1

5

8

6

0

4

8

3

8

4

8

5

5

2

4

6

4

4

6

3

3

4

2

3

6

4

2

6

5

1

             Path-AA* 

8

6

6

8 6

2

6 5

1

6 6

0

1

2

3

4

5

6

2

6

1

8

4

5

6

0

3

4

8

3

4

5

6

2

4

3

4

2

8

4

3

4

6

3

2

3

4

2

8

2

6

4

2

1

6

0

       Path-AA*-opt 

6

2

 

 

 

Figure 3: Tie breaking example.

moved to cell C2, the goal state is in cell C6 and the reusable
path is shown as a dashed arrow. Every cell generated by the
A* search has its g-value in the upper-left corner, h-value
in the lower-left corner and f-value in the upper-right cor-
ner. Expanded cells are shaded. The path found by the A*
search is shown as a solid arrow. When ties are broken us-
ing our optimization, every cell generated by the A* search
has its ed-value in the lower right corner. p is set to cell C4
and never advanced. The A* search expands two cells fewer
when breaking ties using our optimization.

Pseudocode of Path-Adaptive A*

Figure 4 shows the pseudocode of Path-AA* without the op-
timization of tie breaking. This version of Path-AA* extends
the lazy version of AA* (Sun, Koenig, and Yeoh 2008), that
updates the h-value of a state only when it is needed dur-
ing a future A* search (Koenig and Likhachev 2006a). We
use this version of Path-AA* since it ran faster in our ex-
periments than the version of Path-AA* that extends the ea-
ger version of AA*, that updates the h-value of a state after
the A* search that expanded the state (as described before).
Procedure InitializeState updates the h-value of a state, and
procedure ComputePath performs an A* search from sstart to
sgoal. We modiﬁed the pseudocode of AA* as follows: Com-
putePath now terminates when it expands sgoal or a state x on
the reusable path Path(r, sgoal) (line 25). In the latter case,
it ﬁrst calls procedure CleanPath to remove Path(r, x) from
the cost-minimal path to yield Path(x, sgoal) (line 27) and
then procedure MakePath to obtain the cost-minimal path
Path(sstart, x) found by the A* search (line 28). The new
cost-minimal path Path(sstart, sgoal) is then the concatena-
tion of Path(sstart, x) and Path(x, sgoal). In procedure Main,
the agent repeatedly moves from sstart to nextstate(sstart)
along the cost-minimal path (line 53). If the costs of one
or more actions on the cost-minimal path increase, then the
cost-minimal path is shortened (lines 55-57) and the proce-
dure repeats.

Experimental Evaluation

We performed experiments in empty gridworlds in which we
blocked randomly chosen cells (see Figure 5 left), acyclic
mazes whose corridor structure was generated by depth-
ﬁrst search with random tie-breaking (see Figure 5 center),
cyclic mazes that resulted from acyclic mazes in which we
unblocked randomly chosen blocked cells and two maps

if g(s) + h(s) < pathcost(search(s))

h(s) := pathcost(search(s)) − g(s);

g(s) := ∞;

1 procedure InitializeState(s)
2 if search(s) = 0
h(s) := H(s, sgoal);
3
4
g(s) := ∞;
5 else if search(s) 6= counter
6
7
8
9 search(s) := counter;
10 procedure MakePath(s)
11 while s 6= sstart
saux := s;
12
s := parent(s);
13
nextstate(s) := saux;
14
15
backstate(saux) := s;
16 procedure CleanPath(s)
17 while backstate(s) 6= null
18
saux := backstate(s);
backstate(s) := null;
19
nextstate(saux) := null;
20
21
s := saux;
22 procedure ComputePath()
23 while OPEN 6= ∅
24
25
26
27
28
29
30
31
32
33
34
35
36
37 return false;
38 procedure Main()
39 counter := 1;
40 for all s ∈ S
41
42
43
44 while sstart 6= sgoal
45
46
47
48
49
50
51
52
53
54
55
56
57
58

search(s) := 0;
nextstate(s) := null;
backstate(s) := null;

counter := counter + 1;

while nextstate(s) 6= null

if backstate(s′) = s

CleanPath(s′);

delete a state s with the smallest f-value g(s) + h(s) from OPEN;
if s = sgoal or nextstate(s) 6= null

pathcost(counter) := g(s) + h(s);
CleanPath(s);
MakePath(s);
return true;

for all s′ ∈ Succ(s)
InitializeState(s′);
if g(s′) > g(s) + c(s, a)

g(s′) := g(s) + c(s, s′);
parent(s′) := s;
if s′ is in OPEN then delete it from OPEN;
insert s′ into OPEN with f-value g(s′) + h(s′);

InitializeState(sstart);
InitializeState(sgoal);
g(sstart) := 0;
OPEN := ∅;
insert sstart into OPEN with f-value g(sstart) + h(sstart);
if ComputePath() = false

return “goal is not reachable”;

sstart := nextstate(sstart);
update the increased action costs (if any);
for all increased action costs c(s, s′)

Figure 4: Path-Adaptive A*.

adapted from World of Warcraft with 10,280 and 309,600
unblocked cells, respectively (see Figure 5 right) (Koenig
and Sun 2008; Sun, Koenig, and Yeoh 2008). We chose the
start and goal cells randomly and averaged over 2,000 grid-
worlds of each kind.

Table 1 shows our results for AA*, Path-AA* (which
breaks ties in favor of larger g-values), Path-AA*-opt (which
breaks ties using our optimization) and D*Lite (Koenig and
Likhachev 2002) on a LINUX PC with a Pentium Core Duo
CPU. All runtimes are reported in milliseconds. Path-AA*
was faster than AA* in every case (with respect to total
search time per test case, search time per search episode,
cell expansions per test case and cell expansions per search
episode), and Path-AA*-opt was faster than Path-AA* (with
respect to the same criteria). In quite a few cases, Path-AA*
and Path-AA*-opt were even faster than D* Lite (Koenig
and Likhachev 2002), an alternative state-of-the-art algo-
rithm.

AA*
Path-AA*
Path-AA*-opt
D* Lite

AA*
Path-AA*
Path-AA*-opt
D* Lite

AA*
Path-AA*
Path-AA*-opt
D* Lite

AA*
Path-AA*
Path-AA*-opt
D* Lite

(a)
(f)
200 × 200 Gridworlds with 20% Blocked Cells

(d)

(e)

(b)

(c)

0.5
0.3
0.2
1.1

33.0
33.0
34.0
34.0

0.016
0.009
0.007
0.031

2,777.8
1,360.0
1,003.0
4,648.9

170.0
84.2
170.0
41.2
29.5
174.0
175.0
136.7
1000 × 1000 Gridworlds with 20% Blocked Cells
869.0
400.8
869.0
170.3
108.7
893.0
888.0
702.4

66,938.5
28,445.1
18,592.0
120,118.2

167.0
167.0
171.0
171.0

0.151
0.056
0.034
0.269

25.2
9.4
5.8
46.0

151 × 151 Acyclic Mazes

1735.0
1738.0
1712.0
1659.0

136.0
136.0
137.0
136.0

16.3
6.8
4.0
6.7

1.2
0.7
0.6
1.4

678.0
680.0
673.0
561.0

0.024
0.010
0.006
0.012

112,435.9
50,725.1
31,429.1
28,952.1

130 × 130 Game Maps

37.0
37.0
38.0
38.0

0.033
0.018
0.017
0.037

7,337.1
4,067.7
3,765.8
6,913.4

165.8
74.6
46.7
51.6

198.3
109.9
99.1
181.9

200 × 200 Gridworlds with 40% Blocked Cells

(a)

(b)

1,511.0
1,512.0
1,501.0
1,515.0

26.2
13.1
8.2
12.3

(c)

386.0
386.0
390.0
396.0

(d)

0.068
0.034
0.021
0.031

(e)

162,956.3
88,788.9
58,383.0
52,395.4

(f)

422.2
230.0
149.7
132.3

1000 × 1000 Gridworlds with 40% Blocked Cells

0.598
0.194
0.077
0.087

1,969.8
638.1
256.9
295.0

3,294.0
3,289.0
3,336.0
3,391.0

12,799.0
2,242.3
12,791.0
864.2
12,705.0
436.9
257.7
12,862.0
151 × 151 Cyclic Mazes with 150 Blocked Cells Removed
324.7
5,904.0
120.6
5,916.0
80.9
5,844.0
5,738.0
46.9

7,386,199.9
2,842,248.5
1,457,498.4
873,869.4

594,910.9
221,338.3
147,561.6
84,088.0

1,832.0
1,835.0
1,824.0
1,794.0

0.047
0.016
0.010
0.011

86.1
29.4
18.2
19.7

676 × 676 Game Maps

941.0
942.0
946.0
979.0

51.1
25.7
23.2
46.0

273.0
273.0
294.0
295.0

0.187
0.094
0.079
0.156

208,528.8
117,862.2
107,986.2
174,175.7

763.8
431.7
367.3
590.4

(a) = agent moves until the goal is reached per test case; (b) = total search time per test case (in milliseconds); (c) = search episodes per test case;

(d) = time per search episode (in milliseconds); (e) = total cell expansions per test case; (f) = cell expansions per search episode

Table 1: Experimental results.

A graph oriented approach. Artiﬁcial Intelligence 85(1–
2):321–361.
Koenig, S., and Likhachev, M. 2002. D* Lite.
In Pro-
ceedings of the AAAI Conference of Artiﬁcial Intelligence,
476–483.
Koenig, S., and Likhachev, M. 2005. Adaptive A*. In Pro-
ceedings of of the International Joint Conference on Au-
tonomous Agents and Multiagent Systems, 1311–1312.
Koenig, S., and Likhachev, M. 2006a. A new principle
for incremental heuristic search: Theoretical results [poster
abstract]. In Proceedings of the International Conference
on Automated Planning and Scheduling, 402–405.
Koenig, S., and Likhachev, M. 2006b. Real-Time Adaptive
A*. In Proceedings of of the International Joint Conference
on Autonomous Agents and Multiagent Systems, 281–288.
Koenig, S., and Sun, X. 2008. Comparing real-time and
incremental heuristic search for real-time situated agents.
Journal of Autonomous Agents and Multi-Agent Systems
18(3):313–341.
Koenig, S.; Tovey, C.; and Smirnov, Y. 2003. Performance
bounds for planning in unknown terrain. Artiﬁcial Intelli-
gence 147:253–279.
Pearl, J. 1985. Heuristics: Intelligent Search Strategies for
Computer Problem Solving. Addison-Wesley.
Stentz, A. 1994. Optimal and efﬁcient path planning for
partially-known environments. In Proceedings of the Inter-
national Conference on Robotics and Automation, 3310–
3317.
Sun, X.; Yeoh, W.; Chen, P.; and Koenig, S. 2009. Sim-
ple optimization techniques for A*-based search. In Pro-
ceedings of of the International Joint Conference on Au-
tonomous Agents and Multiagent Systems, 931–936.
Sun, X.; Koenig, S.; and Yeoh, W. 2008. Generalized
Adaptive A*. In Proceedings of of the International Joint
Conference on Autonomous Agents and Multiagent Sys-
tems, 469–476.

Figure 5: Gridworlds used in the experimental evaluation.

Conclusions and Future Work

In this paper, we showed how the A* searches performed
by Adaptive A* can reuse part of the path of the previous
search and terminate before they expand a goal state, re-
sulting in Path-Adaptive A*. We also developed a good
strategy for breaking ties among states with the same f-
value. Finally, we demonstrated experimentally that Path-
Adaptive A* expands fewer states per search and runs faster
than Adaptive A* when solving path-planning problems in
initially unknown terrain.
It is future work to combine
Path-Adaptive A* with recent optimization techniques for
Adaptive A* (Sun et al. 2009) to speed it up even fur-
ther and to apply the ideas behind Path-Adaptive A* to
real-time search algorithms, such as RTAA* (Koenig and
Likhachev 2006b), LSS-LRTA* (Koenig and Sun 2008) and
LRTA*LS(k, d) (Hernandez and Meseguer 2008), to speed
up real-time search.

References

Bulitko, V., and Lee, G. 2006. Learning in real time search:
A unifying framework. Journal of Artiﬁcial Intelligence
Research 25:119–157.
Hernandez, C., and Meseguer, P. 2008. Combining looka-
head and propagation in real-time heuristic search. In Pro-
ceedings of the First International Symposium on Search
Techniques in Artiﬁcial Intelligence and Robotics.
Holte, R.; Mkadmi, T.; Zimmer, R.; and MacDonald,
A. 1996. Speeding up problem solving by abstraction:

