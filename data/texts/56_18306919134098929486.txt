Heuristic Search-Based Replanning

Sven Koenig

David Furcy

Colin Bauer

College of Computing

Georgia Institute of Technology

Atlanta, GA 30312-0280

fskoenig, dfurcy, colinosg@cc.gatech.edu

Abstract

Many real-world planning problems require one to solve a
series of similar planning tasks. In this case, replanning can
be much faster than planning from scratch. In this paper, we
introduce a novel replanning method for symbolic planning
with heuristic search-based planners, currently the most pop-
ular planners. Our SHERPA replanner is not only the ﬁrst
heuristic search-based replanner but, different from previous
replanners for other planning paradigms, it also guarantees
that the quality of its plans is as good as that achieved by
planning from scratch. We provide an experimental feasi-
bility study that demonstrates the promise of SHERPA for
heuristic search-based replanning.

Introduction

Artiﬁcial intelligence has investigated planning techniques
that allow one to solve planning tasks in large domains.
Most of the research on planning has studied how to solve
one-shot planning problems. However, planning is often a
repetitive process, where one needs to solve a series of simi-
lar planning tasks, for example, because the actual situation
turns out to be slightly different from the one initially as-
sumed or because the situation changes over time. In these
cases, the original plan might no longer apply or might no
longer be good and one thus needs to replan for the new
situation (desJardins et al. 1999). Examples of practical
signiﬁcance include the aeromedical evacuation of injured
people in crisis situations (Kott, Saks, & Mercer 1999) and
air campaign planning (Myers 1999). Similarly, one needs
to solve a series of similar planning tasks if one wants to
perform a series of what-if analyses or if the cost of opera-
tors, their preconditions, or their effects changes over time
because they are learned or reﬁned (Wang 1996).

Most planners solve each planning task from scratch
when they solve a series of similar planning tasks. Since
planning is time-consuming, this severely limits their re-
sponsiveness or the number of what-if analyses that they
can perform. To enhance their performance, we are devel-
oping replanning methods that reuse information from pre-
vious planning episodes to solve a series of similar plan-
ning tasks much faster than is possible by solving each
Copyright c(cid:13) 2002, American Association for Artiﬁcial Intelli-
gence (www.aaai.org). All rights reserved.

294    AIPS 2002

planning task from scratch.
In particular, we present our
Lifelong Planning A* (LPA*), an incremental version of
A*, and demonstrate how it can be extended to heuristic
search-based replanning, resulting in the SHERPA replan-
ner (Speedy HEuristic search-based RePlAnner). Replan-
ning methods have, of course, been studied before. Exam-
ples include case-based planning, planning by analogy, plan
adaptation, transformational planning, planning by solution
replay, repair-based planning, and learning search-control
knowledge. These methods have been used as part of sys-
tems such as CHEF (Hammond 1990), GORDIUS (Sim-
mons 1988), LS-ADJUST-PLAN (Gerevini & Serina 2000),
MRL (Koehler 1994), NoLimit (Veloso 1994), PLEXUS
(Alterman 1988), PRIAR (Kambhampati & Hendler 1992),
and SPA (Hanks & Weld 1995). One difference between
SHERPA and the other replanners is that SHERPA is so
far the only replanner for the currently most popular plan-
ning paradigm, namely heuristic search-based planning. A
second difference between SHERPA and the other replan-
ners is that SHERPA does not only remember the previ-
ous plans but also the previous plan-construction processes.
Thus, it has more information available for replanning than
even PRIAR, that stores plans together with explanations
of their correctness, or NoLimit, that stores plans together
with substantial descriptions of the decisions that resulted in
the solution. Finally, a third difference between SHERPA
and the other replanners is that the quality of the plans
of SHERPA is as good as that achieved by planning from
scratch. This prevents SHERPA from separating replanning
into two phases, as is often done by hierarchical or partial-
order replanners, namely one phase that determines where
the previous plan fails and one phase that uses slightly mod-
iﬁed standard planning techniques to replan for those parts.
Instead, SHERPA identiﬁes quickly which parts of the pre-
vious plan-construction processes cannot be reused to con-
struct the new plan and then uses an efﬁcient specialized re-
planning method to plan for these parts.

Our LPA* has not been described before in the artiﬁ-
cial intelligence planning literature.
In the following, we
therefore ﬁrst present LPA* and illustrate its behavior on a
simple gridworld problem. We originally developed it for
route-planning tasks for mobile robots in both known and
unknown terrain (Koenig & Likhachev 2001), including the
route-planning tasks solved by Dynamic A* (Stentz 1995).

The main contribution of this paper is to extend LPA* to
heuristic search-based replanning. We describe the result-
ing SHERPA replanner and then present an experimental
feasibility study that demonstrates for three randomly cho-
sen domains from previous AIPS planning competitions that
SHERPA can replan much faster than planning from scratch
and provides some insight into when SHERPA works espe-
cially well.

Lifelong Planning A*

Our Lifelong Planning A* (LPA*) is a search method that
repeatedly determines shortest paths between two given ver-
tices as the edge costs of a graph change. The term life-
long planning, in analogy to lifelong learning (Thrun 1998),
refers to LPA*’s reusing information from previous plan-
construction processes to avoid the parts of the new plan-
construction process that are identical to the previous ones.

Notation and Deﬁnitions
Our LPA* solves the following search tasks: It applies to
ﬁnite graph search problems on known graphs whose edge
costs can increase or decrease over time. S denotes the ﬁnite
set of vertices of the graph. succ(s) (cid:18) S denotes the set of
successors of vertex s 2 S. Similarly, pred(s) (cid:18) S denotes
the set of predecessors of vertex s 2 S. 0 < c(s; s
0) (cid:20)
1 denotes the cost of moving from vertex s to vertex s
0 2
succ(s). LPA* always determines a shortest path from a
given start vertex sstart 2 S to a given goal vertex sgoal 2 S,
knowing both the topology of the graph and the current edge
costs. Since LPA* always determines a shortest path, it also
ﬁnds a plan for the changed planning task if one exists (that
is, it is complete).

The Algorithm
Our LPA* is shown in Figure 1. It ﬁnds a shortest path by
maintaining an estimate g(s) of the start distance of each
vertex s, that is, the distance from sstart to vertex s. It also
maintains rhs-values, a second kind of estimates of the start
distances. The rhs-values are one-step lookahead values
based on the g-values and thus potentially better informed
than the g-values. They always satisfy the following rela-
tionship:

(cid:26)

rhs(s) =

0
mins02pred(s)(g(s

0) + c(s
0

; s))

if s = sstart
otherwise.

A vertex is called locally consistent iff its g-value equals its
rhs-value. This concept is important because the g-values of
all vertices equal their start distances iff all vertices are lo-
cally consistent. However, LPA* does not make every vertex
locally consistent after some of the edge costs have changed.
First, LPA* uses heuristics to focus the search and deter-
mine that some start distances need not be computed at all
because they are irrelevant for recalculating a shortest path
from sstart to sgoal (heuristic search), similar to A* (Pearl
1985). The heuristics h(s) estimate the goal distance of ver-
tex s and need to be consistent, that is, obey the triangle
inequality. Second, LPA* does not recompute the start dis-
tances that have been computed before and have not changed

The pseudocode uses the following functions to manage the priority queue: U.TopKey() returns
the smallest priority of all vertices in priority queue U. (If U is empty, then U.TopKey() returns
[1; 1].) U.Pop() deletes the vertex with the smallest priority in priority queue U and returns the
vertex. U.Insert(s; k) inserts vertex s into priority queue U with priority k. Finally, U.Remove(s)
removes vertex s from priority queue U.

s

; u));

0) + c(s
0

procedure CalculateKey(s)
f01g return [min(g(s); rhs(s)) + h(s); min(g(s); rhs(s))];
procedure Initialize()
f02g U = ;;
f03g for all s 2 S rhs(s) = g(s) = 1;
f04g rhs(sstart) = 0;
f05g U.Insert(sstart; CalculateKey(sstart));
procedure UpdateVertex(u)
f06g if (u 6= sstart) rhs(u) = min
02pred(u)(g(s
f07g if (u 2 U ) U.Remove(u);
f08g if (g(u) 6= rhs(u)) U.Insert(u; CalculateKey(u));
procedure ComputeShortestPath()
f09g while (U.TopKey() _<CalculateKey(sgoal) OR rhs(sgoal) 6= g(sgoal))
f10g u = U.Pop();
f11g if (g(u) > rhs(u))
f12g
g(u) = rhs(u);
for all s 2 succ(u) UpdateVertex(s);
f13g
f14g else
f15g
g(u) = 1;
f16g
for all s 2 succ(u) [ fug UpdateVertex(s);
procedure Main()
f17g Initialize();
f18g forever
f19g ComputeShortestPath();
f20g Wait for changes in edge costs;
f21g for all directed edges (u; v) with changed edge costs
f22g
f23g

Update the edge cost c(u; v);
UpdateVertex(v);

Figure 1: Lifelong Planning A*

(incremental search), similar to DynamicSWSF-FP (Rama-
lingam & Reps 1996). LPA* thus recalculates only very few
start distances.

LPA* applies to the same graph search problems as A*.
The initial search of LPA* even calculates the g-values of
each vertex in exactly the same order as A*, provided that
A* breaks ties between vertices with the same f-values suit-
ably.
In general, both search methods maintain a priority
queue. The priority queue of LPA* always contains exactly
the locally inconsistent vertices. The priority of vertex s in
the priority queue is always

k(s) = [k1(s); k2(s)];

0
1(s) or (k1(s) = k

1(s) and k2(s) (cid:20) k
0

0(s), denoted by k(s) _(cid:20)k

a vector with two components where k1(s) =
min(g(s); rhs(s)) + h(s) and k2(s) = min(g(s); rhs(s)).
The priorities are compared according to a lexicographic
ordering. For example, priority k(s) is smaller than or
0(s), iff either
equal to priority k
0
k1(s) < k
2(s)).
LPA* recalculates the g-values of vertices s (“expands the
vertices”) by executing lines f10-16g) in the priority queue
in the order of increasing ﬁrst priority components, which
correspond to the f-values of an A* search, and vertices with
equal ﬁrst priority components in order of increasing second
priority components, which correspond to the g-values of an
A* search. Thus, it expands vertices in a similar order to an
A* search that expands vertices in the order of increasing f-
values and vertices with equal f-values that are on the same
branch of the search tree in order of increasing g-values.
If g(sgoal) = 1 after the search, then there is no ﬁnite-
cost path from sstart to sgoal. Otherwise, one can trace back a
shortest path from sstart to sgoal by always moving from the

AIPS 2002    295  

0
2
3
4
4
5

A

B

C

D

1
1

4

2
0
1
2
2
3

4
2

3
4
5

5
3
4
5
5
6

3
1

4

A

B

C

D

A

B

C

D

A

B

C

D

2
0

1

3
1

4
2

3
4
5
[8;5]

[8;7]

[8;6]

0
2
3
4
4
5

0
2
3
4
5

0
2
3
4
5

A

B

C

D

A

B

C

D

A

B

C

D

1
1

4

1
1

Iteration #1

2
0

1
2
2
[4;2]
3

3
1

4

Iteration #3

3
1

2
0

1

4
[4;4]

[6;5]

4
[6;4]

Iteration #5

4
2

3
4
5

4
2

3
4
5

4
2

3
1

1
1

2
0

1

[6;6]

[8;6]

A

B

C

D

3
4
5
[8;5]

0
2
3
4
5

5
3
4
5
5
6

5
3
4
5
6

5
3
4
5
6

1
1

6

0
2
3
4
4
5

0
2
3
4
5

0
2
3
4
5

5
3
4
5
5
6

5
3
4
5
6

5
3
4
5
6

4
2

3
4
5

4
2

3
4
5

4
2

3
4
5
[8;5]

Iteration #2

2
0

1

[6;4]
3
[4;3]

3
1

4

iteration #4

2
0

3
1

1
1

4

1
1

frame 2

1

[6;6]

[6;5]

4
[6;4]

Iteration #6

3
1

2
0

1

[8;7]

[8;6]

1
1

6

5
3
4
5
6

Figure 2: An Example

0
current vertex s, starting at sgoal, to any predecessor s
minimizes g(s
broken arbitrarily).

that
; s) until sstart is reached (ties can be

0) + c(s
0

A more detailed and formal description of LPA* , its com-
parison to A*, and proofs of its correctness, completeness,
and other properties can be found in (Likhachev & Koenig
2001).

An Example
To describe the idea behind our LPA* and its operation,
we use a path-planning example in a known four-connected
gridworld with cells whose traversability can change over
time, see Figure 2. They are either traversable or blocked.

296    AIPS 2002

LPA* always determines a shortest path from cell A2 to cell
D1. This is a special case of a graph search problem on four-
connected grids whose edge costs are either one or inﬁnity.
As an approximation of the distance between two cells, we
use their Manhattan distance.

Assume that one is given the g-values in the top gridworld
and it is claimed that they are equal to the correct start dis-
tances. One way to verify this is to check that all cells are
locally consistent, that is, that their given g-values are equal
to their rhs-values (one-step lookahead values), which is in-
deed the case. Now assume that cell B2 becomes blocked,
as shown in the gridworld of iteration one, and it is claimed
that the g-values in the cells remain equal to the correct start
distances. Since the g-values remain unchanged, each g-
value continues to be equal to the corresponding rhs-value
unless the rhs-value has changed which is only possible if
the neighbors of the corresponding cell have changed. Thus,
one needs to check only whether the cells close to changes
in the gridworld remain locally consistent, that is, cells A2
and C2. It turns out that cell C2 is now locally inconsistent
and thus that not all g-values are equal to the correct start
distances. To change this, one needs to work on the locally
inconsistent cells since all cells need to be locally consis-
tent in order for all g-values to be equal to the correct start
distances. Locally inconsistent cells thus provide a starting
point for replanning.

Iterations 1-6 trace the behavior of LPA* if Com-
puteShortestPath() is called in this situation. Each gridworld
shows the g-values at the beginning of an iteration, that
is, when ComputeShortestPath() executes Line 9. At every
point in time, exactly the locally inconsistent cells are in the
priority queue. In the gridworlds, these cells are shaded and
their priorities are given below their g-values. LPA* always
removes the cell with the smallest priority from the priority
queue. If the g-value of the cell is larger than its rhs-value,
LPA* sets the g-value of the cell to its rhs-value. Otherwise,
LPA* sets the g-value to inﬁnity. LPA* then recalculates
the rhs-values of the cells potentially affected by this assign-
ment, checks whether the cells become locally consistent or
inconsistent, and (if necessary) removes them from or adds
them to the priority queue. It then repeats this process un-
til it has found a shortest path from the start cell to the goal
cell, which requires it to recalculate some start distances but
not all of them. One can then trace back a shortest path from
the start cell to the goal cell by starting at the goal cell and
always greedily decreasing the start distance. Any way of
doing this results in a shortest path from the start cell to the
goal cell. Since all costs are one, this means moving from
D1 (6) via D0 (5), C0 (4), B0 (3), A0 (2), and A1 (1) to A2
(0), as shown in the bottom gridworld.

Note that the blockage of cell B2 changes only ﬁve start
distances, namely the ones of C2, D1, D2, D3, and D4. This
allows LPA* to replan a shortest path efﬁciently even though
the shortest path from the start cell to the goal cell changed
completely. This is an advantage of reusing parts of previous
plan-construction processes (in form of the g-values) rather
than adapting previous plans. In particular, the g-values can
easily be used to determine a shortest path but are more eas-
ily reusable than the shortest paths themselves. The number

¥
¥
¥
¥
¥
¥
¥
¥
¥
¥
¥
¥
¥
¥
¥
¥
¥
The pseudocode uses the following functions to manage the priority queue: U.TopKey() returns
the smallest priority of all vertices in priority queue U. (If U is empty, then U.TopKey() returns
[1; 1].) U.Pop() deletes the vertex with the smallest priority in priority queue U and returns the
vertex. U.Insert(s; k) inserts vertex s into priority queue U with priority k. Finally, U.Remove(s)
removes vertex s from priority queue U.

The pseudocode assumes that sstart does not satisfy the goal condition (otherwise the empty plan
is optimal). Furthermore, sgoal is a special symbol that does not correspond to any state.

e2pred(u)(g(source(e)) + cost(e));

procedure CalculateKey(s)
f01g return [min(g(s); rhs(s)) + h(s); min(g(s); rhs(s))];
procedure Initialize()
f02g rhs(sstart) = 0;
f03g g(sstart) = 1;
f04g h(sstart) = the heuristic value of sstart;
f05g pred(sstart) = succ(sstart) = ;;
f06g operators = ;;
f07g U = ;;
f08g U.Insert(sstart; CalculateKey(sstart));
procedure UpdateVertex(u)
f09g if (u 6= sstart) then rhs(u) = min
f10g if (u 2 U ) then U.Remove(u);
f11g if (g(u) 6= rhs(u)) then U.Insert(u; CalculateKey(u));
procedure ComputeShortestPath()
f12g while (U.TopKey() _<CalculateKey(sgoal) OR rhs(sgoal) 6= g(sgoal))
f13g u = U.Pop();
f14g if (u is expanded for the ﬁrst time AND u 6= sgoal) then
f15g
f16g
f17g
f18g
f19g
f20g
f21g
f22g
f23g
f24g
f25g
f26g
f27g
f28g
f29g
f30g
f31g
f32g if (g(u) > rhs(u)) then
f33g
f34g
f35g else
f36g
f37g
f38g
procedure Main()
f39g Initialize();
f40g forever
f41g ComputeShortestPath();
f42g Wait for changes in operator costs;
f43g for all ground planning operators o 2 operators with changed operator costs:
f44g
f45g
f46g

for all ground planning operators o whose preconditions are satisﬁed in u:
if (o =2 operators) then
operators = operators [ fog;
edges(o) = ;;
s = the vertex that results from applying o;
if (vertex s satisﬁes the goal condition) then s = sgoal;
if (s is encountered for the ﬁrst time) then
rhs(s) = g(s) = 1;
h(s) = the heuristic value of s;
pred(s) = succ(s) = ;;
Create a new edge e;
source(e) = u;
destination(e) = s;
cost(e) = the cost of applying o;
edges(o) = edges(o) [ feg;
pred(s) = pred(s) [ feg;
succ(u) = succ(u) [ feg;

g(u) = rhs(u);
for all e 2 succ(u): UpdateVertex(destination(e));
g(u) = 1;
UpdateVertex(u);
for all e 2 succ(u) with destination(e) 6= u: UpdateVertex(destination(e));

for all e 2 edges(o):
cost(e) = the (new) cost of applying o;
UpdateVertex(destination(e));

(Speedy HEuristic search-based RePlAnner). SHERPA ap-
plies to replanning tasks where edges or states are added or
deleted, or the costs of edges are changed, for example, be-
cause the cost of operators, their preconditions, or their ef-
fects change from one planning task to the next. With a small
change, SHERPA can also be used if the goal description or
the heuristic change.

Unfortunately, LPA* cannot be used completely un-
changed for heuristic search-based replanning. There are
three issues that need to be addressed.
(cid:15) First, the pseudocode shown in Figure 1 initializes all
states of the state space up front. This is impossible for
symbolic planning since the state space is too large to ﬁt
in memory. We address this issue by initializing states
and operators only when they are encountered during the
search.
(cid:15) Second, the pseudocode iterates over all predecessors of
a state to determine the rhs-value of the state on Line 6 of
Figure 1. However, it is difﬁcult to determine the prede-
cessors of states for symbolic planning. We address this
issue as follows: Whenever a state is expanded, SHERPA
generates all of its successors and for each of them re-
members that the expanded state is one of its predeces-
sors. Thus, at any point in time, SHERPA has those pre-
decessors of a state available that have been expanded
at least once already and thus have potentially ﬁnite g-
values. We then change the pseudocode to iterate only
over the cached predecessors of the state (instead of all
of them) when it calculates the rhs-value of the state.
This does not change the calculated rhs-value since the
g-values of the other predecessors are inﬁnite.
(cid:15) Third, the pseudocode assumes that there is only one goal
state. However, there are often many goal states in sym-
bolic planning if the goal is only partially speciﬁed. We
address this issue by merging all states that satisfy the goal
condition into one new state, called sgoal, and then remov-
ing their successors.

Figure 3: The SHERPA Replanner

Experimental Results

of cells in our example is too small to result in a large ad-
vantage over an A* search from scratch but larger gridworlds
result in substantial savings (Koenig & Likhachev 2001).

The SHERPA Replanner

Heuristic search-based planners were introduced by (Mc-
Dermott 1996) and (Bonet, Loerincs, & Geffner 1997) and
have become very popular since then. For example, sev-
eral heuristic search-based planners entered the AIPS-2000
planning competition and exhibited very good performance,
including HSP 2.0 (Bonet & Geffner 2000), GRT (Refanidis
& Vlahavas 1999), FF (Hoffmann 2000), and AltAlt (Sri-
vastava et al. 2000). In the following, we show how to ex-
tend our LPA* to symbolic planning with heuristic search-
based planners that perform a forward search using A* with
consistent heuristics, resulting in the SHERPA replanner

In the worst case, replanning is no more efﬁcient than plan-
ning from scratch (Nebel & Koehler 1995). This can happen
in the context of SHERPA if the overlap of the old and new
A* search trees is minimal, for example, if the cost of an
edge close to the root of the old search tree increases and
there is no suitable detour that can be used instead. In many
situations, however, SHERPA can exploit the fact that large
parts of the plan-construction processes are identical in or-
der to decrease its planning effort signiﬁcantly over plan-
ning from scratch. In the following, we provide an experi-
mental feasibility study that shows that SHERPA indeed re-
duces the planning effort substantially compared to planning
from scratch. Our experiments assume that the planning task
changes slightly over time. Thus, SHERPA can use the re-
sults of the previous planning task for replanning.

Replanners are commonly evaluated using the savings
percentage. If x and y denote the computational effort of
replanning and planning from scratch, respectively, then the

AIPS 2002    297  

Domains

blocksworld
blocksworld
blocksworld
blocksworld
blocksworld
gripper
gripper
gripper
gripper
gripper
gripper
gripper
gripper
miconic
miconic
miconic
miconic
miconic
miconic
miconic

(3 blocks)
(4 blocks)
(5 blocks)
(6 blocks)
(7 blocks)
(3 balls)
(4 balls)
(5 balls)
(6 balls)
(7 balls)
(8 balls)
(9 balls)
(10 balls)
(5 ﬂoors, 1 person)
(5 ﬂoors, 2 people)
(5 ﬂoors, 3 people)
(5 ﬂoors, 4 people)
(5 ﬂoors, 5 people)
(5 ﬂoors, 6 people)
(5 ﬂoors, 7 people)

5.3
1.3
0.4
0.2
0.1
1.2
0.8
0.6
0.5
0.5
0.3
0.3
0.2
1.8
1.7
1.7
1.7
1.6
1.5
1.5

Deleted Edges (%)

minimum maximum average
7.5
3.9
2.1
1.2
0.7
8.2
7.2
5.8
5.6
5.2
4.6
4.3
4.5
3.5
3.5
3.4
3.2
2.9
2.8
2.6

25.0
25.0
10.0
4.5
2.7
22.4
21.7
21.8
21.8
21.9
22.0
21.8
21.6
11.1
7.0
5.3
4.9
4.4
4.2
3.9

Sample

Size

Average Savings

Percentage

348
429
457
471
486
340
349
367
361
358
368
374
356
229
217
166
162
158
159
119

6.3
22.9
26.4
31.1
38.0
47.5
57.0
65.1
69.4
73.4
81.0
77.7
80.0
16.3
51.4
46.3
63.1
74.4
80.4
85.2

Table 1: Speedup of SHERPA over Repeated A* Searches

Blocksworld Domain

Gripper Domain

e
g
a

t

n
e
c
r
e
P
 
s
g
n
v
a
S

i

90

80

70

60

50

40

30

20

10

0

3

4

5

Number of Blocks

6

7

e
g
a

t

n
e
c
r
e
P
 
s
g
n
v
a
S

i

90

80

70

60

50

40

30

20

10

0

3

4

5

6

7

Number of Balls

8

9

10

Figure 4: Blocksworld: Average Savings Percentage as a
Function of Domain Size

Figure 5: Gripper: Average Savings Percentage as a Func-
tion of Domain Size

savings percentage is deﬁned to be 100(y − x)=y (Hanks
& Weld 1995). Consequently, we use the savings percent-
age to evaluate SHERPA, which means that we evaluate
SHERPA relative to its own behavior in generating plans
from scratch or, equivalently, relative to an A* search with
the same heuristic and tie-breaking behavior. When calcu-
lating the savings percentage, we use the number of vertex
expansions (that is, updates of the g-values) to measure the
computational effort of SHERPA. This is justiﬁed because
the number of vertex expansions heavily inﬂuences the run-
time of SHERPA. We do not use the runtime directly be-
cause it is implementation and machine dependent and thus
makes it difﬁcult for others to reproduce the results of our

performance comparison. We count two vertex expansions
if SHERPA expands the same vertex twice when it performs
an incremental search, to avoid biasing our experimental re-
sults in favor of replanning.

We used the code of HSP 2.0 (Bonet & Geffner 2000) to
implement SHERPA and performed our experiments with
the consistent hmax-heuristic. We used three randomly
chosen domains from previous AIPS planning competi-
tions, namely the blocksworld, gripper, and miconic (ele-
vator) domains of different sizes. In each of these domains,
we repeated the following procedure 500 times. We ran-
domly generated a start state and goal description, and used
SHERPA to solve this original planning task. We then ran-

298    AIPS 2002

e
g
a

t

n
e
c
r
e
P
 
s
g
n
v
a
S

i

90

80

70

60

50

40

30

20

10

0

Miconic Domain (5 floors)

1

2

3

4

5

6

7

Number of People

e
g
a

t

n
e
c
r
e
P
 
s
g
n
v
a
S

i

70

60

50

40

30

20

10

0

0

3 blocks
4 blocks
5 blocks
6 blocks
7 blocks

1

2

3

4

5

6

7

8

Number of Edges Between Deleted Edge in the Plan and the Goal State

Figure 6: Miconic: Average Savings Percentage as a Func-
tion of Domain Size

Figure 7: Blocksworld: Average Savings Percentage as a
Function of Distance of the Deleted Edge from the Goal

domly selected one of the ground planning operators that
were part of the returned plan and deleted it from the plan-
ning domain. Thus, the old plan can no longer be exe-
cuted and replanning is necessary. Deleting a ground plan-
ning operator deletes several edges from the state space
and thus changes the state space substantially. We then
used SHERPA twice to solve the resulting modiﬁed plan-
ning task: one time it replanned using the results from the
original planning task and the other time it planned from
scratch. Since the hmax-heuristic depends on the avail-
able operators, we decided to let SHERPA continue to use
the heuristic for the original planning task when it solved
the modiﬁed one because this enables SHERPA to cache
the heuristic values. Caching the heuristic values beneﬁts
replanning and planning from scratch equally since com-
puting the heuristics is very time-consuming. No matter
whether SHERPA replanned or planned from scratch, it al-
ways found the same plans for the modiﬁed planning tasks
and the plans were optimal, thus verifying our theoretical
results about LPA*. We tabulated the number of vertex ex-
pansions, together with how many edges were deleted from
the state space and whether this made the resulting planning
task unsolvable. Table 1 shows the results, averaged over
all cases where the resulting planning tasks were solvable
and thus the original plan-construction process could indeed
be reused. The table reports the percentage of edges deleted
from the state spaces, the number of modiﬁed planning tasks
that are solvable, and the savings percentages averaged over
them. Since the state spaces are large, we approximated the
percentage of edges deleted from the state space with the
percentage of edges deleted from the cached part of the state
space. We used a paired-sample z test at the one-percent
signiﬁcance level to conﬁrm that replanning with SHERPA
indeed outperforms planning from scratch signiﬁcantly.

In the following, we interpret the collected data to gain
some insight into the behavior of SHERPA.
(cid:15) Figures 4, 5 and 6 show that the savings percentages tend

to increase with the size of the three domains. (Figures 7
and 8 show the same trend.) This is a desirable property
of replanning methods since planning is time-consuming
in large domains and the large savings provided by re-
planning are therefore especially important. The savings
percentages in the gripper domain appear to level off at
about eighty percent, which is similar to the savings per-
centages that (Hanks & Weld 1995) report for PRIAR and
better than the savings percentages that they report for
SPA. The savings percentages in the other two domains
seem to level off only for domain sizes larger than what
we used in the experiments but also reach levels of eighty
percent at least in the miconic domain.
(cid:15) Figure 7 shows how the savings percentages for the
blocksworld domain change with the position of the
deleted ground planning operator in the plan for the orig-
inal planning task. Note that the savings percentages be-
come less reliable as the distance of the deleted ground
planning operator to the goal increases. This is so because
the number of shortest plans in the sample with length
larger than or equal to n quickly decreases as n increases.
The savings percentages decrease as the distance of the
deleted ground planning operator to the end of the plan
increases. They even become negative when the deleted
ground planning operator is too close to the beginning of
the plan, as expected, since this tends to make the old and
new search trees very different.

(cid:15) Figure 8 shows that

the savings percentages for the
blocksworld domains degrade gracefully as the similar-
ity of the original and modiﬁed planning tasks decreases,
measured using the number of ground planning operators
deleted at the same time. In other words, SHERPA is able
to reuse more of the previous plan-construction process
the more similar the original and modiﬁed planning tasks
are, as expected. We repeated the following procedure
500 times to generate the data: We randomly generated a
start state and goal description, and solved the resulting

AIPS 2002    299  

e
g
a
t
n
e
c
r
e
P
 
s
g
n
v
a
S

i

40

35

30

25

20

15

10

5

0

1

2

3

4 blocks
5 blocks
6 blocks
7 blocks

8

9

10

4
Number of Deleted Ground Operators

5

6

7

Figure 8: Blocksworld: Average Savings Percentage as a
Function of Dissimilarity of the Planning Tasks

planning task from scratch using SHERPA. We call the
resulting search graph G and the resulting plan P . We
then generated a random sequence of 10 different ground
operators. The ﬁrst ground operator was constrained to be
part of plan P to ensure the need for replanning. For each
n = 1 : : : 10, we then deleted the ﬁrst n ground opera-
tors in the sequence from the planning domain and used
SHERPA to replan using search graph G. We discarded
each of the 500 runs in which the planning task became
unsolvable after all 10 ground operators had been deleted
from the domain. Finally, we averaged the savings per-
centages over all remaining planning problems with the
same number n = 1 : : : 10 of deleted ground operators.
We used this experimental setup in the blocksworld do-
main for each problem size ranging from 3 to 7 blocks.
Note that we omitted the results for planning tasks with
three blocks. Because its state space is so small, most
planning tasks are unsolvable after 10 ground planning
operators are deleted.

Future Work

We used small domains in our feasibility study to be able to
average over a large number of runs. Furthermore, SHERPA
ﬁnds optimal plans which also limited the size of the do-
mains we could plan in. Since our feasibility study was so
successful, we intend to test SHERPA with the admissible
h2-heuristic that is more informed than the hmax-heuristic.
We also intend to scale it up to larger problems by adapting
it to the way A* is used by HSP 2.0. HSP 2.0 demonstrates
convincingly that A* is capable of planning in large domains
by trading off plan quality and planning effort. We therefore
intend the next version of SHERPA, like HSP 2.0, to weigh
the h-values more than the g-values and use the inadmissible
hadd-heuristic (Bonet & Geffner 2001). Future work also
includes extending our experimental characterization of the
strengths and weaknesses of SHERPA.

300    AIPS 2002

Conclusions

In this paper, we have described a fast replanning method for
symbolic planning that resulted from extending our LPA* to
heuristic search-based replanning, resulting in the SHERPA
replanner. SHERPA applies to replanning tasks where edges
or states are added or deleted, or the costs of edges are
changed, for example, because the cost of operators, their
preconditions, or their effects change from one planning task
to the next. SHERPA is not only the ﬁrst heuristic search-
based replanner but, different from previous replanners for
other planning paradigms, it also guarantees that the qual-
ity of its plans is as good as that achieved by planning from
scratch. Our experimental results show that SHERPA in-
deed reduces the planning effort substantially compared to
planning from scratch.

Acknowledgments

We thank Blai Bonet and Hector Geffner for making the
code of HSP 2.0 available to us. Blai Bonet also pa-
tiently answered all of our questions about the code. We
thank Sylvie Thi´ebaux and John Slaney for making their
blocksworld planning task generator available to us. We
thank Joerg Hoffmann for making his PDDL planning prob-
lem ﬁles available to us. We thank Maxim Likhachev for
helping to develop LPA* and proving its correctness. Fi-
nally, we thank the anonymous reviewers for their sugges-
tions, some of which we will address in future publications.
The Intelligent Decision-Making Group is partly supported
by NSF awards under contracts IIS-9984827, IIS-0098807,
and ITR/AP-0113881 as well as an IBM faculty partnership
award. The views and conclusions contained in this docu-
ment are those of the authors and should not be interpreted
as representing the ofﬁcial policies, either expressed or im-
plied, of the sponsoring organizations and agencies or the
U.S. government.

References

Alterman, R. 1988. Adaptive planning. Cognitive Science
12(3):393–421.
Bonet, B., and Geffner, H. 2000. Heuristic search planner
2.0. Artiﬁcial Intelligence Magazine 22(3):77–80.
Bonet, B., and Geffner, H. 2001. Planning as heuristic
search. Artiﬁcial Intelligence – Special Issue on Heuristic
Search 129(1):5–33.
Bonet, B.; Loerincs, G.; and Geffner, H. 1997. A robust
and fast action selection mechanism. In Proceedings of the
National Conference on Artiﬁcial Intelligence, 714–719.
desJardins, M.; Durfee, E.; Ortiz, C.; and Wolverton, M.
1999. A survey of research in distributed, continual plan-
ning. Artiﬁcial Intelligence Magazine 20(4):13–22.
2000. Fast plan adapta-
Gerevini, A., and Serina, I.
tion through planning graphs: Local and systematic search
techniques. In Proceedings of the International Conference
on Artiﬁcial Intelligence Planning and Scheduling, 112–
121.
Hammond, K. 1990. Explaining and repairing plans that
fail. Artiﬁcial Intelligence 45:173–228.

Hanks, S., and Weld, D. 1995. A domain-independent
algorithm for plan adaptation. Journal of Artiﬁcial Intelli-
gence Research 2:319–360.
Hoffmann, J. 2000. FF: The fast-forward planning systems.
Artiﬁcial Intelligence Magazine 22(3):57–62.
Kambhampati, S., and Hendler, J. 1992. A validation-
structure-based theory of plan modiﬁcation and reuse. Ar-
tiﬁcial Intelligence 55:193–258.
Koehler, J. 1994. Flexible plan reuse in a formal frame-
work. In B¨ackstr¨om, C., and Sandewall, E., eds., Current
Trends in AI Planning. IOS Press. 171–184.
Koenig, S., and Likhachev, M. 2001. Incremental A*. In
Advances in Neural Information Processing Systems 14.
Kott, A.; Saks, V.; and Mercer, A. 1999. A new technique
enables dynamic replanning and rescheduling of aeromed-
ical evacuation. Artiﬁcial Intelligence Magazine 20(1):43–
53.
Likhachev, M., and Koenig, S. 2001. Lifelong Planning A*
and Dynamic A* Lite: The proofs. Technical report, Col-
lege of Computing, Georgia Institute of Technology, At-
lanta (Georgia).
McDermott, D. 1996. A heuristic estimator for means-
ends analysis in planning. In Proceedings of the Interna-
tional Conference on Artiﬁcial Intelligence Planning and
Scheduling, 142–149.
Myers, K. 1999. Cpef: A continuous planning and execu-
tion framework. Artiﬁcial Intelligence Magazine 20(4):63–
69.
Nebel, B., and Koehler, J. 1995. Plan reuse versus plan
generation: A theoretical and empirical analysis. Artiﬁcial
Intelligence 76(1–2):427–454.
Pearl, J. 1985. Heuristics: Intelligent Search Strategies for
Computer Problem Solving. Addison-Wesley.
Ramalingam, G., and Reps, T. 1996. An incremental al-
gorithm for a generalization of the shortest-path problem.
Journal of Algorithms 21:267–305.
Refanidis, I., and Vlahavas, I. 1999. GRT: a domain-
independent heuristic for STRIPS worlds based on greedy
regression tables. In Proceedings of the European Confer-
ence on Planning, 346–358.
Simmons, R. 1988. A theory of debugging plans and inter-
pretations. In Proceedings of the National Conference on
Artiﬁcial Intelligence, 94–99.
Srivastava, B.; Nguyen, X.; Kambhampati, S.; Do, M.;
Nambiar, U.; Nie, Z.; Niganda, R.; and Zimmerman, T.
2000. AltAlt: Combining graphplan and heuristic state
search. Artiﬁcial Intelligence Magazine 22(3):88–90.
Stentz, A. 1995. The focussed D* algorithm for real-time
replanning. In Proceedings of the International Joint Con-
ference on Artiﬁcial Intelligence, 1652–1659.
Thrun, S. 1998. Lifelong learning algorithms. In Thrun, S.,
and Pratt, L., eds., Learning To Learn. Kluwer Academic
Publishers.
Veloso, M. 1994. Planning and Learning by Analogical
Reasoning. Springer.

Wang, X. 1996. Learning Planning Operators by Observa-
tion and Practice. Ph.D. Dissertation, School of Computer
Science, Carnegie Mellon University, Pittsburgh (Pennsyl-
vania).

AIPS 2002    301  

