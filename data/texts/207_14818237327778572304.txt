From: ISMB-93 Proceedings. Copyright © 1993, AAAI (www.aaai.org). All rights reserved.

Using $to Derive Hidden
Michael Brown Comput.erScience University of California Santa Cruz, CA95064 mpbrown~cse.ucsc.edu

Dirichlet Mixture Priors

Markov Models for Protein Families

Richard Hughey ComputerEngineering University of California
Santa Cruz, CA95064 rph~cse.ucsc.edu

Anders Krogh Electronics Institute, Build. 349 Technical University of Denmark
2800 Lyngby, Denmark
krogh~nordig.ei.dth.dk

I. Saira Mian Sinsheimer Laboratories University of California
Santa Cruz, CA95064 saira@fangio.ucsc.edu

Kimmen SjSlander Computer Science
Universityof C, alifornia
Santa Cruz, CA95064 kimmenC@cse.ucsc.edu

David Haussler ¯ ComputeSrcience University of California
Santa Cruz, CA95064 haussler@cse.ucsc.edu

Abstract
A Bayesian method for estimating the amino acid distributions in the states of a hidden Markov model (HMMf)or a protein family or the colunms of a multiple alignment of that family is introduced. This method uses Dirichlet mixture densities as priors over aminoacid distributions. These mixture densities are determined from examination of previously constructed tlMMsor multiple alignments. It is shownthat this Bayesian method can improve the quality of ItMMsproduced from small training sets. Specific experiments on the EF-hand motif are reported, for which these priors are shown to produce HMMws ith higher likelihood on unseen data, and fewer fal~ positives and false negatives in a database search task.
Introduction
Hidden Markov models (HMMs)are a class of statistical models, related to profiles (Waterman and Perlwitz, 1986; Barton and Sternberg, 1990; Gribskov et al., 1990; Bowieet al., 1991; Li]thy et al., 1991), that can be successfully applied to the problems of modeling protein and nucleic acid families (Churchill, 1989; Whiteel al., 1991; Stultz el al., 1993; Krogh et al., 1992; Hughey, 1993; Baldi el al., 1992; Baldi and Chauvin, 1993; Asai, K. and Hayamizu, S. and Onizuka, K., 1993). HMMcsan be extremely effective for database searching and, without the aid of three-dimensional structural information, can in some
tThis work was supported in part by NSFgrants CDA9115268and IR1-9123692, ONRgrant N00O14-91-J-1162, NIHgrant GM17129a, grant from the Danish Natural Science Research Council, and funds granted by the UCSC Division of Natural Sciences.

cases generate alignments equal in quality to those produced by methods incorporating such high-level information.
One disadvantage of HMMmethods is that they require manytraining sequences from the protein family or domain of interest. Whentraining sets are small, calculating the optimal model for a given protein family is difficult because there are insufficient data to properly estimate the parameters. As only a small numberof sequences is available for most protein families and domains, to date the method has only been applied to large, well studied families such as the EFhand family of proteins that posses a Ca metal ion binding motif. Experimenting with the globin family, we found that 200 randomly chosen family members were required to obtain quality models. The majority of protein families represented in the databases contain
far fewer members.
Onenatural solution is to introduce additional prior
information into the construction of the HMMI.n this paper, we present methodsfor incorporating prior knowledgeof typical amino acid distributions over positions in nmltiple alignments to the problem of HMM training. In fact, our HMMtshemselves include a linear chain of match states that capture aminoacid dis-
tributions for each position in the multiple alignment of a protein family. Thus, in a bootstrapping procedure, we can use distributions from our previously built HMMtos generate prior information for the next model. Additionally, databases can be searched with the model built from a small training data set to find new membersof the family, increasing the size of the training set.
In this paper, we introduce Dirichlet mixture densities (Antoniak, 1974) as a meansof representing prior information about typical amino acid distributions. A

Brown 47

related use of mixture priors, in this case Gaussianmixture priors used in the context of neural net training, was given in (Nowlan and Hinton, 1992). The Dirichlet mixtures cluster aminoacid distributions into prototypicai classes of distributions. Using Bayes' rule, Dirichlet mixture densities can be combined with observed frequencies of amino acids to obtain posterior estimates of aminoacid distributions. Ill a detailed set of experiments on building HMMmodels of the EFhand motif, we showthat such posterior estimates lead to superior HMMsI.n particular, we show that HMMs
for the EF-hand motif trained using appropriate priors produce models that have higher likelihood with
respect to independent (non-training) sets of EF-hand motifs. Furthermore, we show that these models produce fewer false positive and false negative sequences when searching a database.
Our present work has several conceptual similarities
with profile methods, particularly in regard to seeking meaningful or prototypical aminoacid distributions for use in database search and multiple alignment (Water-
manand Perlwitz, 1986; Barton and Sternberg, 1990; Gribskovel al., 1990; Bowieel al., 1991; Lfithy et al., 1991). In particular, Liithy, McLachlan and Eisenberg (1991) have analyzed multiple alignments using secondary structure information to construct a set of distributions describing the columnarstatistics of secoudary protein structures. The result of their work is a set of nine probability distributions, whichwe will call
the LMEdistributions, describing the distribution of aminoacids in nine different structural environmentsin a protein. 1 These LMEdistributions have been shown to increase the accuracy of profiles in both database search and multiple alignment by enabling them to take advantage of prior knowledgeof secondary structure.
There are two difficulties in applying the LMEdis-
tributions to HMMs.First, there is no measure of howmuchvariance is associated with each of the distributions. This is important because Bayes rule de-
mands that in computing the posterior, the observed frequency counts be modified less strongly when the prior distribution has a very high variance. Second, the LMEdistributions are directly associated with secondary structure, whereas we assume no secondary structure information is available.
Instead of beginning with secondary structure, our approach is to use unlabeled training sequences to discover, through clustering, those classes of distributions of amino acids that are intrinsic to the data. Wedo this with statistical methodsthat directly estimate the most likely Dirichlet mixture density from observed
counts of aminoacids. In several cases, the amino acid distributions we find are easily identified as typifying some commonlyfound distribution (e.g., a large nonpolar), but we do not set out a priori to find distribu-
1In morerecent work, they have used 18 different distributions (Bowieet al., 1991).

tions representing these structures. For a review of the essentials of the HMMmethodol-
ogy we use, including architecture, parameter estimation, multiple alignments, and database searches, see (Krogh et al., 1992).

Modeling amino acid distributions with

Dirichlet mixtures

Examiningthe columns in a large multiple alignment of

a homologousset of protein sequences, we see a variety
of distributions of amino acids. In the extreme case, when an anaino acid is highly conserved at a certain position in the protein family, such as the proximal

histidine that coordinates the hemeiron in hemoglobin, the distribution of amino acids in the corresponding column of the multiple alignment is sharply peaked on that one amino acid, whereas in other cases the
distribution is spread over manypossible aminoacids. There are manydifferent commonlyoccurring dis~
tributions. Someof these reflect preference for hy-

drophobic amino acids, some for small amino acids, and some for more complex combinations of physicochemical features. Using a purely statistical method, we have attempted to discover and model the major types of amino acid distributions found in columns of multiple alignments. Our principle intent was to use this iuformation to produce better multiple alignments, but the results mayalso be of independent biological interest.
Our primary data is a set of N count vectors. Each count vector in this set represents data from a specific column in a specific multiple alignment. Many multiple alignments of different protein families are included, so N is typically in the thousands. Let us suppose that we fix a numbering of the amino acids from I to 20. Then, each count vector has the form

iffth--am(niino...a.cid,s

n20), whereni is occurs in the

the numberof times column represented

the by

this count vector. Wemake the simplifying assump-
tion that the amino acids in a particular column are
geuerated independently at random according to an underlying probability distribution fi = (Pl ..... P20) over the 20 anaino acids. Each column, however, is assumedto have its ownunique probability distribution.

Our goal is to model the kinds of distributions/7 that are most likely generating the actual observed count vectors.
A trivial approach wouldbe to estimate a probability distribution /Y separately for each count vector or column. Under our independence assumption, a single couut vector ~ is interpreted as data from a multinomia] distribution with unknownparameters ]. Wecan estimate the Pi parameters from this data using the usual lnaximumlikelihood method, i.e. by finding the pi's that maximize

Proh(n..~.. , n~o,lp.~. . , p2o).

As is well known, this leads to the obvious estimate

ISMB-93

Pi "- nl/n, wheren - ~i2=OInl. These i6i values are just a summaryof the raw data, and for small n provide only poor estimates for the actual underlying probability distributions.
To solve this problem, we propose a two-stage stochastic model for the data. Weassume that, for each count vector if, first a distribution ff is chosen independently from an unknownprobability density p
over all such distributions, then the count vector is generated according to the multinomial distribution with parameters ft. Our goal is now to bypass the estimation of the individual 17 parameter vectors and instead use the data from the count vectors to directly
estimate the underlying density p. To make this feasible, we have assumed a simple
parametric form for the density p, initially choosing a Dirichlet density with unknown parameters al,...,a~0 (Berger, 19851 Santner and Duffy, 1989). The value of p at a particular point 17 is given by:

lr-lr 20 <~,--1

p(p-.) ll i=l Pi
Z

'

(1)

where Z is the normalizing constant such that p inte-

grates to unity. Letting a = ~"~=1a'i, it is easy to see

that the Dirichlet density with parameters cq,..., o~20 is peaked around the amino acid distribution where

Pi = Oti/ot. Thelarger c~ is, the morepeakedis the density. Thus, modelingp by a simple Dirichlet density as-

sumes that all amino acid distributions are deviations from one central underlying anaino acid distribution.

Because this latter assumption seems dubious, in

further experinaents we have used a more complex form for the density p. In particular, we assume that p has

the form

p = qlPi + ... + qkP~,

(2)

where each Pi is a Dirichlet density and the numbers

ql,.-.,qk are positive and sum to one. A density of this form is called a mixture density (or, in this specific case, a Dirichlet mixture density), and the qj values are called mixture coefficients. Each of the densities pj is called a component of the mixture. By using a Dirichlet mixture, we hope to discover several underlying "prototypical" aminoacid distributions: a
collection of aminoacid distributions such that each observed column count from a multiple alignment is very likely obtained from a minor variant of one of the prototypes. The process is similar to clustering amino acid distributions into types. However,instead of having just 20 parameters cq,..., a.~0 to estimate, as in tim case of a single Dirichlet density, we nowhave 21 x k parameters to estimate: twenty oq values for each of the k components of the mixture and twenty mixture coefficients. This is feasible if k small and the number of count vectors available is large.
We have used the maximumlikelihood method to estimate the parameters of p from the set of count vectors. Thus, we searched for the parameters of p that would maximize the probability of occurence of the

observed count vectors. In the simplest case, we have simply fixed the number of components k to a particular value and then estimated the 21 x k parameters. In other experiments, we tried to estimate k as well. Unfortunately, even for fixed k, there does not appear to be an efficient method of estimating these parameters that is guaranteed to always find the maximum
likelihood estimate. However,the standard estimationmaximization (EM) algorithm for mixture density est2imation works well in practice.
The final result of this statistical estimation is a set of k mixture coefficients, ql,...,qk, and a set of
k Dirichlet parameter vectors, ~l,...,~k, where ~j is the vector a~j),. .., a~#0) of parametersof the flh Dirichlet component in the mixture. These parameters are possibly interesting in themselves, in terms of what they reveal about protein structure (as discussed in
the next section), however their main use will be in improving multiple alignments and other models derived from multiple alignments, such as profiles and HMMs.
Consider the production of a multiple alignment for a protein family. Fromone column in a rough, initial alignment, a count vector ~ is obtained. One immediate question to consider is whether or not the count vector is similar to one of the distributions on amino
acids tlmt commonlyoccurs in protein families. If this is the case, then this can be considered evidence for the accuracy of the alignment (otherwise, it maybe considered evidence against that particular alignment). Furthermore, assuming a correspondence, one mayask what structural role is usually played by positions that have this kind of distribution and use this information to discover the commonstructure of the proteins family. Finally, if only a relatively small numberof pro-
teins makeup the alignment (less than 30), then one does not expect the counts ~ to yield goodestimates of the actual probabilities/7 that each aminoacid will appear in that position in other proteins from the family
not yet included in the alignment. Thus, it is difficult to use this alignment to search a database for other proteins in the family, by profile, HMMo,r alternative methods. By combining these counts with prior infor-
mation from the Dirichlet densities, better estimates of the pl parameters can be obtained. In this sense the Dirichlet mixture prior provides an alternative to the use of the Dayhoff matrix (Dayhoff el al., 1978), and other means of "smoothing" probability estimates based on a few occurrences of amino acids.
Once we have estimated the parameters of a Dirich-
let mixture, these issues can all be addressed in a purely statistical manner. Wedo this by treating the
2Anintroduction to this methodof mixture density estimation is given in the book by Dudaand Hart (1973). Wehave modified their procedure to estimate a mixture of Dirichlet rather than Gaussian densities. The mathematical details of this will be describedin a separate paper (Brownet al., 1993).

Brown 49

Dirichlet mixture density p as a prior probability density over the possible actual distributions/Y in the new protein family being modeled. Then, given the actual counts ff for a particular column of a multiple alignment, we can use a Bayesian method to determine tile type of distribution that mayhave generated these counts, (i.e., which of the k compouentsof the Diriclflet mixture may have produced the underlying probability distribution/Yfor this position) and to produce estimates/~1 ..... /~20 of the actual Pi values. The latter estimates will differ from the maximumlikelihood estimates, and should be much better when n is small.
It is straightforward to derive the formulas for these Bayes estinaates, assuming a Dirichlet mixture prior (Brownet al., 1993). In the first case, for each j be-
tween 1 and k, we want to calculate Prob(jla ), the posterior probability that the uuderlying probability distribution /Y that produced the observed counts was chosen from the jth component of the Dirichlet mixture. Hence, instead of identifying one single component of the mixture that accounts for the observed data, we determine howlikely each individual component is to have produced the data. Using Bayes rule,

qj Prob(fflpj Pr°b(JlrT) = E~=I qtPr°b(fflPt)"

(3)

And, if n = E~;=0 I ni and a'J)= E~O10~ i(j),
Prob(~[pj) r(n + 1)r(~(~)) ~-~ r(m + a(/))
F(n. + a'('/I)/']'~1 F(ni1)F(allJ))'

where F(x) is the gammafnnctio,~. Ilence this gives an explicit formula for the first kind of estimate.
For the second kind of estimate, the estimate of the pi parameters from the counts rli, again using Bayes ,srule

ni + )-'~k4=P1rob(j[ff)alj) Pi = Z

,

(4)

where Z is the appropriate normalizing constant so that ~=2t0 .P-i = 1.

Wepropose this method as a new wayof interpreting

count data from multiple alignments. In particular, we

suggest that a comprehensiveDirichlet mixture density

be constructed that covers most of the anfino acid dis-

tributions that have been found in existing nmltiple

alignments. Then, when new multiple alignments are

constructed, we suggest that the statistics from each

column be used to classify that column based on the

posterior probabilities of the componentsof the Dirich-

let mixture, using Equation 3, and that the underlying

probabilities of the 20 aminoacids for that columnbe

estimated using Equation 4. In the following section

we describe the experiments we have done using this

method.

3This is actually the mean posterior estimate of the parameters/~.

50 ISMB-93

Sequences
400 193 88

Columnsin Alignment
147 254 401

Protein Family
Globins Kinases Elongation

Figure 2: Protein families included in the HMMdata set.

Results
Obtaining Priors
As described above, our approach focuses on an automated construction of priors based on multiple alignmeats. Here we describe the construction of several Dirichlet mixture priors and demonstrate the effectiveness of these priors in building accurate models for the EF-hand motif.
Weused two sources of multiple alignments for our raw count data: alignments from the HSSPdatabase
(Sander and Schneider, 1991) (Figure 1), and multiple alignments we generated using HMMtso model the kinasa, globin and elongation factor families (Haussler el al., 1993; Kroghet al., 1992) (Figure 2). The tal number of columns from the HSSPalignments was 5670; the number of columns from the HMMalignmcnts totaled 802.
The HSSPdatabase contains multiple alignments of proteins obtained by taking a single protein whose three dimensional structure is known, and aligning to
it. other proteins that are deemed homologousabove a certain threshold to this protein but whose structure is not known. In (Sander and Schneider, 1991), representative set of HSSPmultiple alignments is suggested that includes a variety of different protein types. Weused all the multiple alignments in this representative set with 30 or more sequences to obtain our HSSP count data. These proteins are listed in Figure 1.
Sequences used to create HMMalignments were obtained from various sources. The training data we used to create our kinase alignment came from the March 1992 release of the protein kinase catalytic domain database maintained by S. K. Hanks and A. M. Quinn (1991). This set is biased towards sequences from vertebrates and higher eucaryotes but includes some from lower eucaryotes. There are only two kinases encoded by viral genomes. Training data for the globin
alignment consisted of all $1obins from the SWISSPROTdatabase, release 22 (Barioch and Boeckmann, 1991). Elongation factor sequences were drawn from
the SWISS-PROTdatabase, releases 22 and 23. Multiple alignments for these sequences were produced by HMMws e built for these families, as described in (Krogh et al., 1992; Hughey, 1993). Summaryinfor-
mation for these data sets is given in Figure 2. Using the maximumlikelihood procedure described
in the previous section, we estimated the parameters of both a one componentDirichlet mixture density and

J Sequences 948
475 372 287 251 242 191 178 130 126 I09 107 102 89 89 89 82
81 77 71 65 63 63 6O 59 54 53 49 46 46 41 39 38 38 36 35
.33 31 31 30 30

HSSPidentifier
1HDS IFDL 2FBJ 2PKA 7ADH ITRC 2TGP ITGS 3HLA 2RUS 3CYT 4INS 5P2P 1R08 2RRI 2RS3 3SGB ICDT 2MEV 1NXB 2LTN IGDI IWSY IFC2
1FC1
IETU 8RSA
5HVP 4LYZ
9API
2CD4 IGCR
2SBT
2SOD
ICSE 9WGA 31CB 1CMS 5LDH
1MHU 2MRT

Protein F,mily HEMOGLOBIN IG=GI FAB FRAGMENT IG"A FAB FRAGMENT KALLIKREIN A ISONICOTINIMIDYLATED LIVER ALCOHOL DEHYDROGENASE CALMODULIN TRYPSINOGEN COMPLEX WITH PANCREATIC TRYPSIN INHIBITOR TRYPSINOGEN COMPLEX WITH PORCINE PANCREATIC SECRETORY HUMAN CLASS I HISTOCOMPATIBILITY ANTIGEN A2.1
RUBISCO CYTOCHROME $C
INSULIN PHOSPHOLIPASE A=2
RHINOVIRUS 14 RHINOVIRUS 14 RHINOVIRUS 14

PROTEINASE B FROM STREPTOMYCES GRISEUS

CARDIOTOXIN V=4===/II$==

MENGO ENCEPHALOMYOCARDITIS VIRUS COAT PROTEIN

NEUROTOXIN $B

PEA LECTIN

HOLO-=D-*GLYCERALDEHYDE-3-PHOSPHATE

DEHYDROGENASE

TRYPTOPHAN SYNTHASE

IMMUNOGLOBULIN FC AND FRAGMENT B OF PROTEIN A COMPLEX

FC1 FC FRAGMENT ELONGATION FACTOR TU

RIBONUCLEASE *A
HIV$-I PROTEASE COMPLEX WITH ACETYL-PEPSTATIN LYSOZYME
MODIFIED ALPHA=I =-*ANTITRYPSIN

CD45

GAMMA-/n$ CRYSTALLIN

SUBTILISIN NOVO

CU,ZN SUPEROXIDE DISMUTASE

SUBTILISIN CARLSBERG WHEAT GERM AGGLUTININ

CALCIUM-BINDING PROTEIN

CHYMOSIN B

LACTATE DEHYDROGENASE H=4= AND S-$LAC./NAD$=m+== COMPLEX

CD.7 METALLOTHIONEIN-2

CD.7 METALLOTHIONEIN-2

Figure 1: Protein families iucluded in the HSSPdata set.

a nine component Dirichlet mixture density from the 5670 count vectors obtained from the I'ISSP multiple alignments. Wecall these Dirichlet mixtures HSSP1 and HSSP9, respectively. As Blentioned in the previous section, the EMmethod we use is not guaranteed to always find the optimal setting of the parameters. However, nmltiple runs of the program with different initial parameter settings, yielded virtually identical priors, indicating that these solutions are very stable. In addition, we conductedall experiment to find a prior with a larger number of components. For this experiment, we started with 100 components using random initial values for the DiricMet parameters. After elim-
inating those components found to not represent any of the data, we obtained a mixture prior having 62 components, which we call HSSP62.
Similar experiments were done for the HMMalignments, obtaining Dirichlet mixture priors with one component, nine components, and 33 components (tIMM1, HMM9,HMM33).The results for the singlecomponent and nine-component priors were also shown to be stable with respect to the initial starting point of the estimation procedure.
We studied the priors we obtained from the IIMM alignments and the HSSPalignments and found several components cominonto both sets. Similarity between components was determined by Kullback-Leibler

distance and by examination of the physieo-chemical attributes of the distributions. The a parameters of the HMMa1nd HMMp9riors are given in Figure 3. The distributions and physico-chemical attributes of the componentsof these priors are summarizedin Figures 4 and 5.
In general, the physico-chemical attributes of the components of the HMMp9rior are consistent with biological intuition. Whenwe order the components with respect to their mixture coefficients (i.e., their probabilities), the first component, HMM9.1c,ontains mostly small residues. The second component, HMM9.2i,s large, charged and polar. HMM9.i3s polar, and has mostly negatively charged residues, except for Aianine(A), whichis small, neutral, andcan be found in virtually every environment. HMM9.4 has a weak tendency towards hydrophobic residues and contains three large non-polarresidues, Isoleucine (I), Leucine (L), and Valine (V) with high probability. Howeveri,t also contains a single chargedresidue, Lysine (K) with high probability, but it is worthnoting that Lysine possesses a long hydrophobic carbon chain in addition to the positively charged nitrogen atom. HMM9.i5s strongly hydrophobic and contains uncharged, nonpolar amino acids. HMM9.i6s charged, hydrophilic and polar, and HMM9.i7s negatively charged and aromatic. HMM9.i8s strongly hydropho-

Brown 51

J'[]dM1 a.,,,4.n

H2~ g.l 0-3.0

lUd]/8.2 ~-5.4

Hfd]d 0.$ a-g,?

LDdid0.4 ,a-14,1

ItM~i 11.5 a-?,~

H~g.6 ,a=2g.~,

HMMg.1

I-IMMg.2

HMMg.3

HMM~4

HMMO.S

I~lM g.7 a-0.86

FLMM9,8 1-11.O

HLrw a.g a-8.6

HMMg.7

HMMg.8

HMIV9l ,g

Figure 3: a parameters for the HMM1and tlMM9 priors. These bar charts showthe 20 t~i parameters of tile Dirichlet density of HMMa1nd of each of the nine components of HMM9T. he ordering of the residues used is that proposed by Taylor (1986). Starting from the left, the amino acids form four groups: small and polar, large and polar, large and non-polar, and small and non-polar. Each bar chart is scaled by the largest ai. The parameter a is the sum of the ai, which gives someidea of the real magnitude of the parameters.
bic, non-polar and uncharged. HMM9.9greatly emphasizes large residues aswell as aromatic, hydrophobic and uncharged residues.
In addition to the priors we obtained via maximumlikelihood estimation, we tested the effectivehess of some additional priors: the standard uniform prior called AddOne, 4 priors obtained directly fi'om the nine-component LMEdistributions (Liithy et al., 1991) and a 29-component EF-hand custom prior in which each componentis derived from a column in our EF-hand multiple alignment. The prior derived from the nine-component LMEdistributions was obtained by forming Dirichlet mixture components for each of the nine LMEamino acid distributions with the same means and a fixed variance. 5 The 29-component EF-
4This prior is often used to avoid zero probabilities on distributions in states of HMMsP.osterior estimates for this prior are obtained by simply adding one to all observed frequency counts and then normalizing so that the parameters sumto one.
5Thevariance wasset so that the sumof the ~i p~tralueters was 10. This appeared to workbest for our experiments with EF-handsequences, but further experimentation wouldbe required to find the optimal value.

Figure 4: Log ratios for the distributions represented by the ItMM1 and HMM9priors. The i th bar in the graph for HMM9.jshows the logarithm of the ratio pi/qi where Pi is the probability of the i th aminoacid in the mean of the jch component of the HMMp9rior. The variable, qi, is the probability of the i th amino acid in the overall mean of HMM1T.hese values represent the difference in meanamino acid distribution of the jth component from the background distribution. Positive numbersindicate higher values than the background distribution; negative numbers represent lower values than the background.
hand custom prior was designed specifically as a kind of control for the EF-handmotif experiments reported in the next section. Each component of this mixture is a Dirichlet distribution that is strongly peaked on the particular amino acid distribution at one of the positions in a multiple alignment of 885 EF-hand motifs. Weuse it as a control in our EF-hand experiments to indicate what kind of performance we might expect if we used the best possible prior for obtaining HMMasnd multiple alignments of EF-hand sequences. Of course this particular prior will be useless for other kinds of proteins.
Using Priors to Build HMMs
We cohducted a series of experiments on building HMMfsor the EF-hand motif. EF-hands are an approximately 29-residue structure present in cytosolic calcium-modulated proteins (Nakayamaet al., 1992; Persechini et al., 1989; Moncrief et al., 1990). These 2pr+o)teins bind the second messenger calcium (Ca and in their active form function as enzymes or regulate other enzymes and structural proteins. The EF-

52 ISMB-93

1 2 3 4 Se 7 8 8
|
I --.... I

123 4567 89
[_____|_.
Md~lw W~ghl

POS~v~Cdyharged

NegativelCy harged

i
i

. ..I ..,I ...I ,,,I .,.I

20 40

I10 80

100

Ira~ngs~s~z¯

Figure 5: Physico-chemical characteristics of components of the HMMp9rior. IIere each bar chart shows the relative scores of one characteristic for all nine components of IIMM9.Apositive score indicates that tile distribution represented by the component puts more weight on residues with that characteristic than does the background distribution (represented by HMM1). A negative score indicates that less weight is put on residues with this characteristic. Each characteristic is defined by a numerical value for all residues, then these are averaged with respect to the distribution, and finally the backgroundaverage is subtracted. Definitions of the numerical scores are taken from (Fasman, 1989) (Hydrophobicity, Standard-state accessibility, Averageaccessible area), (tIunter, 1987) (Molecular Weight), and (King and Sternberg, 1990) (Polar, Charged, Positively and Negatively Charged).
hand motif consists of an a-helix, a loop binding a Ca2+ ion and a second helix. We chose EF-hands to demonstrate the ability of mixture-priors to compensate for limited sample sizes because the motif's small size allowed manyexperiments to be performed relatively rapidly. Furthermore, a large nmnber of EFhand motif sequences are available.
For these experiments we used the June 1992 database of EF-hand sequences maintained by Kretsinger and co-workers (Nakayamaet al., 1992). Sequences in this database are proteins containing two or more copies of the EF-hand motif. Weextracted the EF-hand structures from each of the 242 sequences in the database, obtaining 885 EF-hand motifs having an average length of 29. Training sets were constructed by randomly extracting subsets of size 5, 10, 20, 40, 60, 80, and 100.

Figure 6: Average NLLscores on test data for IIMMs built using different combinations of training set sizes and priors estimated from the HMMdata. Bars indicate one standard deviation above and below the mean. For sample sizes 5, 10, and 20 we did 15 repetitions with independently chosen training sets. For other sample sizes we performed five repetitions.
For each training set size and each prior, several ttMMs were built. We evaluated each HMMon a separate test set containing EF-handsequences not in the training set, yielding an averagenegative log likelihood (N£L)score over all test sequences for each model (Kroghet ai., 1992). Lowerscores represent more accurate models. For every combination of training sample size and prior used, we took the average test-set NLLscore across all models, and the standard deviation of the test-set NLL-scores. The results for the Add One, HMM1I,IMM9, and EF-hand custom priors are shown in Figure 6. The results of tests using priors derived from the HSSPalignments are shown in Figure 7.
Fromthese Figures, we see that AddOne and ttSSP1 perform the worst, followed by HMM1t,ISSPg, HMM9 and EF-hand custom prior. IISSP62 and IIMM33, not shown, both perform about the same as HMMgw, hich was close in performance to ttSSP9. We conducted tests using the nine LMEdistributions on sample size of 10. While these are not shown, the results were at the midpoint between the performance of IIMM1and HMM9.Further tests on the nine LMEand the 18 LMEdistributions are in progress.
In our previous work, the NLLscore has always been aimost perfectly correlated with superior multiple alignments and database search. To further demonstrate the latter point, we tested someof the ttMMs

Brown 53

¯' ' I' "' I

I

Model ~lldlng Performance

' ' I ', ' HSSP

oHSSPI Ix~ ~HSSPp9rior OEF-tm~ cu~m
i

),0

D~ Dm=imir~ion Pcrhxnmnom

1 n.l,,,T,,,f,,,,i,..

1 '"'I'"'I''"I"'T'"

I
0.9 0.9

0.8
i
I ~0.7
l
0.6

~0.8
!o,
0.6

,I,¯,f¯

II,iIi, ,I

20 40 60 80 100

ln~nm0 s4,t s~ze

0.5 1 3 4

Figure 7: Average NLLscores on test data for HMMs built using different combinationsof training set sizes and priors estimated from the HSSPdata. Bars indicate one standard deviation. For sample size 20 we did 15 repetitions with independently chosen training sets. For other sample sizes we performed five repetitions.
built from various priors on timir ability to discriminate sequences containing the EF-hand domain from those not containing the domain. To do this we choose models built from training samples of sizes 5, 10, and 20, and using the Add one, ItMM1, HMM9and EFhand custom priors. For each sample size and prior, we built an HMMas above and then used it to search the SWISS-PROdTatabase for sequences that contain the EF-hand motif, using the method described in (Krogh e~ al., 1992). The results are given in Figure 8.
The results show again that HMM9performs better than HMM1w, hich performs better than Add one. Unfortunately, only one test was done for each eolnbination of sample size and prior, so the results are not as statistically clear as those for NLL-score.
Finally, we note that while the ItSSP alignments contain EF-hand-specific proteins, the HMMalignments do not. Interestingly, results of experiments show that the tIMM-derived priors perform better. This confirms that these priors do indeed capture some universal aspect of aminoacid distributions that are meaningfulacross different protein families.
Conclusions
The use of Dirichlet mixture priors has been shown to increase the accuracy of HMMfsor protein families where only a small numberof sequences are available. In particular, the ability of models trained using prior

Figure 8: Discrimination results for models trained with training set sizes of 5, 10, and 20 sequences and priors. The percentage of EF-hand sequences that are found through a database search is reported for models trained with different training set sizes and priors. The cutoff is set so that there are no false positive classifications.
information to discriminate membersof protein families from non-members is enhanced. Thus, database search using these models can potentially yield previously unknownmembersof the family, enlarging the training set. Fromthis new set, an even better model can be obtained, enabling the iterative refinement of the HMMin a bootstrapping fashion.
As experiments on the EF-hand domain using custom priors demonstrate, if one has a library of Dirichlet priors spanning a variety of amino acid distributions, such that virtually all possible distributions are represented, even extremely small training sets can in principle yield final modelsthat are close to optimal. Ideally, such a library would be continually updated as new models and alignments are produced. Weplan to do this as we continue to build I:IMMsfor protein families.
Acknowledgments
We wish to thank James Bowie and his colleagues for providing us with an additional 18 distributions spanning a large variety of secondary structures. Experiments using these distributions are currently in progress.
The protein project has also included: Brad Gulko, Harry Noiler, Rebecca Underwood, and Anne Urban. Wegratefully acknowledge TonyFink for his comments

54 ISMB-93

on our amino acid distributions. Jon Becher and MasPar Corporation generously provided time on several MasPar computers.
References
Antoniak, C. 1974. Mixtures of Dirichlet processes with applications to Bayesian nonparametric problems. Annals of Statistics 2:1152-1174.
Asai, K. and Hayamizu, S. and Onizuka, K., 1993. HMM with protein structure graramar. In Proceedings of the Hawaii International Conference on System Sciences, Los Alamitos, CA. IEEE Computer Society Press. 783-791.
Baldi, P. and Chauvin, Y. 1993. A smooth learning algorithm for hidden Markov models. To appear.
Baldi, P.; Chanvin, Y.; Hunkapiller, T.; and McClure, M. A. 1992. Adaptive algorithms for modeling and analysis of biological primary sequence information. Technical report, Net-ID, Inc., 8 Cathy Place, Menlo Park, CA 94305.
Barioch, A. and Boeckmann, B. 1991. Nuci. Acids Res. 19:2247-2249.
Barton, G. J. and Sternberg, M. J. 1990. Flexible protein sequence patterns: A sensitive method to detect weak structural similarities. J.of Mol. Bio. 212(2):389-402.
Berger, J. 1985. Statistical Decision Theory and Bayesian Analysis. Springer-Verlag, NewYork.
Bowie, J. U.; LSthy, R.; and Eisenberg, D. 1991. A method to identify protein sequences that fold into a knownthree-dimensional structure. Science 253:164-170.
Brown, M. P.; Hughey, R.; Krogh, A.; Mian, I. S.; SjSlander, K.; and Haussler, D. 1993. Dirichlet mixture priors for HMMsI.n preparation.
Churchill, G A 1989. Stochastic models for heterogeneous DNAsequences. Bull Math Biol 51:79-94.
Dayhoff, M. O.; Schwartz, R. M.; and Orcutt, B. C. 1978. A model of evolutionary change in proteins. In Atlas of Protein Sequence and Structure. National Biomedical Research Foundation, Washington, D. C. chapter 22, 345358.
Duda, R. O. and Hart, P. E. 1973. Pattern Classification and Scene Analysis. Wiley, NewYork.
Fasman, G. 1989. Prediction of protein structure and the principles of protein conformation. Plenum Press, New York.
Gribskov, M.; Lfthy, R.; and Eisenberg, D 1990. Profile analysis. Methods in Enzymology 183:146-159.
Hanks, S K and Quinn, A M 1991. Protein kinase catalytic domain sequence database: identification of conserved features of primary structure and classification of family members. Methods in Enzymology 200:38-62.
Haussler, D.; Krogh, A.; Mian, I. S.; and Sjrlander, K. 1993. Protein modeling using hidden Markov models: Analysis of globins. In Proceedings of the Hawaii International Conference on System Sciences, Los Alamitos, CA. IEEE Computer Society Press.
Hughey, Richard 1993. Massively parallel bioseqeunce analysis. Technical Report UCSC-CRL-93-14,University of California, Santa Cruz, CA.

Hunter, Larry 1987. Representing Amino Acids with Bitstrings. Benjamin/Cummings Pub. Co., Menlo Park, Calif.
King, R. D. and Sternberg, M. J. 1990. Machine learning approach for the prediction of protein secondary structure. J. of Mol. Bio. 216:441--457.
Krogh, A.; Brown, M.; Mian, I. S.; Sjolander, K.; and Hanssler, D. 1992. Hidden Markov models in computational biology: Applications to protein modeling. Submitted to J. Mol. Bio.
Liithy, R.; McLachlan, A. D.; and Eisenberg, D. 1991. Secondary structure-based profiles: Use of structureconserving scoring table in searching protein sequence databases for structural similarities. PROTEINS:Structure, Function, and Genetics 10:229-239.
Moncrief, N. D.; Kretsinger, R. H.; and Goodman, M. 1990. Evolution of EF-hand calcium-modulated proteins. I. relationships based on amino acid sequences. Journal of Molecular Evolution 30:522-562.
Nakayama, S; Moncrief, N D; and Kretsinger, R H 1992. Evolution of EF-hand calcium-modulated proteins, ii. domains of several subfamilies have diverse evolutionary histories. J. Mol. Evol. 34:416-448.
Nowlan,S. J. and Hinton, G. E. 1992. Soft weight-sharing. In Moody,; Hanson, ; and Lippmann, , editors 1992, Advances in Neural Information Processing Systems 4, San Mateo, CA. Morgan Kauffmann Publishers.
Persechini, A.; Moncrief, N. D.; and Kretsinger, R. H. 1989. The EF-hand family of calcium-modulated proteins. Trends in Neurosciences 12(11):462-467.
Sander, C. and Schneider, R. 1991. Database of homologyderived protein structures and the structural meaning of sequence alignment. Proteins 9(1):56-68.
Santner, T.J. and Duffy, D.E. 1989. The Statistical Analysis of Discrete Data. Springer Verlag, NewYork.
Stultz, C.M.; White, J. V.; and Smith, T.F. 1993. Structural analysis based on state-space modeling. Protein Science 2:305-315.
Taylor, WR 1986. The classification of amino acid conservation. Journ The.or Biol 119:205-218.
Waterman, M. S. and Perlwitz, M. D. 1986. Line geometries for sequence comparisons. Bull. Math. Biol. 46:567577.
White, J.V.; Stultz, C.M.; and Smith, T.F. 1991. Protein classification by nonlinear optimal filtering of amino-acid sequences. Unpublished manuscript.

Brown 55

