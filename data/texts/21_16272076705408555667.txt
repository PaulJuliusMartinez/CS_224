DD* Lite: Efﬁcient Incremental Search with State Dominance

G. Ayorkor Mills-Tettey, Anthony Stentz and M. Bernardine Dias

Robotics Institute

Carnegie Mellon University

Pittsburgh, PA 15213

{gertrude, axs, mbdias}@ri.cmu.edu

Abstract

This paper presents DD* Lite, an efﬁcient incremental search
algorithm for problems that can capitalize on state domi-
nance. Dominance relationships between nodes are used to
prune graphs in search algorithms. Thus, exploiting state
dominance relationships can considerably speed up search
problems in large state spaces, such as mobile robot path
planning considering uncertainty, time, or energy constraints.
Incremental search techniques are useful when changes can
occur in the search graph, such as when re-planning paths for
mobile robots in partially known environments. While algo-
rithms such as D* and D* Lite are very efﬁcient incremental
search algorithms, they cannot be applied as formulated to
search problems in which state dominance is used to prune
the graph. DD* Lite extends D* Lite to seamlessly support
reasoning about state dominance. It maintains the algorith-
mic simplicity and incremental search capability of D* Lite,
while resulting in orders of magnitude increase in search efﬁ-
ciency in large state spaces with dominance. We illustrate the
efﬁciency of DD* Lite with simulation results from apply-
ing the algorithm to a path planning problem with time and
energy constraints. We also prove that DD* Lite is sound,
complete, optimal, and efﬁcient.

Introduction

There are many search problems for which state space
reduction can be achieved through simple comparison of
states without compromising the optimality or complete-
ness of the search (Ibaraki 1977; Horowitz & Sahni 1978;
Yu & Wah 1988; Fujino & Fujiwara 1994). For example,
consider the problem of planning a path for a battery pow-
ered mobile robot navigating through some terrain. Suppose
the state of the robot is parameterized by its position and
battery level. Because the available battery power is a ﬁ-
nite resource, we can say that a state, A, is always better
than another state, B, at the same position if it has more bat-
tery power available. We say that state A dominates state
B. Dominance relationships, when they exist, are very im-
portant in search problems because by exploiting these re-
lationships and disregarding dominated states, we can prune
the search space considerably. This enables a much more
efﬁcient solution to the search problem. Dominance rela-
tions have been successfully exploited in problems as varied
Copyright c(cid:13) 2006, American Association for Artiﬁcial Intelli-
gence (www.aaai.org). All rights reserved.

as generating tests for combinatorial circuits (Fujino & Fu-
jiwara 1994) and solving the manufacturer’s pallet loading
problem (Bhattacharya & Bhattacharya 1998).

Formally, given two states in a search algorithm, si and
sj, a dominance relation D is deﬁned as a binary relation
such that siDsj, that is, si dominates sj, implies that sj
cannot lead to a solution better than the best obtainable
from si (Horowitz & Sahni 1978). Dominated states may
be deleted without expansion in the search, thus eliminating
entire branches of the search tree.

Heuristic search techniques such as A* (Hart, Nilsson, &
Raphael 1968) have been successfully used in planning and
many other problems. Dynamic or incremental search al-
gorithms (Frigioni, Marchetti-Spaccamela, & Nanni 2000)
involve efﬁciently computing the paths in a changing graph
such as in a communications network where individual links
may go up or down, in a transportation network where roads
can be detoured, or in a robot’s navigation map where its
sensors may discover new information about its environ-
ment. Combining heuristic search with incremental search
capability, in which solutions are repaired locally when
changes occur, leads to algorithms that support rapid re-
planning and as such are very effective for robot naviga-
tion in unknown or partially known environments. Incre-
mental heuristic search techniques such as D* (Stentz 1994)
and D* Lite (Koenig & Likhachev 2002) have typically been
employed in two-dimensional planning scenarios such as on
a regular grid overlaid on the terrain. However, there are
many scenarios, such as our example of the battery powered
robot, in which the planning and hence re-planning prob-
lem involves a search in a larger state space. For example,
a path planning problem may require reasoning about time,
energy (Tompkins 2005) or even uncertainty (Gonzalez &
Stentz 2005). Increasing the dimensionality, and hence the
size of the state space, greatly limits the set of problems that
can be solved efﬁciently with such techniques. In practice,
however, only a small fraction of the entire state space is
relevant to search. As such, techniques are needed to elimi-
nate regions of the space which do not need to be explored.
Focussing the search using relevant heuristics is one way;
pruning the space by exploiting state dominance is another.
While dominance relations have been used extensively for
pruning in static search problems (Ibaraki 1977; Horowitz &
Sahni 1978; Yu & Wah 1988; Fujino & Fujiwara 1994), it is

1032more complicated to exploit dominance in dynamic or in-
cremental search problems because a previously dominated
branch of the search tree may be needed at a later time when
costs in the graph change. To exploit state dominance in a
dynamic search problem, the TEMPEST planner (Tompkins
2005) explicitly resurrects dominated regions of the space
when changes in the graph occur. However, keeping track
of what regions of the space need to be resurrected can be
complicated.

While the exact deﬁnition of dominance relationships de-
pends on the particular problem domain, the manner in
which dominated states should be handled during the search
is a general problem and can be built into the algorithm.
In an incremental search, states may switch between be-
ing dominated and not dominated as changes occur in the
search graph, and this must be handled seamlessly by the al-
gorithm. In this paper, we introduce the DD* Lite algorithm,
an extension to D* Lite, that supports reasoning about state
dominance, while preserving soundness, completeness, op-
timality, and efﬁciency through incremental search. We ap-
ply DD* Lite to a path planning problem with time and en-
ergy constraints, and present results illustrating that orders
of magnitude gains in performance can result from exploit-
ing state dominance relationships in incremental search.

Incremental Search

The DD* Lite algorithm extends D* Lite, an incremental
search algorithm that enables efﬁcient repair of solutions
when changes occur in a search graph.

As an example incremental search problem, consider a ro-
bot navigating through partially known terrain. The search
graph is an 8-connected graph obtained by overlaying a reg-
ular grid on the terrain. Given the initial knowledge of the
terrain, the algorithm ﬁnds an optimal path from the start to
the goal by computing objective function values (minimum
costs to the goal) for nodes in the graph, as illustrated in Fig-
ure 1(a). Blocked cells are shaded black, while free cells are
clear. In the general case, the traversal cost of a cell may
lie on a continuum between blocked and free. The robot
begins to follow the computed path, but at some point dis-
covers changes in the graph: some cells originally thought
to be blocked are actually free, and other cells thought to be
free are blocked, as shown in Figure 1(b). The portion of
the original path traversed by the robot is indicated with a
dashed line. When the discrepancies are discovered, the al-
gorithm re-plans by searching for an optimal path from the
robot’s current position in the new graph. This path from
the new start location to the goal is indicated by a solid
line. Cells whose objective function values have changed
are shaded gray. Of these, only a few (shaded dark gray) are
relevant to ﬁnding the new solution: D* Lite’s efﬁciency lies
in the fact that it recomputes only these values.

The D* Lite algorithm, like others in the D* family of
algorithms, searches from the goal to the start. In the ro-
bot navigation problem for which it was designed, changes
in the search graph are likely to occur close to the robot’s
current position, as its sensors discover discrepancies in the
environment. Reversing the order of the search in this way,

sgoal
0

1

2

3

4

sgoal
0

1

2

3

4

1

2

3

4

5

6

7

1.4

2.4

3.4

4.4

3.8

4.8

4.8

5.2

4.4

6.2

5.4

5.8

6.8

7.2

6.4

7.2

8.2

8.2

8.6

9.6

9.2

9.6

1

2

3

4

5

6

7

1.4

2.4

3.4

4.4

3.8

4.8

4.8

5.2

4.4

5.4

6.4

5.4

5
.
4

5.8

5
.
8

5
.
8

6
.
8

8.6
sstart

9.6

9
.
6

6.2

7.2

8.2

9.2

9
.
2

11.0

10.6

1
0
.
6

10.2

1
0
.
2

12

11

10.6

10.2

10.6
sstart

(a) Initial solution

13.4

12.4

12.0

11.6

1
1
.
6

11.2

1
1
.
2

(b) Modiﬁed solution

Figure 1: Incremental Search Example

so that areas close to the robot are near the leaves of the
search tree, enables very efﬁcient replanning.

During the search, D* Lite maintains two estimates of the
objective function of a state s: the g-value and the rhs-value.
The g value is the current estimate of the objective function
of the state, while the rhs value is a one step lookahead
estimate of the objective function of the state based on the g
values of its successors (s0) in the graph:
rhs(s) =  0

mins0∈Succ(s)(c(s, s0) + g(s0)) otherwise

if s = sgoal

(1)

In equation 1, c(s, s0) represents the cost of the directed

edge from s to s0.

In D* Lite, a state is deﬁned as consistent if its g-value
equals its rhs-value, and inconsistent otherwise. Speciﬁ-
cally, it is deﬁned as overconsistent if g > rhs and under-
consistent if g < rhs. As the search progresses, inconsistent
states are inserted into the priority queue for processing.

At the beginning of the algorithm, the g and rhs values
of all states are initialized to ∞, except the goal state, sgoal,
whose rhs-value is initialized to 0. States can also be ini-
tialized when they are ﬁrst encountered during the search, to
avoid instantiating all states beforehand in large state spaces.
To start with, the goal is the only inconsistent state and is in-
serted into the priority queue for processing. The main loop
of the algorithm repeatedly processes states from the prior-
ity queue. When an overconsistent state is removed from
the priority queue, its g value is set equal to its rhs value,
thus making it consistent. When an underconsistent state is
removed from the priority queue, its g value is set equal to
∞, thus making it overconsistent. In addition, in either case,
the state’s g value is used to update the rhs values of its
predecessors in the graph according to equation 1, and the
predecessors are in turn inserted into the priority queue if
they become inconsistent. The main loop of the algorithm
terminates when the start state, sstart, has been processed
and is consistent. At this point, an optimal path from sstart
to sgoal has been computed.

1033When changes in the graph occur, D* Lite computes new
rhs values for the affected states and inserts them into the
priority queue if they are inconsistent. The main loop of the
algorithm is then executed again until a new optimal path
has been computed.

D* Lite is algorithmically simple yet efﬁcient, making it
an ideal starting point for an extended algorithm that sup-
ports exploiting state dominance.

Incremental Search with State Dominance

The basic idea underlying search with state dominance is
to identify and prune dominated states before they are ex-
panded.
In incremental search, edge costs in the search
graph may change and so states that were once dominated
may no longer be dominated, and vice-versa. It is important
to keep track of these changes, restoring previously pruned
regions of the space as needed.

To keep track of which states are dominated as we search
through the state space, we label states as dominated or not
dominated. A state is labeled as dominated if there is at
least one other state in the space which dominates it, and
is labeled not dominated otherwise. In the search, we do
not expand dominated states, effectively pruning the subtree
rooted at the dominated state.

We extend the D* Lite algorithm to support this concept.
One extension is that, in addition to keeping track of cur-
rent and one-step lookahead estimates of the objective func-
tion value of a state, as described in the previous section,
we also keep track of current and one-step lookahead esti-
mates of whether or not a state is dominated. Thus, the g
and rhs values are deﬁned as tuples with two components:
an objective function component and a dominance compo-
nent. The objective function component represents the cost
of the path from the state to the goal, and can assume values
ranging from 0 to ∞ inclusive. The dominance component
represents whether or not the state is dominated and can take
on one of two discrete values: NOT DOMINATED or DOMI-
NATED, where NOT DOMINATED<DOMINATED.

g(s) = [gobjf (s), gdom(s)]

rhs(s) = [rhsobjf (s), rhsdom(s)]

(2)
(3)

The g-value is the current estimate of the objective func-
tion and dominance value of a state, while the rhs-value
is the one-step lookahead estimate of the objective function
and dominance value of a state based on the g-values of its
successors in the graph.

We can deﬁne comparison operators on the domain of ob-
jective function and dominance value tuples as follows: ﬁrst
compare the objective function values, and then, in the case
of a tie, compare the dominance values. The <, >,≤,≥, =,
and 6= operators can be deﬁned in this way, as can the min()
and max() functions. For example, we say that g(s) <
g(s0) if and only if (gobjf (s) < gobjf (s0)) ∨ (gobjf (s) =
gobjf (s0) ∧ gdom(s) < gdom(s0)). Similarly, g(s) < rhs(s)
if and only if (gobjf (s) < rhsobjf (s)) ∨ (gobjf (s) =
rhsobjf (s) ∧ gdom(s) < rhsdom(s)).
To focus the search, we deﬁne a heuristic function.
Since the search proceeds from the goal state to the start

state, the heuristic function, represented by h(sstart, s), is
an estimate of the cost from the start state, sstart, to a
given state s. We use g(s) + h(sstart, s) as a shortcut
to represent the tuple, [gobjf (s) + h(sstart, s), gdom(s)].
Similarly, rhs(s) + h(sstart, s) represents [rhsobjf (s) +
h(sstart, s), rhsdom(s)]. In DD* Lite, the heuristic function
must be admissible and consistent. That is, it must represent
a lower bound of the cost to the start, and it must satisfy the
triangle inequality.

As in the D* Lite algorithm, a state, s, is described as
consistent when g(s) = rhs(s), and inconsistent otherwise.
A state is overconsistent if g(s) > rhs(s) and underconsis-
tent if g(s) < rhs(s), where the =, <, and > operators are
as described above. Inconsistent states are inserted into the
priority queue for processing.

Another extension we make to the D* Lite algorithm is
in the deﬁnition of the neighbors of a state, which are used
in computing the state’s rhs value, or whose rhs values are
affected by changes to the state’s g value. In addition to a
state’s predecessors and successors in the graph, we deﬁne
a third class of neighbors: dominance neighbors. The set of
dominance neighbors of a state, s, is the set of states that can
potentially dominate or be dominated by s. Like the prede-
cessors and successors in the graph, the set of dominance
neighbors is problem-dependent.

With this new deﬁnition of the neighbors of a node, we
can specify that the rhs-value of a node, deﬁned in equa-
tion 3, always satisﬁes the following relationship.
In the
following equations, F (s) is used to refer to the set of non-
dominated successors of a state s. D(s) is used to refer to the
set of states which dominate state s. As in D* Lite, c(s, s0)
represents the cost of the directed edge from s to s0.
rhsobjf (s) = 0
rhsdom(s) = NOT DOMINATED if D(s) = ∅
where:
F (s) = {s0 : s0 ∈ Succ(s) ∧ gdom(s0) =NOT DOMINATED} (6)
D(s) = {s0 : s0 ∈ DominanceN eighbors(s)

mins0∈F (c(s, s0) + gobf j(s0)) otherwise

if s = sgoal

DOMINATED

otherwise

(4)

(5)

∧ Dominate(s0, s) ∧ (gobjf (s0) ≤ rhsobjf (s))
∧ (gobjf (s0) + h(sstart, s0)

≤ rhsobjf (s) + h(sstart, s))}

(7)
According to the equations above, the objective function
value of a state s is affected by the objective function and
dominance values of its successors in the graph. Similarly,
the dominance value of s is inﬂuenced by the objective func-
tion values of its dominance neighbors.

The composition of the set D(s) deserves some expla-
nation. The fact that the exact deﬁnition of dominance
is problem-dependent is handled by the use of a function
Dominate(s0, s) which returns TRUE if the state s0 domi-
nates the state s according to the domain deﬁnition of dom-
inance. The formal deﬁnition of dominance requires that a
dominated state does not lead to a solution better than the
best solution that can be obtained from the dominating state.
That is, the dominated state can be ignored without loss of

1034optimality in the solution. Hence, the DD* algorithm also
requires that for a state to be labeled DOMINATED, its objec-
tive function value must be greater than or equal to the ob-
jective function value of the dominating state, as captured by
the third term of equation 7. This guarantees that states la-
beled DOMINATED cannot lead to better solutions than those
obtained from the dominating state. Furthermore, a state is
labeled DOMINATED only when the dominating state has al-
ready been processed off the open list, a condition captured
by the ﬁnal term in equation 7. This makes it possible to
bound the number of times a node is processed off the open
list, as discussed in the section on “Theoretical Properties”.

DD* Lite Algorithm

The basic DD* Lite algorithm is shown in Figure 2. Differ-
ences from the basic D* Lite algorithm are indicated with
line numbers emphasized, such as 1.

The Main() function of the algorithm calls Initialize(),
which initializes the g and rhs values of all states in the
space. Initially, sgoal is inserted into the priority queue as
the only inconsistent state. It is worth noting that in prac-
tice, due to the potentially large size of the state space, only
the goal state is initialized at this time; the other states are
dynamically created and hence initialized only as they are
encountered during the search. Similarly, states are deleted
when they are deemed unreachable (i.e., both the gobjf and
this can occur to predecessors of
rhsobjf values are ∞):
dominated states, or to states that are unreachable due to ob-
stacles in the state space.

Main() then executes ComputeShortestPath(), which con-
tains the principal loop of the algorithm. Like in D* Lite,
ComputeShortestPath() repeatedly removes the state with
the smallest key from the priority queue. The key of a state,
k(s), has two components, [k1(s), k2(s)], where k1(s) and
k2(s) are each an objective function and dominance value
pair, deﬁned as follows: k1(s) = min(g(s), rhs(s)) +
h(sstart, s) and k2(s) = min(g(s), rhs(s)). We compare
two keys, say k(s) and k0(s), by comparing the ﬁrst compo-
nents and, in the case of a tie, comparing the second com-
ponents. Hence, we say that k(s) < k0(s) if and only if
(k1(s) < k01(s)) ∨ (k1(s) = k01(s) ∧ k2(s) < k02(s)).
An overconsistent state (line 20) is processed by being
made consistent on line 21. Cost changes are then propa-
gated to predecessors and dominance neighbors on lines 22-
23, by calling UpdateVertex() on these states. Changes to
the gobjf or the gdom values of a state may affect the rhsobjf
value of its predecessors as indicated in equation 4. Changes
to the gobjf value of a state may affect the rhsdom value of
its dominance neighbors as indicated in equation 5. Updat-
eVertex() computes the updated rhs value of a state. The
state is then inserted into the priority queue if it is inconsis-
tent. Note that if the state has no non-dominated successors,
its rhsobjf value is ∞, which eventually results in the state
being pruned from the space.
An underconsistent state (line 24) is processed by be-
ing made overconsistent on line 25. UpdateVertex() is then
called on its predecessors and dominance neighbors as well
as the node itself, to allow inconsistent states to be inserted

12
13
14
15

16

19
20
21
22

23
24
25
26

The priority queue, U, has the following functions:
U.Insert(node, key) inserts a node into the priority queue
with the given key, U.Pop() removes the node with the
minimum key from the priority queue, U.TopKey() returns the
minimum key of all nodes in the priority queue, and
U.Remove(node) removes a node from the priority queue.

procedure CalculateKey()
1

return
[min(g(s), rhs(s)) + h(sstart, s); min(g(s), rhs(s))] ;

U ←− (cid:11);
for all s ∈ S
rhs(s), g(s) ←− [∞, NOT DOMINATED];
rhs(sgoal) ←− [0, NOT DOMINATED];
U.Insert(sgoal, CalculateKey(sgoal));

procedure Initialize()
2
3
4
5
6
procedure UpdateVertex(s)
7
8
9
10
procedure ComputeRHS(s)
11

if s 6= sgoal ComputeRHS(s);
if s ∈ U U.Remove(s);
if g(s) 6= rhs(s)

U.Insert(s, CalculateKey(s));

F ←− {s0 : s0 ∈ Succ(s) and
gdom(s0) =NOT DOMINATED } ;
tempobjf ←− mins0∈F (gobjf (s0) + c(s, s0));
tempdom ←− NOT DOMINATED;
for all s0 ∈ DominanceN eighbors(s)

if Dominate(s0, s) and gobjf (s0) ≤ tempobjf
and
gobjf (s0) + h(sstart, s0) ≤ tempobjf + h(sstart, s)

17
procedure ComputeShortestPath()
18

tempdom ←− DOMINATED ;
break;
rhs(s) ←− [tempobjf , tempdom];
while U.TopKey() ≤ CalculateKey(sstart) or
rhs(sstart) 6= g(sstart)

s ←− U.Pop();
if g(s) > rhs(s)

else

g(s) ←− rhs(s);
for all
s0 ∈ DominanceN eighbors(s) ∪ P red(s)

UpdateVertex(s0);

g(s) ←− [∞, NOT DOMINATED];
for all s0 ∈
DominanceN eighbors(s) ∪ P red(s) ∪ {s}

UpdateVertex(s0);

Initialize() ;
repeat forever

27
procedure Main()
28
29
30
31
32
33
34

ComputeShortestPath() ;
Wait for changes in edge costs ;
for all directed edges (u, v) with changed edge costs

Update the edge cost c(u, v);
UpdateVertex(u);

Figure 2: DD* Lite

back into the priority queue. ComputeShortestPath() termi-
nates once the start state is consistent and all states that could

1035dominate it have been processed from the priority queue, a
condition captured by the expression on line 18.

Discussion
A couple of ideas underlying the DD* Lite algorithm merit
some comment. First, the DD* Lite algorithm conceptu-
ally implements a tuple-based objective function where the
ﬁrst element is the solution cost and the second is the domi-
nance relation. However, it maintains sufﬁcient information
and performs the checks necessary to incrementally repair
the solution when either the objective function or the dom-
inance relation changes, which would not be possible with
the straight substitution of a tuple-based objective function.
Secondly, while it is typically easy to determine the pre-
decessors and successors of the state from the search graph,
retrieving the “dominance neighbors” of a node may not al-
ways be easy or efﬁcient. Although the correctness of the al-
gorithm is not dependent on identifying all potentially dom-
inated states, the gain in efﬁciency due to pruning obviously
increases with the number of instances of dominance that
are identiﬁed. In general, domain knowledge about potential
dominance relations will need to be exploited to determine
how to store states so that retrieving dominance neighbors
is efﬁcient. For example, in the robot exploration domain
involving a battery-powered rover, we specify dominance
neighbors to be all states that share the same spatial dimen-
sion, and we store these states in a data structure that enables
dominance neighbors to be accessed efﬁciently. In addition,
implementation strategies can allow for efﬁciently stepping
through the set of dominance neighbors. For example, in
the exploration domain, we instantiate states only when they
are ﬁrst encountered in the search so that the list of domi-
nance neighbors of a state is initially small, but grows as the
search progresses. Furthermore, we stop stepping through
dominance neighbors when we encounter one dominating
state, so we often do not have to go through the entire list.

a

expands

Theoretical Properties
As captured in the following theorems, DD* Lite retains the
soundness, completeness and optimality properties of D*
Lite. Additionally, we can prove similar properties concern-
ing its efﬁciency.
Theorem 1 ComputeShortestPath()
non-
dominated state in the space at most twice; namely once
when it is locally underconsistent and once when it is locally
overconsistent.
Theorem 2 ComputeShortestPath() expands a dominated
state in the space at most four times; namely at most once
when it is underconsistent and not dominated, once when it
is overconsistent and not dominated, once when it is under-
consistent and dominated, and once when it is overconsis-
tent and dominated.
Theorem 3 After termination of ComputeShortestPath(),
one can follow an optimal path from sstart to sgoal by al-
ways moving from the current state s, starting at sstart, to
any non-dominated successor s0 that minimizes c(s, s0) +
gobjf (s0) until sgoal is reached (breaking ties arbitrarily).

An informal proof of Theorems 1 and 2 is based on
two observations. First is the observation that the keys of
the states selected for expansion on line 19 of the algo-
rithm are monotonically nondecreasing over time until Com-
puteShortestPath() terminates. This implies that once a state
s is made consistent on line 21, its rhsobjf value does not
change until ComputeShortestPath() terminates. This is be-
cause no state processed after s has a lower key, and hence
a lower objective function value, than s does, implying that
a better path to the goal from s cannot be found.

The second observation is that once a state becomes dom-
inated, it stays dominated until ComputeShortestPath() ter-
minates. Because states are processed in order of increasing
keys, when a dominated state s is processed from the prior-
ity queue, the dominating state s0 is already consistent. s can
become NOT DOMINATED again only if the gobj value of s0
increases, which only occurs if s0 is processed from the pri-
ority queue as an underconsistent state, which in turn does
not occur because s0 is consistent.

Combining these two observations with the fact that the
main loop of the algorithm processes an overconsistent state
by making it consistent and an underconsistent state by mak-
ing it overconsistent, shows that a state is processed from the
priority queue at most once in each of the four different cases
outlined in Theorem 2. If the state is eventually dominated,
it may go through all four scenarios. If it is eventually not
dominated, it is processed in at most two of the scenarios.

Theorem 3 follows from the fact that the ComputeShort-
estPath() terminates only when the start state sstart and all
states with a lower or equal objective function value are con-
sistent. At this point, the gobjf and rhsobjf values of all
states on the path to the goal satisfy equation 4, and from
the equation, none of the rhsobjf values are based on domi-
nated states.

Formal proofs of these theorems appear in an extended
technical report (Mills-Tettey, Stentz, & Dias 2006). The
theorems capture the property that the algorithm correctly
ﬁnds the optimal path between the start and the goal, and
that dominated states are not included on this path. They
also describe the efﬁciency of the algorithm: if no states in
the space are dominated, the algorithm does as much work
as D* Lite, processing each node at most twice. Dominated
states are processed at most four times. Although DD* Lite
potentially does more work per node than D* Lite, we show
in the next section that the performance gains from exploit-
ing state dominance far outweigh the extra processing re-
quired.

Simulation Results

We applied DD* Lite to the problem of planning a path for
a solar-powered mobile robot navigating from a start to a
goal location in partially known terrain. The robot’s solar
panel charges a battery which in turn powers the wheels.
The robot has a ﬁnite battery capacity, MAX BATTERY, and
attempts to reach the goal in the shortest amount of time.
This is a path planning problem in three dimensions: each
state is parameterized by three variables (x, y, e), where x
and y are the two spatial dimensions, and e represents the
energy required to reach the goal.

1036The two spatial dimensions, x and y, are represented as a
regular grid. Each grid cell has an associated time and en-
ergy cost, ct and ce, representing the time and energy respec-
tively required to cross the cell. Time costs are always posi-
tive, but energy costs may be positive or negative to account
for solar charging as well as energy consumption for loco-
motion. When the robot transitions from one cell (x1, y1) to
a neighboring cell (x2, y2), the resulting value of the energy
variable e2 depends on the starting energy e1 and the energy
costs of the two cells.

The problem is to plan a path from the start to the goal
while optimizing traversal time and satisfying energy con-
straints. In this domain, we assert that it is always better to
require less energy to reach the goal. This results in the fol-
lowing deﬁnition of dominace: Two states s1 = (x1, y1, e1)
and s2 = (x2, y2, e2) are dominance neighbors if they are
at the same spatial location, that is, x1 = x2 ∧ y1 = y2.
Furthermore, s1 dominates s2 if e1 < e2. That is, for a state
to dominate another, it must have a lower energy require-
ment. In addition, we use dominance to eliminate states that
are too similar, i.e., that are at the same spatial location and
have very close energy values. We call this type of domi-
nance “resolution equivalency”. This was done to keep the
size of the state space manageable. We used the cost of the
8-connected path assuming minimum time costs as the fo-
cussing heuristic in this domain. This heuristic is both ad-
missible and consistent.

Figure 3 illustrates a path found by the DD* Lite algo-
rithm. The path is shown superimposed on the time and en-
ergy cost maps. In the time map, darker shading represents
larger time costs. In the energy cost map, clear cells indicate
areas where solar charging more than compensates for the
energy requirements of locomotion. Darker cells indicate ar-
eas where this is not the case. The selected path (solid line)
optimizes time while satisfying energy constraints. The path
that would have been selected (dashed line), had there been
no energy constraints, is also shown.

(a) Time cost map

(b) Energy cost map

Figure 3: Example DD* lite plan superimposed on time and
energy cost maps.

To characterize the performance of DD* Lite, we planned
paths through several maps of different sizes with random
time and energy costs. For each map size, we planned paths
for 10 different random costs ﬁelds with the start and goal

states at opposite corners of the map. We compared the plan-
ning time with dominance turned on to that with dominance
turned off (except for resolution equivalency). Figure 4(a)
plots the average planning time in seconds on the vertical
axis against the size of the map on the horizontal axis. The
experiments were run on a Pentium M 770 2.13 GHz proces-
sor. All maps were square, e.g. 64x64. The ﬁgure illustrates
that as expected, exploiting dominance resulted in large im-
provements in planning time. Figure 4(b) illustrates a sim-
ilar comparison for an alternative measure of planning ef-
ﬁciency, that is, the number of unique states visited in the
search.

)
s
(
 
e
m

i

i
t
 
g
n
n
n
a
P

l

1000

100

10

1

0.1

0.01

i

 

d
e
t
i
s
v
s
e
t
a
t
s
e
u
q
n
u
#

 

 

i

1000000

100000

10000

1000

100

8

16

32

64

Map dimension

8

16

32

64

Map dimension

No dominance

Dominance

No dominance

Dominance

(a) Planning time

(b) # unique states encountered

Figure 4: Comparison of planning efﬁciency with and with-
out dominance

Since DD* Lite is an incremental search algorithm, the
real test is of replanning efﬁciency.
In our example, as
the solar powered robot navigates through some terrain, its
sensors will discover discrepancies between its environment
and its prior model of the world. For example, the terrain
in a given cell could be rougher than previously estimated,
resulting in higher time and/or energy costs, or there could
be a greater exposure to sunlight than previously expected,
resulting in lower energy costs. These observed changes
cause the robot to modify its map and replan a new path to
its current location. We compared the efﬁciency of replan-
ning versus planning from scratch for this scenario, again
using maps of varying sizes with random time and energy
costs. The goal was placed at the corner of the grid, while
the start for each run was placed at a random location within
the grid. We planned an initial path to the start location,
made some random changes in the cost ﬁeld in a 3x3 re-
gion at the start location, and replanned a path. The replan-
ning time and the number of states expanded in the search
were compared to the planning time and number of states
expanded when planning a path from scratch in the new cost
ﬁeld. Figure 5(a) shows the ratio of the total plan-from-
scratch time to the total replanning time for 20 runs with
random start locations. It shows that replanning is generally
more efﬁcient than planning from scratch and that, when ex-
pressed as a proportion of plan-from-scratch time, the re-
planning efﬁciency when dominance is exploited is compa-
rable to that when dominance is not exploited. Figure 5(b)
shows similar results for the ratio of the number of states ex-
panded when planning from scratch to the number of states

1037expanded when replanning. These results illustrate that DD*
Lite maintains the incremental search efﬁciency of D* Lite.

 
:
o
i
t
a
r
 
e
m
T

i

l

n
a
p
e
r
/
h
c
t
a
r
c
s
-
m
o
r
f
-
n
a
p

l

100

10

1

:
o
i
t
a
r
 
s
n
o
i
s
n
a
p
x
e
 
#

n
a
p
e
r
/
h
c
t
a
r
c
s
-
m
o
r
f
-
n
a
p

l

l

 

100

10

1

8

16

32

64

8

16

32

64

Map dimension

Map dimension

No dominance

Dominance

No dominance

Dominance

(a) Time

(b) # states expanded

Figure 5: Ratio of performance cost of planning from
scratch versus replanning, with and without dominance

Although the ratio of plan-from-scratch time to replan-
ning time when dominance is exploited is comparable to that
when dominance is not exploited, exploiting dominance re-
sults in performance gains in absolute terms for re-planning
as well as planning. Figure 6(a) compares the average plan-
from-scratch time to the average re-planning time for 20
runs with random start locations. Figure 6(b) compares the
number of states expanded in the search for the same sce-
nario. Both ﬁgures illustrate that exploiting dominance re-
sults in increased efﬁciency in re-planning and planning.

)
s
(
 
e
m
T

i

100

10

1

0.1

0.01

i

s
n
o
s
n
a
p
x
e
#

 

100000

10000

1000

100

10

8

16

32

64

Map dimension

No Dominance (plan-from-scratch)
No dominance (replanning)
Dominance (plan-from-scratch)
Dominance (replanning)

8

16

32

64

Map dimension

No Dominance (plan-from-scratch)
No dominance (replanning)
Dominance (plan-from-scratch)
Dominance (replanning)

(a) Planning/replanning time

(b) # states expanded

Figure 6: Comparison of efﬁciency of planning from scratch
versus re-planning, with and without dominance

Conclusions

We present DD* Lite, an incremental search algorithm that
reasons about state dominance. DD* Lite extends D* Lite
to support reasoning about state dominance in a domain-
independent manner. It maintains the algorithmic simplic-
ity and incremental search capability of D* Lite, whilst en-
abling orders of magnitude improvements in search efﬁ-
ciency in large state spaces with dominance. In addition,
DD* Lite is sound, complete, optimal, and efﬁcient.

An important contribution of the DD* Lite algorithm is
that it enables D*Lite-like incremental search algorithms to

be extended into larger state spaces in a manner that is sim-
ple, easy to understand, and efﬁcient. Several interesting
classes of problems, such as the problem of energy and time
constrained path planning that motivated this work, beneﬁt
from increasing the feasibility of incremental search in these
spaces.

Acknowledgments

This work was sponsored by the Jet Propulsion Labora-
tory, under contract “Reliable and Efﬁcient Long-Range Au-
tonomous Rover Navigation” (contract number 1263676,
task order number NM0710764). The views and conclu-
sions contained in this document are those of the authors and
should not be interpreted as representing the ofﬁcial policies,
either expressed or implied, of NASA or the U.S. Govern-
ment. The authors wish to acknowledge Maxim Likhachev’s
contributions in reviewing this work.

References

Bhattacharya, R., and Bhattacharya, S. 1998. An exact
depth-ﬁrst algorithm for the pallet loading problem. Euro-
pean Journal of Operational Research 110:610–625.
Frigioni, D.; Marchetti-Spaccamela, A.; and Nanni, U.
2000. Fully dynamic algorithms for maintaining shortest
paths trees. Journal of Algorithms 34:351–381.
Fujino, T., and Fujiwara, H. 1994. A method of search
space pruning based on search state dominance. Systems
and Computers in Japan 25(4):1–12.
Gonzalez, J. P., and Stentz, A. 2005. Planning with un-
certainty in position: An optimal and efﬁcient planner. In
Proceedings of the IEEE International Conference on In-
telligent Robots and Systems (IROS ’05).
Hart, P. E.; Nilsson, N. J.; and Raphael, B. 1968. A for-
mal basis for the determination of minimum cost paths.
IEEE Transactions on System Science and Cybernetics
SSC-4(2):100–107.
Horowitz, E., and Sahni, S. 1978. Fundamentals of Com-
puter Algorithms. Computer Science Press.
Ibaraki, T. 1977. The power of dominance relations in
branch-and-bound algorithms. J. ACM 24(2):264–279.
Koenig, S., and Likhachev, M. 2002. D*lite. In AAAI/IAAI,
476–483.
Mills-Tettey, G. A.; Stentz, A.; and Dias, M. B. 2006. DD*
Lite: Efﬁcient incremental search with state dominance.
Technical report, Carnegie Mellon University. (Forthcom-
ing).
Stentz, A. 1994. Optimal and efﬁcient path planning
for partially-known environments. In Proceedings of the
IEEE International Conference on Robotics and Automa-
tion (ICRA ’94), volume 4, 3310 – 3317.
Tompkins, P. 2005. Mission-Directed Path Planning for
Planetary Rover Exploration. Ph.D. Dissertation, Robotics
Institute, Carnegie Mellon University, Pittsburgh, PA.
Yu, C., and Wah, B. W. 1988. Learning dominance rela-
tions in combined search problems. IEEE Transactions on
Software Engineering 14(8):1155–1175.

1038