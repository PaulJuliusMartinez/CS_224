A One-Pass Space-E cient Algorithm for Finding Quantiles
Rakesh Agrawal Arun Swami
IBM Almaden Research Center 650 Harry Road, San Jose, CA 95120
Abstract
We present an algorithm for nding the quantile values of a large unordered dataset with unknown distribution. The algorithm has the following features: i it requires only one pass over the data; ii it is space e cient | it uses a small bounded amount of memory independent of the number of values in the dataset; and iii the true quantile is guaranteed to lie within the lower and upper bounds produced by the algorithm. Empirical evaluation using synthetic data with various distributions as well as real data show that the bounds obtained are quite tight. The algorithm has several applications in database systems, for example in database governors, query optimization, load balancing in multiprocessor database systems, and data mining.
1 Introduction
The p-quantile of an ordered sequence of data values is the smallest value below which p fraction of the total values in the sequence lie. Accurate estimation of the number of tuples satisfying a predicate is a prerequisite for a good query optimizer 11 . It was suggested in 9 that query optimizers should maintain information about attribute values distribution as p-quantiles, and estimation procedures were proposed using p-quantiles. Information about p-quantiles is also useful for balancing workload across multiple processors in a parallel database system 4 .
Current address: Silicon Graphics Computer Systems, 2011 N. Shoreline Blvd, Mountain View, CA 94043.
1

While probabilistic estimates for p-quantile values are adequate for some applications, others require guaranteed bounds on p-quantile values. For example, guaranteed bounds on pquantile values are important in the operation of governors for relational database systems. Governors are used to provide feedback to users on response times for queries. A governor can either indicate the expected response time or provide some upper bound on the response time. For example, SmartMode from the IBI Inc. provides the rst kind of feedback. If guaranteed bounds on response times are required, the governor must use guaranteed bounds on quantile values to estimate selectivities. The need for such predictive governors is a major user requirement. As another example of an application of the guaranteed bounds on the p-quantile values, we cite the algorithm for mining association rules given in 1 . This algorithm concurrently synthesizes several functions of the form fA  A, while making a pass over a relation R, where A is some subset of attributes of R and A is a cut-o threshold that depends on values of A in R. Computation of each of A requires determination of a di erent p-quantile value, with guaranteed bounds.
1.1 Desiderata
The above cited applications yield the following desiderata for an algorithm for nding quantiles:
It should not require prior knowledge of the data distribution.
It should require only one pass over the data, since the data may be too large to t in memory.
It should be space e cient, since p-quantiles values of several attributes of the same relation may need to be obtained.
The true p-quantile should be guaranteed to lie within the lower and upper bounds produced by the algorithm, and the bounds should be tight.
We present in this paper an algorithm that has all of the above features.
1.2 Related work
A straightforward method for nding p-quantiles is to sort the data and then make a pass over the sorted data to nd the desired values. For large datasets, sorting requires multiple passes over the data and may incur large I O costs besides the processing costs. Also, this procedure must be repeated for each attribute of the same relation for which p-quantiles are desired, making it computationally expensive. In 5 , a technique that recursively uses a linear median nding algorithm 2 was proposed. It avoids external sorting and obtains

accurate quantiles. However, this algorithm is not a one-pass algorithm and processes some
data blocks multiple times. The cost of nding quantiles can be reduced by using random sampling 3 . The idea is to
take a random sample of the data, sort the sample values, and then use the sorted sample to estimate the p-quantile values. However, the p-quantile values produced by random sampling do not have guaranteed error bounds. Another algorithm for nding p-quantiles was proposed in 6 . This algorithm maintains a sorted stack of p-quantile estimated values and counts and updates those estimates as new data values are scanned using a piece-
wise parabolic curve- tting technique. Again, no guarantees can be given about the true p-quantile values using this technique. Munro and Paterson 8 describe both single pass and multi-pass algorithms for determining
quantiles they call this the selection problem. Some of the algorithms are probabilistic and may fail to come up with correct bounds for the quantiles. The only deterministic single-pass algorithm they describe requires ON storage, i.e., storage of the same order as the size of the data.
Another method for estimating quantiles works as follows. Let the range of values be partitioned into k intervals. These intervals are known as bins. A single pass is made over the data and the count of values in each bin is accumulated. The bins are scanned from
lowest to highest values and the quantiles are determined based on the counts in the bins. In 10 one such method is analyzed. At rst glance, this method appears to meet all our
criteria. Only one pass is needed, the quantile is guaranteed to lie within a bin and modest computational and storage resources are required. The problem is that unless the data distribution is known a priori, there is no simple way
to determine what the boundaries of the bins should be. Determining the bin boundaries is almost as hard as determining the quantile values. In the absence of any knowledge, bins
of equal width ranging from the minimum value to the maximum value can be used. A problem with this is that we may not know the minimum and maximum values. Sampling
can be used to approximate these values but this requires more work. Even if the minimum and maximum values are known, problems can arise if values that are close together fall into the same bin are of high frequency. This scenario is common in real data where clusters
of high frequency values tend to occur. Multiple frequent values in a single bin may result in highly inaccurate estimates for quantile values.
The algorithm we propose does not require a priori determination of bin boundaries. One way of viewing our algorithm is that it is a dynamic version of the algorithm in 10 in which the bin boundaries are determined on-the- y and are continuously adjusted.

1.3 Formal Problem Statement
Quantile Problem. The p-quantile of an ordered sequence of data values is the smallest
value in the sequence below which p fraction of the total values in the sequence lie. We can express the solution to the p-quantile problem in terms of another problem. Let X = fxig be a large unordered dataset, whose distribution is not known a priori. Denote by kXk the cardinality of X. Let = p  kXk; p 2 0; 1. Given a target count and assuming that kXk  , we can de ne the following problem:
AL-LEQ Problem at least - less than or equal to. Find the smallest value v in X such that kX k  , where X = fxijxi 2 X and xi  v g.
The exact solution to the AL-LEQ problem solves the p-quantile problem. An approximate solution to the AL-LEQ problem would nd a value v in X satisfying all the conditions except that it may not be the smallest such value. Then, the approximate solution provides an upper bound on the p-quantile value. Now consider the following problem:
AM-LT Problem at most - less than. Find the largest value v in X such that kX k , where X = fxijxi 2 X and xi v g.
The approximate solution to the AM-LT problem provides a lower bound on the p-quantile value. Hence, if we can nd approximate solutions to the AL-LEQ and the AM-LT problems, we have guaranteed bounds on the desired p-quantile. If we solve the AM-LT and AL-LEQ problems in the same pass, we obtain the lower and upper bounds respectively for the p-quantile value of X. By solving these problems for di erent values of p in the same pass, we obtain di erent p-quantile values for X. By symmetry, we can obtain lower and upper bounds for the p-quantile value by solving approximately the following problems:
AL-GEQ Problem at least - greater than or equal to. Find the largest value v in X such that kX k  , where X = fxijxi 2 X and xi  v g. AM-GT Problem at most - greater than. Find the smallest value v in X such that kX k , where X = fxijxi 2 X and xi v g.
1.4 Outline of the paper
The rest of this paper is organized as follows. In Section 2, we describe a generic algorithm that can be customized to solve the problems described above. We prove that the algorithm is correct and show an example execution trace. In Section 3, we present an empirical evaluation of the algorithm using both synthetic and real data. We conclude with a summary in Section 4.

2 The Algorithm
We assume, for ease of exposition, that the input dataset X is a set of simple values. In general, X may be an n-ary relation and several functions including accesser functions for attribute values may have been de ned, each of which maps the tuples of the relation to simple values. By maintaining a separate set of counters for each function, the proposed technique can be used for nding quantile values for all of these functions in a single pass. We rst present a generic algorithm, and then show how it can be customized to solve the speci c problems described in Section 1.3.
2.1 The Generic Algorithm
The algorithm given in Figure 1 uses a data structure H, which is an ordered list of k elements e1; e2; : : :; ek. Here k is the maximum number of elements in H, and we assume that k  2. Each element ei of H is a value; count pair. We will use the notations ei:value and ei:count respectively to refer to the value and count elds of the list element ei. The interpretation of these elds is that ei:count is approximately the count of sequence entries that fall between ei:value and ei+1:value. The list H is initially empty. The operator  is a generic comparison operator that will be made speci c in Section 2.2. In Figure 1, NH1 and NH2 need not be computed for every input value by iterating over all the elements in H. These two counts can easily be maintained incrementally. We have omitted these details in to avoid distracting the reader from the main ideas in the algorithm.
2.2 Customization of the Generic Algorithm
AL-GEQ Problem: Maintain H in increasing order of the value eld of the elements.
The  operator is the comparison operator . AL-LEQ Problem:
Maintain H in decreasing order of the value eld of the elements.
The  operator is the comparison operator . AM-GT Problem:
Set = kXk , + 1.
Solve the AL-LEQ Problem for the new value of . AM-LT Problem:
Set = kXk , + 1.
Solve the AL-GEQ Problem for the new value of .

H: An ordered list of maximum k user-speci ed but  2 elements, initialized to be empty forall values x in X do begin
eiflstehseberteegeeixin:icsotusnatn=eleeim:ceonutneti+in1H suchthat ei:value = x then if number of elements in H k then insert x,1 in H
elsifilfextNNdH1eHi11s:cv=aarlPdutheikx=et1nheein:cobuengtin
else begin ilsdneeetstleeeertllte,b1ee:xlct,o1hueniltna=sHt eell,em1:ceonutnotf+Hel:count
end end else begin endsentdeit:hceoulanstt=eieiin:coHunstuc+h1that ei:value  x end
endlief tNNdH2He2le=tePtehki1=e2nei:count
output e1:value
AL-GEQ Problem: H increasing order,   AL-LEQ Problem: H decreasing order,   AM-GT Problem: = kXk , + 1, solve the AL-LEQ Problem AM-LT Problem: = kXk , + 1, solve the AL-GEQ Problem
Figure 1: Generic algorithm and its customization

REMARKS:

If the values are numeric, the AL-LEQ and AM-LT problems can be solved by solving the AL-GEQ and AM-GT problems for the negated values and vice versa. However, in general, X need not be numeric, so that the negation of the values in X is not de ned but the values in X can be ordered and their p-quantiles determined.
Multiple problems can be solved in a single pass by maintaining a separate H list for each problem.

2.3 Example
We show an example execution of the algorithm for the AL-GEQ problem in Figure 2. We are interested in nding the largest value v in input X such that there are at least ve values in X that are greater than or equal to v that is, target count = 5. The list structure H is allowed to have a maximum of 3 elements that is, k = 3. In this gure, the number before colon : is the input value and the list after colon shows the state of H. An element e of this list is represented as VC where e:value = V and e:count = C. The algorithm returns 78 as the answer which happens to be the exact answer.

2.4 Complexity
The time complexity of the algorithm is OkXklogk since any new value has to be inserted in the sorted list of size k. Each problem requires 2  k memory words. Our experiments indicate see Section 3 that a small value for k is su cient to estimate all p-quantiles with
acceptable errors.

2.5 Correctness

We only discuss the correctness of the algorithm for the AL-GEQ problem. The correctness proofs for other problems are similar.

Lemma 1. De ne for element ej

NHj

=

Xk
i=j

ei:count

and

NXj = kfxi 2 X such that xi  ej:valuegk where both NHj and NXj are computed at the same point in time. Some or all of the xi values in X have been read. Then

NHj  NXj

Target count = 5 Maximum number of elements in H, k = 3

Input Stream: 91 55 86 76 41 36 97 25 63 68 2 78 15 82 47

Execution:

91: 911 55: 551 911 86: 551 861 911 76: 552 861 911 41: 552 862
411 552 862 36: 411 552 862 97: 411 552 863
552 863 25: 251 552 863
552 863 63: 552 631 863 68: 552 632 863
632 863 2: 21 632 863
632 863 78: 632 781 863 15: 632 781 863 82: 632 782 863
782 863 47: 471 782 863
782 863

insert 91 ||H|| k insert 55 ||H|| k insert 86 ||H|| k increment the count of 55 delete last, absorbing its count in previous insert 41 discard 36 36 41, total count = target increment the count of 86 delete first, count of remaining = target insert 25 ||H|| k delete first, count of remaining = target insert 63 ||H|| k increment the count of 63 delete first, count of remaining = target insert 2 ||H|| k delete first, count of remaining = target insert 78 ||H|| k discard 15 15 63, total count = target increment the count of 78 delete first, count of remaining = target insert 47 ||H|| k delete first, count of remaining = target

Algorithm Returns: 78

Sorted Stream: 2 15 25 36 41 47 55 63 68 76 78 82 86 91 97

Correct Answer: 78

Figure 2: AL-GEQ Example

for all elements ej in H at all times.

PROOF. At any time, if the algorithm discards an input value x, then x e1:value. In

that case x does not contribute to a count of NHj or NXj for all j.

Otherwise, x contributes to a count of some element ej in H. The element ej is such that

either ej:value = x or ej is the last element in H such that ej:value x. In both the cases,

for 1 value

i NHi

 j, the value NHi has
of remains unchanged

increased by 1 and so also the

and so has the value of NXi .

value

of

NXi ;

for

i

j, the

When the algorithm deletes the last element el of H, el:count is added to el,1:count. Thus,

TthoesveaelutheaotfNNHjHi

arnedmNaiXnj saurnecnhoatnaglewdaaynsdeqeuqaula,lctoonsNidXierfothrei

2 1
case

 l ,
when

1. the

algorithm

deletes

the rst element e1 of H, and the next value v falls between ej and ej+1. Then the value

v is inserted in forgotten", we

position j + 1. Since the have that NHj+1  NXj+1.

values

between

v

and

the

old

ej+1

have

been

Lemma 2. After the processing of m input values,

NH1 = m; if m 

or

NH1  ; if m :

PROOF. No input value is discarded before values have been processed and they all

contribute to a count in H. Once NH1 becomes equal to its value can be reduced only by

the deletion of an element in H. There are two cases: the rst element e1 or the last element

el of H is deleted. The Then NH1 becomes equal last element el is deleted,

rst element is deleted only when the current value
to the current value of NH2 which we know is  el:count is added to el,1:count. Hence the value of

of NH2  .
. When the NH1 remains

unchanged.

Theorem. The algorithm in Figure 1 correctly solves the Al-GEQ problem. PROOF. We have assumed that kXk  . After the set X has been processed, by Lemma 2 NH1  . By Lemma 1, NH1  NX1 . Thus, there are at least values in X that are greater
than or equal to e1:value. The algorithm correctly reports e1:value as the result.

2.6 Additional Heuristics

It is possible to construct pathological cases for the proposed algorithm. The worst-case
error for solving any of the four problems is kXk , kHk. For example, for the AL-GEQ problem, the worst case arises when the rst kHk values in the input data stream consists of the kHk , 1 largest distinct values and the smallest value. In that case, the largest kHk , 1 values will occupy kHk , 1 positions of H and the smallest value will occupy the
rst position.

Several heuristics can avoid this worst case behavior. We present here three such heuristics. The basic idea behind these heuristics is to perturb H in such a way that correctness is not compromised and a position is opened up in H to avoid accumulating a large count at the rst position. Here are the heuristics:
1. After every n input values, where n is an heuristically chosen parameter, do the following: el,1:count = el,1:count + el:count discard el
2. Suppose that the input value is such that it has incremented the count of e1 in H. Now if
e1:count n  NH2
where n is an heuristically chosen parameter, do the following: el,1:count = el,1:count + el:count discard el
3. Suppose that the input value is such that it has incremented the count of e1 in H. Now if1
e1:count  n 
then do the following: el,1:count = el,1:count + el:count discard el
Unfortunately, these heuristics do not always improve the accuracy. In fact, they can even
degrade accuracy as the following example shows. Assume that = 5 and kHk = 3, and
consider the following input stream for the AL-GEQ problem:
1 1 1 1 2 11 12 13 1 3 14 4 15
The algorithm in Figure 1 when applied to this data stream gives 11 as the answer, which is exactly correct. However, if Heuristic 3 with n set to 1 is applied to this data stream, we get 2 as the answer. Fortunately, as the results below using both synthetic and real data show, the empirically observed accuracy of the proposed algorithm is very good. Hence, it does not seem worthwhile to incur the additional implementation complexity due to these heuristics. Our experiments also indicated that on average these heuristics did not improve the accuracy.
1We wish to thank Bruce Lindsay for suggesting a version of this heuristic for n = 1.

3 Empirical Evaluation
We conducted several experiments to empirically assess the behavior of our algorithm. We rst show the results of experiments for X generated according to two distributions: the uniform distribution and the Zipf distribution 12 . For the Zipf distribution, we choose the Zipf parameter to be 0.86, which corresponds to the 80-20" distribution. We also experimented with other distributions by choosing di erent values for the Zipf parameter and found similar results.
The number of values in X kXk was one of f1 million, 2 million, 5 million, 10 milliong. The number of distinct values was xed at kXk 10. The values are positioned randomly in X. The p-quantile bounds were determined for the dectiles, i.e., 10, 20, ..., 80, 90. Denote by Ne the number of tuples between the estimated bounds for each p-quantile. Denote by Nt the number of tuples between the true bounds for the corresponding pquantile. Note that if the value of the p-quantile is duplicated m times then Nt = m. The
relative error is computed as
Ne , Nt=kXk  100
Note that our algorithm gives the bounds on p-quantile values. If a speci c p-quantile value is desired, one can use either of the two bounds for this purpose. If the domain of input values is numeric, one can also take the average of the two bounds. The error we report is the sum of the two errors for the two bounds from the true p-quantile value. Hence, we are being conservative in our error measurement in the sense that we are reporting the sum of two errors. In practice, if we pick either of the bounds for the p-quantile value, we will incur only one of the errors. A number of runs were carried out with the sequence of the data values being varied by changing the seed. For each run, the relative error described above is calculated. The error is estimated by averaging over the errors in the runs. We also calculated the 95 con dence interval. Su cient runs were performed to ensure that the 95 con dence interval was less than 0.1.
3.1 Varying the size of H
We varied the maximum size of H from 250 to 1000 in steps of 250, keeping kXk xed at
1 million. The results of this experiment are shown in Table 1. We observe that beyond a reasonable size for H, the error rates are quite at. In the remaining experiments, we xed the maximum size of H to be 750.
3.2 Varying the size of input
We now test the hypothesis that using a reasonable size of H in our case 750 results in good error behavior for di erent stream sizes, i.e., for di erent values of kXk. In Table 2

Dectiles 10 20 30 40 50 60 70 80 90

Uniform Distribution H Size
250 500 750 1000 1.4 0.4 0.4 0.4 0.5 0.4 0.3 0.2 0.3 0.2 0.1 0.1 2.3 0.6 0.4 0.1 0.5 0.5 0.5 0.5 0.6 0.5 0.5 0.5 1.0 0.3 0.2 0.2 0.0 0.0 0.0 0.0 0.2 0.1 0.1 0.1

Zip an Distribution H Size
250 500 750 1000 0.5 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.3 0.1 0.0 0.0 0.5 0.4 0.3 0.1 1.1 0.5 0.5 0.1 0.9 0.5 0.4 0.4 1.5 0.1 0.1 0.1 0.7 0.2 0.2 0.1 0.5 0.3 0.3 0.2

Table 1: Varying the size of H

Dectiles 10 20 30 40 50 60 70 80 90

Uniform Distribution
kXk
1 2 5 10 million million million million 0.4 0.2 0.6 0.1 0.4 0.4 0.1 0.2 0.1 0.1 0.2 0.1 0.6 0.1 0.4 0.1 0.5 0.4 0.1 0.2 0.5 0.6 0.4 0.2 0.3 0.0 0.1 0.3 0.0 0.6 0.1 0.5 0.1 0.1 0.0 0.1

Zip an Distribution
kXk
1 2 5 10 million million million million 0.0 0.0 0.0 0.1 0.0 0.5 0.3 0.3 0.1 0.1 0.1 0.3 0.4 0.2 0.2 0.4 0.5 0.1 0.0 0.3 0.4 0.3 0.1 0.3 0.1 0.1 0.1 0.0 0.2 0.1 0.4 0.1 0.3 0.4 0.1 0.1

Table 2: Varying the size of input

we show how the errors measured change as kXk varies from 1 million to 10 million. We see that increasing the number of values in the stream X does not a ect the error signi cantly even though the maximum size of H is kept xed at 750. Assume that X is a
set of four byte integers. Each count can be maintained in four bytes. Then, each entry in H is a eight byte entry, and we can determine all the dectiles using about 0.6 megabyte of memory. This shows that using a small bounded amount of memory we can obtain accurate bounds on the p-quantiles. The algorithm becomes even more attractive as the number of values in the stream increases.
3.3 Comparison with Random Sampling
Next we compare the accuracy of our algorithm with random sampling, as random sampling is the technique most often used to estimate quantiles. Random sampling was given the same amount of memory for its sample as used by all the H structures needed for computing the
dectile values. The errors produced by the two algorithms are shown in Table 3 for kXk = 1 million and size of H set to 750.
We see that the accuracy of our algorithm is comparable to the random sampling. In addition, the true p-quantile values are guaranteed to lie within the bounds produced by our algorithm, something that random sampling and other probabilistic algorithms are unable to provide.

Dectiles 10 20 30 40 50 60 70 80 90

Uniform Distribution Our Alg Sampling 0.4 0.1 0.4 0.3 0.1 0.5 0.6 0.5 0.5 0.5 0.5 0.0 0.3 0.1 0.0 0.1 0.1 0.2

Zip an Distribution Our Alg Sampling 0.0 0.1 0.0 0.2 0.1 0.4 0.4 0.1 0.5 0.1 0.4 0.1 0.1 0.3 0.2 0.0 0.3 0.0

Table 3: Comparison with Random Sampling: Synthetic Data

3.4 Reality Check
Finally, we assessed the accuracy behavior of our algorithm on data obtained from some customer databases, and compared it with random sampling. Data sets D1 through D5 had

about 200,000 values and data set D6 had about 11.5 million values. The results are shown in Tables 4 and 5. We see that our algorithm is somewhat more accurate than random sampling. We should note that the real data di ers from the synthetic data we generated in that the real data has more duplicates. Also, the data distributions are not necessarily either uniform or Zip an.

Dectiles 10 20 30 40 50 60 70 80 90

Data Set D1 Our Alg Sampling 0.0 0.2 0.0 0.3 0.0 0.2 0.0 0.3 0.0 0.3 0.0 0.2 0.0 0.0 0.0 0.3 0.0 0.0

Data Set D2 Our Alg Sampling 0.0 0.2 0.1 0.2 0.0 0.2 0.0 0.3 0.0 0.5 0.0 0.3 0.0 0.0 0.0 0.4 0.0 0.0

Data Set D3 Our Alg Sampling 0.0 0.2 0.5 0.0 0.0 0.3 0.1 0.2 0.2 0.3 0.2 0.3 0.4 0.2 0.0 0.2 0.0 0.0

Table 4: Comparison with Random Sampling: Customer Data Sets D1, D2, D3

Dectiles 10 20 30 40 50 60 70 80 90

Data Set D4 Our Alg Sampling 0.0 0.2 0.1 0.2 0.2 0.3 0.0 0.2 0.1 0.3 0.2 0.3 0.0 0.6 0.1 0.0 0.1 0.0

Data Set D5 Our Alg Sampling 0.0 0.1 0.0 0.1 0.0 0.3 0.0 0.2 0.0 0.3 0.0 0.0 0.0 0.0 0.0 0.1 0.0 0.1

Data Set D6 Our Alg Sampling 0.0 0.3 0.0 0.3 0.0 0.0 0.0 0.0 0.0 0.4 0.0 0.1 0.0 1.3 0.0 0.0 0.0 0.5

Table 5: Comparison with Random Sampling: Customer Data Sets D4, D5, D6

4 Summary

We presented an algorithm for estimating p-quantiles that has the following features:
It does not require prior knowledge of the data distribution.
It requires only one pass over data.
The true p-quantile is guaranteed to lie within the lower and upper bounds produced by it.
The bounds produced are quite accurate as shown by the errors observed in the experiments using both synthetic and real data.
It is space e cient. Accurate results were obtained by using a small bounded amount of memory that is independent of the number of values in the dataset.
It was shown in 7 that in the case of queries involving multiple attributes, multi-dimensional equi-depth histograms are superior to equi-width histogram, and an algorithm based on multiple sorts was proposed for this purpose. Finding multi-dimensional equi-depth histograms is the same as nding p-quantiles in multi-dimensions. For future work, it would be interesting to explore how the algorithm proposed in this paper can be generalized to multi-dimensions. Finally, a probabilistic analysis of the proposed algorithm to characterize its average case behavior is a challenging open problem.
Acknowledgments. We thank Tomasz Imilienski for his participation in initial discus-
sions. We also thank Peter Haas, Bruce Lindsay, Guy Lohman and Larry Stockmeyer for their comments.

References

1 MR.aAssgivreawDaal,taTb.asImesi,e"liAnsCkMi, ASI.GSMwaOmDi:93M, Minainyg19A9s3s,oc2i0a7tio2n1s6.between Sets of Items in
2 1M9.72B,lu4m48et4.6a1l., Time Bounds for Selection", Journal of Computers and Systems, 7:4,

3

W. G. Cochran, edition, 1977.

Sampling

Techniques,

John

Wiley

and

Sons,

New

York,

NY,

3rd

4 D. J. DeWitt, J. F. Naughton, and D. A. Schneider, Parallel Sorting on a SharedNothing Architecture using Probabilistic Splitting," 1st Int'l Conf. on Parallel and Distributed Information Systems, Miami Beach, Florida, December 1991, 280 291.

5 A. P. Gurajada and J. Srivastava, Equidepth Partitioning of a Data Set based on FMinindninesgotitas, 1M9e9d0i.ans", Technical Report TR 90-24, Computer Science Dept., Univ. of
6 R. Jain and I. Chlamtac, The P2 Algorithm for Dynamic Calculation of Quantiles 1a0n7d6H1is0t8o5g.rams Without Storing Observations," CACM, Vol. 28, No. 10, Oct. 1985,

7 M. Muralikrishna and D. J. DeWitt, Equi-Depth Histograms for Estimating Selectivi1t9y8F8,ac2t8or3s6f.or Multi-dimensional Queries," ACM SIGMOD 88, Chicago, Illinois, June
8 J. I. Munro and M. S. Paterson, Selection and Sorting with Limited Storage," Theoretical Computer Science, Vol. 12, 1980, 315 323.
9 G. Piatetsky-Shapiro, Accurate Estimation of the Number of Tuples Satisfying a Condition", ACM SIGMOD 84, Boston, June 1984, 256 276.
10 B. W. Schmeiser and S. J. Deutsch, Quantile Estimation from Grouped Data: The 1C9e7ll7,M2i2d1po2i3n4t,." Communications in Statistics: Simulation and Computation, B63,
11 P. G. Selinger, M. M. Astrahan, D. D. Chamberlin, R. A. Lories, and T. G. Price, 7A9,cJceusnseP1a9t7h9S.election in a Relational Database Management System", ACM SIGMOD
12 Gin.g,KM. ZAip, f1,9H49u.man Behavior and the Principle of Least E ort, Addison-Wesley, Read-

