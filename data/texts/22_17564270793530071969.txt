EUROGRAPHICS - IEEE VGTC Symposium on Visualization (2005), pp. 1–9
K. W. Brodlie, D. J. Duke, K. I. Joy (Editors)

High-Quality Volume Rendering with Resampling in the

Frequency Domain

Martin Artner†, Torsten Möller‡, Ivan Viola†, and Meister E. Gröller†

†Institute of Computer Graphics and Algorithms, Vienna University of Technology, Austria

‡School of Computing Science, Simon Fraser University, Vancouver, Canada

Figure 1: The Stanford Head, Tooth, and the Stanford Bunny rendered with our new frequency domain based method.

Abstract
This work introduces a volume rendering technique that is conceptually based on the shear-warp factorization.
We propose to perform the shear transformation entirely in the frequency domain. Unlike the standard shear-warp
algorithm, we allow for arbitrary sampling distances along the viewing rays, independent of the view direction.
The accurate scaling of the volume slices is achieved by using the zero padding interpolation property. Finally, a
high quality gradient estimation scheme is presented which uses the derivative theorem of the Fourier transform.
Experimental results have shown that the presented method outperforms established algorithms in the quality of
the produced images. If the data is sampled above the Nyquist rate the presented method is capable of a perfect
reconstruction of the original function.

Categories and Subject Descriptors (according to ACM CCS): I.3.3 [Computer Graphics]: Picture/Image Generation

1. Introduction and Related Work

The resampling of discrete signals is an important part of any
volume rendering algorithm. The numerically best imple-
mentation of volume rendering is the ray casting approach
introduced by Levoy [Lev88]. For every pixel in the ﬁnal
image a viewing ray is cast into the scene. Numeric integra-

† {artner | viola | meister}@cg.tuwien.ac.at
‡ torsten@cs.sfu.ca

submitted to EUROGRAPHICS - IEEE VGTC Symposium on Visualization (2005)

tion of the volume along the viewing rays is performed. This
requires the computation of equidistant sample points along
each viewing ray. The quality of the resulting image depends
directly on the resampling ﬁlter used in this stage of the ren-
dering process. Research has been done to improve the de-
sign of these spatial domain ﬁlters [MMK∗98], and to eval-
uate and compare the quality of the reconstruction [ML94].

As a basic principle all of these ﬁltering methods are ap-
proximations of the sinc ﬁlter, which provides the ideal sig-
nal reconstruction. Unfortunately the sinc ﬁlter has inﬁnite

2

Artner et al. / High-Quality Volume Rendering with Resampling in the Frequency Domain

extend in the spatial domain, therefore it is usually dismissed
as a theoretical solution. However, the frequency domain
representation of the sinc ﬁlter is a simple box ﬁlter. This
leads to the assumption that volume rendering with sinc ﬁlter
quality is possible if the resampling is done in the frequency
domain. The Fourier transform was introduced to volume
rendering by Dunne et al. [DNR90]. The proposed algo-
rithm, later referred to as frequency domain volume render-
ing (FDVR), or Fourier volume rendering (FVR), was fur-
ther established by Malzbender [Mal93], Levoy [Lev92] and
Totsuka and Levoy [TL93]. The FVR method is based on
the projection slice theorem of the Fourier transform, which
states that projection in the spatial domain is equivalent to
slicing in the frequency domain. If the size of the volume
is N3, the computational expense of FVR is O(N2logN) as
compared to O(N3) of other rendering methods. Therefore
the computational complexity of frequency domain volume
rendering is lower than that of other traditional volume ren-
dering approaches.

Unfortunately even with the most recent improvements
by Lee et al. [LDB96], Westenberger and Roederik [WR00]
and Entezari et al. [ESMM02] which have added lighting ef-
fects, this method generates only “x-ray” like images. The
lack of occlusion and support of transfer functions are the
major drawbacks of this method.

In this paper we utilize the shifting theorem, the pack-
ing theorem (also known as zero-padding), and the derivative
theorem [OS89]. With these theorems we are able to perform
volume rendering using the ideal sinc ﬁlter. Our method
is conceptually based on the shear-warp factorization intro-
duced by Lacroute and Levoy [LL94]. The essence of shear-
warp is a factorization of the viewing transformation into
a permutation, a shear, and a warp transformation. In this
work we propose a new method performing the shear trans-
formation in the frequency domain. To further improve the
quality of the resulting images, two additional modiﬁcations
of the standard shear-warp approach are introduced. First, a
method is proposed for resampling intermediate slices be-
fore the shear operation is applied. This ensures that we
obtain a steerable and view-independent sampling distance
along the viewing rays. Second, we introduce a technique to
perform zooming in the standard object coordinate system as
compared to zooming in the warping stage, which improves
image quality signiﬁcantly. Additionally a high-quality gra-
dient estimation scheme based on the derivative theorem of
the Fourier transform is presented.

During the work on this algorithm a paper by Li et
al. [LME04] was published that uses principles similar to our
method, to perform the resampling of the volume in the fre-
quency domain. Their approach is to decompose the trans-
formation matrix into four shear operations. These four shear
operations are performed by exploiting various frequency
domain techniques and require multiple forward and back-
ward Fourier transforms. In our approach the transformation

matrix is factored according to the shear-warp factorization
which requires only one shear operation to be executed in
the frequency domain. Further, if the volume is resampled
by the application of shear operations it is necessary to add
sufﬁcient spatial domain zero-padding to fully accommodate
the rotated volume. The problem that arises if the spatial
domain zero-padding is too small, is that parts of the data
volume pass over the border of the volume and through the
periodicity of the dataset enter from the other side. This er-
ror is ampliﬁed by the consecutive shears. To allow arbitrary
positions of the viewpoint, a symmetric spatial domain zero-
pad of about
times the maximal volume resolution has
to be applied. This creates an up to three times higher mem-
ory consumption as compared to our method that does not
require spatial domain zero-padding of that amount. We fur-
ther introduce a gradient estimation scheme that takes ad-
vantage of the derivative theorem of the Fourier transform,
which could be also applied to their work.

√3
2

We introduce our new rendering pipeline in the follow-
ing section. Our results are presented in Section 3 which are
followed with conclusions in Section 4.

2. The Rendering Pipeline

The proposed algorithm is based on the shear-warp fac-
torization introduced by Lacroute and Levoy [LL94]. The
shear-warp technique is one of the fastest software based
volume rendering algorithms. It gains its performance by
factoring the projection matrix that transforms the volume
from object space into image space. The transformation de-
scribed by each of these submatrices can be computed very
effectively.

In our work we use the same matrix decomposition as in
the original paper. However, our focus is on high reconstruc-
tion quality. The shear-warp factorization has four stages:
permutation, shearing, compositing and warping. The per-
mutation stage changes the storage order of voxels in mem-
ory in order to maximize cache coherency. During the shear-
ing stage the volume is treated as a set of slices which are
resampled on a sheared grid. The quality of this resampling
process depends very much on the ﬁlter used for the recon-
struction of the signal. Here we propose to perform the shear
by applying the time shifting theorem in the frequency do-
main. The next stage, i.e., the compositing, is equal to a nu-
meric integration along the viewing rays. A major drawback
of the standard shear-warp technique is that the sampling
distance for the numeric integration can not be changed. This
sampling distance is very coarse (≥ 1.0) and view depen-
dent. In our rendering pipeline we propose a resampling step
that allows to perform the numerical integration along the
rays with an arbitrary sampling distance, which is indepen-
dent of the viewing direction. The last stage, i.e., the warp-
ing, transforms the intermediate image of the compositing
stage into the ﬁnal image. The warping in our method re-
mains similar to the standard shear-warp warping. In order

submitted to EUROGRAPHICS - IEEE VGTC Symposium on Visualization (2005)

Artner et al. / High-Quality Volume Rendering with Resampling in the Frequency Domain

3

k

j

i

FFT

3D

(a)

ZERO PAD

IFFT

k

ZERO

PAD

(b)

(c)

(d)

(e)

PHASE SHIFT 
    FD

WARP

COMPOSITE

SHIFT

SD

IFFT

i/j

(j)

(i)

(h)

(g)

(f)

Figure 2: Rendering pipeline of the shear-warp factorization in the frequency domain.

to maintain high-quality a higher-order spatial domain ﬁlter
is used. The quality loss through the resampling of the inter-
mediate image in this stage does not create visible artifacts
in the ﬁnal image.

The adapted rendering pipeline for our new frequency do-
main based method is presented in Figure 2. The ﬁrst stage
of the rendering pipeline starts from the standard object co-
ordinate system, that means the volume is already permuted
such that the (i, j) plane is most perpendicular to the viewing
direction. Through a 3D Fourier transform the next pipeline
stage is reached (see Figure 2(b)).

Resampling in the Principal Viewing Axis: In the stan-
dard shear-warp factorization the number of volume slices
along the principal viewing axis k is kept constant for perfor-
mance reasons. Therefore the distance of the sampling points
along the rays vary with the viewing direction. Figure 3
shows how the sampling distance (s1 vs. s2) varies accord-
ing to the view point settings. Viewing rays are cast from the
left, through the samples of the ﬁrst slice, to the right. The
second sample on each ray is interpolated within the second
plane (black circles). Only a two dimensional interpolation
scheme is required, but an angle dependency of the sampling
distance along the rays (s1, s2) and the distance between the
rays (d1, d2) is introduced. dk indicates the distance between
two slices in k direction. The sample distance variation can

s 2

d2

dk

k

dk

d1

k

s1

Slice 1

Slice 2

Slice 1

Slice 2

Figure 3: The shear transform of the shear-warp factoriza-
tion from two different viewing directions.

arbitrary sampling distance along the rays independent of
the viewing direction. Resampling creates additional volume
slices and is done by exploiting the packing theorem which
is also known as zero-padding in the frequency domain. The
packing theorem states that interpolation in one domain cor-
responds to appending zeros in the other domain. To com-
pute the necessary size of the zero-pad area, the sampling
distance s along the viewing rays before resampling is calcu-
lated. The setup for this calculation is illustrated in Figure 4.
The viewing vector ~vso = (vso,i, vso, j, vso,k) and the distance
between the volume slices along the k axis dk are needed.~vso
is normalized in k direction by dividing each component by
vso,k yielding ~v0so = (v0so,i, v0so, j, v0so,k) with v0so,k = 1.0. The
absolute length |~v0so| of the vector ~v0so is the sampling dis-
tance if the volume slices are 1.0 apart. A multiplication
with dk, the real distance between the volume slices, gives
the sampling distance before resampling.

The sampling distance before resampling s (Equation 1)
and the desired sampling distance s0 are inversely propor-
tional to K the number of slices in the k direction before
resampling, and K0 the number of slices in k direction after
resampling (Equation 2). Using Equation 3 we calculate K0,
the number of samples after zero-padding. The difference
between K0 and K is the amount of zero-padding necessary
for the selected sampling distance s0.

s = dkq(v0so,i)2 + (v0so, j)2 + (v0so,k)2

(1)

s

k

vso,k

vso

dk

1.0

Slice 2

Slice 1

create artifacts that are especially visible in animations. Re-
sampling of the volume in k direction allows to select an

Figure 4: Resampling along k direction.

submitted to EUROGRAPHICS - IEEE VGTC Symposium on Visualization (2005)

4

Artner et al. / High-Quality Volume Rendering with Resampling in the Frequency Domain

a xkSD

a xkFD

a xk

Figure 5: The shift of the signal by axk is split into a spatial
domain (axkSD) and a frequency domain (axkFD) fragment.

=

s0
s
K0 =

K
K0
sK
s0

(2)

(3)

As zero-padding can only be applied in discrete steps, K0
has to be rounded to the closest integer number K0pad ∈ N.
This is typically not an issues, since the numerical integra-
tion improves by the number of slices that are being used.

the spatial domain is actually only a movement of the slice
in full voxel steps. The interpolation part is performed in the
frequency domain. The reason for this split is to keep the
shift in the frequency domain as small as possible to limit
wrapping effects. These effects appear because in the Fourier
transform the volume slices are assumed to be periodic in i
and j directions. To limit the wrapping effects a symmetric
spatial domain zero-pad of one voxel has to be added to sep-
arate the periodic replicas in the spatial domain.

The shifting theorem of the Fourier transform states that
a signal can be shifted in the spatial domain by the applica-
tion of phase shifts in the frequency domain. This theorem
is used to perform the axkFD shift, and the rendering stage
Figure 2(f) is reached. An inverse Fourier transform in i and
j direction moves the rendering process to stage Figure 2(g).
The axkSD part of the slice displacement is applied in the
spatial domain, which completes the transformation of the
volume to the sheared object space, see Figure 2(h).

After the application of the zero-pad in k direction the
pipeline stage Figure 2(c) is reached. The next stage is an
inverse Fourier transform in k direction, while the i and j di-
rection of the volume remain in the frequency domain (Fig-
ure 2(d)).

Compositing: During the compositing stage the resam-
pled slices are blended into a 2D intermediate image along
the k axis. Transfer functions can be applied to the volume,
as well as other visualization techniques (e.g., shading, non-
photorealistic effects, etc.).

Resampling of Volume Slices in i and j Direction:
In the standard shear-warp factorization zooming is per-
formed by scaling of the intermediate image. This approach
leads to considerable blurring artifacts, especially for zoom
factors greater than 2.0, as pointed out by Sweeney and
Mueller [SM02]. In our method zooming is performed ear-
lier, in the standard object space where the rescaling is ap-
plied to the volume slices. Desired slice resolution (I0, J0)
is achieved by increasing the signal period of each slice by
zero-padding in the frequency domain. As adding samples
is only possible in discrete steps a particular zoom factor
can only be achieved with limited precision. If I0pad > 50
and J0pad > 50 then the deviation of the zoom factor is be-
low ±1.0% of I0 and J0. This problem is also present for
any computer screen, which only has pixel accuracy. Hence,
this is a general drawback of any discrete storage-based
pipeline. After the application of the zero-pad the render pro-
cess reaches the stage in Figure 2(e).

Shearing: During shearing the volume is transformed
from standard object space to sheared object space. This
causes the viewing direction to be perpendicular to the slices
of the volume. Performing the calculations explained in de-
tail in Lacroute’s thesis [Lac95] we acquire the shear coef-
ﬁcients (si, s j) and the translation values (ti, t j). The values
aik and a jk describe the displacement of the kth slice in i and
j direction. For both directions the shifts by axk (x ∈ {i, j})
are split into a multiple of the voxel lengths axkSD and the
remainder, a fraction of a voxel length axkFD (see Figure 5).

The shift by axkFD is performed in the frequency domain,
and the shift by axkSD is done in spatial domain. The shift in

During compositing the density information of each slice
ˆfIJ[i, j] is transformed into an image bIJ[i, j]. Each pixel in
bIJ[i, j] has a color c and a transparency coefﬁcient α. Every
image is then composited using the “over” operator [PD84],
which results in the non-warped intermediate image (see
Figure 2(i)).

Warping: The 2D warping transformation applied to the
intermediate image leads to the ﬁnal image. The warping
matrix transforms data points from the sheared object space
into the ﬁnal image space. This transformation compensates
the view dependent scaling of the distances between the
viewing rays (compare d1 and d2 in Figure 3), and performs
the rotation component around the k axis.

If M is the maximal volume extension (maximum of i,
j and k in standard object space), and zi j is the scale fac-
tor applied to the volume, then an image buffer fNN [xi, yi]

with N = √3 · zi j · M can accommodate the resulting im-

age. This calculation is based on the assumption that each
side of the volume has length M and the main diagonal
of the volume is visible in its full length. Every pixel of
fNN [xi, yi] in the image-coordinate space is transformed to
the sheared-object space with the inverse of the warping ma-
trix. The pixel values at the obtained coordinates are inter-
polated from the pixel values of the intermediate image. In
order to maintain high quality, a higher-order spatial domain
ﬁlter (D0 C3 4EF [MMK∗98] comparable to Catmull-Rom
spline [BBB88]) is used for the resampling.

Gradient Estimation: In order to obtain surface normals
for lighting calculations we introduce a high quality gradient
estimation scheme. Since the gradient consists of the partial

submitted to EUROGRAPHICS - IEEE VGTC Symposium on Visualization (2005)

Artner et al. / High-Quality Volume Rendering with Resampling in the Frequency Domain

5

 

r
o
r
r
e
S
M
R

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

(B-Spline)

(Linear)

(CR-Spline)

DN_C2_2EF
DN_C3_4EF
D0_C0_1EF
D0_C2_2EF
D0_C1_3EF
D0_C3_4EF
FD Method

0

50 100 150 200 250 300 350 400 450

Image Length

Figure 6: Error when zooming a slice of ρml with several
spatial domain ﬁlters and by zero padding in the frequency
domain.

 

r
o
r
r
e
S
M
R

0.45
0.40
0.35
0.30
0.25
0.20
0.15
0.10
0.05
0

(B-Spline)

(Linear)

(CR-Spline)

DN_C2_2EF
DN_C3_4EF
D0_C0_1EF
D0_C2_2EF
D0_C1_3EF
D0_C3_4EF
FD Method

0

0.2

0.4

0.6
Samples Shifted

0.8

1

Figure 7: Error when shifting a slice of ρml for sub-pixels
with several spatial domain ﬁlters and phase shifts in the
frequency domain.

derivatives of the original function and ideal interpolation
with the sinc ﬁlter will reconstruct that function, the gradient
can be reconstructed exactly by using the derivate of the sinc
as a reconstruction kernel [BLM96].

For the computation of the gradient vectors three copies
of the original dataset are created and Fourier transformed
in all three space dimensions. Each one of these volumes is
used to calculate one component of the gradient vector. The
derivative theorem of the Fourier transform states that the
derivative of a signal in spatial domain can be computed by
a multiplication in frequency domain. This theorem is used
to derive each volume in one of the three space dimensions.
Subsequently these gradient volumes are processed through
the same rendering pipeline as the density volume. The gra-
dient volumes are combined to a volume of gradient vectors
at the compositing stage. These gradient vectors are used
with the processed original data to compute the intermedi-
ate image.

3. Results

Several 3D datasets are used to compare the reconstruction
quality of the frequency domain method to standard spatial
domain ﬁltering. Two categories of datasets are used, syn-
thetic datasets and CT-scans.

Synthetic Test Dataset: To test

the quality of

the

submitted to EUROGRAPHICS - IEEE VGTC Symposium on Visualization (2005)

new interpolation method, the test function introduced by
Marschner and Lobb [ML94] is used. In this work we refer
to it as ρml. This dataset is sampled almost according to the
Nyquist criteria, i.e., 99.8% of the signal energy is captured.

When using the discrete Fourier transform (DFT) the as-
sumption is that the signal is periodic and discrete in the spa-
tial and the frequency domain. Through the sampling of ρml
we get one period of this signal, which is half the period of a
sine wave in z direction. In z direction, in the zone between
two of these periods, a jump in the signal is present, which
is a source of artifacts. In order to demonstrate the impact
of this discontinuity, but to maintain compatibility with the
original signal ρml a second synthetic dataset was created.
The sample points of ρml are mirrored along the z = −1
plane. The samples at z = −1 are not copied, because they
are positioned at the plane of reﬂection. Further the samples
at z = +1 are not copied as well to create smooth transi-
tions in the periodic sequence of sine waves. This creates
an extended version of the test dataset with dimensions of
41× 41× 80 samples. The extended test dataset is referred
to as ρmlext .

Real-World Test Datasets: The dataset used in Figure 9
was originally created by Levoy and is provided for research
purposes by the Stanford volume data archive. The original
resolution of 512 × 512 × 360 was downsampled to 128 ×
128 × 133 by removing high frequency components in the
frequency domain representation of the datasets. Further, a
Hamming window was applied in all three space directions
to reduce ringing artifacts.

Quality Comparison to Spatial Domain Filters: This
section presents several experiments to show the advantages
and disadvantages of the frequency domain based techniques
as compared to spatial domain ﬁltering.

Image Zooming: The purpose of this experiment is to
compare the quality of zooming by zero-padding in the fre-
quency domain to interpolation with spatial domain ﬁlters.
As the newly introduced rendering algorithm is based on the
shear-warp factorization, most of the rendering steps that are
quality critical are performed on volume slices. Initially a
41 × 41 slice of the ρml function at the position of z = 0
was taken. This slice was then zoomed by a factor f with
f ∈ {2, 3, 4, 5, 6, 7, 8, 9, 10}, in x and y direction. The zoom-
ing of the volume slices by the factor f was done by zero
padding in the frequency domain and by resampling with
standard spatial domain ﬁlters. The synthetic function ρml
with z = 0, was evaluated on an f times denser grid, to cre-
ate a reference solution for this zooming operation. The ref-
erence solution was subtracted from the resampled slices.
To avoid disturbances at the border, after scaling and sub-
traction of the reference image, a frame of 15 samples was
set to 0 in the resulting slices. Finally the root-mean-square
of these slices was used to draw Figure 6. We can observe
that the frequency domain based method (FD method) has
the lowest error. If the ρml dataset would have been sampled

6

Artner et al. / High-Quality Volume Rendering with Resampling in the Frequency Domain

Figure 8: Quality comparison of the analytic dataset ρml with different reconstruction schemes. The ﬁrst column shows refer-
ence images rendered by analytically evaluating the ρml function. The images of the subsequent columns were rendered (from
left to right) based on DN C2 2EF (B-spline) and D0 C0 1EF (Catmull-Rom spline) interpolation, and the new frequency
domain based method applied to the ρml and the ρmlext dataset. The ﬁrst row displays an iso-surface extraction. The second
row shows divergence images of the estimated gradient direction to the analytic reference gradient. The third row presents
resampled center slices (x = 0) of the ρml and ρmlext datasets.

exactly according to the Nyquist criteria, a perfect scaling
with the frequency domain based method would be possible
(RMS error of zero).

To visually demonstrate the quality of zooming with these
methods, a slice (x = 0) of the ρml and the ρmlext dataset
was zoomed by a factor of 10.0 in y and z direction. To
emulate the iso-surface extraction used by Marschner and
Lobb [ML94], the range of voxel values f (x, y, z) from 0.0
to 1.0 was mapped to the gray scale color range 0 to 255.
Afterwards the color of the data points with a value of
f (x, y, z) < 0.5 was set to black.
The ρml dataset has a resolution of 41× 41× 41, and the
ρmlext dataset has a resolution of 41× 41× 80. Therefore a
slice taken at x = 0 from ρml has a resolution of 41× 41, a
slice taken at x = 0 from ρmlext has a resolution of 41× 80.
The lower half of the ρmlext slice is just a mirror of the upper
one. To create slices of the same size, for easier comparison,
the lower half of the slices created from ρmlext was removed
after the zooming process (see third row of Figure 8).

Volume Slice Displacement: Initially a 41 × 41 slice of
the ρml function, with z = 0 was extracted. Sub-pixel shifts
where applied in both x and y direction. As a reference the

function ρml was evaluated shifted by the same amount. To
avoid disturbing inﬂuences of the border regions, a 7 sam-
ples wide border area was set to 0. This size was chosen
because it is the biggest used spatial domain ﬁlter kernel
size (6) plus one additional sample. Therefore no sample that
was inﬂuenced by information outside the 41× 41 samples
affects the result. The root-mean-square of these ﬁnal error
images was then used to draw Figure 7. It is easy to see that
the frequency domain based method has the smallest devia-
tion of the synthetic reference result.

Gradient Estimation: In the rendering algorithm intro-
duced in this work the gradients are calculated by exploiting
the derivative theorem of the Fourier transform. In order to
compare the quality of the frequency domain gradient esti-
mation scheme to standard methods that use analytic deriva-
tives of interpolation ﬁlters in the spatial domain, the ρml
and the ρmlext dataset were rendered as a benchmark. The
ﬁrst row of Figure 8 shows rendered images with a sampling
distance of 0.05 and a zoom factor of 10.0. For better com-
parison of the accuracy of the gradient estimation, parallel to
the rendering process a synthetic gradient vector was calcu-
lated by evaluating the derivatives of the analytic function.
The angular discrepancy between the calculated and the an-

submitted to EUROGRAPHICS - IEEE VGTC Symposium on Visualization (2005)

Artner et al. / High-Quality Volume Rendering with Resampling in the Frequency Domain

7

The Stanford Bunny rendered (from left

Figure 9:
to right) with D0 C0 1EF (linear), DN C2 2EF (B-spline),
D0 C1 3EF (Catmull-Rom spline) interpolation, and the new frequency domain based method. The zoom factor in i and j
direction for the images of the ﬁrst row was 10.0 and for the second row 20.0.

alytic gradient was used to draw the images in the second
row of Figure 8. The gray value of 255 represents an angular
error of 20◦ or more.

The gradient estimation of the frequency domain based
method in Figure 8 is more accurate than the results of the
spatial domain methods. Perfect reconstruction would be
possible if the dataset is sampled according to the Nyquist
criteria.

Resulting Images: The resampling and derivative com-
putations are performed with sinc ﬁlter quality. This ﬁlter
allows perfect reconstruction of the original signal if the
sampling was done according to the Nyquist criteria. Data,
which is not alias-free (e.g. ρml) will show typical artifacts
(such as ringing for ρml in Figure 8 fourth column). Tradi-
tional frequency methods (such as windowing) or non-sinc
ﬁlters, that include a smoothing step should be applied in
such cases. The images in Figure 1 are based on CT-scan
datasets. The Stanford Head and the Tooth images were cre-
ated with our new frequency domain resampling and the ap-
plication of standard transfer functions. In the images ren-
dered from the Stanford Bunny dataset a volumetric pro-
cedural texture was used to color the iso-surface. Figure 8
shows images of the synthetic datasets ρml and ρmlext . The
ﬁrst column shows reference images rendered by analyti-
cally evaluating the ρml function. The images of the sub-
sequent columns were rendered (from left to right) with
DN C2 2EF (B-spline) interpolation, D0 C0 1EF (Catmull-
Rom spline) interpolation, and the new frequency domain

submitted to EUROGRAPHICS - IEEE VGTC Symposium on Visualization (2005)

based method applied to the ρml and the ρmlext dataset. The
ﬁrst row displays an iso-surface extraction. The second row
shows error images of the estimated gradient direction to the
analytic reference gradient. The gray value of 255 represents
an angular error of at least 20◦. The third row presents re-
sampled center slices (x = 0) of the ρml and ρmlext datasets.
As the ρml dataset is not sampled alias-free strong ringing
artifacts are present in the images rendered with the new fre-
quency domain based method. The ρmlext dataset is sampled
closer to the Nyquist criteria and therefore the reconstruc-
tion quality is higher (compare the last two columns in Fig-
ure 8). The spikes are reproduced by the frequency domain
method with much higher accuracy than with the spatial do-
main methods. The images in Figure 9 are based on the Stan-
ford Bunny dataset. The dataset is displayed with a 10.0 and
20.0 times zoom, with the sampling distance in k direction
set to 0.05. This ﬁgure demonstrates that the rendering qual-
ity of the frequency domain based method is superior to stan-
dard spatial domain ﬁltering.

Performance: In the current implementation the fre-
quency domain resampling does not create images at an
interactive rate. The main impact on the rendering perfor-
mance is caused by the global gradient estimation scheme.
Gradients are calculated for the whole volume, even if they
are just used on a small portion of the voxels, like an iso sur-
face. This leads to a considerable computational overhead
that is not contributing to the ﬁnal image.

In our approach, to perform a zoom of the ﬁnal image

8

Artner et al. / High-Quality Volume Rendering with Resampling in the Frequency Domain

every volume slice is resampled before the projection onto
the intermediate image. This creates a noticeable impact on
rendering speed, but leads to signiﬁcant quality improve-
ments in the resulting images. This superior image quality
is bought with a computational effort that is proportional to
the number of volume slices and is higher than zooming in
the warping stage. Currently, if images are zoomed, and only
a small section of interest is to be displayed, the whole image
has to be calculated.

4. Conclusions and Future Work

We have developed a volume rendering algorithm that per-
forms resampling using the ideal interpolation ﬁlter (sinc)
and hence achieves the best theoretical quality. This has been
achieve by exploiting signal processing ideas, such as the
shifting theorem, the packing theorem and the derivative the-
orem. Using synthetic and real data sets, we have demon-
strated that this method can render properly sampled volume
data with higher quality than standard spatial domain resam-
pling. We noted, that special care is required for data whose
periodic extension in the spatial domain would intoduce dis-
continuities. This can always be ﬁxed by a mirrowed exten-
sion. Further, a high-quality gradient estimation scheme that
provides very accurate surface normals for lighting calcula-
tions was introduced.

Our current

implementation has not been optimized.
There are aspects that have to be addressed in order to im-
prove the practicality of the frequency domain resampling.
(Li et al. [LME04] have demonstrated that an efﬁcient im-
plementation can outperform traditional spatial domain ﬁl-
tering.

The ﬁrst challenge is to reduce the memory consumption.
This could be done by exploiting the fact that the data is
given as a real function with a Hermitian Fourier transform.
A Hermitian function has symmetries which allow halve of
the memory to be conserved. The impact on the separability
of the Fourier transform on such a data structure has to be
investigated.

Zooming operations (for the visualization of detailed
structures) could be accellerated by using partial inverse
Fourier transforms.

In order to achieve perspective projection, scaling of vol-

ume slices with arbitrary factors has to be developed.

Acknowledgments

This work was performed during a research stay of the ﬁrst
author at Simon Fraser University. Partial funding of this re-
search was provided by the British Columbia Advanced Sys-
tems Institute.

We would like to thank Alireza Entezari and Steven
Bergner at the Graphics, Usability and Visualization Lab

at Simon Fraser University for their helpful comments and
fruitful discussion. Some of the data sets have been provided
by volvis.org.

References

[BBB88]

[BLM96]

BARTELS R., BEATTY J., BARSKY B.: An
Introduction to Splines for Use in Computer
Graphics and Geometric Modelling. Morgan
Kaufmann, Palo Alto, CA, 1988. 4

BENTUM M. J., LICHTENBELT B. B. A.,
MALZBENDER T.: Frequency analysis of gra-
dient estimators in volume rendering.
IEEE
Transactions on Visualization and Computer
Graphics 2, 3 (1996), 242–254. 5

[DNR90] DUNNE S., NAPEL S., RUTT B.: Fast repro-
jection of volume data. In Proceedings of the
1st International Conference on Visualization
in Biomedical Computing (1990), pp. 11–18. 2

[ESMM02] ENTEZARI A., SCOGGINS R., MÖLLER T.,
MACHIRAJU R.: Shading for Fourier volume
rendering.
In Proceedings of the 2002 IEEE
Symposium on Volume Visualization (2002),
IEEE, pp. 131–138. 2

[Lac95]

[LDB96]

[Lev88]

[Lev92]

[LL94]

[LME04]

LACROUTE P. G.: Fast volume rendering us-
ing a shear-warp factorization of the viewing
transformation. PhD thesis, Computer Systems
Laboratory, Department of Electrical Engineer-
ing and Computer Science, Stanford Univer-
sity, 1995. 4

LEE Z., DIAZ P. J., BELLON E. M.: Analysis
of Fourier volume rendering. In IEEE Proceed-
ings of the 1996 Fifteenth Southern Biomedical
Engineering Conference (1996), pp. 469–472.
2

LEVOY M.: Display of surfaces from volume
data.
IEEE Computer Graphics and Applica-
tions 8, 3 (1988), 29–37. 1

LEVOY M.:
Volume rendering using the
Fourier projection-slice theorem. In Proceed-
ings of Graphics Interface ’92 (1992), pp. 61–
69. 2

LACROUTE P. G., LEVOY M.: Fast volume
rendering using a shear-warp factorization of
the viewing transformation. Computer Graph-
ics 28, Annual Conference Series (1994), 451–
458. 2

LI A., MUELLER K., ERNST T.: Methods for
efﬁcient, high quality volume resampling in the
frequency domain. In Proceedings of the 2004
IEEE Visualization (2004), IEEE, pp. 3–10. 2,
8

submitted to EUROGRAPHICS - IEEE VGTC Symposium on Visualization (2005)

Artner et al. / High-Quality Volume Rendering with Resampling in the Frequency Domain

9

[Mal93]

[ML94]

MALZBENDER T.: Fourier volume rendering.
ACM Transactions on Graphics 12, 3 (1993),
233–250. 2

MARSCHNER S. R., LOBB R. J.: An evalua-
tion of reconstruction ﬁlters for volume render-
ing. In Proceedings of Visualization ’94 (1994),
IEEE, pp. 100–107. 1, 5, 6

[MMK∗98] MÖLLER T., MUELLER K., KURZION Y.,
MACHIRAJU R., YAGEL R.: Design of accu-
rate and smooth ﬁlters for function and deriva-
tive reconstruction.
the
1998 IEEE Symposium on Volume Visualiza-
tion (1998), pp. 143–151. 1, 4

In Proceedings of

[OS89]

[PD84]

[SM02]

[TL93]

[WR00]

OPPENHEIM A. V., SCHAFER R. W.:
Discrete-Time Signal Processing.
Prentice
Hall Signal Processing Series. Prentice Hall,
Englewood Cliffs, NJ, USA, 1989. 2

PORTER T., DUFF T.: Compositing digital im-
ages. Computer Graphics 18, 3 (1984), 253–
259. 4

SWEENEY J., MUELLER K.:
Shear-warp
deluxe: The shear-warp algorithm revisited. In
Proceedings of the 2002 Symposium on Data
Visualisation (2002), Eurographics Associa-
tion, pp. 95–104. 4

TOTSUKA T., LEVOY M.: Frequency domain
volume rendering. Computer Graphics 27, An-
nual Conference Series (1993), 271–278. 2

WESTENBERG M. A., ROERDINK J. B. T. M.:
Frequency domain volume rendering by the
wavelet x-ray transform. IEEE Transactions on
Image Processing 9, 7 (2000), 1249–1261. 2

submitted to EUROGRAPHICS - IEEE VGTC Symposium on Visualization (2005)

