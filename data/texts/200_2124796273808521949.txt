From: AAAI-98 Proceedings. Copyright © 1998, AAAI (www.aaai.org). All rights reserved. 

Towards Text Knowledge Engineering

Udo Hahn & Klemens Schnattinger

L I F Computational Linguistics Group
Text Knowledge Engineering Lab

Freiburg University

Werthmannplatz 1, D-79085 Freiburg, Germany

http://www.coling.uni-freiburg.de

Abstract

bjectO

Action

Degree

We introduce a methodology for automating the maintenance
of domain-speciﬁc taxonomies based on natural language text
understanding. A given ontology is incrementally updated as
new concepts are acquired from real-world texts. The acqui-
sition process is centered around the linguistic and conceptual
“quality” of various forms of evidence underlying the gener-
ation and reﬁnement of concept hypotheses. On the basis of
the quality of evidence, concept hypotheses are ranked ac-
cording to credibility and the most credible ones are selected
for assimilation into the domain knowledge base.

Introduction

Knowledge engineering is still an expert task. Though a va-
riety of architectures have been proposed to date (Buchanan
et al. 1983), the dominating paradigm for the process of elic-
iting and maintaining domain ontologies continues to focus
on the interactive knowledge transfer from humans to ma-
chines (Steﬁk 1995). Some experimental activities tried to
make use of machine learning methods in order to induce
knowledge from structured data repositories (Morik et al.
1993), but even fewer efforts were targeted at unstructured
natural language texts as a source for automating knowledge
engineering processes (Gomez & Segami 1990).

We propose here such a text-based knowledge acquisition
methodology, in which domain knowledge bases are contin-
uously enhanced as a by-product of text understanding pro-
cesses – hence, text knowledge engineering. New concepts
are acquired taking two sources of evidence into account:
background knowledge of the domain the texts are about,
and linguistic patterns in which unknown lexical items oc-
cur. Domain knowledge serves as a comparison scale for
judging the plausibility of newly derived concept descrip-
tions in the light of prior knowledge. Linguistic knowledge
assesses the strength of the interpretative force that can be
attributed to the grammatical construction in which new lex-
ical items occur. Our model makes explicit the kind of qual-
itative reasoning that is behind such a learning process.

This is, then, a knowledge-intensive model of concept ac-
quisition, tightly integrated with the non-learning mode of
text understanding. The “plain” text understanding mode

0Copyright c 1998, American Association for Artiﬁcial Intel-

ligence (www.aaai.org). All rights reserved.

PhysicalObject

Product

...

...

Technology

Hardware

S

oftware

eviceD

...

Computer

P
ossession
<agent : Object>
<patient : 

Object,Degree>

PhysicalSize
<size-of :

Product, ...>

inst-of?

inst-of?

inst-of
?

inst-of?

inst-of
?

Itoh-Ci-8

agent

patient

size.1

possess.1

size-of

"The Itoh-Ci-8 has a size of ..."

Figure 1: A Sample Scenario

can be considered the instantiation and continuous role ﬁll-
ing of single concepts already available in the knowledge
base. Under learning conditions, a set of alternative concept
hypotheses are managed for each unknown item, with each
hypothesis denoting a newly created conceptual interpreta-
tion tentatively associated with the unknown item.

For illustration purposes, consider the following scenario
as depicted in Fig. 1. Suppose, your knowledge of the infor-
mation technology domain tells you nothing about an Itoh-
Ci-8. Imagine, one day your favorite technology magazine
features an article starting with “The Itoh-Ci-8 has a size of
. . . ”. Has your knowledge increased? If so, what did you
learn from just this phrase?

The text knowledge acquisition process starts upon the
reading of the unknown lexical item “Itoh-Ci-8”.
In this
initial step, the corresponding hypothesis space incorporates
all the top level concepts available in the ontology for the
new lexical item “Itoh-Ci-8”. So, the concept ITOH-CI-
8 may be a kind of an OBJECT, an ACTION, a DEGREE,
etc. As a consequence of processing the noun phrase “The
Itoh-Ci-8” as the grammatical subject of the verb “has”,
ITOH-CI-8 is related via the AGENT role to the ACTION

linguistic
quality
labels

conceptual

quality
labels

dependency parse tree

terminological
knowledge base

Language Processor

Hypothesis
space-1

Hypothesis
space-i

1

2

Hypothesis
space-p

Hypothesis
space-q

Hypothesis
space-n

Qualifier

Quality Machine

Figure 2: Architecture for Text Knowledge Engineering

concept POSSESSION, the concept denoted by “has” (lex-
ical ambiguities, e.g., for the verb “has”, lead to the cre-
ation of alternative hypothesis spaces). Since POSSESSION
requires its AGENT to be an OBJECT, ACTION and DEGREE
are no longer valid concept hypotheses. Their cancellation
(cf. the darkly shaded boxes) yields signiﬁcant reduction of
the huge initial hypothesis space. The learner then aggres-
sively specializes the remaining single hypothesis to the im-
mediate subordinates of OBJECT, viz. PHYSICALOBJECT
and TECHNOLOGY, in order to test more restricted hypothe-
ses which – according to more speciﬁc constraints – are eas-
ier falsiﬁable.

In addition, the linguistic constraints for the verb “has”
indicate that the grammatical direct object relation is to be
interpreted in terms of a conceptual PATIENT role. Accord-
ingly, the phrase “ . . . has a size of . . . ” is processed such
is the PATIENT of the POSSESSION relationship.
that
Also, AGENT and PATIENT are both restricted by speciﬁc
conceptual constraints. These come into play in the subse-
quent semantic interpretation step, where possible concep-
tual relations between the AGENT and PATIENT are tried.

A straightforward translation of the basic conceptual re-
lations contained in the utterance above yields the following
terminological expressions:

(P1)
(P2)

PHYSICALSIZE
-

SIZE-OF

Assertion P1 indicates that
concept class PHYSICALSIZE and P2 relates

-

- via the binary relation SIZE-OF.

-
is an instance of the
and

Given the conceptual roles attached to PHYSICALSIZE,
the system recognizes that all specializations of PRODUCT
can be related to the concept PHYSICALSIZE (via the role
SIZE-OF), while for TECHNOLOGY no such relation can be
established. So, we prefer the conceptual reading of ITOH-
CI-8 as a kind of a PRODUCT over the TECHNOLOGY hy-
pothesis (cf. the grey-shaded boxes).

A Model of Text Knowledge Engineering

The methodology and corresponding system architecture for
text knowledge elicitation is summarized in Fig. 2. It depicts
how linguistic and conceptual evidence are generated and
combined to continuously discriminate and reﬁne the set of
concept hypotheses (the unknown item yet to be learned is
characterized by the black square).

The language processor (for an overview, cf. Hahn,
Schacht, & Br¨oker (1994)) yields structural dependency in-
formation from the grammatical constructions in which an
unknown lexical item occurs in terms of the corresponding
parse tree. The kinds of syntactic constructions (e.g., gen-
itive, apposition, comparative), in which unknown lexical
items appear, are recorded and assessed later on relative to
the credit they lend to a particular hypothesis. The concep-
tual interpretation of parse trees involving unknown lexical
items in the terminological knowledge base (cf. Woods &
Schmolze (1992) for a survey of terminological, KL-ONE-
style knowledge representation) is used to derive concept
hypotheses, which are further enriched by conceptual anno-
tations reﬂecting structural patterns of consistency, mutual
justiﬁcation, analogy, etc. This kind of initial evidence, in
particular its predictive “goodness” for the learning task, is
represented by corresponding sets of linguistic and concep-
tual quality labels. Multiple concept hypotheses for each un-
known lexical item are organized in terms of a correspond-
ing hypothesis space, each subspace holding different or fur-
ther specialized concept hypotheses.

The quality machine estimates the overall credibility of
single concept hypotheses by taking the available set of qual-
ity labels for each hypothesis into account. The ﬁnal com-
putation of a preference order for the entire set of compet-
ing hypotheses takes place in the qualiﬁer, a terminologi-
cal classiﬁer extended by an evaluation metric for quality-
based selection criteria. The output of the quality machine
is a ranked list of concept hypotheses. The ranking yields,
in decreasing order of signiﬁcance, either the most plausi-
ble concept classes which classify the considered instance
or more general concept classes subsuming the considered
concept class (cf. Schnattinger & Hahn (1996) for details of
this metareasoning process).

Linguistic Quality Labels
Linguistic quality labels reﬂect structural properties of
phrasal patterns or discourse contexts in which unknown
lexical items occur — we assume here that the type of
grammatical construction exercises a particular interpreta-
tive force on the unknown item and, at the same time, yields
a particular level of credibility for the hypotheses being de-
rived therefrom. As a concrete example of a high-quality
label, consider the case of APPOSITION. This label is gener-
ated for constructions such as “.. the printer @A@ ..”, with
“@..@” denoting the unknown item. The apposition almost
unequivocally determines “@A@” (considered as a poten-
tial noun)1 to denote a PRINTER. This assumption is jus-
tiﬁed independent of further conceptual conditions, simply
due to the nature of the linguistic construction being used.
Still of good quality but already less constraining are occur-
rences of the unknown item in a CASEFRAME construction
as illustrated by “.. @B@ has a size of ..”. In this exam-
ple, case frame speciﬁcations of the verb “has” that relate
to its AGENT role carry over to “@B@”. Given its ﬁnal

1Such a part-of-speech hypothesis can be derived from the in-
ventory of valence and word order speciﬁcations underlying the de-
pendency grammar model we use (Hahn, Schacht, & Br¨oker 1994).

semantic interpretation, “@B@” may be anything that has a
size. Considering an utterance like “The Itoh-Ci-8 has a size
of ..”, we may hypothesize that, in an information technol-
ogy domain, at least, the concept ITOH-CI-8 can tentatively
be considered a PRODUCT (which IS-A PHYSICALOBJECT
and, hence, always provides a HAS-SIZE relation).

Depending on the type of the syntactic construction in
which the unknown lexical item occurs, different hypothe-
sis generation rules may ﬁre. As in a sample phrase such
as “The switch of the Itoh-Ci-8 ..”, genitive noun phrases
place only a few constraints on the item to be acquired. In
the following, let target be the unknown item (“Itoh-Ci-8”)
and base be the known item (“switch”), whose conceptual
relation to the target is constrained by the syntactic relation
in which their lexical counterparts co-occur. The main con-
straint for genitives says that the target concept ﬁlls (exactly)
one of the n roles of the base concept. Since the correct role
cannot yet be decided upon, n alternative hypotheses have
to be posited (unless additional constraints apply), and the
target concept has to be assigned as a ﬁller of the i-th role of
base in the corresponding i-th hypothesis space. As a con-
sequence, the classiﬁer is able to derive a suitable concept
hypothesis by specializing the target concept (initially TOP,
by default) according to the value restriction of the base con-
cept's i-th role. Additionally, this rule assigns a syntactic
quality label to each i-th hypothesis indicating the type of
syntactic construction in which target and base co-occur.

After the processing of “The Itoh-Ci-8 has a size of ..”, the
target ITOH-CI-8 is already predicted as a PRODUCT. Prior
to continuing with the phrase “The switch of the Itoh-Ci-8
..”, consider some fragments of the conceptual representa-
tion for SWITCHes:
SWITCH-OF
(P3)
(P4) SWITCH

SWITCH PART-OF HARDWARE

HAS-PRICE.PRICE
HAS-WEIGHT.WEIGHT

SWITCH-OF

OUTPUTDEV
STORAGEDEV

INPUTDEV
COMPUTER

INPUTDEV

STORAGEDEV

The relation SWITCH-OF is deﬁned by P3 as the set of
all PART-OF relations which have their domain restricted
to SWITCH and their range restricted to HARDWARE.
In
addition, (P4) reads as “all ﬁllers of HAS-PRICE, HAS-
WEIGHT, and SWITCH-OF roles must be concepts subsumed
by PRICE, WEIGHT, and the disjunction of (OUTPUTDEV
COMPUTER), respec-
tively”. So, three roles have to be considered for relat-
ing the target ITOH-CI-8, as a tentative PRODUCT, to the
base concept SWITCH. Two of them, HAS-PRICE and HAS-
WEIGHT, are ruled out due to the violation of a simple in-
tegrity constraint (PRODUCT does not denote a unit of mea-
sure). Therefore, only the role SWITCH-OF must be consid-
ered. Due to the deﬁnition of SWITCH-OF (cf. P3), ITOH-
CI-8 is immediately specialized to HARDWARE by the clas-
siﬁer. Since the classiﬁer aggressively pushes the hypothe-
sizing to be maximally speciﬁc, four distinct hypotheses are
immediately created due to the speciﬁc range restrictions of
the role SWITCH-OF expressed in (P4), the deﬁnition of the
concept SWITCH, viz. OUTPUTDEV, INPUTDEV, STOR-

AGEDEV and COMPUTER, and they are managed in four
distinct hypothesis spaces,
, respectively.
We sketch their contents roughly in the following concept
descriptions (note that for
- we also include parts
of the implicit IS-A hierarchy):

and

-

,

,

-

-

-

-

- OUTPUTDEV

SWITCH-OF

-

-

-

-

INPUTDEV

SWITCH-OF

-
STORAGEDEV
-

SWITCH-OF

COMPUTER

SWITCH-OF

-

-

- DEVICE

-

- DEVICE

-

- DEVICE

-

- HARDWARE

-

-

-

-

Conceptual Quality Labels
Conceptual quality labels result from comparing the repre-
sentation structures of a concept hypothesis with those of
alternative concept hypotheses or already existing represen-
tation structures in the underlying domain knowledge base
from the viewpoint of structural similarity, compatibility,
etc. The closer the match, the more credit is lent to a hy-
pothesis. For instance, a very positive conceptual quality
label such as M-DEDUCED is assigned to multiple deriva-
tions of the same concept hypothesis in different hypoth-
esis (sub)spaces. Positive labels are also assigned to ter-
minological expressions which share structural similarities,
though they are not identical. The label C-SUPPORTED,
e.g., is assigned to any hypothesized relation
between
two instances when another relation,
, already exists in
the knowledge base involving the same two instances, but
where the role ﬁllers occur in “inverted” order (note that
and
need not necessarily be semantically inverse rela-
tions such as with “buy” and “sell”). This rule of “cross”
support captures the inherent symmetry between concepts
related via quasi-inverse conceptual relations.

-

and
-

DEVICE

Quality annotations of the conceptual status of concept
hypotheses are derived from qualiﬁcation rules. For in-
stance, the rule for the label M-DEDUCED applies to the
case where the same assertion is deduced in at least two
in the expres-
different hypothesis spaces (cf.
sion below). That assertion, e.g.,
in the example below, is then annotated by a high-quality
label.
In technical terms, an instance of the quality la-
bel M-DEDUCED is created (for a formal speciﬁcation of
several qualiﬁcation rules, including the representation of
and metareasoning with quality assertions, cf. Hahn, Klen-
ner, & Schnattinger (1996)). Considering our example, for
ITOH-CI-8 the concept hypotheses OUTPUTDEVice, IN-
PUTDEVice and STORAGEDEVice were derived indepen-
dently of each other in different hypothesis spaces. Hence,
DEVICE, as their common superconcept, has been multiply
derived by the classiﬁer in each of these spaces, too. Accord-
ingly, this hypothesis is assigned a high degree of conﬁdence
by issuing the conceptual quality label M-DEDUCED:

-

-

- DEVICE

-

- DEVICE

- DEVICE

M-DEDUCED

1.
2.

3.

4.

5.

6.

7.

8.

9.

Quality-Based Classiﬁcation
Whenever new evidence for or against a concept hypothe-
sis is brought forth in a single learning step all concept hy-
potheses are reevaluated. First, weak or even untenable hy-
potheses are discarded. A quality-based selection among the
remaining hypothesis spaces is grounded in threshold levels
(later on referred to as TH). Their deﬁnition takes linguistic
evidence into account. At the ﬁrst threshold level, all hy-
pothesis spaces with the maximum of APPOSITION labels
are selected. If more than one hypothesis is left to be con-
sidered, only concept hypotheses with the maximum num-
ber of CASEFRAME assignments are approved at the second
threshold level. Those hypothesis spaces that have fulﬁlled
these threshold criteria will then be classiﬁed relative to two
different credibility levels (later on referred to as CB). The
ﬁrst level of credibility contains all hypothesis spaces which
have the maximum of M-DEDUCED labels, while at the sec-
ond level (again, with more than one hypothesis left to be
considered) those are chosen which are assigned the maxi-
mum of C-SUPPORTED labels. A comprehensive termino-
logical speciﬁcation of the underlying qualiﬁcation calculus
is given by Schnattinger & Hahn (1996).

For an illustration, consider the ﬁrst utterance, once again:
“The Itoh-Ci-8 has a size of ..”. An assignment of the syn-
tactic quality label CASEFRAME is triggered only in those
hypothesis spaces where the unknown item is considered
a PHYSICALOBJECT (cf. Table 3, learning step 1). The
remaining hypotheses (cf. Table 3, learning step 2) can-
not be annotated by CASEFRAME, since the concepts they
represent (e.g., MENTALOBJECT, NORM) have no property
such as PHYSICALSIZE. As a consequence, their hypothe-
sis spaces are ruled out by the criterion set up at the second
threshold level, and the still valid concept hypothesis PHYS-
ICALOBJECT is further reﬁned as PRODUCT. As far as the
sample phrase “The switch of the Itoh-Ci-8 ..” is concerned,
four more speciﬁc hypothesis spaces are generated from the
PRODUCT hypothesis, three of which stipulate a DEVICE
hypothesis. Since the conceptual quality label M-DEDUCED
has been derived by the classiﬁer, this result yields a ranking
with these three DEVICE hypotheses preferred over the one
associated with COMPUTER (cf. Table 3, learning step 3).

Evaluation

In this section, we present some data from an empirical
evaluation of the text knowledge acquisition system. We
start with a consideration of canonical performance mea-
sures (such as recall, precision, etc.) and then focus on the
more pertinent issues of learning accuracy and the learning
rate. Due to the given learning environment, the measures
we apply deviate from those commonly used in the machine
learning community.
In concept learning algorithms like
IBL (Aha, Kibler, & Albert 1991) there is no hierarchy of
concepts. Hence, any prediction of the class membership of
a new instance is either true or false. However, as such hi-
erarchies naturally emerge in terminological frameworks, a
prediction can be more or less precise, i.e., it may approxi-
mate the target concept at different levels of speciﬁcity. This
is captured by our measure of learning accuracy which takes

Phrase
The Itoh-Ci-8 has
a size of ..

Semantic Interpretation
(possess.1, agent, Itoh-Ci-8)
(possess.1, patient, size.1)

(size.1,size-of,Itoh-Ci-8)
(Itoh-Ci-8,has-size,size.1)

(Itoh-Ci-8,has-switch,switch.1)

(Itoh-Ci-8,has-case,housing.1)
(memory.1, memory-of, Itoh-Ci-8)

(switch.1, switch-of, Itoh-Ci-8)

The switch of
the Itoh-Ci-8 ..
The housing from (housing.1, case-of, Itoh-Ci-8)
the Itoh-Ci-8 ..
Itoh-Ci-8 with
a main memory ..
Itoh-Ci-8's
LED lines ..
Itoh-Ci-8's
toner supply ..
Paper cassette of
the Itoh-Ci-8 ..
Itoh-Ci-8 with
a resolution rate ..

(resolution.1, rate-of, Itoh-Ci-8)

(LED-line.1, part-of, Itoh-Ci-8)

(Itoh-Ci-8,has-part,LED-line.1)
(tonerSupply.1, part-of, Itoh-Ci-8)

(Itoh-Ci-8,has-part,tonerSupply.1)

(paperSupply.1, part-of, Itoh-Ci-8)

(Itoh-Ci-8,has-part,paperSupply.1)

(Itoh-Ci-8,has-memory,memory.1)

(Itoh-Ci-8,has-rate,resolution.1)

Table 1: Interpretation Results of a Text Featuring “Itoh-Ci-8”

into account the conceptual distance of a hypothesis to the
goal concept of an instance, rather than simply relating the
number of correct and false predictions, as in IBL.

In our approach, learning is achieved by the reﬁnement
of multiple hypotheses about the class membership of an in-
stance. Thus, the measure of learning rate we propose is
concerned with the reduction of possible hypotheses as more
and more information becomes available about one particu-
lar new instance. In contrast, IBL-style algorithms consider
only one concept hypothesis per learning cycle and their no-
tion of learning rate relates to the increase of correct predic-
tions as more and more instances are being processed.

The knowledge base on which we performed our experi-
ments contained 325 concept deﬁnitions and 447 conceptual
relations. The upper-level concepts of that ontology were
taken from Nirenburg & Raskin (1987). We considered a to-
tal of 101 texts (= SizeofTestSet below) randomly selected
from a corpus of information technology magazines. For
each of them, 5 to 15 learning steps were considered. A
learning step captures the ﬁnal result of all semantic inter-
pretation processes being made at the level of hypothesis
spaces after new textual input has been supplied in which the
item to be learned occurs. In order to clarify the input data
available for the learning system, cf. Table 1. It consists of
nine single learning steps for the unknown item “Itoh-Ci-8”
that occurred while processing the entire text. Each learning
step is associated with a particular natural language phrase in
which the unknown lexical item occurs and the correspond-
ing semantic interpretation data.

Canonical Performance Measures
In a ﬁrst series of experiments, we neglected the incremen-
tality of the learner and evaluated our system in terms of its
bare off-line performance. By this we mean its potential to
determine the correct concept description at the end of each
text analysis considering the outcome of the ﬁnal learning
step only. Following previous work on evaluation measures
for learning systems (Hastings 1994), we distinguish here
the following parameters:

Hypothesis denotes the set of concept hypotheses derived
by the system as the ﬁnal result of the text understanding
process for each target item;

Correct
OneCorrect
ConceptSum

RECALL

PRECISION :=
ConceptSum
PARSIMONY := OneCorrect
SizeofTestSet

Correct

SizeofTestSet
Correct

CAMILLE
*
*
*

– TH CB
99
31
255

100
26
360

100
21
446

44% 99% 99% 98%

22% 22% 28% 39%

14% 21% 26% 31%

Table 2: Performance Measures

Correct denotes the number of cases in the test set in
which Hypothesis contains the correct concept descrip-
tion for the target item;
OneCorrect denotes the number of cases in the test set
in which Hypothesis is a singleton set which contains the
correct concept description only;
ConceptSum denotes the number of concepts generated
for all of the target items considering the entire test set.
Measures were taken under three experimental conditions
In the second column (indicated by –), we
(cf. Table 2).
considered the contribution of only the terminological rea-
soning component to the concept acquisition task, the third
column contains the results of incorporating the (linguistic)
threshold criteria (denoted by TH), while the fourth one in-
corporates (linguistic as well as conceptual) credibility crite-
ria (designated by CB). The data indicate a surprisingly high
recall rate. The slight drop for CB (98% relative to 99%) is
due to an incidental selection fault during processing. The
values for precision as well as those for parsimony are con-
sistently in favor of the full qualiﬁcation calculus (CB).

In an attempt to relate these results of the quality-based
learner to a system close in spirit to our approach, we chose
CAMILLE (Hastings 1994), considering versions 1.0, 1.2,
2.0, and 2.1, and the results reported for recall, precision,
and parsimony in the assembly line and the terrorism do-
main (cf. Table 2, column one). Not surprisingly, the preci-
sion of our terminological reasoning component, the LOOM
system (MacGregor 1994), is equal to CAMILLE's,2 but our
system outperforms CAMILLE signiﬁcantly on the evalua-
tion dimensions TH and CB with respect to any of the per-
formance measures we considered. Unlike CAMILLE, our
learner also consistently improves as more and more infor-
mation becomes available for an unknown target item (cf.
the following section).

2Hastings (1994, page 71) mentions that “... classiﬁer sys-
tems [like LOOM] provide a very similar inference mechanism to
CAMILLE's.” This statement is backed up by our precision data
which exhibit equal values for our system and CAMILLE. Hastings
(ibid.) also rightly observes that “... they [the classiﬁer systems]
stop short of inferring the best hypotheses.” The specialization pro-
cedure developed for CAMILLE resembles the one underlying our
system. Contrary to Hasting's approach, however, we evaluate the
different, more speciﬁc hypotheses with respect to linguistic and
conceptual evidence and arrive at a ranked list of hypotheses based
on TH and CB criteria. This way, more speciﬁc hypotheses simul-
taneously pass an evidential ﬁltering mechanism that signiﬁcantly
increases the system's learning performance.

TOP

CONCEPT

TOP

CONCEPT

SP i= 4

PREDICTED
CONCEPT

COMMON
CONCEPT

FP

i= 4

CPi= 3

CP

i= 3

TARGET
CONCEPT

iDP = 1

TARGET
CONCEPT

PREDICTED
CONCEPT

Figure 3: LA for an Under-
speciﬁed Concept Hypothesis

Figure 4: LA for a Slightly
Incorrect Concept Hypothesis

Learning Accuracy
In a second series of experiments, we investigated the learn-
ing accuracy of the system, i.e., the degree to which it cor-
rectly predicts the concept class which subsumes the target
concept to be learned. Learning accuracy (
) is deﬁned as
( being the number of concept hypotheses for the target):

with

if

else

speciﬁes the length of the shortest path (in terms of
the number of nodes being traversed) from the TOP node of
the concept hierarchy to the maximally speciﬁc concept sub-
suming the instance to be learned in hypothesis ;
spec-
iﬁes the length of the path from the TOP node to that concept
node in hypothesis which is common both to the shortest
path (as deﬁned above) and the actual path to the predicted
speciﬁes the length
concept (whether correct or not);
of the path from the TOP node to the predicted (in this case
false) concept (
, if the prediction is correct), and
denotes the node distance between the predicted false
node and the most speciﬁc common concept (on the path
from the TOP node to the predicted false node) still correctly
subsuming the target in hypothesis . Sample conﬁgurations
for concrete LA values involving these parameters are de-
picted in Fig. 3, which illustrates a correct, yet too general
, while Fig. 4 contains a false
prediction with
prediction with
. Though the measure is sensitive
to the depth of concept graphs, it produced adequate results
in the technology domain we considered. As the graphs in
knowledge bases for “natural” domains typically have an al-
most canonical depth that ranges between seven to ten nodes
from the most general to the most speciﬁc concept, our mea-
sure seems to generalize to other domains as well.3

Given the LA measure from above, Table 3 and Table 4
illustrate how alternative concept hypotheses for ITOH-CI-8
develop in accuracy from one step to the other. The num-
bers in brackets in the column Concept Hypotheses indicate

3We tested the WORDNET lexical database (Fellbaum 1998),
a common-sense ontology, in order to determine concept paths
of maximal length. In the computer domain, the maximum path
length amounts to eight nodes. For the entire ontology, the maxi-
mum path length of eleven nodes was found in the biology domain.
The data were collected by one of our colleagues, Katja Markert.

Concept
Hypotheses
PHYSICALOBJECT(176)
MENTALOBJECT(0)
INFORMATIONOBJECT(5)
MASSOBJECT(0)
NORM(3)
TECHNOLOGY(1)
MODE(5)
FEATURE(0)

PRODUCT(136)
MENTALOBJECT(0)
INFORMATIONOBJECT(5)
MASSOBJECT(0)
NORM(3)
TECHNOLOGY(1)
MODE(5)
FEATURE(0)

LA
–

0.30
0.16
0.16
0.16
0.16
0.16
0.16
0.16
:0.18
Learning Step 1

0.50
0.16
0.16
0.16
0.16
0.16
0.16
0.16
:0.20
Learning Step 2

0.50
0.80
0.55
0.55
:0.60
Learning Step 3

COMPUTER(5)
OUTPUTDEV(9)
STORAGEDEV(5)
INPUTDEV(2)

LA
TH
0.30
0.16
0.16
0.16
0.16
0.16
0.16
0.16
:0.18

0.50

:0.50

0.50
0.80
0.55
0.55
:0.60

LA
CB
0.30
0.16
0.16
0.16
0.16
0.16
0.16
0.16
:0.18

0.50

:0.50

0.80
0.55
0.55
:0.63

Table 3: Learning Steps 1 to 3 for the Sample Text

for each hypothesized concept the number of concepts sub-
sumed by it in the underlying knowledge base (cf. also our
notion of learning rate, as introduced below); LA CB gives
the accuracy rate for the full qualiﬁcation calculus includ-
ing threshold and credibility criteria, LA TH for threshold
criteria only, while LA – depicts the accuracy values pro-
duced by the terminological reasoning component without
incorporating any quality criteria. As can be read off from
both tables, the full qualiﬁcation calculus produces either
the same or even more accurate results on average, equally
many or fewer hypothesis spaces (indicated by the number
of rows), and derives the correct prediction more rapidly (in
step 6) than the less knowledgeable variants (in step 9).

The data also illustrate the continuous specialization of
concept hypotheses achieved by the terminological classi-
ﬁer, e.g., from PHYSICALOBJECT in step 1 via PRODUCT in
step 2 to OUTPUTDEVice, PRINTER, and LASERPRINTER
in step 3, 4, and 5, respectively. The overall learning accu-
racy – due to the learner's aggressive specialization strategy
– may even temporarily decrease in the course of hypothe-
sizing (e.g., from step 3 to 4 or step 5 to 6 for LA –, as well
as for LA TH), but the learning accuracy value for the full
qualiﬁcation calculus (LA CB) always increases.

Fig. 5 depicts the learning accuracy curve for the entire
data set (101 texts). We also have included the graph de-
picting the growth behavior of hypothesis spaces (Fig. 6).
For both data sets, we distinguish again between the mea-
surements for LA –, LA TH and LA CB. In Fig. 5, we
start from LA values in the interval between 48% to 54% for
LA –/LA TH and LA CB, respectively, in the ﬁrst learning
step, whereas the number of hypothesis spaces (NH) range
between 6.2 and 4.5 (Fig. 6). In the ﬁnal step, learning ac-
curacy rises up from 79%, 83% to 87% for LA –, LA TH
and LA CB, respectively, and the NH values reduce to 4.4,
3.6 and 2.5 for each of the three criteria, respectively.

Concept
Hypotheses
NOTEBOOK(0)
PORTABLE(0)
PC(0)
WORKSTATION(0)
DESKTOP(0)
PRINTER(3)
VISUALDEV(2)
LOUDSPEAKER(0)
PLOTTER(0)
RW-STORE(2)
RO-STORE(1)
MOUSE(0)
KEYBOARD(0)

NOTEBOOK(0)
PORTABLE(0)
PC(0)
WORKSTATION(0)
DESKTOP(0)
LASERPRINTER(0)
INKJETPRINTER(0)
NEEDLEPRINTER(0)

NOTEBOOK(0)
PORTABLE(0)
PC(0)
WORKSTATION(0)
DESKTOP(0)
LASERPRINTER(0)

LASERPRINTER(0)

LA
–

0.43
0.43
0.43
0.43
0.43
0.90
0.66
0.66
0.66
0.50
0.50
0.50
0.50
:0.54

0.43
0.43
0.43
0.43
0.43
1.00
0.75
0.75
:0.58

0.43
0.43
0.43
0.43
0.43
1.00
:0.53

1.00
:1.00

LA
TH
0.43
0.43
0.43
0.43
0.43
0.90
0.66
0.66
0.66
0.50
0.50
0.50
0.50
:0.54

0.43
0.43
0.43
0.43
0.43
1.00
0.75
0.75
:0.58

0.43
0.43
0.43
0.43
0.43
1.00
:0.53

1.00
:1.00

LA
CB

0.90
0.66
0.66
0.66
0.50
0.50

:0.65

1.00
0.75
0.75
:0.83

1.00
:1.00

1.00
:1.00

Learning Step 4

Learning Step 5

Learning Step 6,7,8

Learning Step 9

Table 4: Learning Steps 4 to 9 for the Sample Text

The pure terminological reasoning machinery always
achieves an inferior level of learning accuracy and generates
more hypothesis spaces than the learner equipped with the
qualiﬁcation calculus. Also, the inclusion of conceptual cri-
teria (CB) supplementing the linguistic criteria (TH) helps a
lot to focus on the relevant hypothesis spaces and to further
discriminate the valid hypotheses (on the range of 4% of pre-
cision). Note that an already signiﬁcant plateau of accuracy
is usually reached after the third step (viz. 67%, 73%, and
76% for LA –, LA TH, and LA CB, respectively, in Fig. 5;
the corresponding numbers of hypothesis spaces being 6.1,
5.1, and 3.7 for NH –, NH TH, and NH CB, respectively,
in Fig. 6). This indicates that our approach not only yields
competitive accuracy rates (a mean of 87%) but also ﬁnds
the most relevant distinctions in a very early phase of the
learning process, i.e., it requires only a few examples.

Learning Rate
The learning accuracy focuses on the predictive power of the
learning procedure. By considering a third type of measure,
the learning rate, we supply data from the step-wise reduc-
tion of alternatives for the learning process. Fig. 7 depicts
the mean number of transitively included concepts for all
considered hypothesis spaces per learning step (each con-
cept hypothesis denotes a concept which transitively sub-
sumes various subconcepts). Note that the most general
concept hypothesis, in our example, denotes OBJECT which
currently includes 196 concepts. In general, we observed a

A
L

1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

ALL

LA CB
LA TH
LA ----

1

2

3

4

5

6

7

8

9 10 11 12 13 14 15

Learning steps

H
N

7

6

5

4

3

2

1

1

2

3

4

5

6

ALL

NH ----
NH TH
NH CB

7

8

9 10 11 12 13 14 15

Learning steps

200

150

R
L

100

50

0

1

2

3

4

5

ALL

LR ----
LR TH
LR CB

7

6
Learning steps

8

9 10 11 12 13 14 15

Figure 5: Learning Accuracy (LA)

Figure 6: Number of Hypotheses (NH)

Figure 7: Learning Rate (LR)

strong negative slope of the curve for the learning rate. After
the ﬁrst step, slightly less than 50% of the included concepts
are pruned (with 93, 94 and 97 remaining concepts for LR
CB, LR TH and LR –, respectively). Again, learning step 3
is a crucial point for the reduction of the number of included
concepts (ranging from 16 to 21 concepts). Summarizing
this evaluation experiment, the quality-based learning sys-
tem exhibits signiﬁcant and valid reductions of the predicted
concepts (up to two, on the average).

Related Work

Our approach bears a close relationship to the work of
Granger (1977), Mooney (1987), Berwick (1989), Rau, Ja-
cobs, & Zernik (1989), Gomez & Segami (1990), Hastings
(1994), and Moorman & Ram (1996), who all aim at the
automated learning of word meanings from context using a
knowledge-intensive approach. But our work differs from
theirs in that the need to cope with several competing con-
cept hypotheses and to aim at a reason-based selection in
terms of the quality of arguments is not an issue in these
studies. Learning from real-world texts usually provides the
learner with only sparse and fragmentary evidence such that
multiple hypotheses are likely to be derived and a need for a
hypothesis evaluation arises.

The work closest to ours has been carried out by Rau,
Jacobs, & Zernik (1989) and Hastings (1994). They also
generate concept hypotheses from linguistic and conceptual
evidence. Unlike our approach, the selection of hypotheses
depends only on an ongoing discrimination process based
on the availability of these data but does not incorporate an
inferencing scheme for reasoned hypothesis selection. The
difference in learning performance for Rau et al.'s system –
in the light of our evaluation study (cf. Fig. 5, ﬁnal learn-
ing step) – amounts to 8%, considering the difference be-
tween LA - (plain terminological reasoning) and LA CB
values (terminological metareasoning based on the qualiﬁ-
cation calculus). Similarly strong arguments hold for a com-
parison of our results with Hasting's (1994) approach at the
precision dimension, with an even greater advantage for the
full qualiﬁcation calculus (39%) over terminological-style
reasoning in the CAMILLE System (22%). Hence, our claim
that we produce competitive results.

Note that the requirement to provide learning facilities
for real-world text knowledge engineering also distinguishes

our approach from the currently active ﬁeld of information
extraction (IE) (Appelt et al. 1993). The IE task is deﬁned
in terms of a pre-ﬁxed set of templates which have to be in-
stantiated (i.e., ﬁlled with factual knowledge items) in the
course of text analysis. In particular, no new templates have
to be created. This step would correspond to the procedure
we described in this contribution.

In the ﬁeld of knowledge engineering from texts, our sys-
tem constitutes a major achievement through the complete
automatization of the knowledge elicitation process (cf. also
Gomez & Segami (1990)). Previous studies mainly dealt
with that problem by either hand-coding the content of the
textual documents (Skuce et al. 1985), or providing semi-
automatic, interactive devices for text knowledge acquisition
(Szpakowicz 1990), or using lexically oriented statistical ap-
proaches to text analysis (Shaw & Gaines 1987).

Conclusion

Knowledge-based systems provide powerful forms of rea-
soning, but it takes a lot of effort to equip them with the
knowledge they need by means of manual knowledge en-
gineering. In this paper, we have introduced an alternative
solution based on the fully automatic processing of exposi-
tory texts. This text knowledge engineering methodology is
based on the incremental assignment and evaluation of the
quality of linguistic and conceptual evidence for emerging
concept hypotheses. No specialized learning algorithm is
needed, since learning is a (meta)reasoning task carried out
by the classiﬁer of a terminological reasoning system. How-
ever, strong heuristic guidance for selecting between plau-
sible hypotheses comes from the different quality criteria.
Our experimental data indicate that, given these heuristics,
we achieve a high degree of pruning of the search space for
hypotheses in very early phases of the learning cycle.

The procedure for text knowledge engineering was tested
on a medium-sized knowledge base for the information tech-
nology domain. The choice of a single domain reduces the
number of possible conceptual ambiguities when concept
hypotheses are created, in particular when compared with
common-sense ontologies such as WORDNET (Fellbaum
1998). However, one might envisage partitioning mecha-
nisms in order to control the activation of reasonable por-
tions of a knowledge base and thus escape from a prohibitive
explosion of the number of alternatives to be pursued.

Actually, we also like to contrast our text knowledge en-
gineering approach to standard machine learning algorithms
like ID3, k-nearest neighbor and Bayesian classifers. Initial
evidence from current experiments indicates that either the
number of hypotheses they generate become prohibitively
large, even in the medium-sized knowledge base we use (es-
pecially for k-nearest neighbor), or the learning accuracy
drops down very seriously (e.g., for ID3). The outcome of
these experiments might clarify the usefulness of standard
ML algorithms for the text knowledge engineering task.

It should also be obvious that the accuracy of our text
knowledge engineering procedure is dependent on the input
supplied by the parser. This is particularly true of false se-
mantic interpretations (cf. Table 1), which directly misguide
the reasoning process of the learner. Missing data, however,
are far less harmful, since the knowledge acquisition proce-
dure needs only a few examples to narrow down the search
space, as has become evident from the evaluation study.

In our experiments, learning was restricted to the case of
a single unknown concept in the entire text. Generalizing to
n unknown concepts can be considered from two perspec-
tives. When hypotheses of another target item are generated
and assessed relative to an already given base item, no ef-
fect occurs. When, however, two targets (i.e., two unknown
items) have to be related, then the number of hypotheses that
have to be taken into account is equal to the product of the
number of hypothesis spaces associated with each of them.
In the future, we intend to study such test cases, too. For-
tunately, the number of hypothesis spaces decreases rapidly
(cf. Fig. 6) as does the learning rate (cf. Fig. 7) so that the
learning system should remain within feasible bounds.

Acknowledgements. We would like to thank our colleagues
in the CLIF group for fruitful discussions and instant support, in
particular Joe Bush who polished the text as a native speaker. K.
Schnattinger is supported by a grant from DFG (Ha 2097/3-1).

References

Aha, D.; Kibler, D.; and Albert, M. 1991. Instance-based
learning algorithms. Machine Learning 6:37–66.
Appelt, D.; Hobbs, J.; Bear, J.; Israel, D.; and Tyson, M.
1993. FASTUS: a ﬁnite-state processor for information
extraction from real-world text.
In IJCAI' 93 – Proceed-
ings 13th International Joint Conference on Artiﬁcial Intel-
ligence., 1172–1178. San Mateo, CA: Morgan Kaufmann.
Berwick, R. 1989. Learning word meanings from exam-
ples. In Waltz, D., ed., Semantic Structures. Advances in
Natural Language Processing. L. Erlbaum. 89–124.
Buchanan, B.; Barstow, D.; Bechtal, R.; Bennett, J.;
Clancey, W.; Kulikowski, C.; Mitchell, T.; and Waterman,
D. 1983. Constructing an expert system. In Hayes-Roth,
F.; Waterman, D.; and Lenat, D., eds., Building Expert Sys-
tems. Reading, MA: Addison-Wesley. 127–167.
Fellbaum, C., ed. 1998. WordNet: An Electronic Lexical
Database. Cambridge, MA: MIT Press.
Gomez, F., and Segami, C. 1990. Knowledge acquisition
from natural language for expert systems based on classi-
ﬁcation problem-solving methods. Knowledge Acquisition
2(2):107–128.

Granger, R. 1977. FOUL-UP: a program that ﬁgures out
meanings of words from context. In IJCAI' 77 – Proc. of the
5th Intl. Joint Conf. on Artiﬁcial Intelligence., 172–178.
Hahn, U.; Klenner, M.; and Schnattinger, K. 1996. Learn-
ing from texts: a terminological metareasoning perspec-
tive. In Wermter, S.; Riloff, E.; and Scheler, G., eds., Con-
nectionist, Statistical and Symbolic Approaches to Learn-
ing for Natural Language Processing. Springer. 453–468.
Hahn, U.; Schacht, S.; and Br¨oker, N. 1994. Concurrent,
object-oriented natural language parsing: the PARSETALK
model. International Journal of Human-Computer Studies
41(1/2):179–222.
Hastings, P. 1994. Automatic Acquisition of Word Meaning
from Context. Ph.D. Dissertation, Computer Science and
Engineering Department, University of Michigan.
MacGregor, R. 1994. A description classiﬁer for the pred-
icate calculus.
In AAAI' 94 – Proceedings 12th National
Conference on Artiﬁcial Intelligence., 213–220. Menlo
Park, CA: AAAI Press & Cambridge, MA: MIT Press.
Mooney, R. 1987. Integrated learning of words and their
underlying concepts.
In CogSci' 87 – Proceedings of the
9th Annual Conference of the Cognitive Science Society,
974–978. Hillsdale, NJ: L. Erlbaum.
Moorman, K., and Ram, A. 1996. The role of ontology in
creative understanding. In CogSci' 96 – Proceedings of the
18th Annual Conference of the Cognitive Science Society,
98–103. Mahwah, NJ: L. Erlbaum.
Morik, K.; Wrobel, S.; Kietz, J.-U.; and Emde, W. 1993.
Knowledge Acquisition and Machine Learning: Theory,
Methods, and Applications. London: Academic Press.
Nirenburg, S., and Raskin, V. 1987. The subworld concept
lexicon and the lexicon management system. Computa-
tional Linguistics 13(3/4):276–289.
Rau, L.; Jacobs, P.; and Zernik, U. 1989.
Information
extraction and text summarization using linguistic knowl-
edge acquisition. Information Processing & Management
25(4):419–428.
Schnattinger, K., and Hahn, U. 1996. A terminological
qualiﬁcation calculus for preferential reasoning under un-
certainty.
In KI' 96 – Proceedings 20th Annual German
Conference on Artiﬁcial Intelligence, 349–362. Springer.
Shaw, M., and Gaines, B. 1987. KITTEN: knowledge
initiation and transfer tools for experts and novices. Inter-
national Journal of Man-Machine Studies 27(3):251–280.
Skuce, D.; Matwin, S.; Tauzovich, B.; Oppacher, F.; and
Szpakowicz, S. 1985. A logic-based knowledge source
system for natural language documents. Data & Knowl-
edge Engineering 1(3):201–231.
Steﬁk, M. 1995. Introduction to Knowledge Systems. San
Francisco, CA: Morgan Kaufmann.
Szpakowicz, S. 1990. Semi-automatic acquisition of con-
ceptual structures from technical texts. International Jour-
nal on Man-Machine Studies 33:385–397.
Woods, W., and Schmolze, J. 1992. The KL-ONE family.
Computers & Mathematics with Applications 23:133–177.

