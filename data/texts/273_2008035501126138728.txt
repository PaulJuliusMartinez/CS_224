WERLBERGER et al.: ANISOTROPIC HUBER-L1 OPTICAL FLOW

1

Anisotropic Huber-L1 Optical Flow

Manuel Werlberger1 werlberger@icg.tugraz.at Werner Trobin1 trobin@icg.tugraz.at Thomas Pock1 pock@icg.tugraz.at Andreas Wedel2 wedel@cs.uni-bonn.de Daniel Cremers2 dcremers@cs.uni-bonn.de Horst Bischof1 bischof@icg.tugraz.at

1 Institute for Computer Graphics and Vision Graz University of Technology
2 Department of Computer Science University of Bonn

Abstract
The presented work is motivated by the problem of restoring severely degraded historic video material via an optical flow-based interpolation. In order to increase the robustness as well as the accuracy of discontinuity preserving variational optical flow models, we propose two extensions. First, we will discuss the deficiencies of an isotropic Total Variation regularization and introduce an anisotropic (i.e. image-driven) regularization based on the robust Huber norm. Second, to cope with the gross outliers contained in historic video material, we propose a novel spatio-temporal regularization approach. Instead of assuming gradual flow changes over time, we impose a symmetry constraint with respect to a central frame. The benefit of the suggested enhancements is illustrated qualitatively on historic video material and quantitatively on the Middlebury optical flow benchmark.
1 Introduction
The estimation of the optical flow between two images, usually taken in close temporal succession, is one of the key problems in low-level vision. Ignited by the two seminal works of Lucas & Kanade [9] and Horn & Schunck [7], a diverse range of optical flow estimation techniques have been developed and we refer to the surveys [3, 6, 18] for a detailed review of the vast amount of related literature.
In order to compare the accuracy of these flow estimation techniques and, even more importantly, to illustrate where they still fail, challenging benchmark sequences with a reliable ground truth are required. The so-called Middlebury dataset [2] is the most recent effort in this direction and we will use these sequences throughout this work. On the corresponding evaluation site at http://vision.middlebury.edu/flow/, discontinuity preserving variational models based on Total Variation (TV) regularization and L1 data terms are
c 2009. The copyright of this document resides with its authors. It may be distributed unchanged freely in print or electronic forms.

2 WERLBERGER et al.: ANISOTROPIC HUBER-L1 OPTICAL FLOW

(a) Isotropic TV-L1

(b) Anisotropic Huber-L1

(c) Isotropic TV-L1

(d) Anisotropic Huber-L1

Figure 1: Comparison of isotropic and anisotropic Huber regularization on (a), (b) the Dumptruck and (c), (d) the RubberWhale sequence (AAE = 4.06  2.93, AEPE = 0.13  0.09). Please note the hole in the semicircle-shaped element and the more distinct
lattice-edges in the anisotropic case

among the most accurate flow estimation techniques, but there is still room for improvement. While Papenberg et al. [11] mainly focused on improving the data conservation constraints, we will take a closer look at the deficiencies of isotropic TV regularization and propose an improved regularizer in Section 2.
Total Variation regularization is an L1 penalization of the flow gradient magnitudes, and due to the tendency of the L1 norm to favor sparse solutions (i.e. lots of `zeros'), the fill-in effect caused by the regularizer leads to piecewise constant solutions in weakly textured areas. This effect, known as `staircasing' in a 1D setting, can be reduced significantly by using a quadratic penalization for small gradient magnitudes while sticking to linear penalization for larger magnitudes to maintain the discontinuity preserving properties known from TV. Huber [8] proposed such a function as an alternative to quadratic penalization in the field of robust statistics, and Shulman and Hervé were the first to apply it in the context of flow estimation [15].
Based on the two observations that motion discontinuities often occur along object boundaries and that in turn object boundaries often coincide with large image gradients, Nagel and Enkelmann [10] proposed to adapt the regularization to the local image structure. Even for the quadratic regularizers used at that time, their anisotropic (image-driven) regularization decreased the well-known oversmoothing effects of the Horn & Schunck model [7] by impeding smoothing across image edges. Therefore, we propose to replace the isotropic TV regularization, e.g. used in [11, 19], with an anisotropic (image-driven) Huber regularization term.
A second contribution of this paper is motivated by an application: the restoration of historic video material via flow-based video interpolation. To cope with the gross outliers contained in the historic video material (cf . Figs. 4 and 5), we propose a novel spatio-temporal regularization approach in Section 3 and compare it against the well-known spatio-temporal regularization proposed in [17]. After a short discussion of implementation details in Section 4 and an evaluation of the presented models on the Middlebury dataset in Section 5, we conclude with a few final remarks in Section 6.
To facilitate further development and to simplify comparisons to alternative flow estimation methods, the Matlab source of the presented flow estimation algorithm can be downloaded from http://www.gpu4vision.org. In addition, we offer a GPU-based highperformance implementation in binary form to encourage the use of state-of-the-art flow estimation techniques in higher-level vision applications.

WERLBERGER et al.: ANISOTROPIC HUBER-L1 OPTICAL FLOW
2 Anisotropic Huber-L1 Optical Flow

3

To make this paper self-contained, we briefly discuss the starting point for our extensions
­ a disparity preserving, spatially continuous formulation of the optical flow problem based on an L1 data term and isotropic TV regularization [11, 19]. For two input images I0 and I1 defined on a rectangular domain   IR2, the model can be stated as

2
min |ud| +  |I1 (x + u (x)) - I0 (x)| dx ,
u  d=1

(1)

where u(x) = (u1(x), u2(x))T, ud :   IR and the free parameter  is used to balance the relative weight of data and regularization term. In contrast to [11], we linearize the data term, which yields a convex optimization problem

2
min |ud| +  |(u(x))| dx ,
u  d=1

(2)

where (u(x)) = u(x)TI1(x) + I1(x) - I0(x) is the well-known optical flow constraint equation. In order to accommodate large displacements, this linearized model has to be embedded in a coarse-to-fine/warping scheme [6]. Nevertheless, to streamline the presentation we will only consider the linearized model from now on.
The functional (2) is hard to minimize in this setting, so to simplify the optimization procedure we introduce an auxiliary variable v and a coupling term to ensure that v is a close approximation of u

min
u,v

2  d=1

|ud| +

1 2

(ud

-

vd )2

+  |(v(x))| dx

,

(3)

where  is a small positive constant [1]. To introduce the anisotropic Huber regularization, we start with a simple manipulation
of a discontinuity preserving, image-driven regularization term

22

 (ud)TDud dx =



 d=1

 d=1

D1/2ud T D1/2ud

dx ,

(4)

where D is a symmetric, positive definite diffusion tensor and  (s2) a (robust) penalty function. Replacing the isotropic TV regularization in (3) with such an image-driven regularizer
leads to

min
u,v

2  d=1

|qd

|


+

1 2

(ud

- vd)2

+  |(v(x))| dx

, with

|qd| =

|qd |2

2

|qd |

-

 2

|qd|   , else

(5) (6)

where qd = D1/2ud for brevity. A reasonable choice for the diffusion tensor is D1/2 =

exp - |I|

n nT

+ n

nT,

where

n

=

I |I|

,

and

n

denotes

a

vector

normal

to

n.

4 WERLBERGER et al.: ANISOTROPIC HUBER-L1 OPTICAL FLOW

Chambolle proposed a projected gradient descent algorithm to minimize the ROF model, which is based on a dual formulation of the TV [5]. In order to obtain a similar algorithm to minimize (5), we need the Legendre-Fenchel (LF) dual [13] of the anisotropic Huber norm fH (qd) = |qd| , which is given as

fH (pd) = sup qd · pd - fH (qd)
qd

=

I{| pd

|1}

+



|

pd |2 2

,

(7)

where  denotes the LF transform, p is the dual variable, and the so-called indicator function I(x) is 0 if x   and  otherwise. The biconjugate of fH can be obtained by applying the LF transform to the conjugate fH (pd):

fH (qd) = sup
pd

pd · qd - fH (pd)

= sup
|pd |1

pd

·

qd

-



|

pd 2

|2

.

(8)

The LF transform is self-inversive due to fH (qd) being convex and lower semi-continuous in qd. Therefore, the biconjugate is equivalent to the initial anisotropic Huber norm fH (qd) = fH (qd). Incorporating this equality in (5) yields

min sup
u,v |pd |1

2  d=1

D1/2ud

·

pd

-

| pd |2 2

+

1 2

(ud

- vd)2

+  |(v(x))| dx

. (9)

This convex minimization problem in u and v can be solved iteratively by an alternating minimization procedure:

1. For fixed v, solve:

min sup
u |pd |1

2  d=1

D1/2ud

·

pd

-

| pd |2 2

+

1 2

(ud

- vd)2

dx

(10)

This optimization problem is similar to the well-known ROF model [14] and can be solved using a variant of the projected gradient descent algorithm proposed in [5]. Applying the divergence theorem on (10) and using D1/2 = D1/2 we get

min sup
u |pd |1

2  d=1

-ud div

D1/2 pd

-

| pd |2 2

+

1 2

(ud

-

vd )2

dx

,

which is now a pointwise problem in u, and hence

(11)

:  ud

- div

D1/2 pd

+ 1 (ud - vd) = 0 



ud = vd +  div D1/2 pd

The functional derivative of (10) w.r.t. pd is given by

:  pd

D1/2ud -  pd = D1/2

vd +  div

D1/2 pd

-  pd

(12) (13)

WERLBERGER et al.: ANISOTROPIC HUBER-L1 OPTICAL FLOW

5

Embedding this into a projected gradient descent update scheme, leads to the iterative scheme

und+1 = vnd +  div D1/2 pnd+1 ,

pnd+1 = max

pnd +  D1/2und+1 -  pnd 1, pdn +  D1/2und+1 -  pnd

,

(14) (15)

where the step-width is given by  = 1/(4 + ).

2. For fixed u, solve for the auxiliary variable v:

min
v



1 2

2
(ud
d=1

- vd)2

+

| (v(x))|

dx

(16)

Here a simple thresholding step with three different cases yields a direct solution [19]:

 



I1



vn+1 = un+1 + -  I1

- un+1

I1 |I1 |2

if  un+1 < -  |I1|2 if  un+1 >   |I1|2
else

(17)

The difference between an isotropic TV and an isotropic Huber regularization is illus-
trated in Fig. 2, showing a rendering of u1 from the Dimetrodon sequence (cf . Fig. 7(a)). The color coded flow is superimposed as texture. While the TV regularization causes the characteristic piecewise constant levels (cf . Fig. 2(a), AAE = 3.03, AEPE = 0.16), the Huber regularization (cf . 2(b),  = 0.01, AAE = 2.77, AEPE = 0.14) yields a significantly
smoother result. In Fig. 2(c) the influence of the threshold , which defines the location of the
transition from a quadratic to a linear penalty, on the average angular error (AAE, cf . [2]) and
the average end-point error (AEPE, cf . [2]) is shown on the Dimetrodon dataset. Please note that the Huber norm approaches the TV as   0. The benefits of integrating directional
information are depicted in Fig. 1.

Average anglular error (AAE) Average end-point error (AEPE)

3.2 0.16

3.1 0.155

3
2.9
2.8 0

0.15

AAE AEPE

0.145

0.01 0.02 0.03 0.04 0.05 

(a) (b)

(c)

Figure 2: Comparing (a) the staircasing afflicted TV regularization and (b) the Huber regularization on the Dimetrodon dataset; (c) average angular and average end-point error as a function of the Huber norm parameter 

6 WERLBERGER et al.: ANISOTROPIC HUBER-L1 OPTICAL FLOW
3 A Temporal Symmetry Constraint

A majority of optical flow estimation methods impose only spatial continuity constraints to solve the aperture problem. Widely cited extensions to a spatio-temporal continuity include [4] for a causal method, [17] for a method that is symmetric w.r.t. `past' and `future' in the image sequence and therefore only suitable for offline processing and [12] for a patch-based variant. Here we will only consider the spatio-temporal regularization presented in [17], which is based on the assumption that the flow field changes gradually over time. This assumption has been used successfully on the well-known Yosemite benchmark sequence (with clouds), where the average angular error could be reduced from 2.44 to 1.78 by including a temporal continuity constraint [11]. Considering the quoted improvements, it is surprising that not a single one out of 27 flow estimation methods currently listed on the Middlebury benchmark site employs such a spatio-temporal continuity constraint. Upon closer inspection, however, it turns out that the properties of the Yosemite sequence (steady camera motion through a distant, static scene combined with relatively small displacements) are perfectly suitable for temporal smoothing, whereas the Middlebury benchmark sequences contain more complex motions as well as significantly larger displacements, so using the spatio-temporal regularization proposed in [17] has adverse effects on the estimated flows.
Instead of assuming gradual flow changes through time, we propose a 3-frame method that `mirrors' the flow symmetric w.r.t. the central frame by extending the anisotropic flow (5) with one additional data fidelity term

min
u,v

2  d=1

|qd

|


+

1 2

(ud

- vd)2

+  |1c (v(x))| +  |3c (v(x))| dx

,

(18)

where 1c and 3c denote the linearized brightness constancy constraints between the first and the central frame and between the third and the central frame, respectively:

1c(v(x)) = -v(x)TI1(x) + I1(x) - Ic(x) 3c(v(x)) = v(x)TI3(x) + I3(x) - Ic(x) .

(19) (20)

[16] shows how to extend the thresholding scheme (17) using a second data fidelity term. Conceptually, this model implies ­ independently for every pixel ­ a linear motion from
the first to the third frame, which is obviously constrained to be symmetric to the central

(a) (b) (c)
Figure 3: Comparison of: (a) ground truth; (b) spatio-temporal TV regularization (AAE=11.70, AEPE=1.75); (c) anisotropic Huber-L1 flow with symmetry constraint (AAE=6.32, AEPE=0.70) on the Urban3 sequence. For the result without symmetry constraint we refer to Fig. 7(h)

WERLBERGER et al.: ANISOTROPIC HUBER-L1 OPTICAL FLOW

7

frame. The key difference to [17] is that the frames one and three are both warped towards
the central frame, so this model is applicable to a wider class of motions. We illustrate
this difference using the Urban3 sequence of the Middlebury database. The color-coded
ground truth flow is depicted in Fig. 3(a), the result of a spatio-temporal TV regularization (AAE=11.70, AEPE=1.75) can be observed in Fig. 3(b), and the result of the proposed model (AAE=6.32, AEPE=0.70) is depicted in Fig. 3(c). The simultaneous presence of
outliers (red and green blobs) and heavy oversmoothing in Fig. 3(b) indicates that the as-

(a) Frame 47

(b) Frame 48

(c) Frame 49

(d) Spatio-temporal TV

(e) Anisotropic Huber-L1
Figure 4: `Krems' sequence

(f) Aniso. Huber-L1 + sym. cstr.

(a) Frame 58

(b) Frame 59

(c) Frame 60

(d) Spatio-temporal TV

(e) Anisotropic Huber-L1

(f) Aniso. Huber-L1 + sym. cstr.

Figure 5: Sequence 'Car Ride in the Pyrenees', 1910

8 WERLBERGER et al.: ANISOTROPIC HUBER-L1 OPTICAL FLOW sumption of a gradual flow field change over time is invalid for this sequence.
The proposed symmetry constraint is specifically targeted at video restoration applications, where single frames are degraded, e.g. with blobs and scratches, and trades some flexibility for robustness. Hence, compared to a purely spatial regularization, the accuracy is slightly inferior on the clean Middlebury data (cf . Fig. 7(h) and Table 1). However, the comparison on the sequences shown in Figs. 4 and 5, where the central frames are severely degraded, illustrates that the imposed symmetry of the flow increases the robustness of the estimate in the presence of gross outliers, compared to both spatio-temporal TV regularization [11] as well as the anisotropic (two-frame) flow proposed in Section 2.
4 Implementation
As stated in Section 2, the proposed algorithm is based on a linearized data term and therefore has to be embedded in a coarse-to-fine/warping scheme. For all experiments in this paper, the image pyramid was constructed using a scale factor of 0.8. In a slight departure from [11], we additionally decomposed every image in the pyramid into a `structure' and a `texture' part via ROF denoising [14] ( = 10). The actual input to the flow algorithm was a linear combination of these two parts with the relative weights structure:texture = 1:4 to reduce the impact of illumination changes.
The derivative operators were discretized as forward differences with reflecting (Neumann) boundary conditions. Hence, the divergence operator is based on backward differences with Dirichlet boundary conditions. The iterative solution procedure starts with u = 0 on the coarsest scale of the pyramid and since we aim for high-accuracy, we repeatedly warp the `moving' image [6] with a median-filtered version of the current solution. This 3x3 median filter is also applied when prolonging the flow to the next finer level in the image pyramid, because it helps to get rid of outliers.
We implemented our proposed optical flow approach using Matlab and in addition we have a GPU-accelerated C++ implementation, using the Nvidia CUDA framework. The parallelization capabilities of modern GPUs are well suited to optimize such variational problems.
Figure 6: Screenshots of the Middlebury benchmark results; More details and the given references are available at http://vision.middlebury.edu/flow/.

WERLBERGER et al.: ANISOTROPIC HUBER-L1 OPTICAL FLOW

9

(a) (b) (c) (d)

(e) (f) (g) (h)
Figure 7: Anisotropic Huber-L1 flow results on the training sequences of the Middlebury benchmark dataset. The second row in Table 1 lists the respective average end-point errors
5 Evaluation
To quantify the improvements of the proposed anisotropic Huber regularization over TV regularization and to compare it to other state-of-the-art algorithms, we evaluated our algorithm on the Middlebury benchmark sequences [2]. As required, the parameters were held constant for all sequences and, in fact, for all the other experiments presented in this paper as well. We used a scale factor of 0.8 for the image pyramid and set  = 40,  = 0.1,  = 0.01,  = 5.0 and  = 0.5. At the time of submission, the proposed method was ranked within the top four results for almost all error measures listed on http://vision.middlebury. edu/flow/, cf . Fig. 6 for the average end-point error and the angular error (both ranked third). While the anisotropic Huber-L1 model yields accurate results on most sequences, there are some notable outliers: Mequon, Schefflera, and Yosemite. On the Mequon sequence, the university logo on the T-shirt causes strong edges in the image, thereby inducing a large anisotropy in the regularization. At the same time, the T-shirt is only weakly shaded, hence the regions close to the motion discontinuity around the two figures are handled incorrectly. The fragmented occlusion caused by the Schefflera leaf in the right/top corner of the aptly named sequence is hard to get right for local optimization approaches, let alone the repetitive texture and the illumination changes. On the noisy Yosemite sequence, the accuracy could easily be improved by pre-smoothing or a significantly lower  . For completeness, we also give an overview of the results on the Middlebury training dataset in Fig. 7. The corresponding average end-point errors are shown in the second row of Table 1. In the first row of Table 1, the results of an isotropic TV regularization can be seen and the last row lists the results obtained when imposing the symmetry constraint we proposed in Section 3. As discussed previously, this modeling constraint is too restrictive for the complex motions contained in the Middlebury sequences. However, for the degraded historic sequences in Figs. 4 and 5 the qualitative improvement is evident, although we do not have ground truth data to back this up quantitatively.
Our C++/CUDA implementation of the proposed algorithm is highly configurable and the user can either emphasize performance or accuracy. Using the `high-accuracy' settings mentioned above with 10 warps and 50 iterations per warp, the flow estimation takes 1.13

10 WERLBERGER et al.: ANISOTROPIC HUBER-L1 OPTICAL FLOW

Algorithm

Dimetrodon Hydrangea RubberWhale Venus Grove2 Grove3 Urban2 Urban3

I-TV-L1

0.16 0.16

0.12 0.37 0.14 0.64 0.41 0.91

A-Huber-L1

0.14 0.16

0.09 0.34 0.14 0.55 0.40 0.48

A-Hub.-L1 SY n.a. 0.33 0.13 n.a. 0.14 0.61 0.77 0.70

Table 1: The average end-point error (AEPE) on the Middlebury training sequences for

isotropic TV-L1 (I-TV-L1), anisotropic Huber-L1 (A-Huber-L1), and anisotropic Huber-L1

with symmetry constraint (A-Hub.-L1 SY)

seconds on the Urban sequence (640x480) on a recent 64bit Linux system, equipped with an Intel Core 2 Quad at 2.66 GHz and an Nvidia GTX 280 GPU. Enabling the symmetry condition increases the amount of data to be processed, hence the calculation time increases to 1.23 seconds on Urban.

6 Conclusion and Future Work
In this paper we illustrated the benefits of an image-driven, discontinuity preserving regularization term over the widely used isotropic TV regularization. Moreover, we demonstrated that the staircasing effect in weakly textured areas can be reduced substantially by using the Huber norm instead of the TV. We also demonstrated in which situations the spatio-temporal regularization approach introduced in [17] fails and proposed a more robust alternative. Due to the promising results so far, we plan to extend this spatio-temporal regularization from the current `linear parametric' model to higher-order polynomials.

7 Acknowledgement
This work was partly supported by the Austrian Research Promotion Agency (FFG) within the vdQA Project (816003).

References
[1] J. F. Aujol, G. Gilboa, T. Chan, and S. J. Osher. Structure-texture image decomposition: Modeling, algorithms, and parameter selection. International Journal of Computer Vision, 67(1):111­136, 2006.
[2] S. Baker, D. Scharstein, J. P. Lewis, S. Roth, M. J. Black, and R. Szeliski. A database and evaluation methodology for optical flow. In Proceedings 13th International Conference on Computer Vision, 2007.
[3] S. S. Beauchemin and J. L. Barron. The computation of optical flow. ACM Computing Surveys, 27(3):433­466, September 1995.
[4] M. J. Black and P. Anandan. Robust dynamic motion estimation over time. In Proceedings IEEE Conference on Computer Vision and Pattern Recognition, pages 296­302, June 1991.
[5] A. Chambolle. An algorithm for total variation minimization and applications. Journal of Mathematical Imaging and Vision, 20(1-2):89­97, 2004.

WERLBERGER et al.: ANISOTROPIC HUBER-L1 OPTICAL FLOW

11

[6] D. J. Fleet and Y. Weiss. Optical flow estimation. In N. Paragios, Y. Chen, and O. Faugeras, editors, Handbook of Mathematical Models in Computer Vision, chapter 15, pages 239­258. Springer, 2006.

[7] B. K. P. Horn and B. G. Schunck. Determining optical flow. Artificial Intelligence, 17: 185­203, 1981.

[8] P. J. Huber. Robust regression: Asymptotics, conjectures and Monte Carlo. Annals of Statistics, 1(5):799­821, 1973.

[9] B. D. Lucas and T. Kanade. An iterative image registration technique with an application to stereo vision. In Proceedings of the 7th International Joint Conference on Artificial Intelligence, pages 674­679, April 1981.

[10] H.-H. Nagel and W. Enkelmann. An investigation of smoothness constraints for the estimation of displacement vector fields from image sequences. IEEE Transactions on Pattern Analysis and Machine Intelligence, 8(5):565­593, 1986.

[11] N. Papenberg, A. Bruhn, T. Brox, S. Didas, and J. Weickert. Highly accurate optic flow computation with theoretically justified warping. International Journal of Computer Vision, 67(2):141­158, April 2006.

[12] I. Patras, M. Worring, and R. van den Boomgaard. Dense motion estimation using regularization constraints on local parametric models. IEEE Transactions on Image Processing, 13(11):1432­1443, November 2004.

[13] R. T. Rockafellar. Convex analysis. Princeton Landmarks in Mathematics. Princeton University Press, Princeton, NJ, 1997. ISBN 0-691-01586-4. Reprint of the 1970 original, Princeton Paperbacks.

[14] L. Rudin, S. J. Osher, and E. Fatemi. Nonlinear total variation based noise removal algorithms. Physica D, 60:259­268, 1992.

[15] D. Shulman and J.-Y. Hervé. Regularization of discontinuous flow fields. In Proceedings Workshop on Visual Motion, pages 81­86, 1989.

[16] A. Wedel, T. Pock, J. Braun, U. Franke, and D. Cremers. Duality TV-L1 flow with fundamental matrix prior. In Proceedings Image and Vision Computing New Zealand, November 2008.

[17] J. Weickert and C. Schnörr. Variational optic flow computation with a spatio-temporal smoothness constraint. Journal of Mathematical Imaging and Vision, 14(3):245­255, 2001.

[18] J. Weickert, A. Bruhn, T. Brox, and N. Papenberg. A survey on variational optic flow methods for small displacements. In O. Scherzer, editor, Mathematical Models for Registration and Applications to Medical Imaging, pages 103­136. Springer, Berlin, 2006.

[19] C. Zach, T. Pock, and H. Bischof. A duality based approach for realtime TV-L1 optical flow. In Pattern Recognition, volume 4713 of LNCS, pages 214­223, 2007.

