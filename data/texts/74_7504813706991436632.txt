Logic Programming Revisited: Logic
Programs as Inductive Deﬁnitions

MARC DENECKER and MAURICE BRUYNOOGHE
Katholieke Universiteit Leuven
and
VICTOR MAREK
University of Kentucky

Logic programming has been introduced as programming in the Horn clause subset of ﬁrst-order
logic. This view breaks down for the negation as failure inference rule. To overcome the problem, one
line of research has been to view a logic program as a set of iff-deﬁnitions. A second approach was
to identify a unique canonical, preferred, or intended model among the models of the program and
to appeal to common sense to validate the choice of such model. Another line of research developed
the view of logic programming as a nonmonotonic reasoning formalism strongly related to Default
Logic and Autoepistemic Logic. These competing approaches have resulted in some confusion about
the declarative meaning of logic programming. This paper investigates the problem and proposes
an alternative epistemological foundation for the canonical model approach, which is not based on
common sense but on a solid mathematical information principle. The thesis is developed that logic
programming can be understood as a natural and general logic of inductive deﬁnitions. In particular,
logic programs with negation represent nonmonotone inductive deﬁnitions. It is argued that this
thesis results in an alternative justiﬁcation of the well-founded model as the unique intended model
of the logic program. In addition, it equips logic programs with an easy-to-comprehend meaning
that corresponds very well with the intuitions of programmers.
Categories and Subject Descriptors: D.1.6 [Programming Techniques]: Logic Programming;
D.3.1 [Programming Languages]: Formal Deﬁnitions and Theory—Semantics; F.3.2 [Logics
And Meanings Of Programs]: Semantics of Programming Languages—Algebraic approaches to
semantics; F.4.1 [Mathematical Logic And Formal Languages]: Mathematical Logic—Compu-
tational logic; Logic and constraint programming; I.2.3 [Artiﬁcial Intelligence]: Deduction and
Theorem Proving—Logic programming; Nonmonotonic reasoning and belief revision; I.2.4 [Artiﬁ-
cial Intelligence]: Knowledge Representation Formalisms and Methods
General Terms: Languages, Theory
Additional Key Words and Phrases: Epistemological foundations, inductive deﬁnitions

Research supported by the project GOA/98/08 and the research network Declarative Methods in
Computer Science (both funded by the Flemish government). The third author acknowledges a
partial support of the NSF grant IRI-9619233.
Author addresses: M. Denecker and M. Bruynooghe, Department Computer Science, Celestijnen-
laan 200A, B 3001 Heverlee, Belgium; V. Marek, Computer Science Department, University of
Kentucky, Lexington, KY 40506-0046.
Permission to make digital/hard copy of all or part of this material without fee for personal or class-
room use provided that the copies are not made or distributed for proﬁt or commercial advantage,
the ACM copyright/server notice, the title of the publication, and its date appear, and notice is given
that copying is by permission of the ACM, Inc. To copy otherwise, to republish, to post on servers,
or to redistribute to lists requires prior speciﬁc permission and/or a fee.
C(cid:176) 2001 ACM 1529-3785/01/1000–0623 $5.00

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001, Pages 623–654.

624

†

Marc Denecker et al.

1. INTRODUCTION
Logic programming has its roots in the investigations of the resolution principle
[Robinson 1965], an inference method for ﬁrst-order logic. Restricting the ﬁrst-
order theories to Horn theories consisting of deﬁnite clauses and a deﬁnite
goal, one could design proof procedures that avoid many of the redundancies
showing up in the search spaces of the more general theorem provers of those
days. Moreover, one could give a procedural reading to the deﬁnite clauses
that corresponds to the strategy followed by SLD-proof procedures as explained
in the seminal Kowalski [1974] paper. Meanwhile, the group of Colmerauer
developed a programming language along the same lines and called it Prolog
[Colmerauer et al. 1973] as abbreviation for PROgrammation en LOGique.

Many researchers were attracted by the new paradigm: application program-
mers by the ability to program at a, until then, unprecedented level of abstrac-
tion; implementors by the challenge to design and develop efﬁcient implemen-
tations; theoreticians by the opportunity to analyze a paradigm rooted in logic.
Originally, logic programming was often summarized as programming in
a subset of ﬁrst-order logic. Speciﬁcally, this subset is the Horn logic, based
on Horn theories, i.e., theories consisting of clauses with at most one positive
literal. Despite the fact that this view is still wide-spread, it broke down soon
after logic programming originated. The introduction of the negation as failure
rule raised the following dilemma to the logic programming community:

—On the one hand, the negation as failure inference rule was unsound with
respect to the declarative reading of a program as a ﬁrst-order Horn theory
[Clark 1978].

—On the other hand, negation as failure derived conclusions with a strong
commonsense appeal and turned out to be very useful and natural in many
practical situations.

The way out was either to drop negation as failure or to strengthen the interpre-
tation of logic programs as Horn theories. The multiple and natural applications
of negation as failure resulted in choosing the second option. What at the start
seemed to be a hack became a feature. The logic programming community de-
cided that they did not want classical logic semantics for logic programs. As
Przymusinski [1989b] expressed it later, “we want the semantics of logic pro-
grams to be determined more by their commonsense meaning than by their
purely logical contents.” This raised the following fundamental question: what
is this commonsense meaning, and how can we provide a formal semantics for
it? The search for an answer to this question started in the late seventies and
was intensively pursued until the early nineties. These investigations resulted
in a complex and heterogeneous landscape of logic programming.

With respect to deﬁnite programs (i.e., programs without negation), the ques-
tion was soon settled. While logicians [Smullyan 1968] knew for long time
that consistent Horn theories possess a least Herbrand model, van Emden
and Kowalski [1976] showed the existence of the least Herbrand model as the
least ﬁxpoint of a monotone operator, the immediate consequence operator. A
few years later, Reiter [1978] showed that the least Herbrand model was the

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

Logic Programs as Inductive Deﬁnitions

†

625

unique intended interpretation of a Horn program augmented with the com-
monsense reasoning principle of the Closed-World Assumption. The least Her-
brand model is now widely accepted as the intended interpretation of a deﬁnite
logic program.

With respect to programs with negation, things turned out to be much more
complex. There seemed to be different commonsense ways in which a logic
program could be interpreted. This resulted in three major research directions.
Clark [1978] proposed to interpret a logic program as a ﬁrst-order theory,
called the completion of the program. It consists of a set of logical iff-deﬁnitions
of which the rules of the programs represent only the if-parts, augmented with
a theory that axiomatizes the uniﬁcation. Although this approach resulted in
a large body of research, including a three-valued completion semantics for
programs with negation [Fitting 1985], a basic shortcoming of it is that it fails to
capture the intuitive meaning, even in the case of deﬁnite programs. A notorious
example is the transitive closure program. The unique intended interpretation
of this program is its least Herbrand model. However, the completed theory
can have also other models. In fact, every ﬁxpoint of the van Emden-Kowalski
operator is a model of the completion.

The canonical model, standard or preferred model approach is the second
major research direction. The idea is to select one model among the Herbrand
models as the intended model. The justiﬁcation for the chosen model is typ-
ically based on the appeal to common sense, i.e., on what the reader natu-
rally expects to be the meaning of the program. The approach was initiated by
Reiter [1978] for deﬁnite programs. Later, the canonical model approach was ex-
tended to larger classes of programs. It started with work on the perfect model
semantics for stratiﬁed programs [Apt et al. 1988; Van Gelder 1988], which
was extended to locally stratiﬁed [Przymusinski 1988] and weakly stratiﬁed
[Przymusinska and Przymusinski 1990] programs. This direction culminated
in the well-founded semantics which deﬁnes a unique (possibly three-valued)
model for all normal programs [Van Gelder et al. 1991].

A third major direction was motivated by the research in nonmonotonic rea-
soning. The idea was introduced by Gelfond [1987], who proposed to interpret
failure to prove literals not p as epistemic literals I do not know p and rep-
resented them by the modal literal :K p in autoepistemic logic (AEL) [Moore
1985]. In this embedding, a logic programming rule

p :-

q, not r

is interpreted as the following AEL formula:
p ˆ q ^ :K r

Marek and Truszczy ´nski [1989] proposed a similar embedding in default logic
[Reiter 1980] which maps the above rule to the default:

q : :r
p

In this view, logic programming is seen as a restricted form of default logic or
autoepistemic logic. This approach resulted in stable semantics of logic

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

626

†

Marc Denecker et al.

programs [Gelfond and Lifschitz 1988] and was the foundation for answer set
programming [Niemel¨a 1999; Marek and Truszczy ´nski 1999].

It is easy to see that the above approaches are based on different common-
sense interpretations of logic programming. Consider for example the deﬁnite
program fp : ¡qg. In the completion, stable, and well-founded semantics, its
unique model is the empty set fg.
—Under completion semantics, the meaning of the program is given by the
theory fq $ false, p$ qg which entails the falsity of p and q. The same holds
for the canonical model views which all coincide for this program.
—Interpreted as an answer set program, its meaning is given by the unique
answer set fg. Since an answer set is to be interpreted as a ﬁrst-order theory
consisting of literals, the meaning of this answer set program is given by the
empty ﬁrst-order theory and entails neither :p, nor :q, nor even pˆ q. This
interpretatigon matches with the embedding of the program in default logic.
The unique default extension of the default

is the (deductive closure of the) empty ﬁrst-order logic theory.

q:
p

This example illustrates that “the” commonsense meaning of logic programs
does not exist; in fact a number of different intuitions exist. The existence
of multiple “commonsense” meanings of logic programming is responsible
for the complex landscape of logic programming semantics. Consequently,
common sense gives little hope for deﬁning a generally accepted single seman-
tics. In view of this multiplicity of viewpoints, we need to ﬁnd other, more solid
information principles that can serve as an epistemological foundation for logic
programming.

The goal of this paper is to propose such an alternative epistemological foun-
dation for logic programming. It is not based on a commonsense principle but on
a solid mathematical information principle.1 The thesis is developed that logic
programming can be understood as a natural and general logic of inductive deﬁ-
nitions In this view, logic programs represent deﬁnitions; logic programs with
recursion represent inductive deﬁnitions. In particular, viewing logic programs
as inductive deﬁnitions yields a solid justiﬁcation for the well-founded model as
the unique intended model of a logic program. Thus, our work provides an epis-
temological foundation for the well-founded model as the canonical model of a
logic program. Moreover, it equips logic programs with an easy-to-comprehend
meaning that corresponds very well with the intuitions of programmers.

The main argument for the thesis comes from the comparison of logic
programming with studies of inductive deﬁnitions in mathematical logic.
Such a comparison shows a strong congruence between these studies and
logic programming at the knowledge-theoretical, syntactical, semantical, and
complexity-theoretical level. In particular, this paper compares deﬁnite logic

1With the term “information principle” we mean a semantic principle, disconnected from any par-
ticular inferential mechanism.

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

Logic Programs as Inductive Deﬁnitions

†

627

programs with positive and monotone inductive deﬁnitions, and programs with
negation with two approaches for generalized nonmonotone inductive deﬁ-
nitions, inﬂationary inductive deﬁnitions and iterated inductive deﬁnitions.
Moreover, it is pointed out that there are natural types of inductive deﬁnitions
that can be represented by logic programs that have no counterpart in mathe-
matical logic studies of inductive deﬁnitions. It is argued therefore that logic
programming under well-founded semantics can make an original knowledge-
theoretical contribution to the formal study of inductive deﬁnitions and can help
to improve our understanding of what nonmonotone inductive deﬁnitions are.
We believe that appealing to the reading of logic programs as inductive
deﬁnitions provides a much stronger justiﬁcation for the intended model than
appealing to common sense; it explains why the intended model has a common
sense appeal.

Our paper is structured as follows. Sections 2 and 3 offer brief overviews of
the syntax and semantics of logic programming and of inductive deﬁnitions.
These sections deﬁne the necessary background for the main arguments in the
text, the comparison of both areas in Section 4. In Section 5 we discuss the
implications of our view. We conclude in Section 6.

2. A BRIEF OVERVIEW OF LOGIC PROGRAMMING

SYNTAX AND SEMANTICS

We assume familiarity with basic syntactical and semantical concepts of classi-
cal logic and logic programming [Lloyd 1987]. A logical alphabet 6 consists of
variables, constants, function symbols, and predicates. The ﬁrst-order logical
language based on 6 is the set of all well-formed ﬁrst-order formulas using
symbols of 6. Terms are deﬁned in the usual inductive process from constants
and variables of the language by application of function symbols. Atoms are
formulas of the form p(t1, : : : , tn) where p is a predicate symbol and t1, : : : , tn
are terms; literals are atoms or their negation. The Herbrand-universe HU is
the set of all ground terms. The Herbrand base H B is the set of all ground atoms.
A deﬁnite rule is of the form a :- B where a is an atom and B a conjunction of
atoms. A normal rule can also have negative literals in the body B. Note that we
use the rule operator :- to distinguish rules from classical logic implications. A
deﬁnite (respectively: normal) program is a set of deﬁnite (respectively: normal)
rules. A normal program P is called stratiﬁed [Apt et al. 1988; Van Gelder
1988] if it can be split in a sequence of nP strata (Pi)0•i<nP such that for each
predicate symbol p there exists a unique natural number ip called the level of p
such that for each rule C D p(t1, : : , tn):-B2 P it holds that (1) C 2 P iff C 2 Pip,
(2) if predicate symbol q occurs in a positive literal of B then iq • ip, and (3) if
predicate symbol q occurs in a negative literal of B, then iq < ip. Pi is called the
ith stratum of P.

Local stratiﬁcation generalizes the concept by considering the grounding
of the program: the possibly inﬁnite propositional2 logic program, denoted
ground(P), consisting of all rules that can be obtained by substituting all
variables of a rule by ground terms. A normal program P is called locally

2Ground atoms are considered propositions in the corresponding propositional system.

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

628

†

Marc Denecker et al.

stratiﬁed [Przymusinski 1988] if there is a possibly inﬁnite ordinal number nP
and if the grounding of P can be split in a sequence of nP strata (Pi)0•i<nP such
that for each atom p there exists a unique ordinal number ip called the level of
p such that for each rule C D p:-B 2 ground (P) it holds that (1) C 2 ground (P)
iff C 2 Pip, (2) if atom q occurs in a positive literal of B then iq • ip, and (3) if
atom q occurs in a negative literal of B then iq < ip.
As usual in logic programming, we will use the grounding of a program P

rather than the program itself to provide the meaning of the program.3

We now give an overview of the semantics of logic programming. The theory
outlined here is the algebraic approach to logic programming semantics based
on operators in lattices, mostly due to Fitting [1985], Gelfond and Lifschitz
[1988], Przymusinski [1990], and Fitting [1991; 1993]. To make this paper self-
contained we will introduce the main concepts of this approach.
The lattice T WO D ff, tg is ordered by the natural ordering • with f • t.
This deﬁnes a complete lattice ordering of T WO. We will also consider the
lattice FOUR that consists of elements ?, >, f4, t4. There are two natural lattice
orderings in FOUR. Namely the truth ordering •t where f4 •t ?, f4 •t >, ? •t
t4, > •t t4 and the knowledge ordering •k where ? •k f4, ? •k t4, f4 •k >, t4 •k
>. Each element has its inverse ?¡1 D ?, >¡1 D >, f4
¡1 D f4. T HREE
is the restriction of FOUR to ?, f4, t4. Note that t4, f4 have no least upperbound
with respect to •k in T HREE hence •k is not a complete lattice ordering in
T HREE.

¡1 D t4, t4

To deﬁne semantics for logic programs we will need to discuss interpretations.
Those are deﬁned as mappings from the Herbrand base H B of the program
into the set of truth values: two-valued interpretations map atoms into T WO,
three-valued interpretations into T HREE, and four-valued interpretations into
FOUR. The orderings • in T WO and •t and •k in FOUR lift to interpre-
tations. So, for two-valued interpretations, I • J holds if I(a)• J(a) for each
atom a. The orders • and •t deﬁne complete lattice orderings in the corres-
ponding sets of two-, three-, and four-valued interpretations; the order •k is a
complete lattice ordering of four-valued interpretations but not of three-valued
interpretations.

We will use a slightly different representation for three-valued and four-
valued interpretations which will allow to simplify the formalization of the
semantics. It is based on the fact that FOUR can be deﬁned alternatively as
the product lattice of T WO. Namely, we can deﬁne ? D (f, t), > D (t, f), f4 D
(f, f), t4 D (t, t). In this representation, the orders •t, •k, and the inverse in
FOUR are generated by the simple laws: (v, w) •t (v1, w1) iff v • v1 and w • w1;
(v, w) •k (v1, w1) iff v • v1 and w ‚ w1; (v, w)¡1 D (w¡1, v¡1). Note that T HREE
is the set of tuples (v, w) such that v • w.

With this representation in mind, it is easy to see that there is a one-
to-one correspondence between three- and four-valued interpretations v and
pairs (I, J) of two-valued interpretations, namely, for each symbol p, v(p) D

3Using the grounding of a program boils down to restricting models to Herbrand interpretations.
In Section 5.4, we brieﬂy discuss the effect of this restriction and the extension of the semantics to
general interpretations.

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

Logic Programs as Inductive Deﬁnitions

†

629

(I(p), J(p)). Thus, a four-valued interpretation can also be deﬁned as a pair
hI, Ji of two-valued interpretations. Three-valued interpretations correspond
to pairs hI, Ji such that I • J. The orders are then deﬁned by hI, Ji •t hI1, J1i
iff I • I1 and J • J1; hI, Ji •k hI1, J1i iff I • I1 and J ‚ J1. If we view the two-
valued interpretations I and J in the four-valued interpretation hI, Ji as sets
of true atoms, then the set I \ J identiﬁes the atoms that are true in hI, Ji; the
set H Bn(I [ J) deﬁnes the false atoms; the set J n I those that are undeﬁned
and ﬁnally, the set InJ those that are inconsistent.

A useful and natural way of interpreting a three-valued interpretation is as
an approximation of two-valued interpretations. A three-valued interpretation
hI, Ji approximates every two-valued interpretation I0 such that I • I0 • J.
Here I is an underestimate of I0, whereas J is an overestimate. The know-
ledge ordering of approximations corresponds to the intuition of a tighter, more
precise approximation. As we will show, the four-valued semantics of logic pro-
grams can be considered as a computation of a sequence of improving approxi-
mations until some ﬁxpoint is reached. The sequence is obtained by iterating
some operator that takes an approximation and reﬁnes it by deriving a better
approximation consisting of a greater underestimate and lower overestimate.
While we are really interested in approximations (i.e., three-valued interpreta-
tions), the considerations of the bilattice of four-valued interpretations consi-
derably simplify the arguments because the set of three-valued interpretations
does not form a lattice under the ordering •k, whereas the set of four-valued
interpretations does.

Now we are ready to discuss the operators in the lattices of interpretations.
The ﬁrst operator is the immediate consequence operator TP deﬁned by van
Emden and Kowalski [1976]. There exists three versions of it: the two-valued
operator denoted TP was deﬁned by van Emden and Kowalski [1976]; the three-
valued version 8P was introduced by Fitting [1985], and the four-valued version
was introduced by Fitting [1991] and will be denoted by TP . These operators
can be deﬁned uniformly in the following way. Let I be any two-valued in-
terpretation (respectively three-valued, four-valued interpretation). We deﬁne
J D TP (I) (respectively 8P (I), TP (I)) so that, for each atom a, J(a) is computed
in two steps:
(a) Compute the truth value4 of the body B of each clause a:- B with respect

to I.

(b) Take the maximum5 of the values computed in point (a). This is J(a).
Obviously, TP generalizes 8P , which in turn generalizes TP ; so, for a three-
valued interpretation I, TP (I) D 8P (I).
The operator TP is •-monotone if P is a deﬁnite program, but not in general.
The Knaster-Tarski theorem [Tarski 1955] asserts that every monotone opera-
tor in a complete lattice possesses a ﬁxpoint, that the ﬁxpoints themselves form

4In the case of three- and four-valued interpretations, the truth value of B is the •t-minimum of
the truth values of the literals in B.
5In the case of three- and four-valued interpretations, the maximum with respect to •t is to be
computed.

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

630

†

Marc Denecker et al.

a complete lattice, and that the least ﬁxpoint can be computed by iteration of
the operator starting at the least element of the lattice. Thus in case of a deﬁ-
nite program P, TP has a unique least ﬁxpoint called the least Herbrand model
[van Emden and Kowalski 1976]. But in the general case of normal programs,
there is no guarantee that TP has a least ﬁxpoint; it may have no ﬁxpoint at
all or multiple minimal ones. Fixpoints of TP have been identiﬁed as Herbrand
models of the completion of P [Apt and van Emden 1982].
The operators 8P and TP can be deﬁned equivalently on pairs of two-valued
interpretations. It can be easily veriﬁed that TP maps a pair hI, Ji to a pair
hI1, J1i such that, for each atom a2 H B, a is true in I1 if a rule a :- B can be found
such that each positive literal in B is true in I and each negative literal in B is
true in J; a is true in J1 if a rule a :- B can be found such that all positive literals
of B are true with respect to J and all negative literals of B are true with respect
to I. This observation is interesting for two reasons. First, it deﬁnes the three-
and four-valued operators in terms of standard two-valued truth arithmetic.
Second, it illuminates the way TP computes new approximations. Assume that
we have obtained a pair hI, Ji that approximates some intended but so far
unknown interpretation I0. The operator TP produces a new approximation
hI1, J1i of I0: I1 is obtained by underestimating all literals in the bodies of rules,
hence by evaluating positive literals with respect to I and negative literals with
respect to J. I2 is obtained by overestimating all literals. Thus, I1 and J1 provide
a new under- and overestimate.
Given this intuition, it is now easy to see that better approximations
produce (via TP ) yet better approximations. That is, if hI, Ji•k hI0, J0i then
TP (hI, Ji) •k TP (hI0, J0i). In other words TP is •k-monotone. Moreover, for ap-
proximations hI, Ji (i.e., when I • J), the value TP (hI, Ji) is also an approxima-
tion. The effect of the ﬁrst of these two facts is that the Knaster-Tarski theorem
is applicable, and so the operator TP possesses a least ﬁxpoint (in the ordering
•k). The second fact implies that the least ﬁxpoint computation generates more
and more precise approximations and that the ﬁxpoint is also an approximation.
In other words, the least ﬁxpoint has no inconsistent atoms. Hence, it is also
the least ﬁxpoint of the three-valued immediate consequence operator. Since a
similar construction has been applied by Kleene in his ﬁxpoint theorem for par-
tial recursive functions and by Kripke in his famous paper on truth, the least
ﬁxpoint of the operator TP is often called the Kripke-Kleene ﬁxpoint [Fitting
1985].

We will now discuss the other two operators important for our investigations.
Let I be a two-valued interpretation. The Gelfond-Lifschitz reduct, P I , of

the propositional program P is obtained in two steps.
(a) We eliminate from P all clauses C such that the body of C contains a literal

:a false in I (i.e., a is true in I);

(b) in the remaining clauses, we eliminate all negative literals in the bodies.

Note that negative literals in these clauses are true in I.

The program P I is a deﬁnite program, and so it possesses a least model N. This
interpretation N is the value of the two-valued Gelfond-Lifschitz operator GLP
on I [Gelfond and Lifschitz 1988].

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

Logic Programs as Inductive Deﬁnitions

†

631

The larger the I, the less clauses are being left in P I , and so it follows that
the operator GLP is antimonotonic, i.e., I1 • I2 implies GLP (I2) • GLP (I1). The
ﬁxpoints of GLP , if they exist, are called the stable models of P [Gelfond and
Lifschitz 1988]. When P is a program with variables, the stable models of P
are stable models of the grounding of P.

The Gelfond-Lifschitz operator has been generalized to three-valued inter-
pretations by Przymusinski [1990] and to four-valued interpretations by Fitting
[2001]. Here we provide a simpliﬁed but equivalent deﬁnition of these operators
presented by Denecker et al. [2000]. The four-valued operator GLP is deﬁned
on the bilattice of four-valued interpretations as follows:
GLP (hI, Ji) D hGLP (J), GLP (I)i:

As was the case with TP , the operator GLP can also be understood as an opera-
tor for reﬁning approximations. Assume that we obtained an approximation
hI, Ji of the intended but unknown interpretation I0 such that I • I0 • J. A
common intuition about I0 is that true atoms in I0 should be supported, i.e.,
they should be provable from the false atoms in I0. This intuition indicates how
to revise the approximation hI, Ji. The new overestimate for I0 is computed by
ﬁxing the truth values of the negative literals in the bodies of P by some safe
overestimation, and then performing a ﬁxpoint computation using the result-
ing deﬁnite program. A safe overestimate of the negative literals not p is given
by interpreting p by the current underestimate I. Analogously, the new under-
estimate is obtained by ﬁxing the truth values of the negative literals not p in
rules by a safe underestimation, and performing the ﬁxpoint computation. A
safe underestimation of not p is obtained by interpreting p by the current over-
estimation J.
The antimonotonicity of the operator GLP implies two important properties
of GLP analogous to those of the operator TP . First, the operator GLP is mono-
tone with respect to the ordering •k. Second (which, in fact was outlined above,
when we discussed the intuition for GLP ), GLP maps approximations to approxi-
mations. Consequently, just like in case of the operator TP , we ﬁnd that the
Knaster-Tarski theorem is applicable in case of GLP , and so GLP possesses a
•k-least ﬁxpoint. Moreover, this least ﬁxpoint is an approximation (as deﬁned
above).
The least ﬁxpoint of GLP is called the well-founded model of P. The well-
founded model happens to be a ﬁxpoint of the operator TP . Consequently, the
well-founded model is •k-greater than the Kripke-Kleene ﬁxpoint.

The well-founded model was originally deﬁned by Van Gelder et al. [1991]
using a different construction. Its characterization as the least ﬁxpoint of the
three-valued Gelfond-Lifshitz operator is due to Przymusinski [1990]. The un-
derlying algebraic structure of the product lattice of interpretations, the role
of the four-valued generalization of the van Emden-Kowalski operator TP ,
and of the algebraic structure of the three-valued and four-valued versions of
the Gelfond-Lifschitz operator have been presented by Fitting [1993], Fitting
[2001], and Denecker et al. [2000].

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

632

†

Marc Denecker et al.

3. A BRIEF OVERVIEW OF INDUCTIVE DEFINITIONS

IN MATHEMATICAL LOGIC

3.1 Monotone Induction
The study of induction can be deﬁned as the investigation of a class of effec-
tive construction techniques in mathematics. There, sets are frequently deﬁned
through a constructive process of iterating some recursive recipe that adds new
elements to the set given that one has established the presence or absence of
other elements in the set. Such a recipe corresponds naturally to an operator on
sets (mapping any set S to the set obtained by applying the recipe to elements
of S). The set deﬁned by the inductive deﬁnition can be obtained through some
iterated application of this operator until a ﬁxpoint is reached. Consequently
the study of inductive deﬁnitions is closely related to the study of operators and
their ﬁxpoints [Aczel 1977].
Originally, mathematical logicians focused on monotone inductive deﬁni-
tions. When an operator 0 is monotone (i.e., R (cid:181) R0 implies 0(R) (cid:181) 0(R0)),
it follows from the Knaster-Tarski theorem that 0 possesses a least ﬁxpoint.
This set can be characterized either in a nonconstructive way as the intersec-
tion of all sets that are closed under 0 (i.e., 0(S) (cid:181) S) or in a constructive way as
the limit of the increasing sequence obtained by iterated applications of 0. For
this reason, Tarski’s least ﬁxpoint theory of monotone operators [Tarski 1955]
can be considered as the algebraic theory of monotone induction.

Applications of monotone induction are frequent in mathematics. Typical
examples are sets closed under some operation. For instance, the subgroup
G(B) generated by a set B of elements in a group hG, : , (¢)¡1i is deﬁned as the
least subset S (cid:181) G such that B (cid:181) S and for each x, y 2 S : x: y¡1 2 S. Other
examples are the deﬁnitions of terms and formulas of logic, or the deductive
closure Cn(T ) of a logic theory T , i.e., the least set of formulas containing T
and closed under application of all inference rules of classical logic.
Let L be a language of predicate calculus with predicate symbols p1, : : : , pk
and one additional n-ary relational symbol p. Let ’[x1, : : : , xn] be a formula of
L with n free variables x1, : : : , xn. Let us ﬁx an interpretation of the symbols
p1, : : : , pk by hA, R1, : : : , Rki. Here A ﬁxes the domain and interpretation of
constant and function symbols, and Ri is an n-ary relation interpreting pi. We
say that ’ is monotone (in relational symbol p) if for all interpretations S1
and S2 of symbol p, such that S1 (cid:181) S2, and for all tuples of domain elements
d1, : : : , dn
hA, R1, : : : , Rk, S1i jD ’[d1, : : : , dn] implies hA, R1, : : : , Rk, S2i jD ’[d1, : : : , dn]:
Given such interpretation hA, R1, : : : , Rki and the monotone formula ’, we
can deﬁne an operator 0’ : An ! An by

0’(R) D fhd1, : : : , dni :hA, R1, : : : , Rk, Ri jD ’[d1, : : : , dn]g:

The operator 0’ is monotone; thus it possesses a least ﬁxpoint S. The ﬁxpoint
S possesses the property

fhd1, : : : , dni :hA, R1, : : : , Rk, Si jD ’[d1, : : : , dn]g D S:

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

Logic Programs as Inductive Deﬁnitions

†

633

By the Knaster-Tarski theorem, S D 0ﬂ
’ (;) for a least ordinal ﬂ. The sets 0ﬁ
ﬁ • ﬂ are called levels. The ordinal ﬂ is called the length of the recursion.

’ for

The Knaster-Tarski theorem tells us that when we deal with a monotone in-
ductive deﬁnition then a highly nonconstructive deﬁnition of a ﬁxpoint (deﬁned
as the intersection of a large, possibly nondenumerable, family of sets) can be
turned into a constructive one (iterate the operator until the ﬁxpoint is reached;
when the universe is denumerable, the ﬁxpoint will be reached at a denumer-
able ordinal). The logical theory of inductive sets in mathematical logic studies
the complexity of sets that are inductively deﬁnable, the complexity of levels,
and the length of the process to reach the ﬁxpoint. Pioneering work in this area
was done by Kleene and Spector.

Spector [1961] discussed the question of monotone inductive deﬁnability of
sets of integers and sets of elements of the Baire space N N (i.e., sets of number-
theoretic functions). Spector announced that recursively enumerable sets are
precisely those deﬁnable by positive existential inductive deﬁnitions (i.e., posi-
tive formulas without universal quantiﬁers). Moreover the length of induc-
tion is at most !, i.e., the ﬁxpoint is reached in ! steps. Even earlier, Kleene
[1955] studied so-called 51
1 sets of natural numbers.6 Spector [1961] noticed
that Kleene’s results imply that all 51
1 sets are one-to-one reducible to a set
deﬁned inductively by a 50
1 positive inductive deﬁnition, i.e., a positive induc-
tive deﬁnition where the deﬁning formula ’ is of the form 8nˆ and ˆ does
not contain quantiﬁers. The length of induction is, however, !CK
is
the least ordinal that is not the type of a recursive well-ordering. Even the 51
1
positive inductive deﬁnitions (i.e., those with the formula ’ being 51
1) do not
increase the complexity of the ﬁxpoint; it is still 51
1. Spector found the exact
bounds on the complexity classes of the levels of monotone inductive deﬁnitions.
An abstract version of Spector’s results is given in Aczel [1977].

1 where !CK
1

The fundamental study of the abstract version of the results of Kleene
and Spector was performed by Moschovakis [1974] (see also Aczel [1977] and
Barwise [1977]).

3.2 Extensions for Nonmonotone Induction
In mathematical logic, there exists two very different extensions of the above
framework to deal with nonmonotonic forms of induction.

Moschovakis [1974] considered a scheme where formulas ’ are not necessar-
ily monotone. Operators associated to such deﬁnitions are nonmonotone and
may have no ﬁxpoints or multiple minimal ﬁxpoints. To avoid this problem he
modiﬁed the deﬁnition of level, by adding the previously deﬁned level, i.e., by
setting

SﬁC1 D Sﬁ [ 0’(Sﬁ)

(and S‚ D [ﬁ<‚Sﬁ for limit ‚).
It is easy to see that the sequence of levels is increasing and has a limit S’
which we call the inﬂationary ﬁxpoint deﬁned by ’. Note that S’ D S’ [ 0’(S’)
6These are sets of integers deﬁnable as fm : 8 f 9n R(m, n, f (n))g where R is a recursive relation
(quantiﬁer 8 f ranges over all number-theoretic functions, i.e., elements of the Baire space N N ).

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

†

Marc Denecker et al.

634
or equivalently 0’(S’) (cid:181) S’. In other words, S’ is a pre-ﬁxpoint of 0’. In general,
it is not a ﬁxpoint of 0’, and it is not even a minimal pre-ﬁxpoint. As an example,
consider the predicate p(x) deﬁned by the formula x D a^:p(b)_x D b^:p(a).
The set deﬁned by this formula is fa, bg. It is not a ﬁxpoint and is strictly larger
than both ﬁxpoints (fag and fbg) of this formula.

Moschovakis called this type of deﬁnitions nonmonotone inductive deﬁni-
tions. Later, Gurevich and Shelah [1986] called them inﬂationary inductive
deﬁnitions.

A very different account of nonmonotone induction is found in Iterated In-
ductive Deﬁnitions (IID). These were ﬁrst introduced in [Kreisel 1963] and later
studied in Feferman [1970], Martin-L¨of [1971], and Buchholz et al. [1981]. Aczel
[1977] formulates the intuition of Iterated Inductive Deﬁnitions in the follow-
ing way. Given a mathematical structure M0 ﬁxing the interpretation of the
function symbols and some set of interpreted predicates, a positive or mono-
tone inductive deﬁnition deﬁnes one or more new predicates in terms of M0.
The deﬁnition of these new predicates may depend positively or negatively on
the interpreted predicates. Once the interpretation of the deﬁned symbols p
is ﬁxed, M0 can be extended with these interpretations, yielding a new inter-
pretation M1. On top of this structure, again new predicates may be deﬁned
in the similar way as before. The deﬁnition of these new predicates may now
depend positively or negatively on the deﬁned predicates p as their interpre-
tation is now ﬁxed by M1. This modular principle can be iterated arbitrar-
ily many times, yielding a possibly transﬁnite sequence of positive inductive
deﬁnitions.

Though the intuition is simple, it is not straightforward to see how this idea
is implemented in IID-approaches. Feferman [1970] and Buchholz et al. [1981]
investigate IIDs encoded in an IID-form, a single FOL formula of the form
F [n, x, Q, P],7 and expresses its semantics in a circumscription-like second-
order formula. The problem is that this encoding is extremely tedious and blurs
the simple intuitions behind this work. For more details on the encoding of
iterated inductive deﬁnitions, we refer the reader to Denecker [1998].

Inﬂationary inductive deﬁnitions and iterated inductive deﬁnitions are not
equivalent and are based on very different intuitions. At present, there is no
standard well-motivated treatment of nonmonotone inductive deﬁnitions.

3.3 Discussion of Nonmonotone Induction
When evaluating the two different approaches to nonmonotone induction, the
question arises which of them has an empirical basis in mathematical prac-
tice. The speciﬁc question is: can we ﬁnd inductive constructions in mathe-
matics that use a recipe that adds new elements to the constructed relations
based on the established absence of other elements in the relation (and hence

7The meaning of the variables is as follows: x is a candidate element of the set deﬁned by the IID; n
is an ordinal number; Q is a set of elements; and P is a set of elements deﬁned in the nth stratum.
Roughly speaking, F [n, x, Q, P] is true when x belongs to the nth stratum and x can be obtained
from the set P and the restriction of the set Q to the elements deﬁned in strata m < n by an
application of a rule of the nth stratum.

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

Logic Programs as Inductive Deﬁnitions

†

635

modeling a nonmonotone operator)? And if such applications can be found, do
such constructions correspond to inﬂationary induction or to iterated induction,
or can we ﬁnd both types?

Nonmonotone iterated induction occurs frequently in the context of induc-
tive deﬁnitions over a well-founded set. A well-founded set is a partial order
without inﬁnite descending chains x0 > x1 > x2 > : : : . Equivalently, it is a par-
tial order such that each subset contains a minimal element. Such orderings
are also called Noetherian orderings. Inductive deﬁnitions of this kind describe
the membership of an element, say a, of the deﬁned predicate X in this domain
in terms of the presence (or absence) of strictly smaller elements in the deﬁned
predicate. Thus, to check if an element a belongs to X we need to check some
properties of predecessors of a. By applying this deﬁnition recipe to the minimal
elements and then iterating it for higher levels, the deﬁned predicate can be
completely constructed. Consequently, this type of deﬁnition correctly and fully
deﬁnes a predicate, even when it is nonmonotone.

The following example illustrates this principle. We can deﬁne an even nat-

ural number n by induction on the natural numbers:
—n D 0 is even;
—if n is not even then n C 1 is even; otherwise n C 1 is not even.

Representing this deﬁnition in the same style as monotone inductions yields
the following nonmonotone formula deﬁning even in the language of arithmetic:
(1)
It turns out that the set of even numbers is the unique ﬁxpoint of the operator
associated to this formula. Equivalently, the set of even numbers is correctly
characterized with respect to the natural numbers by the following recursive
iff-deﬁnition:

x D 0 _ 9 y :x D s( y) ^ :even( y)

8x:even(x) $ x D 0 _ 9 y :x D s( y) ^ :even( y)

It is easy to see that the inﬂationary approach applied on this formula does
not yield the intended set of even numbers. Indeed, applying the operator to
the empty set produces the set of all natural numbers, which is necessarily the
inﬂationary ﬁxpoint.

On the other hand, it is natural to consider this deﬁnition as an iterated
inductive deﬁnition if we split up the deﬁnition in a sequence of deﬁnitions
compatible with the order on the natural numbers. The following list depicts
the splitting of the deﬁnition in small deﬁnitions each deﬁning a single atom:

even(0) :D true:
(0)
even(1) :D :even(0)
(1)
even(2) :D :even(1)
(2)
(n C 1) even(n C 1) :D :even(n)

:::

It is clear, at least intuitively, that the iterated induction correctly constructs
the predicate even.

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

:::

636

†

Marc Denecker et al.

Although intuitively correct, it is unfortunate that in the IID approach this
inductive deﬁnition cannot be encoded by the simple formula (1) deﬁned above.
Instead, it must be encoded by a rather complex formula in which the level of
the deﬁned atoms are explicitly encoded. This formula is8

n D 0 ^ x D 0 _ 9m:(n D s(m) ^ x D s(m) ^ :Q(m)):

(2)
For more details on this we refer to Buchholz et al. [1981] and Denecker

[1998].
Notice that induction over a well-founded order is frequently nonmonotone.
A common example is that of rank of an element in a well-founded order hP, „i.
The rank of an element x of P is deﬁned by transﬁnite induction as the least
ordinal which is a strict upper-bound of the ranks of elements y 2 P such that
y ` x.
larger ordinal than the ranks of all elements y ` x:
) ! n

Formally, let F [x, n] denote the following formula expressing that n is a

0:( y ` x ^ rank( y, n
0

8 y, n

0 < n)

Intuitively, rank(x, nx) is represented by the following formula:

F [x, nx] ^ 8n:(F [x, n] ! nx • n)

Note that rank occurs negatively in this deﬁnition (it occurs as a condition
in the implication in the ﬁrst conjunct) and that the associated operator is
nonmonotone. As in the case of even, the meaning of this deﬁnition cannot be
obtained via inﬂationary induction.9 Instead, iterated induction is required. In
the context of a well-founded structure, rank is also correctly described by the
corresponding iff-deﬁnition:

8x, nx :rank(x, nx) $ F [x, nx] ^ (8n:F [x, n] ! nx • n)

Possibly the most important application of this form of induction is the deﬁ-
nition of the levels of a monotone operator in Tarski’s least ﬁxpoint theory. Given
an operator O in a complete lattice hL, ?, >, •i, Tarski deﬁnes the levels of the
operator O by transﬁnite induction:
—O0 D ?
—O ﬁC1 D O(O ﬁ)
—O ﬁ D lub(fO ﬁ0 j ﬁ0 < ﬁg) if ﬁ is a limit ordinal.
This induction deﬁnes a function mapping ordinal numbers from some pre-
selected segment (cid:176) of ordinals to the lattice L. The function is deﬁned by trans-
ﬁnite iterated induction in the well-founded order of the segment of ordinals.
It is of interest to see if this deﬁnition is monotone or nonmonotone. It is not
straightforward to see this due to the use of the functional notation and of the
higher-order lub function. Therefore, consider the following reformulation us-
ing a predicate notation. We introduce the binary predicate levelO such that

8Note that there is no positive induction involved, so only the variable Q representing the elements
of lower strata occurs (see the discussion in footnote 7).
9The inﬂationary ﬁxpoint assigns rank 0 to all elements.

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

637
levelO(ﬁ, x) iff O ﬁ D x. Using this notation, one could represent the above in-
ductive deﬁnition by the following formula:

Logic Programs as Inductive Deﬁnitions

†

8<: ﬁ D 0 ^ x D ?_

9ﬁ0, y :(ﬁ D ﬁ0 C 1 ^ x D O( y) ^ levelO(ﬁ0, y))_
limit(ﬁ) ^ x D lub(f y j9ﬂ < ﬁ : levelO(ﬂ, y)g)

The operator 0 associated to this deﬁnition is an operator on the power-set of
the cartesian product (cid:176) £ L. It is easy to see that even if O is monotone, 0 is
nonmonotone. This is due to the rule describing the predicate levelO at limit
ordinals and the fact that lub has a nonmonotone behavior with respect to (cid:181).
Indeed, take some limit ordinal ﬁ and two sets S (cid:181) S0 (cid:181) (cid:176) £ L. If (ﬁ, x) 2 0(S),
then x is the lub of the set f y j9ﬂ < ﬁ : (ﬂ, y) 2 Sg, but in general not of the set
f y j9ﬂ < ﬁ : (ﬂ, y) 2 S0g. Hence (ﬁ, x) does not in general belong to 0(S0).

The above deﬁnition still contains the higher-order function lub but can be
expressed as a ﬁrst-order inductive deﬁnition which (necessarily) contains neg-
ative occurrences of the deﬁned predicate levelO:

8>>>><>>>>:

0@ limit (ﬁ)^

ﬁ D 0 ^ x D ?_
9ﬁ0, y :(ﬁ D ﬁ0 C 1 ^ x D O( y) ^ levelO(ﬁ0, y))_

(1)
8ﬂ, v:(ﬂ < ﬁ ^ levelO(ﬂ, v) ! x ‚ v)^
(2)
8z:(8ﬂ, v:(ﬂ < ﬁ ^ levelO(ﬂ, v) ! z ‚ v)) ! x • z (3)

1A

In this formula, (2) expresses that x is an upper bound; (3) expresses that x is
less or equal than upperbounds. Note that levelO has a negative occurrence in
(2).

Induction on a well-founded order deﬁnes elements in terms of strictly ear-
lier elements. This excludes that such deﬁnitions contain positive (or negative)
loops. Iterated induction generalizes this form of induction by allowing posi-
tive loops. An example illustrating this principle is the deﬁnition of a stable
theory [Moore 1985]. A stable theory extends the notion of closure Cn(T ) of a
ﬁrst-order theory T and represents the known formulas of a ﬁrst-order theory
T expressible in the language of modal logic. It can be deﬁned through the
following ﬁxpoint expression:

S D Cn(T [ fK F : F 2 Sg [ f:K F : F 62 Sg)

Alternatively, Marek [1989] gives a deﬁnition by iterated induction, based on
the standard inference rules and two additional inference rules:

‘ F
K F

6‘ F:K F

The ﬁrst expresses that if we can infer F then we can infer K F ; the second that
if we cannot infer F then we can infer :K F . Note that the second rule is non-
monotone. The iterated induction proceeds as follows: ﬁrst Cn(T ) is computed,
using the classical inference rules on ﬁrst-order formulas; next the two new
inference rules are applied, and the extended set is again closed for all modal
formulas without a nested modal operator. This can be iterated for formulas

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

638

†

Marc Denecker et al.

of increasing nesting of modal operators until a ﬁxpoint is reached in ! steps.
This process constructs the unique stable theory of T .

Notice that the iterated inductive deﬁnition of a stable theory is not a deﬁni-
tion in a well-founded set. Indeed, for any pair of logically equivalent formulas
` and ˆ, there is a sequence of inference steps leading from ˆ to ` and vice
versa. Hence, ˆ belongs to the stable theory if ` belongs to it and vice versa.
Hence, formulas and inference rules cannot be well-ordered in a way that the
conditions of all inference rules are strictly less than the derived formula. This
deﬁnition is a simple example of an inductive deﬁnition in a well-founded semi-
order10 • in which membership of a domain element a in a deﬁned relation X
is deﬁned in terms of the presence of domain elements b • a in X and in terms
of absence of domain elements b < a in X .

It is certainly much easier to ﬁnd applications of iterated induction than
of inﬂationary induction. The applications of inﬂationary induction, e.g., in
Moschovakis [1974], tend to be for deﬁning highly abstract concepts in set the-
ory. Although inﬂationary induction is expressive [Moschovakis 1974; Kolaitis
and Papadimitriou 1991; Gurevich and Shelah 1986], it turns out to be very dif-
ﬁcult to use it to encode even simple concepts. This is illustrated by Van Gelder
[1993] with a discussion of the deﬁnition of the complement of the transitive
closure of a graph. This concept can be deﬁned easily by an iterated deﬁnition
with 2 levels: at the ﬁrst level, the transitive closure is deﬁned; at the second
level, the complement is deﬁned as the negation of the transitive closure. On the
other hand, it was considered as a signiﬁcant achievement when a (function-
free) solution was found using inﬂationary induction. Van Gelder [1993] adds:
“Presumably, in a practical language, we do not want expression of such simple
concepts to be signiﬁcant achievements!”

The cause for this may lay in the weakness of the characterization of the in-
ﬂationary ﬁxpoint. A positive feature of inﬂationary semantics is its simple and
elegant mathematics. A negative property is that the set characterized by inﬂa-
tionary induction, though unique, apparently has rather weak mathematical
properties. The inﬂationary ﬁxpoint is not a ﬁxpoint of the semantic operator
of the deﬁnition, only a pre-ﬁxpoint and not even a minimal one. The property
of being just a pre-ﬁxpoint seems too weak to be useful. Notice in all above
applications of nonmonotone induction that the intended sets are ﬁxpoints of
the operator of the inductive deﬁnition.

Let us summarize this discussion. Which form of nonmonotone induction
has an epistemological foundation in mathematical practice? In the case of
inﬂationary induction, while we do not exclude that it exists, we are not aware
of it. For iterated induction, we showed that such a basis exists. However, the
current logics of iterated induction impose an awkward syntax which makes
them unsuitable for practical use. To their defence, we must say that IIDs
were never intended for practical use but rather for constructive analysis of
mathematics. But it is a natural and modular principle. As will be argued below,

10This concept extends well-founded order. A semi-order • is a reﬂexive and transitive relation.
Let x < y denote that x • y and y 6• x. Then • is a well-founded semi-order if there is no inﬁnite
descending chain x0 > x1 > x2 > : : :

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

Logic Programs as Inductive Deﬁnitions

†

639

logic programming builds on the same principle and, from an epistemological
point of view, contributes by offering a more general and much more elegant
formalization of this principle.

4. INDUCTIVE DEFINITIONS AS AN EPISTEMOLOGICAL

FOUNDATION FOR LOGIC PROGRAMMING

4.1 Deﬁnite Programs—Monotone Induction
The relationship between logic programs and inductive deﬁnitions is already
apparent in many standard prototypical logic programming examples. Recall
the following programs:

list([]).
list([X|Y]) :- list(Y).

member(X,[X|T]).
member(X,[Y|T]):- member(X,T).

append([],T,T).
append([X|Y],T,[X|T1]):-append(Y,T,T1).

sorted_list([]).
sorted_list([X]).
sorted_list([X,Y|Z]):-X<Y,sorted_list([Y|Z]).

arc(a,a).
arc(b,c).
connected(X,Y) :- arc(X,Y).
connected(X,Y) :- arc(X,Z), connected(Z,Y).
These programs are natural representations of inductive deﬁnitions of the
concepts. Interpreting them as inductive deﬁnitions provides a justiﬁcation
for deducing that the atoms member(a,[b,c]), append([a,b],[c,d],[a,d]), as
well as sorted list([1,3,2]) are false, facts which could not be justiﬁed by
interpreting these programs as Horn theories. Indeed, only positive facts can
be deduced from a Horn theory.

At the syntactical level, there is a close relationship between the way induc-
tive deﬁnitions are represented in logic programs and in mathematical logic. In
particular, the mathematical logic form corresponds exactly to the right-hand
side of the completed deﬁnition of the predicate. For example, the completed
deﬁnition [Clark 1978] of the member-program is

8x, y:member(x, y) $ 9z: y D [x j z] _ 9z, t: y D [z j t] ^ member(x, t):

The right-hand side of the equivalence is the formula that inductively deﬁnes
the member relation. Thus, (ﬁnite) deﬁnite logic programs correspond to (a sub-
class of) positive existential inductive deﬁnitions.

Also at the semantical level, there is congruence between semantical meth-
ods in mathematical logic and in logic programming. Aczel [1977] gives an

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

640

†

Marc Denecker et al.

overview of three equivalent mathematical principles for describing the se-
mantics of a (positive) inductive deﬁnition. They are equivalent with the way
the least Herbrand model semantics of deﬁnite logic programs can be deﬁned:

—the least set or least Herbrand model deﬁnition.
—the least ﬁxpoint characterization.
—The model can be expressed also as the interpretation in which each atom has
a proof tree.11 Also this formalization has been used in logic programming,
e.g., in Denecker and De Schreye [1993]

The logic programming community devoted considerable attention to the
study of the complexity and expressivity issues of deﬁnite logic programs.
Not surprisingly, the results thus obtained resemble those found by Spector.
Andr´eka and N´emeti [1978] found that deﬁnite (Horn) programs compute the
same sets as positive existential inductive deﬁnitions, i.e., recursively enumer-
able sets (for the case of Herbrand interpretations, this result has been estab-
lished already by Smullyan [1968]). That is, for a given recursively enumerable
set S there is a normal program PS such that the language of PS contains a
predicate sol=1 and a function symbol s=1 and S D fn : sol(sn(0)) 2 M Pg where
M P is the least Herbrand model of PS. In other words, the least ﬁxpoint of the
operator TP allows for the computation of all recursively enumerable sets. But
the converse is also true—sets computed by deﬁnite programs are recursively
enumerable.

4.2 Stratiﬁed Programs—Iterated Inductive Deﬁnitions
Consider now the following examples of stratiﬁed or locally stratiﬁed logic pro-
grams:

% Using list/1, sorted_list/1
unsorted_list(L):-list(L), not sorted_list(L).

% Using connected/2
disconnected(X,Y):-node(X), node(Y), not connected(X,Y).

% Using
woman(X):-person(X),not man(X).

person/1, man/1

even(0).
even(s(X)):- not even(X).

These are clearly examples of iterated deﬁnitions. There is an obvious cor-
respondence between (locally) stratiﬁed logic programs under perfect model
semantics [Apt et al. 1988; Van Gelder 1988; Przymusinski 1988] and Iterated
Inductive Deﬁnitions.

Let P be a stratiﬁed (or locally stratiﬁed) program with stratiﬁcation
(Pi)0•i<nP . Let Di be the set of all symbols that are deﬁned in Pi. Then the perfect

11We will discuss those in detail below.

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

Logic Programs as Inductive Deﬁnitions

†

641

model of P is the union MnP of the sequence of Herbrand models (Mi)1•i•nP :
—M1 is the least Herbrand model of P0;
—MnC1 is the least Herbrand model of Pn such that the restriction of MnC1 to

the symbols in [i•nDn is Mn.

—In case when nP is inﬁnite, for a limit ordinal ‚, M‚ is the union of the

increasing sequence (Mi)1•i<‚.
Though at the intuitive and semantical level, (locally) stratiﬁed logic pro-
gramming and iterated inductive deﬁnition formalisms are analogous, there
are substantial differences at the level of the syntactical sugar (and thus in
their availability for programming). In the IID formalisms, a possibly trans-
ﬁnite sequence of positive inductive deﬁnitions is encoded in one (often quite
complex) ﬁnite iterated induction formula. As the above examples illustrate,
in particular the even program, (locally) stratiﬁed logic programs offer a much
more simple and elegant syntax to represent inductive deﬁnitions. Yet, as will
be argued in the next section, this formalism also imposes severe disadvantages.
The expressivity of the class of stratiﬁed programs has been studied by
Apt and Blair [1990]. Speciﬁcally, they have shown that the Andr´eka-N´emeti-
Smullyan result can be lifted in a very natural way. Namely, the stratiﬁed
programs with n strata, n ‚ 1 compute precisely all 60
nC1 sets in the Kleene-
Mostowski hierarchy.12

Thus the programs with n strata are complete for 60

nC1 sets of integers, and
stratiﬁed programs compute precisely arithmetic sets. This result was signiﬁ-
cant for the following reasons. On one hand it pinpointed the expressive power
of a natural class of programs. On the other hand it demonstrated that normal
programs go beyond the generally accepted class of computable sets.13

REMARK 4.1.

It is interesting to note that the inﬂationary ﬁxpoint construc-
tion resurfaced in the context of logic programming, more precisely in the context
of database investigations of logic programs with negation. Kolaitis and Pa-
padimitriou [1991] advocate the use of the inﬂationary ﬁxpoint as the semantics
of normal programs. It is easy to see that in none of the above programs with
negation, the inﬂationary ﬁxpoint corresponds to the perfect model and with
what most logic programmers would consider as the intended interpretation.

12The formulas of the form 9k18k29k3 : : : R (with n ¡ 1 alternations of quantiﬁers), where R has
n formulas. Sets with the deﬁnition of the form fn : ’(n)g where, ’ is
no quantiﬁers, are called 60
n sets of natural numbers. Notice that in 51
a 60
n formula, are called 60
1 deﬁnitions deﬁned above
the quantiﬁer over f was a function-theoretic quantiﬁer. Here there are only number quantiﬁers.
The classiﬁcation of sets of natural numbers deﬁned by 60
n formulas
is called the Kleene-Mostowski hierarchy.
13Blair et al. [1995] generalized the Apt-Blair result for the case of locally stratiﬁed programs and
the hyperarithmetical hierarchy. Further, Schlipf [1995b] proved that a complete 51
1 set can be de-
ﬁned using the well-founded model (this result generalizes the Blair et al. [1995] result mentioned
above). A further relationship between the set of all stable models of a normal program and effec-
tively closed subsets of the Baire space has been established by Marek et al. [1994]. Finally, Ferry
[1994] characterized the family of stable models of a normal program in terms of the inverse-Scott
topology of Cantor space.

n formulas and, dually, by 50

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

642

†

Marc Denecker et al.

For example, the inﬂationary ﬁxpoint of even is the set of natural numbers; that
of disconnected the total binary relation of nodes, that of unsorted list the set
of all lists, etc.

4.3 A Critique of Syntactic Stratiﬁcation
A problem with stratiﬁcation is that stratiﬁability of a program or deﬁnition
is broken even by the most innocent syntactic changes. The following variant
of the even program illustrates this. Assume that we introduce the predicate
successor/2 to represent the successor relation. In what is essentially an in-
nocent linguistic variant of the even program deﬁned in the previous section,
we can write down the following deﬁnitions for successor/2 and even/1:

successor(s(X),X).
even(0).
even(Y):- successor(Y,X),not even(X).

This variant program is not longer locally stratiﬁed due to the presence of rule
instances of the form:

even(m) :- successor(m,m), not even(m).

This simple example is just one out of a broad class of simple transformations
that transform a stratiﬁed logic program into an unstratiﬁed logic program. A
detailed study of semantics-preserving transformations has been conducted by
Brass and Dix [1999] who showed that several classes of semantics can be
characterized in these terms.

Another familiar example is the vanilla meta-interpreter [Bowen and Kowal-

ski 1982] which consists of the following rules:

demo(true).
demo((P,Q)):-demo(P),demo(Q).
demo(P):-atomic(P),clause(P:-Q),demo(Q).
demo(not P):- not demo(P).

This program induces a transformation of a normal program to the vanilla
meta-program consisting of the above deﬁnition of demo augmented with the
clause representation of the program. This transformation transforms any nor-
mal program into a nonstratiﬁable program [Martens and De Schreye 1995].
For example, for any atom p, the grounding contains the following unstratiﬁable
rules:

demo(p):- atomic(p),clause(p:-not p), demo(not p).
demo(not p):- not demo(p).

Consequently, syntactical restrictions such as stratiﬁcation or local stratiﬁ-
cation are untenable in the sense that they cannot lead to robust formalisms
for the representation of inductive deﬁnitions. At the same time, the above ex-
amples show that also general, syntactically unstratiﬁable logic programs can
still be interpreted as inductive deﬁnitions.

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

Logic Programs as Inductive Deﬁnitions

†

643

However, dropping the stratiﬁability constraint introduces several problems
at the semantical level. In IID and stratiﬁed logic programming, the construc-
tion of the formal semantics of a deﬁnition is strongly based on the explicit
stratiﬁcation. Such a base longer exists in the unstratiﬁed case. Consequently,
alternative semantic techniques are needed to characterize the model of a gene-
ralized inductive deﬁnition. A second problem is that for some logic programs,
in particular those with recursion through negation, the interpretation as in-
ductive deﬁnitions breaks down. This problem is considered in Section 5.1.

4.4 Normal Programs—General Nonmonotone Inductive Deﬁnitions
This section presents and argues the main thesis of this paper, that the well-
founded semantics of logic programming [Van Gelder et al. 1991] provides a
more general and more robust formalization of the principle of iterated induc-
tive deﬁnition that applies beyond the stratiﬁed case. Under this semantics,
logic programming can be naturally seen as a generalized nonmonotone induc-
tive deﬁnition logic not suffering from the aforementioned limitations imposed
by syntactic stratiﬁcation. The arguments below are based on and extend the
discussion in Denecker [1998].

First, the well-founded semantics is a conservative extension of the perfect
model semantics; the well-founded model of a (locally) stratiﬁed program is
its perfect model. Second, many transformations of the type illustrated in the
previous section which may transform stratiﬁed into unstratiﬁed programs
preserve the well-founded model—see Brass and Dix [1999].

The third argument is based on the analogy between the well-founded se-
mantics and the semantic principle used in IID and stratiﬁed logic program-
ming. Przymusinski [1989a] showed that each logic program P has a dynamic
stratiﬁcation (Pi)0•i<nP such that the well-founded model can be obtained by
an iterated least model construction. In particular, Pi consists of all rules p :- B
of P such that i is the least ordinal for which p is not undeﬁned in the level
i C 1 of GLP . Then the well-founded ﬁxpoint can be obtained by an iterated
process of extending a 3-valued interpretation deﬁning the atoms of level < i
by extending it with the least model of Pi.

Below is an alternative attempt to show the deep structural similarities in
the way the perfect model and the well-founded model are constructed. The
well-founded semantics formalizes the same intuition of iterated induction but
implements them in a superior, more robust and syntax-independent way. To
illustrate this, let us compare the formalizations. A stratiﬁed program P can
be split up in a (possibly transﬁnite) sequence (Pi)0•i<nP of deﬁnitions Pi of a
subset Di of the atoms. If we ﬁx the meaning of the already deﬁned atoms,
each Pi is a monotone deﬁnition. The perfect model is the limit M P of the
sequence (Mi)0<i•nP where each MiC1 is obtained by applying the positive in-
ductive deﬁnition Pi on Mi. Each Mi approximates M P and gives the correct
truth values on all atoms of [ j <i Di. The role of the stratiﬁcation in this pro-
cess is to delay the use of some part of the deﬁnition until enough information
is available to safely apply the positive induction principle on that part of the
deﬁnition.

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

644

†

Marc Denecker et al.

The same idea could be implemented in a different way, without relying on an
explicit syntactical partitioning of the deﬁnition. As in perfect model semantics,
the model could be obtained as the limit of a sequence of gradually more re-
ﬁned interpretations (monotonically increasing with respect to the knowledge
ordering •k deﬁned in Section 2). But rather than approximating by 2-valued
interpretations of subalphabets, partial interpretations can be used; they also
deﬁne the truth value of a subset of the atoms. Rather than extending at each
level i the given interpretation Mi by applying the positive deﬁnition Pi, Mi
is extended by applying an operator that implements the positive induction
principle. This operator takes as input a partial interpretation I representing
well-deﬁned truth values for a subset of atoms, and derives an extended partial
interpretation deﬁning the truth values of other atoms that can be derived by
positive induction. Deﬁnition of truth values of atoms for which not enough
information is available is delayed.

The key challenge in the above enterprise is to deﬁne an operator that embod-
ies the principle of positive induction in the context of deﬁnitions with nega-
tion. In Denecker [1998], it is argued that the multivalued Gelfond-Lifschitz
operator GLP (¢) of Section 2 is an answer to this problem. Below we give an
alternative deﬁnition for this operator based on proof-trees; this formalization
shows very clearly the correspondence with positive induction. The deﬁnition is
restricted to the three-valued case; this sufﬁces for our purposes: the approxi-
mations of the well-founded model computed during ﬁxpoint computation are
three-valued.

tree labeled with literals such that

Let P be a ground program. We assume that each atom occurs as the head
of a rule, and that each rule has a nonempty body. To obtain this, it sufﬁces to
add to the program the rule p:-f for each atom p with the empty deﬁnition and
to transform every atomic rule p. to the rule p:-t. This preprocessing allows
for a more uniform treatment.
Deﬁnition 4.2. A proof-tree T for an atom p in a normal program P is a
† p is the root of T ;
† each nonleaf node is an atom q; its direct descendants are the literals in
† each leaf is either t, f, or a negative literal.
† there are no inﬁnite branches.
This deﬁnition formalizes the notion of a candidate proof. Note that the leaves
of proof-trees of a deﬁnite program P are all t or f. The least model of a deﬁnite
program can be characterized as the set of all atoms that have a proof-tree
without f among the leaves.

the body B of some rule q:- B of P;

The intuition of the positive induction operator can be expressed as follows.
Assume that we have constructed a partial interpretation I which assigns cor-
rect truth values to a subset of atoms as deﬁned by P. We can extend I in the
following way. Assume that an atom p has a proof-tree with only true leaves
w.r.t. I: either t or negative literals not q where I(q) D f. In that case, it is
justiﬁed to extend I by assigning t to p. On the other hand if each proof-tree for
p contains a false leaf (either f or a negative literal not q where I(q) D t), then

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

Logic Programs as Inductive Deﬁnitions

†

645

it is impossible to prove p no matter how I is further extended; consequently,
it is justiﬁed to extend I by assigning f to p. All other atoms have at least one
proof-tree without false leaves and at least one undeﬁned leaf not q and no
proof-tree with only true leaves; the computation of the truth value of such an
atom must be delayed until all leaves of one of its proof trees are known to be
true or all proof-trees are known to contain at least one false leaf.

The above intuition is formalized as follows:
Deﬁnition 4.3. The Positive Induction Operator PIP maps partial interpre-

tations I to I0 such that for each atom p
— I0(p) D t if p has a proof-tree with all leaves true in I.
— I0(p) D f if each proof-tree of p has a false leaf in I;
— I0(p) D u otherwise, i.e., if no proof-tree of p has only true leaves but there

exists at least one without false leaves.
It is straightforward to see that PIP is monotone (w.r.t. •k): indeed, if I •k J,
each proof tree with only true leafs in I has only true leaves in J; each proof
tree with a false leaf in I has a false leaf in J. Consequently, if p is true or false
in PIP (I), then it has the same truth value in PIP (J).
Given a partial interpretation I, PIP computes the truth value of all atoms
that can be obtained by applying monotone induction starting from I; PIP
delays the computation of the truth value of all other atoms. Thus, iterating
the operator PIP corresponds to the process of iterating monotone induction.

PROPOSITION 4.4. PIP coincides with GLP on 3-valued interpretations.
PROOF. We begin by showing that our proposition is true for 2-valued inter-

pretations.
p is true in PIP (I), then p is true in GLP (I).

Let I be an arbitrary 2-valued interpretation. First, we show that if an atom

Consider the set S of all proof-trees of the program P with only true leaves
in I, with a root false in GLP (I). We must show that this set is empty. It is
straightforward to see that the collection of proof-trees of P is a well-founded
order under the subtree relation. That is, each nonempty set of proof-trees
contains a minimal element. Consequently, S contains a minimal element T
with a root p false in GLP (I). At the top level of T , some rule p :- B of P is used
such that (1) T comprises a strict subtree without false leaves for each atom q
in B and (2) all negative literals in B are true in I. From (1) and the minimality
of T it follows that each q is true in GLP (I). From (2) it follows that P I contains
the rule p :- B’ where B’ is obtained from B by eliminating all negative literals.
Consequently, applying TP I on GLP (I) yields p. This is a contradiction, because
GLP (I) is a ﬁxpoint of TP I . This proves the ).

For the opposite direction, assume that atom p is true in GLP (I). We construct
a proof-tree for p by induction on the levels of the operator TP I . Assume that for
some ordinal ﬁ, each atom of level ﬂ < ﬁ has a proof-tree without false leaves.
Let p be an atom of level ﬁ. Then for some rule p :- B of P I , each atom in B
belongs to a level ﬂ < ﬁ, and by the induction hypothesis, it has a proof-tree. By

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

646

†

Marc Denecker et al.

construction of P I , there exists a rule p :- B’ of P such that B’ extends B with
negative literals that are true in I. Obviously, this rule and the proof-trees of
the atoms in B can be used to construct a proof-tree for p.
Finally, we extend the argument to the general 3-valued interpretations.
Given an arbitrary 3-valued interpretation I D hI1, I2i (i.e., I1 •k I2). Recall
that GLP (I) D hGLP (I2), GLP (I1)i, and let PIP (I) D hJ1, J2i.
Note that an atom p is true (resp., false) in PIP (I) iff it is true in J1 (resp.,
false in J2). Vice versa a literal not q is true (resp., false) in I iff it is true in
I2 (resp., false in I1). Therefore, a proof-tree of P has only true leaves in I iff it
has only true leaves in I2, and has a false leaf in I iff it has a false leaf in I1.
Consequently, J1 D PIP (I2) and J2 D PIP (I1). Since PIP and GLP coincide on
the 2-valued interpretations, the argument is complete.
This proposition shows that GLP is an operator performing monotone in-
duction, and that the well-founded model is the model obtained by iterating
monotone induction. This, together with our discussion of Iterated Inductive
Deﬁnitions, shows that the well-founded semantics is an alternative formaliza-
tion of iterated induction.

4.5 Conclusions
The well-founded model of a stratiﬁed program coincides with the perfect model
and is preserved by transformations that destroy syntactic stratiﬁcation. Be-
yond the class of stratiﬁed programs, we have pointed to the strong structural
resemblances between IID and perfect model construction and the way the
well-founded model is constructed. We ﬁnd essentially the same ingredients:
—Computation by•k-monotonically increasing sequence of approximating par-

tial interpretations.

—Delaying computation of truth values of atoms for which no sufﬁcient infor-

mation is available.

—Deriving truth values by monotone induction.
The superiority of the well-founded model construction lies in the fact that
there is no need for an a priori splitting of the program in different levels. The
Positive Induction Operator PIP looks at the complete program and derives
truth values whenever sufﬁcient information is available.

Consequently, we postulate the thesis that the well-founded semantics for-
malizes the principle of nonmonotone iterated induction. This thesis is about
the relation between a mathematical theory and an empirical reality, in partic-
ular the notion of (general) inductive deﬁnition as found in mathematics. Such
a thesis of course cannot be formally proven; it is a thesis of a similar nature,
e.g., as Church’s thesis.

5. DISCUSSION

5.1 Total Deﬁnitions
An aspect that we have ignored so far is that for some programs, the well-
founded model is partial. Consider for example the following program which is

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

Logic Programs as Inductive Deﬁnitions

†

647

a formalization of the barber’s paradox.

shaves(b,X) :- citizen(X), not shaves(X,X).
citizen(a).
citizen(b).
...

The well-founded model of this program is partial and does not deﬁne the
truth value of the atom shaves(b,b). The reason is the recursion through nega-
tion. If shaves(b,b) is false then the rule body is true, and one can infer that
shaves(b,b) is true; however, the rule by which that atom is inferred is then
no more applicable, and the support for its truth is lost.

A natural quality criterion for deﬁnitions is that they deﬁne the truth values
of all atoms of the deﬁned predicates. This criterion boils down to the require-
ment that good deﬁnitions should have a two-valued well-founded model. We
call such deﬁnitions total deﬁnitions. When the requirement of stratiﬁability is
dropped, the formalism allows deﬁnitions for which this quality criterion does
not hold. Partial models point to bugs in the deﬁnition. The set of undeﬁned
atoms identiﬁes exactly the atoms that are ill-deﬁned. For programs with a
partial well-founded model, the interpretation as inductive deﬁnitions breaks
down to some extent.

There seem to be two sensible treatments for deﬁnitions that are not total.
A rigorous treatment would be to simply consider them as inconsistent. In this
strict view, we would deﬁne that the model of a normal program is the well-
founded model if it is total; otherwise the program has no model. The result is a
2-valued logic in which deﬁnitions that are not total have no models and entail
everything.

The approach to reject partial models and thus to treat nontotal programs
as inconsistent logical theories can be questioned. The problem of such a rig-
orous position is that it seriously complicates the design of query-answering
systems which then not only should compute answers to a query but also
check the consistency of the program, i.e., the fact that the well-founded model
is total. The latter is in general an undecidable problem [Schlipf 1995a].14
Even for programs for which it is feasible to prove that they are total, the
cost of doing so could be prohibitive.15 Moreover, in some complex applica-
tions, partial models simply cannot be avoided. An illustration is the theory
of truth presented in Fitting [1997]. Fitting uses the well-founded seman-
tics to deﬁne the truth predicate and obtains one in which the liar para-
dox (“I am a liar”) is undeﬁned (?) but the truth sayer (“I am true”) is
false.

Hence a more reasonable position is to accept deﬁnitions with partial well-
founded models. The result is a kind of paraconsistent deﬁnition logic, i.e., a
logic in which deﬁnitions with local inconsistencies do not entail every formula.
In the context of logics for deﬁnitions, 3-valued well-founded semantics offers

14Schlipf showed that the set of indices of ﬁnite programs for which the well-founded semantics is
2-valued forms a 51
15But note that showing totality of the program should be done only once, not for every query.

1-complete set.

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

648

†

Marc Denecker et al.

an answer to an old critique on classical logic, namely that it collapses totally
in the case of inconsistency.

5.2 Computational Aspects
As discussed in Apt and Blair [1990], the perfect model and hence the well-
founded model are not recursively enumerable for all programs, and no effective
proof procedure is possible for the general case. However, computation is effec-
tive for function-free logic programs (Datalog). As proven in Van Gelder [1993],
the data complexity of Datalog16 under the well-founded semantics is polyno-
mial time; this is better than the computational complexity of the stable model
semantics [Gelfond and Lifschitz 1988]. For instance the existence problem for
stable models of Datalog programs is NP-complete. Similarly, “membership-in-
some” problem for such programs is also NP-complete, while the “membership-
in-all” problem is co-NP-complete [Marek and Truszczy ´nski 1991].

With the introduction of tabling [Tamaki and Sato 1986] and the development
of the SLG resolution procedure [Chen and Warren 1996], more powerful top
down proof procedures became available. It is proven in Chen and Warren [1996]
that SLG is sound and search space complete with respect to the well-founded
partial model and is polynomial time in case of function-free programs.

The impossibility of a complete proof procedure could be considered a draw-
back with respect to the completion semantics. Indeed, the SLDNF proof pro-
cedure [Lloyd 1987] is known to be complete for certain classes of programs
under the completion semantics—see Apt and Bol [1994] for an overview. First,
we believe it is more important to use a semantics that corresponds to the intui-
tive meaning of a program than one for which complete proof procedures exist.
Second, despite completeness results for SLDNF, in practice the completeness
of SLD(NF) is lost anyway due to the use of the depth-ﬁrst search strategy of
Prolog implementations. So, Prolog programmers are used to (sound but) in-
complete proof procedures. In the current systems, incompleteness is caused
either by nontermination or by ﬂoundering. Users know that they have to rea-
son about this and have developed methodologies to avoid these problems. To
some extent, reasoning about the decidability of a class of queries of interest
can even be automated. Indeed, as mentioned, decidability of a query is closely
related to nonﬂoundering termination of the query. Techniques for analysis of
termination of SLD [De Schreye and Decorte 1994] and of SLG [Verbaeten et al.
2001] exist. Floundering can be analyzed by means of abstract interpretation
[Cousot and Cousot 1977], more speciﬁcally by groundness analysis [Marriott
and Søndergaard 1993]. Of course, due to the undecidability results, these tech-
niques cannot be complete.

5.3 Inductive Deﬁnitions in the Absence of Complete Knowledge
A logic program, which expresses a correct inductive deﬁnition, has a unique
well-founded total model. This presupposes that the programmer, when writing
the program, has complete knowledge of the problem domain and can deﬁne
each predicate of the program.

16As deﬁned in Vardi [1982].

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

Logic Programs as Inductive Deﬁnitions

†

649

In recent years, several logic programming extensions capable of represent-
ing incomplete knowledge have been proposed. One is Abductive Logic Pro-
gramming [Kakas et al. 1992; Denecker 1995], an extension of logic program-
ming by means of abductive reasoning. An abductive logic program is a triple
hA, P, ICi consisting of a set A of abducible (or open) predicates, a logic pro-
gram P deﬁning the set of nonabducible predicates, and a set IC of classical
logic constraints. Another new paradigm is Answer Set Programming [Marek
and Truszczy ´nski 1999; Lifschitz 1999; Niemel¨a 1999]. This approach is based
on the stable model semantics [Gelfond and Lifschitz 1988] and is fundamen-
tally different from the view we have developed so far. Under the stable model
semantics, a normal program is viewed not as a set of deﬁnitions but as a set
of rules expressing constraints on the problem domain. Stable models are “pos-
sible sets of beliefs that a rational agent might hold” given the rules of the
program [Gelfond and Lifschitz 1988].

There are more possibilities, in fact. For instance, the interpretation of a nor-
mal program as an inductive deﬁnition can and has been adapted to cope with
missing knowledge at the predicate level. The approach consists of distinguish-
ing between deﬁned predicates and open predicates. The latter are predicates
for which the program contains no deﬁnition (to be distinguished from predi-
cates with empty deﬁnition). We illustrate it with an example for ﬁnding the
Hamiltonian cycles in a ﬁnite directed graph.17 The unknown Hamiltonian cycle
can be expressed by a binary predicate in/2; the property that all nodes have to
be reachable from a particular node (say node 1) can be deﬁned by a predicate
reachable/1 This gives the following piece of code:

open in/2
node(1).
...
edge(1,2).
...
reachable(U) :- in(1,U).
reachable(V) :- reachable(U), in(U,V).

Note that the reachable/1 predicate depends on the open predicate in/2. Given
a deﬁnition for in/2, it is a correct inductive deﬁnition and determines a unique
model. However not every model (in the language of the program) of in/2 is a
Hamiltonian cycle. As in Answer Set Programming, the set of candidate models
has to be constrained. For this task, ﬁrst-order logic is an excellent tool. The
constraints that the cycle must pass over the edges and must visit all nodes
exactly once can be expressed as the following set of constraints18

edge(U,V) <- in(U,V).
VW <- in(U,V), in(U,W).
U=V <- in(U,W), in(V,W).
reachable(U) <- node(U).

17The interested reader can ﬁnd a solution by means of the Answer Set Programming paradigm in
Lifschitz [1999].
18We use ˆ to stress that these are FOL integrity constraints and not program rules or queries.

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

650

†

Marc Denecker et al.

Under these constraints, models of in/2 are restricted to be Hamiltonian cycles.
Note that the last constraint does not involve directly the open predicate (but
reachable/ depends on it).

The distinction between deﬁnitions and partial knowledge is similar to the
distinction in the literature of knowledge representation between assertional
knowledge and deﬁnitional knowledge [Reichgelt 1991].

As the example shows, combining inductive deﬁnitions of deﬁned predicates
in terms of open predicates with FOL formulas gives an expressive language
facilitating the declarative formulation of problems. The idea is elaborated in
the inductive deﬁnition logic presented in Denecker [2000]. A theory of this
logic, called ID-logic, consists of a set of FOL formulas and a set of deﬁnitions.
In models of such theories, the deﬁned predicates of a deﬁnition are interpreted
by the well-founded model of the deﬁnition extending some interpretation of the
open predicates. The FOL assertions ﬁlter away those well-founded models in
which these assertions do not hold. This logic is closely related to and provides
the epistemological foundation for abductive logic programming [Kakas et al.
1992] (under extended well-founded semantics [Pereira et al. 1991]), which in
turn can be viewed as the study of abductive reasoning in the context of ID-logic.

5.4 Herbrand Interpretations versus General Interpretations
The use of the grounding of a program as a basis for deﬁning semantics boils
down to the use of Herbrand interpretations. The restriction to Herbrand in-
terpretations imposes two assumptions at the knowledge level:

—Domain Closure: every element of the domain of discourse is named by at

least one ground term.

—Unique Names: two different ground terms denote different objects.

These two restrictions imply that there is an isomorphism between the
Herbrand Universe and the objects in the problem domain, i.e., that one knows
all objects of interest and can distinguish among them. These axioms express
complete knowledge of the domain of discourse. However as stated in Denecker
[2000], these restrictions are independent of each other and of the view of logic
programs as inductive deﬁnitions. The inductive deﬁnition logic ID-logic in-
troduced in Denecker [2000] is based on general interpretations rather than
Herbrand interpretations and comprises neither domain closure nor unique
names axioms (but both can be expressed in ID-logic).

5.5 Closing the Circle: A Fixpoint Theory for Nonmonotone Operators
Throughout this paper we have argued that the theory of inductive deﬁnitions
in mathematical logic provides an epistemological foundation for logic program-
ming. Vice versa, logic programming can contribute to the study of nonmono-
tone induction in two ways. First, as argued above, the well-founded semantics
can be seen as a more general and more robust formalization of the principle
of iterated induction. Second, logic programming can also contribute to the
algebraic theory of induction, namely the ﬁxpoint theory of generalized
operators.

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

Logic Programs as Inductive Deﬁnitions

†

651

Until recently, no ﬁxpoint theory for general (monotone or nonmonotone)
operators was known that was modeling the principle of iterated induction.
Building on Fitting’s work [Fitting 1993] on semantics of logic programming in
bilattices Denecker et al. [2000] developed Approximation Theory, an algebraic
ﬁxpoint theory for general (monotone and nonmonotone) operators in a lattice.
This theory deﬁnes for each operator O a set of stable ﬁxpoints and a unique
well-founded ﬁxpoint which is a pair (x, y) of lattice elements such that (x, y)
approximates each stable ﬁxpoint z (i.e., x • z • y). This theory has two key
properties: (1) it extends Tarski’s ﬁxpoint theory in the sense that if the
operator O is monotone, then its well-founded ﬁxpoint is the pair (x, x) where
x is the least ﬁxpoint of O (in this case, x is also the unique stable ﬁxpoint of
O), and (2), the well-founded ﬁxpoint of the immediate consequence operator
TP of a normal program is exactly the well-founded model of P.

In combination with the arguments in Section 5.1 that well-founded seman-
tics is the generalized principle of iterated induction, we put forward the thesis
that Approximation Theory is the natural ﬁxpoint theory of nonmonotone iter-
ated induction.

6. CONCLUSIONS
We have revisited the semantics of logic programming. We have developed the
thesis that logic programs can be understood as inductive deﬁnitions. Elabo-
rating on ideas originally proposed by one of the authors [Denecker 1998], we
have argued that their interpretation as inductive deﬁnition gives a more solid
epistemological foundation for their canonical models than a reference to com-
mon sense. Moreover, this interpretation corresponds to the well-founded se-
mantics. Next, we have shown that this reading of logic programs extends the
notion of iterated inductive deﬁnitions as studied so far in mathematical logic.
Finally, we have elaborated on some of the consequences of this thesis.

We believe that logic programs as deﬁnitions offer a simple, elegant, and
general conceptualization of logic programming, within reach of comprehension
for a broad audience not versed in the literature on semantics of negation and
moreover, that it reconciles the semantics of logic programs with the intuitions
and expectations of programmers inspired by Kowalski’s vision of logic as a
programming language.

ACKNOWLEDGEMENTS
The authors thank Krzysztof R. Apt for his encouragement as well as a num-
ber of valuable suggestions. The anonymous referees suggested a number of
improvements. The ﬁrst author also wants to thank Danny De Schreye and
Eugenia Ternovska for support and comments on earlier versions of the paper.

REFERENCES

ACZEL, P. 1977. An Introduction to Inductive Deﬁnitions. In Handbook of Mathematical Logic,

J. Barwise, Ed. North-Holland Publishing Company, 739–782.

ANDR´EKA, H. AND N´EMETI, I. 1978. The Generalized Completeness of Horn Predicate Logic as a

Programming Language. Acta Cybernetica 4, 3–10.

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

652

†

Marc Denecker et al.

APT, K. AND BLAIR, H. 1990. Arithmetical classiﬁcation of perfect models of stratiﬁed programs.

Fundamenta Informaticae 13, 1, 1–17.

APT, K. AND BOL, R. 1994. Logic programming and negation: a survey. Journal of Logic Program-

ming 19-20, 9–71.

APT, K. R. AND VAN EMDEN, M. 1982. Contributions to the Theory of Declarative Knowledge. Journal

of the ACM 29, 3, 841–862.

APT, K., BLAIR, H., AND WALKER, A. 1988. Towards a theory of Declarative Knowledge. In Foun-
dations of Deductive Databases and Logic Programming, J. Minker, Ed. Morgan Kaufmann,
89–148.

BARWISE, J. 1977. Admissible Sets and Structures. Springer Verlag.
BLAIR, H., MAREK, V., AND SCHLIPF, J. 1995. The expressiveness of locally stratiﬁed programs.

Annals of Mathematics and Artiﬁcial Intelligence 15, 209–229.

BOWEN, K. AND KOWALSKI, R. 1982. Amalgamating Language and Metalanguage in Logic Program-

ming. In Logic Programming, K. Clark and S.-A. T¨arnlund, Eds. Academic Press, 153–172.

BRASS, S. AND DIX, J. 1999. Semantics of (disjunctive) logic programs based on partial evaluation.

Journal of Logic Programming 40, 1 (July), 1–46.

BUCHHOLZ, W., FEFERMAN, S., AND SIEG, W. P. W. 1981. Iterated Inductive Deﬁnitions and Subsystems
of Analysis: Recent Proof-Theoretical Studies. Lecture Notes in Mathematics, vol. 897. Springer-
Verlag.

CHEN, W. AND WARREN, D. 1996. Tabled evaluation with delaying for general logic programs. Jour-

nal of the ACM 43, 1 (January), 20–74.

CLARK, K. 1978. Negation as failure. In Logic and Databases, H. Gallaire and J. Minker, Eds.

Plenum Press, 293–322.

COLMERAUER, A., KANOUI, H., PASERO, R., AND ROUSSEL, P. 1973. Un syst`eme de communication

homme-machine en Franc¸ais. Tech. rep., GIA, Universit´e d’Aix Marseille II, Luminy, France.

COUSOT, P. AND COUSOT, R. 1977. Abstract interpretation: A uniﬁed lattice model for static analysis
of programs by construction or approximation of ﬁxpoints. In Proceedings of the Fourth ACM
Symp. on Principles of Programming Languages. 238–252.

DE SCHREYE, D. AND DECORTE, S. 1994. Termination of logic programs: the never-ending story.

Journal of Logic Programming 19-20, 199–260.

DENECKER, M. 1995. A Terminological Interpretation of (Abductive) Logic Programming. In Inter-
national Conference on Logic Programming and Nonmonotonic Reasoning, V. Marek, A. Nerode,
and M. Truszczynski, Eds. Lecture notes in Artiﬁcial Intelligence 928. Springer, 15–29.

DENECKER, M. 1998. The well-founded semantics is the principle of inductive deﬁnition. In Logics
in Artiﬁcial Intelligence, J. Dix, L. Fari ˜nas del Cerro, and U. Furbach, Eds. Lecture Notes in
Artiﬁcial Intelligence, vol. 1489. Springer-Verlag, 1–16.

DENECKER, M. 2000. Extending classical logic with inductive deﬁnitions. In First International
Conference on Computational Logic (CL2000). Lecture Notes in Artiﬁcial Intelligence, vol. 1861.
Springer, 703–717.

DENECKER, M. AND DE SCHREYE, D. 1993. Justiﬁcation semantics: a unifying framework for the
semantics of logic programs. In Proc. of the Logic Programming and Nonmonotonic Reasoning
Workshop. MIT Press, 365–379.

DENECKER, M., MAREK, V., AND TRUSZCZYNSKI, M. 2000. Approximating operators, stable operators,
well-founded ﬁxpoints and applications in nonmonotonic reasoning. In Logic-based Artiﬁcial
Intelligence, J. Minker, Ed. Kluwer Academic Publishers, Boston, Chapter 6, 127–144.

FEFERMAN, S. 1970. Formal theories for transﬁnite iterations of generalised inductive deﬁnitions
and some subsystems of analysis. In Intuitionism and Proof theory, A. Kino, J. Myhill, and
R. Vesley, Eds. North Holland, 303–326.

FERRY, A. 1994. Topological characterizations for logic programming semantics. Ph.D. thesis,

University of Michigan.

FITTING, M. 1985. A Kripke-Kleene Semantics for Logic Programs. Journal of Logic Program-

ming 2, 4, 295–312.

FITTING, M. 1991. Bilattices and the semantics of logic programming. Journal of Logic Program-

ming 11, 2 (August), 91–116.

FITTING, M. 1993. The family of stable models. Journal of Logic Programming 17, 2,3&4, 197–

225.

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

Logic Programs as Inductive Deﬁnitions

†

653

FITTING, M. 1997. A theory of truth that prefers falsehood. Journal of Philosophical Logic 26,

477–500.

FITTING, M. 2001. Fixpoint semantics for logic programming - a survey. Journal of Theoretical

Computer Science. To appear.

GELFOND, M. 1987. On Stratiﬁed Autoepistemic Theories. In Proc. of AAAI87. Morgan Kaufman,

207–211.

GELFOND, M. AND LIFSCHITZ, V. 1988. The stable model semantics for logic programming. In Proc.
of the International Joint Conference and Symposium on Logic Programming. MIT Press, 1070–
1080.

GUREVICH, Y. AND SHELAH, S. 1986. Fixed-point Extensions of First-Order Logic. Annals of Pure

and Applied Logic 32, 265–280.

KAKAS, A. C., KOWALSKI, R., AND TONI, F. 1992. Abductive Logic Programming. Journal of Logic

and Computation 2, 6, 719–770.

KLEENE, S. 1955. Arithmetical predicates and function quantiﬁers. Transactions Amer. Math.

Soc. 79, 312–340.

KOLAITIS, P. G. AND PAPADIMITRIOU, C. H. 1991. Why not negation by ﬁxpoint. Journal of Computer

and System Sciences 43, 1, 125–144.

KOWALSKI, R. 1974. Predicate logic as a programming language. In Proc. of IFIP 74. North-

Holland, 569–574.

KREISEL, G. 1963. Generalized inductive deﬁnitions. Tech. rep., Stanford University.
LIFSCHITZ, V. 1999. Answer set planning. In Logic Programming, Proc. 1999 Int. Conf. on Logic

Programming (ICLP’99), D. De Schreye, Ed. MIT Press, 23–37.

LLOYD, J. 1987. Foundations of Logic Programming. Springer-Verlag.
MAREK, V. AND TRUSZCZY´NSKI, M. 1989. Stable semantics for logic programs and default reasoning.
In Proc. of the North American Conference on Logic Programming and Nonmonotonic Reasoning,
E.Lust and R. Overbeek, Eds. 243–257.

MAREK, V. AND TRUSZCZY´NSKI, M. 1991. Autoepistemic Logic. Journal of the ACM 38, 3, 588–619.
MAREK, V. AND TRUSZCZY´NSKI, M. 1999. Stable models and an alternative logic programming
paradigm. In The Logic Programming Paradigm: a 25 Years Perspective, K. Apt, V. Marek,
M. Truszczynski, and D. Warren, Eds. Springer-Verlag, pp. 375–398.

MAREK, V., NERODE, N., AND REMMEL, J. 1994. The stable models of predicate logic programs. Jour-

nal of Logic Programming 21, 3, 129–154.

MAREK, W. 1989. Stable theories in autoepistemic logic. Fundamenta Informaticae 12, 2, 243–254.
MARRIOTT, K. AND SøNDERGAARD, H. 1993. Precise and efﬁcient groundness analysis for logic pro-

grams. ACM-LOPLAS 2, 1-4, 181–196.

MARTENS, B. AND DE SCHREYE, D. 1995. Why untyped non-ground meta-programming is not (much

of) a problem. Journal of Logic Programming 22, 1 (January), 47–99.

MARTIN-L¨OF, P. 1971. Hauptsatz for the intuitionistic theory of iterated inductive deﬁnitions. In

Proceedings of the Second Scandinavian Logic Symposium, J. Fenstad, Ed. 179–216.

MOORE, R. 1985. Semantical considerations on nonmonotonic logic. Artiﬁcial Intelligence 25, 1,

75–94.

MOSCHOVAKIS, Y. N. 1974. Elementary Induction on Abstract Structures. North-Holland Publishing

Company, Amsterdam- New York.

NIEMEL¨A, I. 1999. Logic programs with stable model semantics as a constraint programming

paradigm. Annals of Mathematics and Artiﬁcial Intelligence 25, 3,4, 241–273.

PEREIRA, L., APARICIO, J., AND ALFERES, J. 1991. Hypothetical Reasoning with Well Founded
Semantics. In Proc. of the 3th Scandinavian Conference on AI, B. Mayoh, Ed. IOS Press, 289–
300.

PRZYMUSINSKA, H. AND PRZYMUSINSKI, T. 1988. Weakly perfect model semantics for logic programs.
In Proc. of the Fifth International Conference and Symposium on Logic Programming, R. Kowalski
and K. Bowen, Eds. MIT Press, 1106–1120.

PRZYMUSINSKA, H. AND PRZYMUSINSKI, T. 1990. Weakly Stratiﬁed Logic Programs. Fundamenta In-

formaticae 13, 51–65.

PRZYMUSINSKI, T. 1988. On the declarative Semantics of Deductive Databases and Logic Pro-
grams. In Foundations of Deductive Databases and Logic Programming, J. Minker, Ed. Morgan
Kaufman, 193–216.

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

654

†

Marc Denecker et al.

PRZYMUSINSKI, T. 1989a. Every Logic Program Has a Natural Stratiﬁcation And an Iterated Least
Fixed Point Model. In Proceedings of the Eight ACM SIGACT-SIGMOD-SIGART Symposium on
Principles of Database Systems. 11–21.

PRZYMUSINSKI, T. 1989b. On the declarative and procedural semantics of logic programs. Journal

of Automated Reasoning 5, 167–205.

PRZYMUSINSKI, T. 1990. Well founded semantics coincides with three valued Stable Models. Fun-

damenta Informaticae 13, 445–463.

REICHGELT, H. 1991. Knowledge Representation: an AI Perspecitive. Ablex Publishing Corporation.
REITER, R. 1978. On Closed World Data bases. In Logic and Data Bases, H. Gallaire and J. Minker,

Eds. Plenum Press, New York, 55–76.

REITER, R. 1980. A logic for default reasoning. Artiﬁcial Intelligence 13, 81–132.
ROBINSON, J. 1965. A machine-oriented logic based on the resolution principle. Journal of the

ACM 12, 1, 23–41.

SCHLIPF, J. 1995a. Complexity and undecidability results in logic programming. Annals of Math-

ematics and Artiﬁcial Intelligence 15, 257–288.

SCHLIPF, J. 1995b. The expressive powers of the logic programming semantics. Journal of Com-

puter and System Sciences 51, 64–86.

SMULLYAN, R. 1968. First-Order Logic, second ed. Springer, New York.
SPECTOR, C. 1961. Inductively deﬁned sets of natural numbers. In Inﬁnitistic Methods (Proc. 1959

Symposium on Foundation of Mathematis in Warsaw). Pergamon Press, Oxford, 97–102.

TAMAKI, H. AND SATO, T. 1986. OLD resolution with tabulation. In Third International Conference

on Logic Programming. Lecture Notes in Computer Science, vol. 225. Springer-Verlag, 84–98.

TARSKI, A. 1955. Lattice-theoretic ﬁxpoint theorem and its applications. Paciﬁc journal of Math-

ematics 5, 285–309.

VAN EMDEN, M. AND KOWALSKI, R. 1976. The semantics of Predicate Logic as a Programming Lan-

guage. Journal of the ACM 4, 4, 733–742.

VAN GELDER, A. 1988. Negation as Failure Using Tight Derivations for General Logic Programs. In
Foundations of Deductive Databases and Logic Programming, J. Minker, Ed. Morgan Kaufmann,
149–176.

VAN GELDER, A. 1993. The Alternating Fixpoint of Logic Programs with Negation. Journal of

Computer and System Sciences 47, 1, 185–221.

VAN GELDER, A., ROSS, K. A., AND SCHLIPF, J. 1991. The Well-Founded Semantics for General Logic

Programs. Journal of the ACM 38, 3, 620–650.

VARDI, M. 1982. The complexity of relational query languages. In 14th ACM Symposium on Theory

of Computing. 137–145.

VERBAETEN, S., SAGONAS, K., AND DE SCHREYE, D. 2001. Termination proofs for logic programs with

tabling. ACM Transactions on Computational Logic 2, 1, 57–92.

Received August 2000; revised February 2001 and April 2001; accepted April 2001

ACM Transactions on Computational Logic, Vol. 2, No. 4, October 2001.

