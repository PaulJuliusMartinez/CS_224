Cambridge  University  Press
978-0-521-86571-5  -  Introduction  to  Information  Retrieval
Christopher  D.  Manning,  Prabhakar  Raghavan  and  Hinrich  Schutze
Frontmatter
More information

Introduction to Information Retrieval

Introduction to Information Retrieval is the ﬁrst textbook with a coherent treat-
ment of classical and web information retrieval, including web search and
the related areas of text classiﬁcation and text clustering. Written from a
computer science perspective, it gives an up-to-date treatment of all aspects
of the design and implementation of systems for gathering, indexing, and
searching documents and of methods for evaluating systems, along with an
introduction to the use of machine learning methods on text collections.

Designed as the primary text for a graduate or advanced undergraduate
course in information retrieval, the book will also interest researchers and
professionals. A complete set of lecture slides and exercises that accompany
the book are available on the web.

Christopher D. Manning is Associate Professor of Computer Science and Lin-
guistics at Stanford University.

Prabhakar Raghavan is Head of Yahoo! Research and a Consulting Professor
of Computer Science at Stanford University.

Hinrich Sch ¨utze is Chair of Theoretical Computational Linguistics at the In-
stitute for Natural Language Processing, University of Stuttgart.

 

© Cambridge University Press

www.cambridge.org

Cambridge  University  Press
978-0-521-86571-5  -  Introduction  to  Information  Retrieval
Christopher  D.  Manning,  Prabhakar  Raghavan  and  Hinrich  Schutze
Frontmatter
More information

Introduction
to
Information
Retrieval

Christopher D. Manning
Stanford University

Prabhakar Raghavan
Yahoo! Research

Hinrich Sch ¨utze
University of Stuttgart

 

© Cambridge University Press

www.cambridge.org

Cambridge  University  Press
978-0-521-86571-5  -  Introduction  to  Information  Retrieval
Christopher  D.  Manning,  Prabhakar  Raghavan  and  Hinrich  Schutze
Frontmatter
More information

cambridge university press
Cambridge, New York, Melbourne, Madrid, Cape Town, Singapore, S˜ao Paulo, Delhi

Cambridge University Press
32 Avenue of the Americas, New York, NY 10013-2473, USA
www.cambridge.org
Information on this title: www.cambridge.org/9780521865715
C(cid:1) Cambridge University Press 2008

This publication is in copyright. Subject to statutory exception
and to the provisions of relevant collective licensing agreements,
no reproduction of any part may take place without
the written permission of Cambridge University Press.

First published 2008

Printed in the United States of America

A catalog record for this publication is available from the British Library.

Library of Congress Cataloging in Publication data
Manning, Christopher D.
Introduction to information retrieval / Christopher D. Manning, Prabhakar
Raghavan, Hinrich Sch ¨utze.

p.

cm.

Includes bibliographical references and index.
ISBN 978-0-521-86571-5 (hardback)
1. Text processing (Computer science) 2. Information retrieval. 3. Document
II. Sch ¨utze, Hinrich.
clustering. 4. Semantic Web.
III. Title.
QA76.9.T48M26 2008
025.04 – dc22

I. Raghavan, Prabhakar.

2008001257

ISBN 978-0-521-86571-5 hardback

Cambridge University Press has no responsibility for
the persistence or accuracy of URLs for external or
third-party Internet Web sites referred to in this publication
and does not guarantee that any content on such
Web sites is, or will remain, accurate or appropriate.

© Cambridge University Press

www.cambridge.org

Cambridge  University  Press
978-0-521-86571-5  -  Introduction  to  Information  Retrieval
Christopher  D.  Manning,  Prabhakar  Raghavan  and  Hinrich  Schutze
Frontmatter
More information

Contents

Table of Notation
Preface

1 Boolean retrieval

1.1 An example information retrieval problem
1.2 A ﬁrst take at building an inverted index
1.3 Processing Boolean queries
1.4 The extended Boolean model versus ranked retrieval
1.5 References and further reading

2 The term vocabulary and postings lists

2.1 Document delineation and character sequence decoding
2.2 Determining the vocabulary of terms
2.3 Faster postings list intersection via skip pointers
2.4 Positional postings and phrase queries
2.5 References and further reading

3 Dictionaries and tolerant retrieval

3.1 Search structures for dictionaries
3.2 Wildcard queries
3.3 Spelling correction
3.4 Phonetic correction
3.5 References and further reading

4 Index construction

4.1 Hardware basics
4.2 Blocked sort-based indexing
4.3 Single-pass in-memory indexing
4.4 Distributed indexing
4.5 Dynamic indexing

 

page xi
xv

1

3
6
9
13
16

18

18
21
33
36
43

45

45
48
52
58
59

61

62
63
66
68
71

v

© Cambridge University Press

www.cambridge.org

Cambridge  University  Press
978-0-521-86571-5  -  Introduction  to  Information  Retrieval
Christopher  D.  Manning,  Prabhakar  Raghavan  and  Hinrich  Schutze
Frontmatter
More information

vi

Contents

4.6 Other types of indexes
4.7 References and further reading

5 Index compression

5.1 Statistical properties of terms in information retrieval
5.2 Dictionary compression
5.3 Postings ﬁle compression
5.4 References and further reading

6 Scoring, term weighting, and the vector space model

6.1 Parametric and zone indexes
6.2 Term frequency and weighting
6.3 The vector space model for scoring
6.4 Variant tf–idf functions
6.5 References and further reading

7 Computing scores in a complete search system

7.1 Efﬁcient scoring and ranking
7.2 Components of an information retrieval system
7.3 Vector space scoring and query operator interaction
7.4 References and further reading

8 Evaluation in information retrieval

8.1 Information retrieval system evaluation
8.2 Standard test collections
8.3 Evaluation of unranked retrieval sets
8.4 Evaluation of ranked retrieval results
8.5 Assessing relevance
8.6 A broader perspective: System quality and user

utility

8.7 Results snippets
8.8 References and further reading

9 Relevance feedback and query expansion

9.1 Relevance feedback and pseudo relevance

feedback

9.2 Global methods for query reformulation
9.3 References and further reading

10 XML retrieval

10.1 Basic XML concepts
10.2 Challenges in XML retrieval
10.3 A vector space model for XML retrieval
10.4 Evaluation of XML retrieval

73
76

78

79
82
87
97

100

101
107
110
116
122

124

124
132
136
137

139

140
141
142
145
151

154
157
159

162

163
173
177

178

180
183
188
192

© Cambridge University Press

www.cambridge.org

Cambridge  University  Press
978-0-521-86571-5  -  Introduction  to  Information  Retrieval
Christopher  D.  Manning,  Prabhakar  Raghavan  and  Hinrich  Schutze
Frontmatter
More information

Contents

10.5 Text-centric versus data-centric XML retrieval
10.6 References and further reading

11 Probabilistic information retrieval

11.1 Review of basic probability theory
11.2 The probability ranking principle
11.3 The binary independence model
11.4 An appraisal and some extensions
11.5 References and further reading

12 Language models for information retrieval

12.1 Language models
12.2 The query likelihood model
12.3 Language modeling versus other approaches

in information retrieval

12.4 Extended language modeling approaches
12.5 References and further reading

13 Text classiﬁcation and Naive Bayes

13.1 The text classiﬁcation problem
13.2 Naive Bayes text classiﬁcation
13.3 The Bernoulli model
13.4 Properties of Naive Bayes
13.5 Feature selection
13.6 Evaluation of text classiﬁcation
13.7 References and further reading

14 Vector space classiﬁcation

14.1 Document representations and measures of relatedness

in vector spaces

14.2 Rocchio classiﬁcation
14.3 k nearest neighbor
14.4 Linear versus nonlinear classiﬁers
14.5 Classiﬁcation with more than two classes
14.6 The bias–variance tradeoff
14.7 References and further reading

15 Support vector machines and machine learning on documents

15.1 Support vector machines: The linearly separable case
15.2 Extensions to the support vector machine model
15.3 Issues in the classiﬁcation of text documents
15.4 Machine-learning methods in ad hoc information retrieval
15.5 References and further reading

 

vii

196
198

201

202
203
204
212
216

218

218
223

229
230
232

234

237
238
243
245
251
258
264

266

267
269
273
277
281
284
291

293

294
300
307
314
318

© Cambridge University Press

www.cambridge.org

Cambridge  University  Press
978-0-521-86571-5  -  Introduction  to  Information  Retrieval
Christopher  D.  Manning,  Prabhakar  Raghavan  and  Hinrich  Schutze
Frontmatter
More information

viii

16 Flat clustering

16.1 Clustering in information retrieval
16.2 Problem statement
16.3 Evaluation of clustering
16.4 K -means
16.5 Model-based clustering
16.6 References and further reading

17 Hierarchical clustering

17.1 Hierarchical agglomerative clustering
17.2 Single-link and complete-link clustering
17.3 Group-average agglomerative clustering
17.4 Centroid clustering
17.5 Optimality of hierarchical agglomerative

clustering

17.6 Divisive clustering
17.7 Cluster labeling
17.8 Implementation notes
17.9 References and further reading

18 Matrix decompositions and latent semantic indexing

18.1 Linear algebra review
18.2 Term–document matrices and singular value

decompositions

18.3 Low-rank approximations
18.4 Latent semantic indexing
18.5 References and further reading

19 Web search basics

19.1 Background and history
19.2 Web characteristics
19.3 Advertising as the economic model
19.4 The search user experience
19.5 Index size and estimation
19.6 Near-duplicates and shingling
19.7 References and further reading

20 Web crawling and indexes

20.1 Overview
20.2 Crawling
20.3 Distributing indexes
20.4 Connectivity servers
20.5 References and further reading

Contents

321

322
326
327
331
338
343

346

347
350
356
358

360
362
363
365
367

369

369

373
376
378
383

385

385
387
392
395
396
400
404

405

405
406
415
416
419

© Cambridge University Press

www.cambridge.org

Cambridge  University  Press
978-0-521-86571-5  -  Introduction  to  Information  Retrieval
Christopher  D.  Manning,  Prabhakar  Raghavan  and  Hinrich  Schutze
Frontmatter
More information

Contents

21 Link analysis

21.1 The Web as a graph
21.2 PageRank
21.3 Hubs and authorities
21.4 References and further reading

Bibliography
Index

ix

421

422
424
433
439

441
469

 

© Cambridge University Press

www.cambridge.org

Cambridge  University  Press
978-0-521-86571-5  -  Introduction  to  Information  Retrieval
Christopher  D.  Manning,  Prabhakar  Raghavan  and  Hinrich  Schutze
Frontmatter
More information

Table of Notation

Symbol
γ

γ



λ

(cid:2)µ(.)

237

370
269

σ



105
374
(·)
10
328
ω, ωk
328

arg maxx f (x) 164
arg minx f (x) 164
237
c, c j
cft
82

C
C

C
d
d
(cid:2)d, (cid:2)q
D
Dc
D

237
248

369
4
65
163
326
269
237

 

Page Meaning
90
237

γ code
Classiﬁcation or clustering function: γ (d) is d’s class
or cluster
Supervised learning method in Chapters 13 and 14:
(D) is the classiﬁcation function γ learned from
training set D
Eigenvalue
Centroid of a class (in Rocchio classiﬁcation) or a
cluster (in K -means and centroid clustering)
Training example
Singular value
A tight bound on the complexity of an algorithm
Cluster in clustering
Clustering or set of clusters {ω1, . . . , ωK}
The value of x for which f reaches its maximum
The value of x for which f reaches its minimum
Class or category in classiﬁcation
The collection frequency of term t (the total number
of times the term appears in the document collection)
Set {c1, . . . , c J } of all classes
A random variable that takes as values members of
C
Term–document matrix
Index of the dth document in the collection D
A document
Document vector, query vector
Set {d1, . . . , dN} of all documents
Set of documents that is in class c
Set {(cid:3)d1, c1(cid:4), . . . , (cid:3)dN, c N(cid:4)} of all labeled documents in
Chapters 13–15

© Cambridge University Press

www.cambridge.org

xi

Cambridge  University  Press
978-0-521-86571-5  -  Introduction  to  Information  Retrieval
Christopher  D.  Manning,  Prabhakar  Raghavan  and  Hinrich  Schutze
Frontmatter
More information

xii

dft

H
HM
I (X; Y)
idft
J
k

k
K
Ld
La

Lave
M
Ma

Mave

Md
N

Nc
N(ω)
O(·)
O(·)
P
P(·)
P
q
R
si
si
sim(d1, d2)
T
Tct

t
t
tft,d

108

91
93
252
108
237
267

50
326
214
242

64
4
242

71

218
4

240
275
10
203
142
202
425
55
143
53
103
111
40
240

4
56
107

Table of Notation

The document frequency of term t (the total number
of documents in the collection the term appears in)
Entropy
Mth harmonic number
Mutual information of random variables X and Y
Inverse document frequency of term t
Number of classes
Top k items from a set, e.g., k nearest neighbors in
kNN, top k retrieved documents, top k selected fea-
tures from the vocabulary V
Sequence of k characters
Number of clusters
Length of document d (in tokens)
Length of the test document (or application docu-
ment) in tokens
Average length of a document (in tokens)
Size of the vocabulary (|V|)
Size of the vocabulary of the test document (or appli-
cation document)
Average size of the vocabulary in a document in the
collection
Language model for document d
Number of documents in the retrieval or training col-
lection
Number of documents in class c
Number of times the event ω occurred
A bound on the complexity of an algorithm
The odds of an event
Precision
Probability
Transition probability matrix
A query
Recall
A string
Boolean values for zone scoring
Similarity score for documents d1, d2
Total number of tokens in the document collection
Number of occurrences of word t in documents of
class c
Index of the tth term in the vocabulary V
A term in the vocabulary
The term frequency of term t in document d (the total
number of occurrences of t in d)

© Cambridge University Press

www.cambridge.org

Cambridge  University  Press
978-0-521-86571-5  -  Introduction  to  Information  Retrieval
Christopher  D.  Manning,  Prabhakar  Raghavan  and  Hinrich  Schutze
Frontmatter
More information

Table of Notation

xiii

Ut

V
(cid:2)v(d)
(cid:2)V(d)
wft,d
w
(cid:2)wT(cid:2)x = b
(cid:2)x

X

X

|A|
|S|
|si|
|(cid:2)x|
|(cid:2)x − (cid:2)y|

246

190

111
110
115
103
269

204

246

237
56
370
53
128
121

Random variable taking values 0 (term t is present)
and 1 (t is not present)
Vocabulary of terms {t1, . . . , tM} in a collection (a.k.a.
the lexicon)
Length-normalized document vector
Vector of document d, not length normalized
Weight of term t in document d
A weight, for example, for zones or terms
Hyperplane; (cid:2)w is the normal vector of the hyperplane
and wi component i of (cid:2)w
Term incidence vector (cid:2)x = (x1, . . . , xM); more gener-
ally: document feature representation
Random variable taking values in V, the vocabulary
(e.g., at a given position k in a document)
Document space in text classiﬁcation
Set cardinality: the number of members of set A
Determinant of the square matrix S
Length in characters of string si
Length of vector (cid:2)x
Euclidean distance of (cid:2)x and (cid:2)y (which is the length of
((cid:2)x − (cid:2)y))

 

© Cambridge University Press

www.cambridge.org

Cambridge  University  Press
978-0-521-86571-5  -  Introduction  to  Information  Retrieval
Christopher  D.  Manning,  Prabhakar  Raghavan  and  Hinrich  Schutze
Frontmatter
More information

Preface

As recently as the 1990s, studies showed that most people preferred getting
information from other people rather than from information retrieval (IR)
systems. Of course, in that time period, most people also used human travel
agents to book their travel. However, during the last decade, relentless opti-
mization of information retrieval effectiveness has driven web search engines
to new quality levels at which most people are satisﬁed most of the time, and
web search has become a standard and often preferred source of information
ﬁnding. For example, the 2004 Pew Internet Survey (Fallows 2004) found
that “92% of Internet users say the Internet is a good place to go for getting
everyday information.” To the surprise of many, the ﬁeld of information re-
trieval has moved from being a primarily academic discipline to being the
basis underlying most people’s preferred means of information access. This
book presents the scientiﬁc underpinnings of this ﬁeld, at a level accessible
to graduate students as well as advanced undergraduates.

Information retrieval did not begin with the Web. In response to various
challenges of providing information access, the ﬁeld of IR evolved to give
principled approaches to searching various forms of content. The ﬁeld be-
gan with scientiﬁc publications and library records but soon spread to other
forms of content, particularly those of information professionals, such as
journalists, lawyers, and doctors. Much of the scientiﬁc research on IR has
occurred in these contexts, and much of the continued practice of IR deals
with providing access to unstructured information in various corporate and
governmental domains, and this work forms much of the foundation of our
book.

Nevertheless, in recent years, a principal driver of innovation has been the
World Wide Web, unleashing publication at the scale of tens of millions of
content creators. This explosion of published information would be moot if
the information could not be found, annotated, and analyzed so that each
user can quickly ﬁnd information that is both relevant and comprehensive
for their needs. By the late 1990s, many people felt that continuing to in-
dex the whole Web would rapidly become impossible, due to the Web’s

xv

 

© Cambridge University Press

www.cambridge.org

Cambridge  University  Press
978-0-521-86571-5  -  Introduction  to  Information  Retrieval
Christopher  D.  Manning,  Prabhakar  Raghavan  and  Hinrich  Schutze
Frontmatter
More information

xvi

Preface

exponential growth in size. But major scientiﬁc innovations, superb engi-
neering, the rapidly declining price of computer hardware, and the rise of
a commercial underpinning for web search have all conspired to power to-
day’s major search engines, which are able to provide high-quality results
within subsecond response times for hundreds of millions of searches a day
over billions of web pages.

Book organization and course development

This book is the result of a series of courses we have taught at Stanford Uni-
versity and at the University of Stuttgart, in a range of durations including
a single quarter, one semester, and two quarters. These courses were aimed
at early stage graduate students in computer science, but we have also had
enrollment from upper-class computer science undergraduates, as well as
students from law, medical informatics, statistics, linguistics, and various en-
gineering disciplines. The key design principle for this book, therefore, was
to cover what we believe to be important in a one-term graduate course on
IR. An additional principle is to build each chapter around material that we
believe can be covered in a single lecture of 75 to 90 minutes.

The ﬁrst eight chapters of the book are devoted to the basics of information
retrieval and in particular the heart of search engines; we consider this ma-
terial to be core to any course on information retrieval. Chapter 1 introduces
inverted indexes and shows how simple Boolean queries can be processed
using such indexes. Chapter 2 builds on this introduction by detailing the
manner in which documents are preprocessed before indexing and by dis-
cussing how inverted indexes are augmented in various ways for function-
ality and speed. Chapter 3 discusses search structures for dictionaries and
how to process queries that have spelling errors and other imprecise matches
to the vocabulary in the document collection being searched. Chapter 4 de-
scribes a number of algorithms for constructing the inverted index from a
text collection with particular attention to highly scalable and distributed al-
gorithms that can be applied to very large collections. Chapter 5 covers tech-
niques for compressing dictionaries and inverted indexes. These techniques
are critical for achieving subsecond response times to user queries in large
search engines. The indexes and queries considered in Chapters 1 through 5
only deal with Boolean retrieval, in which a document either matches a query
or does not. A desire to measure the extent to which a document matches a
query, or the score of a document for a query, motivates the development of
term weighting and the computation of scores in Chapters 6 and 7, leading
to the idea of a list of documents that are rank-ordered for a query. Chapter 8
focuses on the evaluation of an information retrieval system based on the
relevance of the documents it retrieves, allowing us to compare the relative

© Cambridge University Press

www.cambridge.org

Cambridge  University  Press
978-0-521-86571-5  -  Introduction  to  Information  Retrieval
Christopher  D.  Manning,  Prabhakar  Raghavan  and  Hinrich  Schutze
Frontmatter
More information

Preface

xvii

performances of different systems on benchmark document collections and
queries.

Chapters 9 through 21 build on the foundation of the ﬁrst eight chapters
to cover a variety of more advanced topics. Chapter 9 discusses methods by
which retrieval can be enhanced through the use of techniques like relevance
feedback and query expansion, which aim at increasing the likelihood of re-
trieving relevant documents. Chapter 10 considers IR from documents that
are structured with markup languages like XML and HTML. We treat struc-
tured retrieval by reducing it to the vector space scoring methods developed
in Chapter 6. Chapters 11 and 12 invoke probability theory to compute scores
for documents on queries. Chapter 11 develops traditional probabilistic IR,
which provides a framework for computing the probability of relevance of
a document, given a set of query terms. This probability may then be used
as a score in ranking. Chapter 12 illustrates an alternative, wherein, for each
document in a collection, we build a language model from which one can
estimate a probability that the language model generates a given query. This
probability is another quantity with which we can rank-order documents.

Chapters 13 through 18 give a treatment of various forms of machine learn-
ing and numerical methods in information retrieval. Chapters 13 through 15
treat the problem of classifying documents into a set of known categories,
given a set of documents along with the classes they belong to. Chapter 13
motivates statistical classiﬁcation as one of the key technologies needed for
a successful search engine; introduces Naive Bayes, a conceptually simple
and efﬁcient text classiﬁcation method; and outlines the standard method-
ology for evaluating text classiﬁers. Chapter 14 employs the vector space
model from Chapter 6 and introduces two classiﬁcation methods, Rocchio
and k nearest neighbor (kNN), that operate on document vectors. It also
presents the bias-variance tradeoff as an important characterization of learn-
ing problems that provides criteria for selecting an appropriate method for a
text classiﬁcation problem. Chapter 15 introduces support vector machines,
which many researchers currently view as the most effective text classiﬁca-
tion method. We also develop connections in this chapter between the prob-
lem of classiﬁcation and seemingly disparate topics such as the induction of
scoring functions from a set of training examples.

Chapters 16, 17, and 18 consider the problem of inducing clusters of related
documents from a collection. In Chapter 16, we ﬁrst give an overview of a
number of important applications of clustering in IR. We then describe two
ﬂat clustering algorithms: the K -means algorithm, an efﬁcient and widely
used document clustering method, and the expectation-maximization al-
gorithm, which is computationally more expensive, but also more ﬂexible.
Chapter 17 motivates the need for hierarchically structured clusterings (in-
stead of ﬂat clusterings) in many applications in IR and introduces a number
of clustering algorithms that produce a hierarchy of clusters. The chapter

 

© Cambridge University Press

www.cambridge.org

Cambridge  University  Press
978-0-521-86571-5  -  Introduction  to  Information  Retrieval
Christopher  D.  Manning,  Prabhakar  Raghavan  and  Hinrich  Schutze
Frontmatter
More information

xviii

Preface

also addresses the difﬁcult problem of automatically computing labels for
clusters. Chapter 18 develops methods from linear algebra that constitute
an extension of clustering and also offer intriguing prospects for algebraic
methods in IR, which have been pursued in the approach of latent semantic
indexing.

Chapters 19 through 21 treat the problem of web search. We give in Chap-
ter 19 a summary of the basic challenges in web search, together with a set
of techniques that are pervasive in web information retrieval. Next, Chap-
ter 20 describes the architecture and requirements of a basic web crawler.
Finally, Chapter 21 considers the power of link analysis in web search, using
in the process several methods from linear algebra and advanced probability
theory.

This book is not comprehensive in covering all topics related to IR. We
have put aside a number of topics, which we deemed outside the scope of
what we wished to cover in an introduction to IR class. Nevertheless, for
people interested in these topics, we provide the following pointers to mainly
textbook coverage:

Cross-language IR Grossman and Frieder 2004, ch. 4, and Oard and
Dorr 1996.
Image and multimedia IR Grossman and Frieder 2004, ch. 4; Baeza-
Yates and Ribeiro-Neto 1999, ch. 6; Baeza-Yates and Ribeiro-Neto 1999,
ch. 11; Baeza-Yates and Ribeiro-Neto 1999, ch. 12; del Bimbo 1999; Lew
2001; and Smeulders et al. 2000.
Speech retrieval Coden et al. 2002.
Music retrieval Downie 2006 and http://www.ismir.net/.
User interfaces for IR Baeza-Yates and Ribeiro-Neto 1999, ch. 10.
Parallel and peer-to-peer IR Grossman and Frieder 2004, ch. 7; Baeza-
Yates and Ribeiro-Neto 1999, ch. 9; and Aberer 2001.
Digital libraries Baeza-Yates and Ribeiro-Neto 1999, ch. 15, and Lesk
2004.
Information science perspective Korfhage 1997; Meadow et al. 1999;
and Ingwersen and J¨arvelin 2005.
Logic-based approaches to IR van Rijsbergen 1989.
Natural language processing techniques Manning and Sch ¨utze 1999;
Jurafsky and Martin 2008; and Lewis and Jones 1996.

Prerequisites

Introductory courses in data structures and algorithms, in linear algebra, and
in probability theory sufﬁce as prerequisites for all twenty-one chapters. We
now give more detail for the beneﬁt of readers and instructors who wish to
tailor their reading to some of the chapters.

© Cambridge University Press

www.cambridge.org

Cambridge  University  Press
978-0-521-86571-5  -  Introduction  to  Information  Retrieval
Christopher  D.  Manning,  Prabhakar  Raghavan  and  Hinrich  Schutze
Frontmatter
More information

Preface

xix

Chapters 1 through 5 assume as prerequisite a basic course in algorithms
and data structures. Chapters 6 and 7 require, in addition, a knowledge of
basic linear algebra, including vectors and dot products. No additional pre-
requisites are assumed until Chapter 11, for which a basic course in prob-
ability theory is required; Section 11.1 gives a quick review of the concepts
necessary in Chapters 11, 12, and 13. Chapter 15 assumes that the reader
is familiar with the notion of nonlinear optimization, although the chapter
may be read without detailed knowledge of algorithms for nonlinear op-
timization. Chapter 18 demands a ﬁrst course in linear algebra, including
familiarity with the notions of matrix rank and eigenvectors; a brief review
is given in Section 18.1. The knowledge of eigenvalues and eigenvectors is
also necessary in Chapter 21.

Book layout

left margin. Advanced or difﬁcult material appears in sections or subsections
indicated with scissors in the margin. Exercises are marked in the margin

✎ Worked examples in the text appear with a pencil sign next to them in the
✄ with a question mark. The level of difﬁculty of exercises is indicated as easy
?

[(cid:9)], medium [(cid:9)(cid:9)], or difﬁcult [(cid:9) (cid:9) (cid:9)].

Acknowledgments

The authors thank Cambridge University Press for allowing us to make the
draft book available online, which facilitated much of the feedback we have
received while writing the book. We also thank Lauren Cowles, who has been
an outstanding editor, providing several rounds of comments on each chap-
ter; on matters of style, organization, and coverage; as well as detailed com-
ments on the subject matter of the book. To the extent that we have achieved
our goals in writing this book, she deserves an important part of the credit.
We are very grateful to the many people who have given us comments,
suggestions, and corrections based on draft versions of this book. We thank
for providing various corrections and comments: Cheryl Aasheim, Josh At-
tenberg, Luc B´elanger, Tom Breuel, Daniel Burckhardt, Georg Buscher, Fa-
zli Can, Dinquan Chen, Ernest Davis, Pedro Domingos, Rodrigo Panchiniak
Fernandes, Paolo Ferragina, Norbert Fuhr, Vignesh Ganapathy, Elmer Gar-
duno, Xiubo Geng, David Gondek, Sergio Govoni, Corinna Habets, Ben
Handy, Donna Harman, Benjamin Haskell, Thomas H ¨uhn, Deepak Jain,
Ralf Jankowitsch, Dinakar Jayarajan, Vinay Kakade, Mei Kobayashi, Wes-
sel Kraaij, Rick Laﬂeur, Florian Laws, Hang Li, David Mann, Ennio Masi,
Frank McCown, Paul McNamee, Sven Meyer zu Eissen, Alexander Murzaku,
Gonzalo Navarro, Scott Olsson, Daniel Paiva, Tao Qin, Megha Raghavan,

 

© Cambridge University Press

www.cambridge.org

Cambridge  University  Press
978-0-521-86571-5  -  Introduction  to  Information  Retrieval
Christopher  D.  Manning,  Prabhakar  Raghavan  and  Hinrich  Schutze
Frontmatter
More information

xx

Preface

Ghulam Raza, Michal Rosen-Zvi, Klaus Rothenh¨ausler, Kenyu L. Run-
ner, Alexander Salamanca, Grigory Sapunov, Tobias Scheffer, Nico Schlae-
fer, Evgeny Shadchnev, Ian Soboroff, Benno Stein, Marcin Sydow, Andrew
Turner, Jason Utt, Huey Vo, Travis Wade, Mike Walsh, Changliang Wang,
Renjing Wang, and Thomas Zeume.

Many people gave us detailed feedback on individual chapters, either
at our request or through their own initiative. For this, we’re particularly
grateful to James Allan, Omar Alonso, Ismail Sengor Altingovde, Vo Ngoc
Anh, Roi Blanco, Eric Breck, Eric Brown, Mark Carman, Carlos Castillo,
Junghoo Cho, Aron Culotta, Doug Cutting, Meghana Deodhar, Susan Du-
mais, Johannes F ¨urnkranz, Andreas Heß, Djoerd Hiemstra, David Hull,
Thorsten Joachims, Siddharth Jonathan J. B., Jaap Kamps, Mounia Lal-
mas, Amy Langville, Nicholas Lester, Dave Lewis, Stephen Liu, Daniel
Lowd, Yosi Mass, Jeff Michels, Alessandro Moschitti, Amir Najmi, Marc
Najork, Giorgio Maria Di Nunzio, Paul Ogilvie, Priyank Patel, Jan Peder-
sen, Kathryn Pedings, Vassilis Plachouras, Daniel Ramage, Stefan Riezler,
Michael Schiehlen, Helmut Schmid, Falk Nicolas Scholer, Sabine Schulte
im Walde, Fabrizio Sebastiani, Sarabjeet Singh, Alexander Strehl, John Tait,
Shivakumar Vaithyanathan, Ellen Voorhees, Gerhard Weikum, Dawid Weiss,
Yiming Yang, Yisong Yue, Jian Zhang, and Justin Zobel.

And ﬁnally there were a few reviewers who absolutely stood out in terms
of the quality and quantity of comments that they provided. We thank them
for their signiﬁcant impact on the content and structure of the book. We ex-
press our gratitude to Pavel Berkhin, Stefan B ¨uttcher, Jamie Callan, Byron
Dom, Torsten Suel, and Andrew Trotman.

Parts of the initial drafts of Chapters 13, 14, and 15 were based on slides
that were generously provided by Ray Mooney. Although the material has
gone through extensive revisions, we gratefully acknowledge Ray’s contri-
bution to the three chapters in general and to the description of the time
complexities of text classiﬁcation algorithms in particular.

The above is unfortunately an incomplete list; we are still in the process of
incorporating feedback we have received. And, like all opinionated authors,
we did not always heed the advice that was so freely given. The published
versions of the chapters remain solely the responsibility of the authors.

The authors thank Stanford University and the University of Stuttgart for
providing a stimulating academic environment for discussing ideas and the
opportunity to teach courses from which this book arose and in which its
contents were reﬁned. CM thanks his family for the many hours they’ve let
him spend working on this book and hopes he’ll have a bit more free time on
weekends next year. PR thanks his family for their patient support through
the writing of this book and is also grateful to Yahoo! Inc. for providing a
fertile environment in which to work on this book. HS would like to thank
his parents, family, and friends for their support while writing this book.

© Cambridge University Press

www.cambridge.org

Cambridge  University  Press
978-0-521-86571-5  -  Introduction  to  Information  Retrieval
Christopher  D.  Manning,  Prabhakar  Raghavan  and  Hinrich  Schutze
Frontmatter
More information

Preface
Web and contact information

xxi

This book has a companion website at http://informationretrieval.org. As well
as links to some more general resources, it is our intention to maintain
on this website a set of slides for each chapter that may be used for the
corresponding lecture. We gladly welcome further feedback, corrections,
and suggestions on the book, which may be sent to all the authors at
informationretrieval@yahoogroups.com.

 

© Cambridge University Press

www.cambridge.org

