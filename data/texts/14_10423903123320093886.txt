MOTION BLUR FREE HDR IMAGE ACQUISITION USING MULTIPLE EXPOSURES Takao Jinno and Masahiro Okuda
The University of Kitakyushu, JAPAN

ABSTRACT
The high dynamic range image (HDRI) acquisition method based on Markov random field model is proposed. By combining multiple exposure images shot with different shutter speed, we estimate the irradiance value for each pixel. Our method estimates displacements, occlusion and saturated regions, and by using them construct the motion blur free HDRI with higher quality than other existing methods.
Keywords: HDRI, multiple exposures, MRF model
1. INTRODUCTION
By adapting lights in any viewing condition, the human visual system can capture a wide dynamic range of irradiance (about 14 orders in log unit). While the dynamic range of CCD or CMOS sensors in most of today's cameras is a limited range of real scenes. It is important for many applications to capture the wide range of irradiance of natural scene and store the irradiance value in each pixel. For example, it can address the problem of under- or over-exposure when taking a photo of a man with very bright backlight, or shooting outside from a tunnel. In the application of CG, a high dynamic range image (HDRI) is widely used for high quality rendering with image based lighting [1].
In the last decade, to capture the HDRI, many techniques have been proposed based on the multiple-exposure principle, in which a HDRI is constructed by merging some photos shot with multiple exposures. Many of the techniques assume that a scene is still during shooting photos. The motion of objects causes motion blur and ghosting artifacts. Although in some fields such as video coding and stereo vision, many displacement (or motion) estimation methods are proposed, simply applying them into the multiple exposure fusino often fails since the intensity levels of the images are significantly different due to the failure of camera response curve estimation, and more importantly the low and high exposure causes white and black out to some regions of the images, respectively, in which correspondence between the images is hard to find. Moreover in case of low exposure, offset noises like thermal noise and dark current sometimes makes the displacement estimation difficult. The conventional methods [1]-[7] do not address all of the problems.
In this paper, we propose an algorithm of the HDRI estimation based on the Markov random field (MRF) model. We can systematically construct the HDRI by taking into considerations displacements, under- and over-exposures and occlusions. The displacement vectors as well as the occlusion and the saturation are detected by the MAP estimation. In our method we do not need to estimate accurate
This work is supported by a Grant-in-Aid for Young Sciences (#14750305) of Japan Society for the Promotion of Science.

motion vectors but displacement to the pixel with the closest irradiance, while the conventional methods such as [5] try to estimate the motion accurately. This relaxation improves the final quality of the HDRI. The occlusion and the saturation are clearly classified and then treat it separately, which results in the accurate removal of ghosting artifacts. We show some experimental results to confirm the validity of our work with comparisons to the other methods.

2. ACQUISITION OF HDRI 2.1. Camera Calibration
ÊThe relationship between the radiance and the amount of lights Ä(that is the product of irradiance times a shutter speed) that we
measure through some sensor can be expressed by [4]

¾
Ä Ê Ó× ´ µ Ø

(1)

Øwhere , , , and are a focal length, the diameter of an aperture,
the angle determined by an optical axis, and exposure time respectively.
ÄIn many of camera sensors, the captured are nonlinearly trans-
formed to pixel values . To accurately retrieve the irradiance, we
need to compensate the nonlinearity by estimating the transform. Here we call the transform "camera response curve" and we denote it by
´Äµ (2)

Among the existing methods for the camera calibration problem, we

adopt Mitsunaga et al.'s method [4] to find , in which the curve is

approximated by a low order polynomial using multiple images and

the values of exposure ratios between the images. In our method, the

multiple exposure images are taken by varying the shutter speed of

a camera with other settings fixed. Then the images are merged by

ÁÑ

ÈÒÆ

½

ÛÈ´ÆÒÑÒ

µ
½

¢ Û

 ½ ´ ÒÑ ´ ÒÑµ

µ

ØÒ£

(3)

where ÑÒ is the value of
is the number of images,

a pixel Ñ of the Ò-th exposure image. Æ ØÒ is the exposure time of the Ò-th image,

Ûand is a weighting function. The weighting function is introduced

because under- or over- exposed regions are much less reliable than

the regions of middle intensities. Thus the weight is specified to be

small for pixel values of the saturated regions, high for the middle

intensities.

Ä2.2. MRF Model in (2) can be estimated by

 ½ only when pixels are not under- or

over-exposed. Moreover (3) is effective only when scenes are still.

Since moving objects cause the motion blur, it is required to compensate the displacement as much as possible. In usual, the compensation is done by two steps, global motion and local displacement compensation steps. In our method we assume that the global motion (e.g. camera shake) is already compensated by some image alignment algorithm [1]. In this section we focus on the local displacement compensation.
In our situation, the displacement estimation may fail due to (1) occlusion, (2) saturation, that is, under- and over-exposure, and (3) differences in intensity caused by the failure of the camera response curve estimation. Fig.1 illustrates an example of two exposures, where some region of the high exposure image (white area in the left image) is over-exposed. There may be three types of regions where correspondence between the images are hard to find: occlusion (marked by light grey in the right image), saturation (overexposure in this example), and both of the two (dark grey in the right image).

È ´ µand × by using the observed
the posterior probability

imÓ a×gesÔ

ÔÕan. dApÕp,lythinagt

is, maximizing the Bayes rule,

the posterior probability is written by

È

´ È

´ÓÔ

×

Ô
Ó

Õµ

×
È

Õ
´

µÔÈµ

´

Ó × Õµ

È ´ Ô Ó × ÕµÈ ´ ÈÓ´×Ôµ ÕµÈ ´Ó × ÕµÈ ´× Õµ (6)

From (6), our MAP estimation is stated as
Ñ Ü È ´ Ô Ó × ÕµÈ ´ Ó × ÕµÈ ´Ó × ÕµÈ ´× Õµ Ó×

(7)

È ´ µSince Ó×

Ô

Ó Õancdan×

are modeled by MRFs, the probability be characterized by a Gibbs distribution

[8]-

[9].

È ´ Ó × Ô Õµ ½ ÜÔ  Í´ Ó × Ô Õµ Ì (8)

Fig. 1. example of multiple exposure images: (left) high exposure, (right) low exposure

Here we introduce a probability model for the estimation of the

displacement between two images, the regions of occlusion and the

ssautruer,atÔion.

LeÔt

us denote
Ð ´ Ðµ ¾

£twoamndeasÕured

imÕ aÐge´s

with different expo-
Ðµ ¾ £ , which are

considered to be samples from a random field. The field is defined on

£ Êa discrete rectangular sampling lattice in ¾. Here we introduce

three random fields,
and × × Ð ´ Ðµ

¾

£

,

Ð ´ Ðµ ¾ £ , Ó
which correspond

to

Ó Ð ´ Ðµ ¾ £ ,
the displacement,

the occlusion, and the saturation. Although the displacement field

in our framework is similar to the conventional motion vector fields,

they differ in that we try to find a pixel with closest luminance but

motion estimation is not required. The occlusion is a binary random

field that indicates whether each pixel belongs to the occlusion. The
´random variable on each site Ðµ, Ó ¼ ½Ð takes or according to the

following rule,

ÓÐ

½ ¼

if Õ Ð is in occlusion
otherwise

´

Ðµ ¾ £

(4)

iTnhtehseaitmuraagtieonÕi.s

defined by the region of the underThis is also a binary random field

and that

over-exposure indicates the

saturation:

×Ð

½ ¼

if Õ Ð is under- or over-exposure
otherwise

´

Ðµ ¾ £

(5)

In our method, instead of Ó and ×, we estimate the complement variables Ó and ×, which have "0" in cases of occlusion and saturation, respectively
Since all of these three fields mostly consist of some regions of similar values, they can be considered as Markov Random Fields (MRF). Our estimation problem is to find most likely fields , Ó,

´ µÌ Íwhere , are normalization constants, and ¡ is an energy func-
tion. Then the MAP estimation can be replaced by the minimization problem of the energy function. From (7) and (8), we can formulate the problem,
Ñ Ò Í´ Ô Ó × Õµ · Í´ Ó × Õµ · Í´Ó × Õµ · Í´× Õµ Ó× (9)

2.3. Formulation of Energy Functions
Í ´ Ð Ð µTpcisaihxsdÓeeeel,fit×seinnirnemacdÔnebdstyheneÕtÔshdiegtiiifvvf½eeeÓrlnoye.rn×acIf¾enfeÕiemcnrtrsopionsitrxth(beec9lea)qtvswueacaslehuleaisetnruysacbcoohtlffeoarctihsÕkzese[a9sfini]ndnt-h[ai1eltÕs3Hia]cm,DnodtarRhrgeeIesÔwfp.uohÔnInincldwetoiiionautngnhr
accurate motion estimation is not necessary, we use the minimum value of the difference,

´ Ðµ ´Ñ ÒÑµ¾ÒÆ½ Ð Õ Ð   ÔÑ Ò

(10)

´ £µ ´ µÐwhere
sumes

Æ½Ð ¾
that the

is pixel

tÕheÐ

neighborhood of and its corresponding

.diTshpelaacbeodvpeixeerrloirnasÔ-

ideally coincides. In the occlusion, however, it is not the case. Fur-

thermore, since the value of the luminance can not be estimated in

the area of the saturation, the assumption does not hold. Considering

these, we define the energy function,

Í´ Ô Ð Ð Ó Ð × Ð Õ Ðµ Ó Ð ¡ × Ð ¡ ´ Ðµ (11)

This equation excludes the occlusion and the saturation from the cost function.
The second term of (9) is a cost imposed on the displacement vectors . Since the displacement generally occurs due to object movements, the displacement vectors should be smooth. As in the conventional methods [9], [10], we define the energy function as follows

Í´ Ð Ó Ð × Ð Õ Ðµ Ó Ð ¡ × Ð

Ð   Ñ Ò ¾ (12)

´Ñ Òµ¾Æ¾ Ð

The third and forth terms in (9) are constraints on the area of Ó and ×. Since the occlusion mainly depends on objects, we impose penalty on the isolated small regions by

Í´Ó Ð × Ð Õ Ðµ × Ð ¡ Î ´ ´Ó Ðµ   µ

(13)

´ µ ½where ¡ is an operator that counts the number of the value " " in Î ´ µthe eight adjacent pixels, ¡ is the potential function that has the
minimum value at 0. The saturated area has the value of either 0 or 255. Again the isolated small regions are penalized as

Í´× Ð Õ Ðµ Î ´ ´× Ðµ   µ ¡ Æ´ Õ Ðµ

(14)

where Æ is

Æ´Üµ

¼ if Ü ¼ or ¾ ½ otherwise

(15)

From (9), (10), (11), (13), and (14), the energy function to minimize is defined as

Í´ Ó × Ô Õµ Ó Ð ¡ × Ð ¡ ´ Ðµ
´ Ðµ¾£

·Û½ Ó Ð ¡ × Ð ¡

Ð  Ð ¾

´ Ðµ¾£

´Ñ Òµ¾Æ¾ Ð

·Û¾ × Ð ¡ Î ´Ó Ðµ  

´ Ðµ¾£

·Û¿ Î
´ Ðµ¾£

´× Ðµ  

¡ Æ´ Õ Ðµ

(16)

Ûwhere are weights.

2.4. Suboptimal Search
The problem to minimize (16) is difficult to solve due to its nonlinearity. To address the difficulty, some relaxation algorithms have been proposed such as simulated annealing [8] and the mean field theory [11], [12], [14]. The former has high computational complexity. The latter can relieve the complexity but it is not straightforward to apply it to our problem. In our method, instead, we adopt a suboptimal approach similar to [10].
In our search, first we find × by deterministic thresholding. Then using the given realization of ×, the displacement vectors and the complement of the occlusion Ó are estimated by an iterative fashion. The algorithm is stated as follows.

[Estimation Algorithm]

1. Search the pixels that have small values in the forth term of
×(16), then set them Ð ½.

2. The initial displacement vectors are found by searching the

¼ ´ µÓ Ðpixel with closest pixel value in the window Æ ½ Ð, and set

Ð if the value at the site

is above a pre-scribed

½Óthreshold, otherwise set Ð .

3. For each pixel Õ Ð, search the corresponding pixel with the

minimum values in the energy function (16), and then the pix-

els with high values in (16) are set as the occlusion, that is,
Ó Ð ¼.

4. If Í ´

Ó

× Ô Õµ Í  ½´

 Í
Ó×

 ½
Ô

´

Õ

Ó
µ

×

Ô

Õµ

¯ holds, then

stop (where is the number of iterations). Otherwise go to

Step 3.

2.5. Post Processing

Using the above algorithm, we can determine the regions of the occlusion and the saturation and obtain the displacement vectors except in these area. Next it is necessary to combine the images using the
oiwnÕfhf,oetÕrrhmeiesauaÔtnlisohdonae.sur-Dnlaodunweedre-treooxvespxeporpa-soceusxerupelrioemisnutihtraÔaetn.iaoWrneÕ,h.ihenTenvhreeurÔsswehtelahysectohruneingasdhitdeeederr-reeionxxnpptlhooyessuutfhrroeeelltcaoharwaesnea-
ing algorithm. In the occlusion, we simply search the closest value within the
window in Ô for each pixel in Õ, and then set it as the corresponding
pixel, while in the over-exposure region we do not compensate the motion. In the estimation of Sec. 2.4, we independently determine the saturation and the occlusion. However since in the saturation region, there can also be occlusion (like the dark grey region in the right image of Fig.1), we need to find the occlusion in the saturation. We solve the problem by a thresholding method as follows. Since we assume that we shoot the multiple exposure images with changing
Äonly the shutter speed, from (1) the amounts of light of the two
images at some pixel are rewritten by

ÄÔ ´Ø   ¡Øµ ÄÕ Ø ´ contantµ (17)

½¯ ÄSuppose that the dynamic range of the sensor is

. Then if Õ is

larger than 1 (that is over-exposure), its measured value is saturated

to 1. Thus, the actual value for satisfies

½ Ø (18)

Substituting this to the first equation in (17), we obtain
ÄÔ ½   ¡Ø Ø

(19)

From these we set the pixels satisfying (19) as the saturation, those
less than ½   ¡Ø Ø as the occlusion.

3. EXPERIMENTAL RESULTS
In the experiment, we shot five photos by changing shutter speeds, some of which are shown in Fig.2 and use them as an input of our algorithm. We select a main image from those, we apply the methods in Sec.2.4 and 2.5 to each pair of the main and an other image. And then the modified images are merged by (3). The dynamic range of
¾the map is about ¡ ½¼ . Fig.3 depicts the HDRI constructed by our method (for displaying, its dynamic range is scaled and then compressed by a tone mapping). In the set of input images, the face moves in the dark area, while his left elbow moves from bright region of the sky to dark region of the pole. It can be seen from Fig.3 that our algorithm reconstructs the irradiance well and successfully removes the blur caused by these motions. In Fig.4, we show some comparisons with three conventional methods: (1) block matching algorithm , (2) HDR Video [5] with Lukas-Kanade's optical flow estimation [15], (3) Ghost removal in [1]. We implement (1) and (2) using OpenCV and are used in subtitution for the method in Sec2.4 . Other processing such as in Sec.2.5 are unchanged. And if the motion vectors

¼are unreliable, they are set to for the pixels (note that we have
confirmed that large error occured when simply applying the methods without these treatments). The results of (3) are obtained using the software [16]. These conventional methods often fail to compensate the motion due to the saturations and the noises described in Sec.1. The block matching based algorithm often yields blocking artifacts and is sensitive to luminance change caused by an inaccurate calibration of the camera response curve. The method in [5] fails especially for under-exposure regions since the offset noises significantly affect the performance. We have tested some other examples and confirmed that our method performs best for all the tests.
4. CONCLUSION We propose the method for the HDRI acquisition. The proposed method can compensate the effects of the motion, occlusion and the saturation and can obtain motion blur free HDRIs.

[13] A.G. Bors, I. Pitas, "Optical flow estimation and moving object segmentation based onmedian radial basis function network", IEEE Transactions on Image Processing, Vol. 7, Issue 5, pp.693 - 702, May 1998
[14] Q. Liu, R.J. Sclabassi, C.C. Li and M. Sun, "An application of MAPMRF to change detection in image sequence based on mean field theory", EURASIP Journal on Applied Signal Processing, 13, pp. 19561968, 2005.
[15] B.D. Lucas, and T. Kanade, "An iterative image registration technique with an application in stereo vision," Seventh International Joint Conference on Artificial Intelligence, 674-679, 1981.
[16] http://www.anyhere.com/

5. REFERENCES
[1] E. Reinhard, S. Pattanaik, G. Ward and P. Debevec, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting (Morgan Kaufmann Series in Computer Graphics and Geometric Modeling), Morgan Kaufmann Publisher 2005.
[2] S. Mann and R. Picard", "On being 'undigital' with digital cameras: Extending dynamic range by combining differently exposed pictures", In Proceedings of IS&T 46th annual conference (May 1995), pp. 422­428. 1995
[3] P.E. Debevec and J. Malik. Recovering High Dynamic Range Radiance Maps from Photographs, Proceedings of SIGGRAPH 97, Computer Graphics Proceedings, pp. 369-378 .
[4] T. Mitsunaga, and S. K. Nayer,"Radiometric Self Calibration," IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Vol.1, pp.374-380, Jun, 1999.
[5] S. B. Kang, M. Uyttendaele, S. Winder, R. Szaliski, "High Dynamic Range Video", ACM Transactions on Graphics, Volume 22, Issue 3 pp. 319 - 325, 2003.
[6] E.A. Khan, A.O. Akyuz, E. Reinhard, "Ghost Removal In High Dynamic Range Images", IEEE International Conference on Image Processing, pp.2005-2008, Oct 2006.
[7] X. Liu and A. El Gamal, "Synthesis of High Dynamic Range Motion Blur Free Image from Multiple Captures," IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications, Vol. 50, No. 4, pp. 530-539, April 2003.
[8] S. Geman and D. Geman, "Stochastic Relaxation, Gibbs Distributions and the Bayesian Restoration of Images," IEEE Transaction on Pattern Analysis and Machine Intelligence, Vol.6, No.6, pp.721-741, 1984.
[9] J. Konrad and E. Dubois, "Bayesian Estimation Of Motion Vector Fields", IEEE Trans. on Pattern Analysis and Machine Intelligence, Vol.14, pp.910-927, 1992.
[10] W. Woo and A. Ortega, "Stereo Image Compression with Disparity Compensation using the MRF Model," in Visual Communications and Image Processing (VCIP '96), vol. 2727 of Proceedings of SPIE, pp. 28-41, Orlando, Fla, USA, March 1996.
[11] J. Zhang and G.G. Hanauer, "The Application of Mean Field Theory to Image Motion Estimation," IEEE Transaction on Image Processing, Vol.4, No.1, pp.19-33, 1995
[12] Jie Wei Ze-Nian Li, "An efficient two-pass MAP-MRF algorithm for motion estimation basedon mean field theory", IEEE Transactions on Circuits and Systems for Video Technology, Vol.9, Issue 6 pp.960972, Sep 1999

Fig. 2. some samples of multiple exposure images Fig. 3. Our result (it is tone mapped to displayable range)
Fig. 4. Motion blur in dark region (from upper left to lower right) Our method, Block matching, HDR video [5], Ghost removal [1]

