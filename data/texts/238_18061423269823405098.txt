From: AAAI-94 Proceedings. Copyright © 1994, AAAI (www.aaai.org). All rights reserved. 

CHATTERBOTS, TINYMUDS, and  the Turing  Test 

Entering  the Loebner  Prize  Competition 

Michael  L. Mauldin 

Carnegie  Mellon  University  Center  for  Machine  Translation 

5000  Forbes  Avenue 

Pittsburgh,  PA  15213-3890 

fuzzy @cmu.edu 

Abstract 

test.  Annual  competitions 

The  Turing  Test  was  proposed  by  Alan  Turing  in  1950;  he 
called  it the  Imitation  Game.  In  1991 Hu 
h Loebner  started  the 
Loebner  prize  competition,  offering  a  f 
100,000  prize  to  the 
author  of  the  first  computer  program 
to  pass  an  unrestricted 
Turing 
are  held  each  year  with 
smaller  prizes  for  the  best  program  on  a restricted  Turing  test. 
This  paper  describes 
of  one  such  Turing 
System,  including 
the  technical  design  of  the  program  and  its 
performance  on  the  first  three  Loebner  Prize  competitions.  We 
also  discuss  the  program’s  four  year  development  effort,  which 
has  depended  heavily  on  constant 
interaction  with  people  on 
the  Internet  via  Tinymuds  (multiuser  network  communication 
servers).  Finally,  we  discuss  the  design  of  the  Loebner  com- 
petition 
the 
development  of  Artificial  Intelligence. 

itself,  and  address 

the  development 

its  usefulness 

in  furthering 

Introduction 

that  by 

for  the  question,  “Can  machines 

the  Imitation  Game  as  a 
In  1950,  Alan  Turing  proposed 
think?”  He 
replacement 
predicted 
progress 
would  produce  computing  machines  with  a capacity  of  log 
a  computer  program 
bits,  and  that  with  such  machinery, 
would  be  able  to  fool  the  average  questioner 
for  5  minutes 
about  70%  of the  time  (Turing,  1950). 

the  year  2000 

technological 

and  the  Sloan  Foundation 

In  1991,  Dr.  Hugh  Loebner, 

the  National  Science 
started  the  Loebner 
Foundation, 
an  annual  contest  between  computer 
Prize  Competition: 
the  most  “human’~  programs,  and 
to  identify 
programs 
to  the  program 
that  first 
eventually 
to  award  $100,000 
passes  an  unrestricted  Turing 
test  (Epstein,  1992).  This 
competition  has  been  criticized  as  a  parlor  game,  reward- 
ing  tricks  rather  than  furthering 
the  field  of  Artificial  Intel- 
ligence  (Shieber,  1992). 

In  this  paper,  we  discuss  our  own  entry  in  the  Loebner 
competition, 
including  a description  of  our  own  tricks,  and 
describe  how  techniques  and  methods  from  AI  are  used  to 
go  beyond 
tricks.  One  of  our  goals  is  to  encourage  more 
participation 
in  the  Loebner  Com- 
petition. 

by  the  AI  community 

History 

ELIZA  program 

the  imitation  game, 
Fifteen  years  after  Turing  proposed 
Weizenbaum’s 
that  “a 
simple  computer  program”  could  successfully  play  the  im- 
the  most  im- 
itation  game  by  resorting 
portant  being  to  answer  questions  with  questions 
(Weizen- 
baum,  1976). 

to  a  few  “tricks,” 

demonstrated 

ELIZA  sparked 

researchers,  but 
perhaps 
result  was  Colby’s  work  on 
PARRY (Colby,  1975).  Criticism  of  ELIZA as  a  model  for 

the  interest  of  many 

the  most  interesting 

16 

The  Arts 

that 

scientists 

influenced 

and  computer 

lack  of  an  internal  world 
AI  focused  on  the  program’s 
the  conversation. 
tracked 
model 
and 
its  own 
PARRY simulates  paranoid  behavior  by  tracking 
state  on  a  few  different  dimensions. 
internal  emotional 
Colby  subjected  PARRY to  blind 
tests  with  doctors  ques- 
tioning  both  the  program  and  three  human  patients  diag- 
Reviews  of  the  transcripts  by  both 
nosed  as  paranoid. 
that  neither 
psychiatrists 
group  did  better  than  chance  in  distinguishing 
the  computer 
from  human  patients. 
Often  overlooked 

is  Colby’s  comparison  of  PARRY’s 
and  human  dialogs  with  RANDOM-PARRY. He  showed  that 
merely  choosing 
the 
as  well  as  standard  PARRY. 
human  patients’ 
its  judges  because 
Shieber  argues 
responses  or  non 
paranoid  behavior  makes 
sequiturs  appropriate.  But  there  is  still  a  certain 
logic  to 
them  that  PARRY simulates  effectively. 
to 
It  is  simpler 
simulate  paranoid  behavior,  perhaps,  but  it  is no& trivial. 

responses  at  random  did  not  model 
responses 
that  PARRY  fooled 

inappropriate 

showed 

In  our  view,  PARRY is  an  advance  over  ELIZA because 
therapist  strives  to 
and 

PARRY has  a personality.  The  Rogerian 
eliminate 
ELIZA therefore  succeeds  without  one. 

all  traces  of  his  or  her  own  personality, 

See  (Rheingold, 

TINYMUD 
In  August  1989,  Jim  Aspnes  opened  TINYMUD, an  elegant 
reimplementation 
of  Richard  Bartle’s  multiuser  dungeon 
(MUD). 
1991)  for  more  details.  Key 
features  of TINYMUD include: 
0 multiplayer  conversation, 
0 textual  “scenery” 
0 user  extensibility. 
This  last  feature,  the  ability  of  players 
subareas  within 
made  TINYMUD very  popular. 

the  world  model,  was  a  key  feature 

to  create  their  own 
that 

simulating  physical  spaces, 

TINYMUD  provided  a  world 

by  typing.  This  seemed 
the  Turing 
for  work  on 

filled  with  people  who 
to  us  to  be  a  ripe 
communicate 
opportunity 
it 
provided  a  large  pool  of  potential  judges  and  interviewees. 
are  called 
In  TINYMUD,  computer 
robots  were 
“hots,” 
created,  and  even  ELIZA  was  connected 
to  one  stationary 
robot  (if  a  player  went  alone  into  a  certain  cave,  he  could 
chat  with  ELIZA). 

controlled 
for  robots.  Many 

players 
simple 

test,  because 

short 

that  can  converse  with  other  players,  explore 

We  created  a  computer  controlled  player,  a  “Chatter 
the 
rooms, 
(providing 
on  request),  and  answer  ques- 
It  can  even 

Bot,” 
world,  discover  new  paths 
answer  players’  questions 
shortest-path 
tions  about  other  players,  rooms  and  objects. 

through 
about  navigation 

the  various 

information 

in  a  multi-player 

join 
many  rounds,  “shooting 
conversational 

The 

card  game  of  “Hearts” 

It  has  won 

the  moon  ”  on  several  occasions. 

abilities  were 

im- 
plemented  as  simple  IF-THEN-ELSE 
rules,  based  on  pat- 
tern  matching  with  variable  assignment.  Most  patterns 
have  multiple  outputs 
in  a  random,  non- 
repeating  sequence 

to  handle  repeated  questions. 

that  are  presented 

originally 

appropriate 

A  primary  goal  of  this  effort  was  to  build  a  conver- 
sational  agent  that  would  answer  questions, 
instead  of  ig- 
noring  them,  and  that  would  be  able  to  maintain  a sequence 
on 
of 
non-sequiturs.  We 
the 
responses,  and  succeeded 
in  making  an  agent  more  inter- 
esting  than  ELIZA;  Wired  magazine  described  our  program 
as  “...a  hockey-loving 
ex-librarian  with  an  attitude.” 
(Wired,  1993). 

relying 
included  a  lot  of  humor  among 

responses, 

instead 

of 

The  CHATTERBOT succeeds  in  the  TINYMUD world  be- 
that  the 
is  a  person,  and  will 
it 

cause  it  is  an  unsuspecting  Turing  test,  meaning 
players  assume  everyone  else  playing 
give 
makes  a major  gaffe. 

the  CHATR%BOT  the  benefit  of  the  doubt  until 

The  Loebner  Prize 
the  framework  of  the  robot  was  mature,  and 
By  mid-1991 
the  conversational 
work  was  concentrated 
the  first  Loebner  competition  was  an- 
component.  When 
nounced 
the 
robot’s  sessions  on  TINYMUD.  The  program  qualified  for 
entry,  and  placed  third  of  six  programs 
in  the  first  competi- 
tion,  ranked  above  a human  by  one  of the  10 judges. 

that  same  year,  we  submitted 

on  improving 

logs  from 

The  final  round  of  competition  was  smaller  in  1992  and 
1993,  down  to  three  computer  programs  from  six,  and  the 
same  three  programs  have  finished  first,  second,  and  third 
In  1992,  we  chose  hockey  as  a  domain  for 
all  three  years. 
finished  dead  last,  partly  be- 
discourse,  and  the  program 
cause  of  a  lack  of  hockey  fans  among 
the  judges  (leading 
The  conversational  model 
to  more  difficult  questions). 
was  expanded 
include 
of 
tree-shaped 
input/output 
the  opening  book  of  a 
patterns,  much 
chess  program,  but  the  mismatch  of  expectation  between 
the  program  and  the  judges  was  so  great  that  very  few 
conversations 

followed  the  expected  lines  of  questioning. 

network 

a 
like 

to 

For  1993,  we  chose  a  more  universal 

topics,  “Pets,” 
on  the  premise  that  everyone  has  had  a pet  at  some  time  in 
their  life.  The  tree-based  model  was  scrapped 
in  favor  of 
that  was  less  rigid  and  allowed  the 
an  activation  network 
the  judge’s 
program 
input  and 
still 
third  of  three,  it  was  no  longer  dead  last:  two  of 
finished 
eight  judges  ranked 
than  the  second  place 
it  more  human 
program,  and  a  third  judge  ranked 
it  above  the  first  place 
program. 

its  own  output.  Although 

to  make  more  associations 

the  program 

between 

Two  other  computer  programs  qualified 

for  the  final 
the  first  place  entry  discussed  “Liberal  or  Conser- 
tried  to  help  people 

round; 
vative,”  and  the  second  place  program 
discuss  “Bad  Marriage.” 
Liberal  or  Conservative.  The  winning  entry  was  written 
by  Joseph  Weintraub  of  Thinking  Softwure,  and  was  based 
on  his  PC  Therapist  program. 

J:  What  would  you  say  is  a  liberal  position 

on  drugs? 

C:  Do  you  have  liberal  or  conservative  views 

about  the  legalization  of  pot?  Oh,  all 
this  typing  is  getting  to  meI  Please 
continue..  . 

J: 

C: 

implies 

Being  liberal  or  coneenmtive 
that  we  can  attach  these  labels  and 
have  some  kind  of  self  image  and free 
Do  you  agree that  we  have  free 
will. 
will? 
YOU  have  free  will  only  if  you  believe 
you  have  free  will1  Can  you  converse 
with  an  arrdvaark?  Pleaee  continue... 

Weintraub’s  program  won  the  first  competition  using 
Even  though  the 
the topic of  “Whimsical  Conversation.” 
topics  he  has  chosen  for  the  two  following  years  are  more 
serious,  the  program  retains  a comedic  flavor,  and  humor  is 
the  program’s  main  strength. 
Bad  Marriage.  The  second  place  program  was  written  by 
Peter  and  Ken  Colby  of  Malibu  Artifactual 
Intelligence 
Works,  based  on  a conversational  program  they  sell. 

J:  my  husband  is  inumtent  and  im  a 

nymphomaniac  can  you  help  me  dot? 

C:  what  makes  your husband  so  helplese? 
J:  he  has  environmental  poisoning 
C:  He  has  lost  interest  in  life. 
Although  Ken  Colby  was  PARRY’S author,  this  program 
from  a 
for 
It  is  rule-based,  with  the  left-hand  side 
in  the  user  input  string,  and 
side  containing  multiple  options  for  substr- 
lexical 

is  not  a  variant  of  PARRY.  Instead 
program 
depressed  patients. 
matching  concepts  expressed 
the  right-hand 
ings,  which  are  instantiated 
variation. 

that  serves  as  a  conversational 

is  is  derived 

to  provide 

companion 

randomly 

A  CWA'TTERBOT is  a  robot  TINYMUD player  whose  main 
service  is  chattering.  When  few  players  are  logged  into  the 
game,  some  people  find  talking  to  a  robot  better  than  talk- 

Figure  1:  CHA~RBOT  Configured 

for TINYMUD 

Architecture 
The  CHATTERBOT is  implemented 
as  a  C  program  with 
several  different  modules  for  dealing  with  the  various  func- 
tions  required  to automate  a player  in  the  TINYMUD world: 
Q) communications,  handles  the  TCP/IP  connections. 
e protocol  interpreter,  decodes  game  related  messages. 
8 world  model,  tracks 

rooms  and  objects, 
the  world  as  a  directed  graph,  and  providing 

the  various 

modeling 
shortest  path  searches  as needed. 

e player  memory,  tracks  the  other  players  and  records  up 

to 2000  bytes  of  their  most  recent  utterances. 

e exploration  module,  directs  an  open-ended  exploration 

of the  world  when  the  robot  is not  conversing. 
e conversation  module,  provides  the  “chatter.” 

Believable Agents 

17 

The 

in  which 

to  talk  with 

it  simulates  human 

Figure  1  shows  the  CHATTERBOT configured 

for  play 
on  a  TINYMUD.  Records  of  other  players’  appearances, 
rooms  within 
the  MUD,  and  other  players’  utterances  are 
kept  in  long  term  (world)  memory.  The  CHA-ITERBOT also 
has  a  contest  mode, 
typing 
the  program  does  not 
using  a  Markov  model.  Because 
expect 
the  same  judge  again,  no  long  term 
world  model  is kept  in  contest  mode. 
is 

a 
prioritized 
each  an  ordered  collection 
of  input  patterns  coupled  with  a  set  of  multiple  possible 
responses. 
0 command  patterns  are 
represent  direct  commands 
include 
challenges, 
word?,  ”  to  prevent  other  players 
mands  to quit  the  game. 

These 
from  the  robot’s  owner,  and 
the  code 
“What’s 
from  spoofing  com- 

conversation 
module 
layer  of  mini-experts, 

the  highest  priority. 

hand-shaking 

implemented 

as 

0 hi  priority  responses  include  common  queries 

that  the 
keyword  patterns  handle  well,  “How  do I  get from  the 
Town  Square  to  the  Library  Desk?  * ’ 

0 activation  network 

topic 
oriented  responses;  weights  on  the  nodes  of  the  network 
encode 
the  user  and 
program  have  said. 

the  bulk  of 

about  what 

information 

includes 

state 

the 

e lo  priority  responses 

include  a  series  of  patterns 

for 
common  sense  things  the  robot  should  know  about  itself, 
“Where  do  you  live?”  “What’s  2  times  23?”  “What 
color  is  your  hair?,  ”  that  have  been  collected  over  4 
years  of  interaction  on  TINYMUD. 

0 sorry  responses  are  the  typical 

that 
are  used  when  no  input  pattern  matches.  As  a debugging 
aid,  any  input  that  generates  a  “Go  on,”  “So?”  or  “I’ll 
remember  that”  response 

is  logged  in  a separate  file. 

last  ditch  responses 

Activation-based  Responses 
The  bulk  of  the  topic-oriented 
responses  are  encoded  in  an 
activation  network,  partially  shown  in  Figure  2.  Details  of 
the  starting  node  and  two  subnodes  are  shown  in  Figure  3; 
each  node  has  5 attributes: 

ACTIVATION(a) 

PA-lTERNS(p) 

RESPONSE(r) 

ENHANCEMENT 

INHIBITION(-) 

each  node  starts  with  an  initial  activa- 
tion  level  between  0.0  and  1.0. 

one  or  more  patterns  (with  weights)  are 
the  user  input. 
matched  against 
If  the 
pattern  succeeds, 
the  activation  of  the 
node  is raised  by  that  amount. 

a  single  text  string  used  as the  response 
if  this  node  has  the  highest  activation. 

(+)  if  this  node  is  used  for  a  response, 
named  nodes  have  their  activation 
creased. 

if  this  node  is  used  for  a  response, 
named  nodes  have  their  activation 
hibited. 

the 
in- 

the 
in- 

These  figures  show  a  small  portion  of  the  pet  domain 
network.  Additional  world  knowledge 
in  the 
ontology  used  during  pattern  matching.  The  program  has  a 
typical 
to  match  just 
DOG,BIRJJ,PET,WILD,OrANIMAL, 

that  allows  a  pattern 

type  hierarchy 

fOreXample. 

is  encoded 

18 

The  Arts 

re 2:  Portion  of conversational 

network 

<havepet> 
a:l.O 
p:l  * 
~:DO  you  have  any  pets? 
+:<havepet-1s  <havepet-2*  <haveget-3s  . . . 

*havepet-1s 
a:O.l 
p:l  NE0 
r:Why not? 
+:<havepet-l-1, 
-:<havepet-9,  &d-46, 

thaveget-l-2> 

<have-t-l-1, 
a:0.02 
p:2  *apartment* 
p:3  *allerg* 
r:You  could  still  have  a  flab  tank,  or 

maybe  a  terrarium  with  a  turtle  or two. 

-:<havepet-9> 

Figure 3:  Sample  conversational 

nodes 

Given  a  sufficiently 

large  network  of  conversational 

nodes  (our  program  ran  with  224  nodes,  plus  529  fixed 
responses), 
to  a retrieval 
problem:  among  the  things  that  I  could  say,  what  should  I 
say? 

the  conversation  problem  reduces 

birds, 

if  the  user 

For  example, 

input  mentions 

the 
response  strings  are  searched  for  matches 
to  birds,  includ- 
ing  parrots,  canaries,  etc.,  and  those  nodes  have  their  ac- 
tivation 
level  raised.  The  code  was  borrowed  from  one  of 
our  information 
By  encoding 

about  the  user  in  the  activa- 
tion  levels,  the  program  tracks  the  judge’s  responses.  For 
example, 
to  the  question 
about  whether  he  has  pets,  the  other  nodes  that  ask  about 
pets  are  inhibited. 

retrieval  engines. 
information 

if  the  judge  answers  negatively 

Tricks 

the  Loebner  competition 

Shieber  has  criticized 
as  reward- 
ing  tricks  (Shieber,  1992).  This  sort  of  qualitative  assess- 
is  exactly  what  the  Turing 
ment  of programmed  knowledge 
test  is  supposed 
the  question  “Can 
machines 

test. 
some  of  the  better 
tricks,  confident 
that  when  someday  a  com- 
puter  program  does  pass  the  Turing  test,  it will  use  many  of 
them,  for  the  simple  reason  that  people  already  use  them. 

replacing 
think?”  with  a performable 
describe 

Here  we  unashamedly 

in  the  belief 

to  avoid, 

but 

this 

fragment 

two  computers, 

Transcripts 
is  taken  from  the  1993  Loebner  Competi- 
This  transcript 
tion  (Epstein,  1993).  It  contains 
the  entire  record  of  Judge 
#4’s first  of  two  turns.  The  elapsed  time  is  about  9 minutes 
and  29  seconds.  This  judge  rated  the  program  behind  the 
other 
the 
longest  string  of  reasonable  responses  during 
the  competi- 
tion.  This  judge’s  low  score  is  most  likely  explained  by 
the  fact  that  during  his  second  turn,  the  program  repeated 
two  responses  verbatim,  and  completely 
several 
The  judge’s  questions  are  marked  “J” 
direct  questions. 
and  the  computer’s  responses  are  marked  “C.” 
DO you  know  anything  about  miniature 
schnauzers? 
I don't  know  anything  ahout  miniature 
schnauzers, Judge. 

represents 

ignored 

J: 

c: 

Admitting  Ignorance,  repeating  user input 

Tricks 

ELIa’s 
ELIzA's main  trick  was  to  use  questions 
to  draw  a conver- 
sation  out  of  the  user  himself,  with  little  or  no  actual  con- 
This  works  because  most 
tribution 
people 
to 
believe 
(Weizenbaum, 

like 
the  program 

To  quote  Weizenbaum 

and  are  happy 

to  talk  about 

the  program. 

is  listening. 

themselves, 

1976): 

from 

What  I  had  not  realized 
posures 
to  a  relatively 
could 
normal  people. 

induce  powerful  delusional 

is  that  extremely 
computer 
simple 
thinking 

short  ex- 
program 
in  quite 

The  illusion  of  listening 

is  fostered  by  including 

ings  of  the  user’s  input  in  the  program’s  output 

substr- 

Ueer  :  You  hate  me. 
Eliza:  Doe6  it  please  YOU  to  believe  that 

I hate  you? 

A  further  trick  is  the  use  of  the  Rogerian  mode,  which 
cover  for  the  computer.  Since  the 
it  cannot  con- 

provides  unimpeachable 
program  never  says  anything  declaratively, 
tradict  itself  later. 

PARRY'S Tricks 
PARRY has  a  much 
1975): 
0 admitting  ignorance,  unlike  ELIZA, PARRY can say  “I 

larger  collection 

of  tricks 

(Colby, 

don  ‘t know.  ”  in  response  to  a question. 

@ changing  the  level  of  the  conversation,  “Why  do  you 
the  sub- 

ask  that?,  ”  which  is  really  a  way  of  changing 
ject. 
0 rigidly  continuing  previous 

topic,  PARRY  includes 
these 

to  tell 

tries 

the  Mafia,  and 

small  stories  about 
stories  in  a  fixed  order. 

e introducing  new  topic,  launching 

into  a  new  story. 
This  simulates  paranoid  behavior  well,  but  can  also  work 
to a limited  extent  in  regular  conversation. 

These 

enhance 

fragments 

the  whole  conversation 

statements,  “People  don  ‘t own  cats...,  ”  are 

stored 
like  the  opening  book  of  a 
the 
of  the  program’s  own  responses,  and  if 
can  hang 

CHATTERBOT'S  Tricks 
The  CHATIERBOT  implements  all  of  the  above  tricks  from 
ELIZA and  PARRY.  It also  uses  several  other  tricks: 
e Having  many  fragments  of  directed  conversation 
in  activation  network,  much 
chess  playing  program. 
“connectedness” 
the  user  plays  along, 
together  for  a while. 
0 Controversial 
a  way  to  drag  the  user  into  the  program’s  conversation, 
rather  than  letting  the  user  direct  the  discourse. 
e Humorous 
statements,  “Guinea  pigs  are  about  as  smart 
as  cucumbers,  *’ also  make  the  program  seem  more  human. 
e Agreeing  with  the  user,  in  certain  cases,  the  program  can 
safely  agree  with  the  user  rather  than  being  non-committal. 
0 Excerpting  USENET  News,  many  of  the  fragments 
activation 
REC.PETS. Input  patterns  were  added  by  hand. 
realistic  delays  between 
8 Simulated 
characters,  we 
typing. 
Slowing  down  the  interaction  also  gives  the  program  fewer 
chances  to make  a big  mistake. 

in  the 
the  newsgroup 

the  rhythm  of  a  person 

network  were  gleaned 

typing,  by  including 

imitate 

from 

J: 

c: 

J: 

c: 

J: 

c: 

J: 
c: 

J: 

c: 

J: 

c: 

well,  I have  one.  We  call  him  Pucci.  He 
ie  a  crazy  cat--have  YOU  ever 
had  a  cat? 
What  a  coincidence1 

I have  two  cats 

direct  answer  to direct  question from  activation  net 

doge  myself. 

I prefer 
independent  and  they  always  jump  up  on 
things. 
By  the  way,  are  you  a  h8D  Cat? 
People  don't  own  cats...it's  the  other 
way around. 

Cat0  are too 

controversial  statement  with  expectedfollowups 

Soma  people  have  enakee  for  pets--  do 
you  think  they  can  be  of  any  value  as 
a  pet? 
I  think  cat  people  are  very  self-aeeured. 
Cata  are  very  independent,  but  they  can 
also  be  very  loving.  Dogs  are  juet  too 
eubeervient  and  quick  to  pleaee  for  my 
taste. 

rigidly following  up on previous  statement  about  cats, 
but reference  to snakes  increases  activation  of snake topic. 
Okay-  -  but  how  do  you  "pet"  a  snake? 
Wow,  that's  unuaual. 
make  owners. 

I don't  know  many 

snake  topic  activated  after  two  references 

All  they  do  ie  eit  in 

How  about  turtles? 
their  little  artificial  ponds, 
shit,  am  I  right? 
Turtle6  just  aren't  very  satisfying  a0 
D@btB. They  don't  seem  to  have  emotione. 

eat  and 

direct  response from  activation  network 

Ahal  But  where  do  we  draw  the  line  a6 
humana?  Who  are we  to  decide  which 
animala  have  worth  and  which  do  not? 
00  on. 

default,  non-committal  response,  given  no hot  topic  keywords 

J:  Take  bees  for  exarpgls.  I happen  to  like 

them. 

C:  He  too. 

TINYMUD  level  lo-priority  response  to user’s liking something 

By  our  rough  estimate,  7  of  these  8 replies  are  respon- 
the  last  2  are  somewhat  weak.  The  “self- 
sive,  although 
assured” 
reply  we judge  unresponsive.  A  similar  analysis 
of  the  entire  3  hour  log  showed  that  only  45  of  the  137 
(34%)  replies  were  responsive,  so  the  average  performance 
was  not  as  good  as  this  particular  dialog.  We  also  found 

Believable Agents 

19 

another  34  cases  (25%)  where  the  activation  network  did 
contain  a responsive 
reply  that  could  have  been  used  if  the 
input  patterns  were  more  complete. 

Simulating  Human  Typing 
the  first  Loebner  Prize  was 
One  observation  made  during 
to  simulate  human 
that  although  many  programs  attempted 
(Epstein,  1992).  Although 
typing,  most  failed  miserably 
our  first  program  did  attempt 
to  simulate  human 
typing, 
this  module  was  replaced  for  the  second  and  third  annual 
competitions. 
all  output  from 
programs  was  buffered,  but  even  so,  by  simulating  human 
typing  at  all  points,  we  obtain  realistic  delays 
in  the  ap 
pearance  of  the  response 
to  the  judge.  And  if  character- 
mode  is  used  in  future  competitions.  we  have  a  realistic 
model  available. 

In  the  last  two  competitions, 

The  basic  method 

logs  of  the  1991  competition 

is  to  use  a  Markov  model  of  the 
trigrams.  We  ob- 
intercharacter  delay  based  on  character 
tained  the  real-time 
from  the 
Cambridge  Center  for  Behavioral  Studies,  and  sampled  the 
record  of  judge  #lO  (chosen  because  he  was  the 
typing 
slowest 
typist  of  all  10  judges). 
The  average  delay  be- 
is  330  milliseconds,  with  a  standard 
tween  two  characters 
(these  values  were  computed 
deviation  of 490  milliseconds 
typed  by  that  judge  during 
from  a total  of  9,183  characters 
a  three  hour  period).  We  also  determined 
that  the  average 
last  output  and  the  judge’s 
delay  between 
first  typed  character  was  12.4  seconds  with  a  standard 
deviation  of  11.4  seconds. 

the  terminal’s 

Does  The  Loebner  Prize  Further  AI? 

that  the  current  work  on  the  Loebner 
We  strongly  believe 
the  passing  of  an  unrestricted 
competition  will  hasten 
test.  Any  such  program  will  have  to  be  more  than 
Turing 
just  a  general  problem  solver: 
some  of  its  knowledge  and 
tactics  will  be  based  on  long  experience  with  typed  com- 
munication  with  real  people.  The  best  two  examples  of 
typed  conversational 
today  are  network  com- 
(TINYMUD and  INTERNET Relay  Chat),  and 
munications 
the  Loebner  Prize,  and  only  the  Loebner  Prize  competition 
is  committed 
judges  and  a  double- 
blind  judging  scheme  to validate  the  results. 

to  providing  unbiased 

interaction 

A Restricted  Turing  Test 
Because  current  programs  are  a  long  way  from  passing  an 
unrestricted  Turing 
the  Loebner  prize  competition 
to  a  single 
allows  the  programme  r to  restrict  the  discussion 
domain.  But  this  can  be  problematic; 
for  example,  here 
Judge  #2  is  clearly 
to  avoid  talking  directly  about 
the  topic  of  “Pets:” 

trying 

test, 

J:  Have  you  ever  kept  a penthouae  pet? 
C:  Do  you  have  any  pets? 

J:  I  think  you're  avoiding  my  question. 
C:  Do  you  think  that  animals  can  think? 
J:  Do  you  think  it  ethical  for  one  species 

to  enslave  another? 

C: What kind8  of pet8  did  you  have  ae  a 

child? 

J:  I'm  asking  the  questions.  what  ia  a  pet 

if  it  ie  not  a  slave  of  epeciee-iem? 

C:  Oh,  that's  so  sad.  I  think  pets  enrich 

a  childhood  immneely. 

J:  How  can  we  keep  8ome  animals  a.8 pets, 

yet  eat  others? 

C:  Guinea  pigs  are  about  as  smart  a6 

cucumbers. 

Om6 

2SOm8 

5OOms 

Intercharacter  Delay in Milliseconds 

750 mo 

the  typing  simulator 

Figure 4:  Judge  #lo:  Intercharacter  delay  distribution 
After  the  response  has  been  generated  by  the  conver- 
sational  components, 
inserts  random 
errors  (1  in  68  characters),  such  as  mishits,  transpositions, 
insertions  and  deletions,  and  case  errors.  A  physical  model 
of  key  positions  on  the  standard  QWERTY  keyboard 
is 
used  to  generate  mishits.  After  the  error  is  inserted,  back- 
spaces  and  the  correct  letters  are  inserted  to  simulate  back- 
ing  up  to  correct  the  error  (5%  of  mistakes  are  left  uncor- 
these  probabilities  were  estimated  by 
rected). 
analyzing 

All  of 
the  log  of judge  #lo. 

Once  the  errorful  string  with  corrections 

is  generated,  it 
to  the  judge  one  character  at  a  time  with 
is  displayed 
the  characters.  The  delay  times  are 
random  delays  between 
generated  by  using 
the  smoothed  probability  distribution 
shown  in  Figure  4,  with  the  mean  and  standard  deviation 
modified  to match  the  trigram  statistics  (for  trigrams  with  3 
or  fewer  occurrences 
log,  bigram  or  single 
character  statistics  are  used). 

in  the  input 

20 

The  Arts 

similar  programs 

that  the  restriction 

We  do  not  believe 

the  test  in  any  important  way. 

to  a  domain 
weakens 
If  a  program  can 
pass  the  test  in  a  single  domain, 
then  50  or  100  groups 
making 
for  different  domains  would 
make  a  program  broad  enough 
the 
program  could  find  common  ground  for  a  discussion.  By 
taking  the  initiative, 
the  program  could  lead  the  judge  into 
an  area  of  its  own  expertise.  Neither  ELIZA  nor  PARRY 
restricted  their  users  to a single  domain. 

the  judge  and 

that 

Lastly  we  note  that  in  1995  the  Loebner  Competition 
test,  with  no  limits  on 

will  hold  its  first  unrestricted  Turing 
the  topics  discussed. 

Chosing  Judges 
term  in  Turing’s  description  of  the  imitation 
The  slipperiest 
The  1991  and  1992  com- 
game  is  “average  questioner.” 
the  general  public  using  a 
petitions 
from 
judges 
newspaper  classified  ad.  For  the  1993  competition, 
were  members  of  the  national  press. 
It’s  clear  from  the 
transcripts  and  scores  that  the  press  corps  are  a  much  less 
docile  and  cooperative  group  of questioners. 

chose  judges 

faced  by  our  program 

Another  unforeseen  difficulty 

in 
1993  was  that  each  judge  was  given  two  turns,  instead  of 
one  turn  as  in  the  first  two  competitions.  We  had  just 
weeks  before 
installed  code  to  detect  a  change  of  judges 
based  on  the  timing  of  the  input  (the  Colbys’  program  also 
used  timing  to  detect  new  judges).  When  a new  judge  was 

the  activation 

started  out  with  a  fresh  network. 

detected, 
that  each  judge 
greatly 
improves 
judge,  but  it  meant 
most  of  the  judges  had  one  or  more  responses 
Some  even  co mmmented  on  it  during  the  test: 
J:  What  is  your  favorite  dog  breed? 
c:  we  had  to  give  her  away.  We  only  had  a 

levels  of  the  nodes  were  reset  so 
This 
for  each 
their  second  conversations 
repeated. 

the  coherence  of  the  dialog 
that  during 

fifth  of an  acre of  land,  and  auseiee 
love  to  run. 

J:  You're  giving  me  the  exact  taame answers 
ie 

around. 

you  gave  me 
your  favorite  dog  breed? 

What 

time 

first 

long. 

In  effect, 

this  change 

Indeed,  by  asking 

in  the  methodology 

turns  what 
test  into  a 3 hour  long  test,  making  it 
had  been  a  15 minute 
for  the  program. 
Turing’s  original 
much  more  difficult 
the 
game  was  only  5  minutes 
final  rankings  after  they’ve  had  3  hours  of  inter- 
judges’ 
they  may 
action  with  a collection  of  people  and  computers, 
to  no  longer  qualify 
have  learned  enough  about  computers 
The  scores  would  probably  be 
as  average  questioners. 
quite  different 
if each  judge  spent  only  5 minutes  with  each 
program.  One  of  the  judges,  Judith  Gunther  of  Popular 
told  me  that  her  rankings  might  have 
Science  magazine, 
been  different 
if  she  had  been  asked  to  score  each  terminal 
immediately  after  each  conversation. 

reward 

tricks,  and 

the  winning  program 

Trick  or  AI? 
test  in  general  and  the  Loebner  prize  in  par- 
The  Turing 
ticular 
the  last 
three  years  clearly  has  some  good  tricks.  But  adding  real 
in  addition  to 
world  knowledge  and  deeper  understanding 
the  tricks  helped  our  program  perform  better  (we  credit  our 
between  1992  and  1993  in  part  to  the  ad- 
improvement 
dition  of 
of 
animals,  and  not  at  all  to  better  tricks). 
It  may  be  amazing 
how  far  a  program  can  get  on  tricks  alone,  but  our  current 
improvements 
the  world  and  the  con- 
versation,  and  that  will  be  our  focus  in  coming  competi- 
tions. 

come  from  modeling 

the  activation 

the  ontology 

network 

and 

But  suppose  that  simply  increasing 

the  size  of  ELIzA’s 

script  or  the  CHATIERBOT’S activation  net  could  achieve 
Turing’s  prediction  of  fooling  70%  of  average  questioners 
5  minutes.  After  all,  the  CHAITERBOT has already fooled 
in  the  TINYMUD domain  for  a  few 
“average”  questioners 
sufficed,  would 
minutes. 
“average 
ques- 
you 
tioner,”  or  “trick?” 

If  a  larger  collection  of  “tricks” 

intelligence,” 

“artificial 

redefine 

Conclusion 

test. 

This 

tension 

answering 

is  present 

Perhaps  the  biggest  obstacle  to  improvement 
in  this  area  is 
that  there  aren’t  very  many  uses  for  fooling  people  besides 
in  our  own 
the  Turing 
in  the  TINYMUD world,  the  robot  is  most  useful 
program: 
somewhat 
when 
computer-like 
services 
The  only  funded 
are  disabled  during  actual  competitions. 
is  for  entertain- 
research  we  know  of  in  Turing 
ment: 
fiction. 
In  such 
works,  the  reader  wishes 
to  be  fooled;  it  becomes  a  posi- 
tive  part  of  the  experience. 

fashion.  These  TINYMuD-specific 

agents  for  interactive 

providing 

questions 

systems 

stylized 

in 

a 

like 

We  would 

to  see  increased  participation 

in  the 
Loebner  Prize.  We  hope  by  dissecting  one  of  the  three  best 
programs 
to  spur  others  to  conclude  “I 
could  have  written  something  better  than  that!”  and  then 
do  so. 

in  the  competition 

Acknowledgments 

the  permission 

from  the  Loebner  Competition  were  used 
All  transcripts 
with 
for  Be- 
havioral  Studies,  675  Massachusetts  Avenue,  Cambridge, 
Mass.,  02139. 

of  the  Cambridge  Center 

in  part  by  the  Center 

This  work  was  supported 

for 
from  the  collaboration 
NIachine  Translation, 
and  inspiration  of  many  people, 
Jim  Aspnes, 
Joseph  Bates,  Stewart  Clamen,  Scott  Dickenshied,  Guy 
Jacobson,  Ben  Jackson,  Eric  Nyberg,  John  Ockerbloom, 
Russ  and  Jennifer  Smith,  Conrad  Wong,  and  Bennet  Yee. 

and  benefited 

including: 

More  Infomaation 
for  the  1994  competition 

The  entry  deadline 
is  November 
1.  Entrants  must  submit  up  to  10  double-spaced  pages  of 
logs  of  their  program  interacting  with  human  beings.  The 
Loebner  Prize  committee  will 
than  8 
finalists  from  the  submissions,  and  finalists  will  be  notified 
by  November  21.  The  competition 
itself  will  be  held  in 
real-time 
in  San  Diego  on  December  12,  1994.  To  obtain 
an  entry  form,  write  the  Cambridge  Center  at  the  above 
address. 

select  no  more 

To  converse  with 

Julia  yourself,  TELNET to  host 
FUZINE.MT.CS.CMIJ.EDU, 
and  enter  usemame  “julia”  with 
no  password.  Type  one  or  more  lines  of  English,  followed 
by  two  carriage  returns  to end  your  input. 

eferences 

Colby,  K.  Artificial  Paranoia:  A  Computer  Simulation  of 
Paranoid  Process.  Pergamon  Press,  New  York,  1975. 

Epstein,  R.  The  Quest  for  the Thinking  Computer.  AAAl 
Magazine  13(2):80-95,  Summer,  1992. 

in Artificial 
Epstein,  R.  1993 Loebner  Prize  Competition 
Intelligence:  OJicial  Transcripts  and  Results.  Technical 
Report,  Cambridge  Center  for  Behavioral  Studies,  Decem- 
ber,  1993. 

Rheingold,  H.  Virtual  Reality.  Summit  Books,  New  York, 
1991. 

Shieber,  S.  Lessons  from  a Restricted  Turing  Test.  Tech- 
nical  Report  TR-19-92,  Harvard  University,  Sept.,  1992. 
Revision  4. 

Turing,  A.M.  Computing  Machinery  and  Intelligence. 
Mind  54(236):433-460,  October,  1950. 

Weizenbaum, 
WI-I.  Freeman  and  Co.,  New  York,  1976. 

J.  Computer  Power  and  Human  Reason. 

Wired.  Wired  Magazine.  Louis  Rossetto,  San  Francisco, 
Dec.  1993. 

Believable  Agents 

21 

