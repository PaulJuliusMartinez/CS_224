From: AAAI-86 Proceedings. Copyright ©1986, AAAI (www.aaai.org). All rights reserved.
PRELIMINARY STEPS TOWARD THE AUTOMATION OF INDUCTION

Stuart J. Russell Department of Computer Science
Stanford University Stanford, CA 94305

ABSTRACT
Rational inductive behaviour is strongly influenced by existing knowledge of the world. This paper begins to elucidate the formal relationship between the base-level induction to be attempted, the direct evidence for it (positive and negative instances) and the indirect evidence (higher-level regularities in the world). By constructing a program to search the space of forms of higher-level regularity WC discover some important new forms which have direct application to analogy, singleinstance generalization and enumerative induction in general. We outline a theory which we hope is the first step towards the construction of powerful and robust learning systems. *
I INTRODUCTION
Ultimately, the source of all our knowledge of the world must be observation, either direct, communicated or inherited. One of the principal problems of philosophy has been to explain how this accumulation of observations can be used to fill in the gaps in our knowledge, particularly of the future. Without such an ability, rationality, which requires the prediction of the outcome of our actions, would be impossible. In AI, the problem is doubly acute: not only do we desire to understand the process for its own sake, but also without such an understanding we cannot build machines that learn. The basic answer to the problem is that we come to believe in some generally applicable rules (universals) by a process of induction from prior instances of their application; we then apply these rules in situations of incomplete knowledge using deduction. So far, so good. In AI, the two halves of the process correspond roughly to the division into the areas of machine learning and knowledge-based systems. Analogy, which seems at first sight to defy this classification, is shown in [Davies & Russell 861 to belong more to the deductive phase.
In this paper, our object is to make some progress towards a theory of induction which will prescribe, as far as is possible, the correct inductive behaviour for an intelligent system. As explained below, one essential element of this task is to explicate the way in which existing world knowledge affects a system's inductive acquisition of new knowledge. This need is pointed out in [Michalski 831. In order to explain how presentday intelligent systems (such as ourselves) have arrived at our degree of understanding of the world, given the fact that at the beginning of evolutionary history there was no existing knowledge, our theory must provide a formal relationship between
* This work was performed while the author was supported by a NATO studentship from the UK Science and Engineering Research Council, and by ONR contract N00014-81-K-0004. Computing support was provided by the SUMEX-AIM facility, under NIH grant RR-00785.

the system's existing knowledge and the universal to be induced; put simply, we seek a domain-independent theory. The basic problem to be solved is this: given a mass of ground facts

and no other domain knowledge, what can be inferred?

As mentioned earlier, we perform inductions on the ground

facts to obtain universals.

Enumerative induction is just

the simple process by which, from a collection of instances

. a, satisfying P(u,) and Q(ai), we induce the general rule

i&`(z)

+ Q(x)]. Th e search for a rationale for this induc-

tive step seems to be circular: we use it because it has always

worked, but the belief that this means it will work in the fu-

ture requires an inductive step. This is Hume's Problem of In-

duction, which, according to modern interpretation, he rightly

deemed to be inherently insoluble. If we could prove an enu-

merative induction to be valid, this would amount to prevision

of the future, a scientifically dubious concept.*

Intuitively, an enumerative induction is made more certain

by the discovery of further confirming instances as long as no

disconfirmation occurs. This model of induction is somewhat

different from the version space approach to concept learn-

ing ([Mitchell 78]), in which the generalizations produced are

justified by a linguistic bias which limits the set of allowable

generalizations so that if only one of the set is consistent with

the observations then it is assumed to be true. This means

that the number of confirming instances is ignored. Moreover,

the factual content of the linguistic bias is neither elucidated

nor motivated (but see [Utgoff 841); in this light it is hard to

view the version space approach as a form of inference. This

issue is also discussed in [Dietterich 861. The problem with

which we are concerned is not just the selection of an appro-

priate generalization for some data, but the assessment of its

probable truth; selection derives automatically from this if we

select the most probable generalization.

In particular, we wish to investigate why one generaliza-

tion may be given a great deal of credence, whilst another is

regarded very suspiciously, even though they both have the

same number of positive instances and no negative instances.

For example, consider the case of the traveller to Italy meeting

her first Italian. On hearing him speak Italian, she immedi-

ately concludes that all Italians speak Italian; yet on discov-

ering that his name is Giuseppe, she doesn't conclude that all

Italians are called Giuseppe. Clearly, the difference lies in the

traveller's prior knowledge of countries, languages and names.

Goodman's classic example of grue emeralds is another case

in point, which he used in [Goodman 461 to refute the early

claims of the confirmation theorists (Carnap and others) that

the probability of a proposition could be inferred from its in-

stances and syntactic form alone. In Goodman's example, we

* For, despite our best predictions, the whole world could be swallowed tomorrow by a giant intergalactic toad ([Hoppe]).

LEARNING / 477

are to evaluate the two inductions
1) All emeralds are green
2) All emeralds are grue
given that all the millions of emeralds observed to date are green, where grue means `green if observed before tomorrow, and blue if observed thereafter'. Both have the same overwhelming collection of positive instances, but the second seems somewhat undesirable. Goodman's answer to what became known as the `new riddle of induction' is that the rule must be projectible. We will return to the definition of projectibilitp in a later section. In spirit, his answer is the same as ours:
"\Yhile confirmation is indeed a relation between cvidence and hypotheses, this does not mean that our definition of this relation must refer to nothing other than such evidence and hypotheses. The fact is that whenever we set about determining the validity of a given projection from a given base, we have and use a good deal of other relevant knowledge." ([Goodman 8.31 pp.
845).
The object of this paper is to show what this knowledge consists of, and to show how it can be found and used to give additional confirmation to enumerative inductions. What we want is a theory which will be able to start with nny body of knowledge of any world (preferably in wff form), and say which inductions are reasonable and which aren't. We therefore require that the `other relevant knowledge' have a syntactic relationship to the evidence and inductive hypothesis, since otherwise the theory itself will be assuming something factual about the world, and hence will fail when applied to a world in which the factual assumption is false. In this, we strongly disagree with [Holland et al. 861, who say "In essence, our approach is
to deny the sufficiency of purely syntactic accounts . . . and to insist that sensible inferential rules take into account the kinds of things being reasoned about." We believe that such an approach simply begs the question of how such world-dependent rules could ultimately be acquired, except by some syntactic process; moreover, a physical system seems fundamentally incapable of performing anything but syntactic processes. Fortunately, in a formal system, logical entailment is a syntactic relationship (this is the fundamental achievement of the study of logic since Aristotle) and will play a large role in our theory.
If we are to build systems which observe an environment containing regularities and make use of them via the process of induction, we must be able to eliminate such spurious inductions as `all emeralds are grue'. It might be argued that Goodman is playing the sophist here; a philosopher might wish to know why emeralds are not considered grue, but the AI pragmatist might object that this is creating difficulties for the sake of it, and that we can avoid such problems in real systems just by not coining absurd, unmotivated concepts. However, an AI system needs to coin new terms (see? e.g., [Lenat 83a,83b], [Lenat et al. 791); not being endowed with common sense, an AI system is quite likely to generate terms as absurd as `grue', and thus we need a theory to guard against inductions using them and a theory to help avoid their generation. At a more basic level, we wish to avoid calling all Italians Giuseppe.

II HIGHER-LEVEL

REGULARITIES

The fundamental idea which we aim to expound and formalize is that an inductive generalization can be confirmed or disconfirmed, not only by the observation of its own instances or counter-examples, but also by the observation of

other, higher-level regularities in the world. Naturally, these regularities will be based on other instances and, in turn, on other regularities. The general idea is to bring our outside experience to bear on whether to accept a given rule. It is extremely rare for inductions to be performed in vucuo. In the case of the traveller in Italy, the generalization that all Italians speak Italian is supported by the more general regularity that, within any given country, most people tend to speak the same language; on the other hand, Giuseppe is not assumed to be the name of all Italians because of the higher-level regularity that almost all social groups use a variety of names. Assuming that emeralds are grue contradicts the general rule that
intrinsic properties of objects don't change, particularly not over a whole class and particularly not in response to some absolute time point (as opposed to a time point related to each individual). Some philosophers have objected to the use of such properties as grue in inductions on the grounds that they are intrinsically disjunctive ([Sanford 70]), not ostensively definable ([Salmon 74]), positional and non-qualitative ([Barker & Achinstein SO]) and epistemologically inferior ([Swinburne 731). But to the little-known species of bond-weevil that lives exclusively on unmatured, fixed-date, treasury bonds, properties such as `grue' will seem perfectly natural and useful. A theory of induction cannot, therefore, rest on `intrinsic' prop-
erties of the induced rule, but on its relation to the sum of our knowledge of the universe.

In this paper, we will concentrate on confirmatory, rather than disconfirmatory, regularities. Our proposal is that each such regularity corresponds to a universally quantified proposition which, if taken as literally true, would be sufficient to deductively imply the base-level generalization we are at-tempt-

ing, given its observed, positive instances. Furthermore, if the higher-level regularity is to provide additional confirmation, it

must have positive instances, preferably a large number, which

are not instances of the base-level rule. This is the external ev-

idence requirement. In a formal system, therefore, the higher-

level regularities have the desired syntactic relationship to the

base-level rule (see the discussion of the syntactic requirement

in the Introduction).

The higher-level regularities, in turn,

may be confirmed by regularities at a still higher level, until

ultimately we have to give in to the necessity to do simple

enumerative induction. In essence, therefore, we are trying

to bring deduction to the aid of induction as far as possible,

as a means of allowing our world knowledge to influence our inductive processes.
In the remainder of this paper, we describe the following steps in the process of building a theory of induction:
1) Construction of the space of possible classes of higherlevel regularities.
2) Searching the space for interesting classes. 3) Analyzing the results of the search. 4) Applying the results.

III CONSTRUCTING

THE SP.4CE OF

HIGHER-LEVEL

REGULARITIES

For any particular induction, we can often think of some higher-level rule, derived from our experience, which either confirms or denies it, as in the Italian case. In order to automate this process, we need to elucidate the formal relationship between the base-level and the general rule. We must also endeavour to identify all such classes of general rules, in order
that

178 / SCIENCE

1) We can take into account all the applicable higher-level rules already known.
2) We can perform further inductions to decide if a potentially relevant higher-level regularity actually holds.
As mentioned above, the higher-level rule; if literally true, should form part of a deductive argument, together with the base-level instances, leading to the affirmation of the base-level rule. Our approach is therefore to construct the space of all possible deductive arguments that lead to the base-level rule as their conclusion. The construction is schematic, i.e., we use generalized predicate schemata P and Q as antecedent and COII-
sequent, and the results we are looking for are thus schematic classes of regularities, such that when faced with the task of confirming a given induction, we can instantiate the schematic rule appropriately and use it for steps 1) and 2) given above.
In order to maintain completeness, we construct all resolution proofs of the base-level rule, given the instances. In describing how to do this, we will use rules with unary predicates, for simplicity. As we show below, this results in an overlyrestricted space of first-order regularities; this restriction is relieved by using binary predicates. The simplest schematic rule is Vz[P(x) =s- Q(z)]; we must find those sets of facts which, when combined with the instances and the negation of the rule, lead to a contradiction.
We thus begin with t,he negation of the rule, which, in clausal (CNF) form, is

Pb>
1QW

for some skolem constant a; we then ask what other facts could

be added to lead to a contradiction. To cut a long story short,

the only interesting fact we can add is the rule itself, written

+`(W

Q(5 > in CNF. Thus our task becomes that of find-

ing all sets of facts which can be resolved, together with the

instances, to leave the base-level rule as the only remaining

clause. Since a resolution step removes two complementary

literals: our reverse resolution algorithm takes as input the

current state of the database, then generates all possible new

pairs of complementary literals (and finds all possible existing

clauses to which they could be added), such that if the litcrals

were resolved the database would be left in the current state.

The literals we introduce can contain any existing predicate,

variable or constant, or include a new one of each (designated

R;, y;, b; respectively; we choose not to include function sym

bols in our language). * Thus two possible `parent' databases

of the database containing just the clause UP V Q(z) are

-(xc> v RI@)

and -I(YI) v +W v Q(d

-1(4 v Q(x)

h(h)

As one might suspect, the space is quite large (in fact, doubly exponential): the base-level database MY V Q(x) has 20 possible parents; at the second level the average database has around 350 parents. Although we will not discuss them here, our implementation therefore includes a number of pruning heuristics which keep the search manageable without losing any of the interesting points in the space. Another modification is to introduce the instances in a `macro-move': for the

* The exact details of the algorithm used are not important here; one can imagine constructing a simple PROLOG predicate resolve(Clause1, Clause,?, Clause) which suceeds iff Clause is the result of resolving Clause1 and Clause2; we then in\-okc the predicate with only the Clause argument instantiated.

itt" instance we add the literals P(c~i) and Q(a;) clauses, along with their complementary literals ot,her part,s of the dat,abase, all in one step.

as separate attached to

IV SFARCHING THE SPACE
So far we have given a somewhat simplistic picture of the space of regularities we have constructed. As soon as we start searching it, we realize that many of the regularity classes are simply not plausible; that is, they fail to correspond to any possible regularity in the actual world. Unfortunately, this is a hard condition for any machine with limited experience to recognize. For this reason, we currently use a human evaluator for nodes in the space, so that the machine follows paths that the author thinks promising. As a preliminary measure, this has been quite successful; however, to attain our goal of a worldindependent theory, and to explore more of the space, we also need to investigate how a machine can recognize that a given class of regularities is uncommon in the world of its experience. It is intended that such a capability be built into the prototype system we have constructed; for our world-knowledge, we will use the broad, common-sense knowledge base of the CYC project ([Lenat et al. 861). Inasmuch as this knowledge base corresponds to our actual world, this will also constitute empirical research into the actual structure of high-level commonsense knowledge.
It is important for our purposes that the causal structure of the world be such that there are really only a few important, classes of regularities. If this were not the case, then whenever we wished to confirm an induction it would be necessary to esamine a large amount of potentially relevant information, and to perform a large amount of cumulative detection to maintain
the currency of the stock of regularities. Our results so far indicate that there are grounds for optimism, at least in the real world.

V RESULTS

The following subsections describe the general classes of regularity which have been identified after searching the space, with the help of some additional thought. 1Ve start with the unary space to illustrate its restrictions, and then move to the binary space. In each section vve give the schematic, logical form of the regularity, display the deductive argument leading to the base-level rule, and give an example. Some of these classes were already known to us; others were quite unexpected (sections A and E), although perhaps obvious in retrospect. We are thus convinced of the usefulness of an automatic, (semi)exhaustive generator of classes of deductive arguments.

A. Rules with a more general left-hand side
The simplest class of higher-level regularities rules with the same consequent as the base-level weaker (more general) antecedent. Thus the rule

consists of rule but a

V'r[A(z) 3 Q(x)]

(where

Wf'(~> * RWI)

is sufficient to imply the base-level rule V.x[P(x) j Q(x)] di-

rectly.
Examples: a) .`All social groups use a variety of names" confirms

"All nations use a variety of names." llcre P = Nation, Q = ~YameT'ari~ty,

R = SocialGroup. b) "All things made of (a certain type of) beryl are green"

confirms

LEARNING !' 4")

"All emeralds are green."

Here P = Emerald, Q = Green,

R = MadeOfBeryl.
Because R is more general than P, the rule VZ[R(Z) =F Q(x)] can be confirmed by many instances which are not P; thus, if we have the appropriate data, it becomes easier to prove the more general rule than the more specific (base-level) rule.

This class of confirmation has two apparently distinct in-

terpretations.

On the one hand, a) is `empirical' in flavour:

by observing lots of other social groups, we add plausibility

to the base-level rule, but no explanation is offered. On the

other hand, b) is causal in flavour, offering the beginning of an

explanation. Two important points to note here:

a No observations of positive instances of the base-level

rule are required.

l The `explanation' type of support for the generalization is the starting-point for explanation-based generaliza-
tion [Mitchell et al. 861, which also has no logical need for an instance of the proposed generalization; we can extend the basic principle by adding further intermediary concepts, for example

where S is `reflects light of wavelength 550 nm'. The process of explanation-based generalization uses exactly
such a detailed, non-operational theory and compiles it into such useful encapsulations as "all emeralds are green " and "never run outside during an earthquake".

B. Decision rules
The only other simple regularity the unary space takes the form

we have found so far in

V~YPW A J=(Y) A Q(Y) * Q(41
which can also be written as
WW * Q(41 v WP(4 * ~QWI.
In [Davies 851 these are called decision rules, because P decides the truth of Q. With one instance described by P(al) A Q(al), the base-level rule becomes deductively justified. Example:
"Either all cars in Japan drive on the left, or they all drive on the right ." Once we see one car driving on the left, we know that all cars in Japan drive on the left. While it seems true that we can know this decision rule without having been to Japan, in fact it has no confirming instances that are not also instances of the base-level rule. Thus it does not satisfy the external evidence requirement. We actually believe it as a result of a further generalization; if we restrict ourselves to formulae with only unary predicates, we must express this as a second-order regularity, by quantifying over the country predicate P:

VP[NationaEityPredicate(P) Vzy[P(x) A LeftDriver

I A P(y)

* LeftDriwer( y)]]

We will see in the next subsection that this awkward formulation is turned into a first-order sentence by using binary predicate schemata.

C. Direct generalizations using binary predicates
As noted above, using only unary predicates limits the richness of the hierarchy of regularity classes; this limitation is

eased when we use binary predicates. The base-level rule that we are now trying to confirm is written V'z[P(z,b) + Q(x,c)], where b and c are constants. In the unary space, the only interesting database that refutes the negation of the base-level rule was the rule itself. With binary predicates, we also have the following three `variabilization' generalizations:
V~YP'(~, Y> * Qb, 41
v's@`(~, b)* Q(z, 41
V~YZP(~, Y) * Q(v)l.

D. More general rules using binary predicates
The binary equivalent of the unary formulae for rules with more general antecedents is

W&(~, al>* Q(G41

where

Vz[P@, b) * &(z, al)].

Thus the rule "things made of beryl are green" is expressed as

Vz[MateriaE(z,

Beryl) + CoZour(z, Green)]

The normal type of causal argument introduces a chain of intermediate predicates Ri using appropriate linking constants a;.
A simple generalization relationship between P and R can also be used:

`WRl(z, where

b) * Qh 41

V~YW,

Y> * Rda:,~)l.

E. Determination rules

The binary equivalent of a decision rule is called a determination, a form which captures a very common and useful type of regularity. The form

VWZY@`(Z,

w) A P(Y, w> A Q(Y, z> =+ Qb d]

together with one instance described by P(a, b), Q(a, c) is suf-

ficient to guarantee the base-level rule.

Example:

If NationaZity(s,

w) means "x has nationality w", and

Language(z, Z) means `Oxspeaks language z", then the

determination

V'ws yz[Nationality(x,

w) A Nationality( y, w)

ALanguage(y,

z) + Language(z, z)]

means "Nationality determines Language", since it requires that any two people with the same nationality must speak the same language. With the observation of Giuseppe, an Italian speaking Italian, this gives us the base-level rule "All Italians speak Italian". T`wo important points to note: Decision and determination rules find a common expression in the extension of predicate calculus described in [Davies and Russell 861, which also shows this form of regularity to be the necessary background knowledge for the successful use of analogical reasoning. We define a new connective, representing the determination relationship as P&w) > Q(z, 2). Determinations also provide a valid form of singleinstance generalization which actually utilizes information contained in the instance in forming the generalization. This contrasts with the explanation-based generalization (EBG) technique which simply uses the in-

480 / SCIENCE

stance as a focus, assuming that the domain theory is already strong enough to prove the base-level rule. A corollary of this is that, by taking information from the instance, we can build a more powerful single-instance generalization system, in the sense that we can perform the generalization with a weaker domain theory. For example, using the determination "Nationality determines Language", and one instance of an Italian, we predict that all Italians speak Italian; for an EBG system this would require a theory which could predict an entire Ianguage (vocabulary, grammar and all) from facts about a nation - needless to say, no such theory is available.
F. Extended determinations
The regularity classes given above are sufficient to guarantee the generalization from no instances or from one instance. Yet quite often we find that one instance is not quite satisfying, but after several confirmations we are happy. One way to account for this is to postulate that the appropriate determination is only weakly supported, so that we need the extra instances to convince ourselves. A different way is to extend the search direction already taken to reach determination, by adding further instances:
VWw,X,Yl,... , in, dP(x, w> A P(YI 7w> A Q(YI, z)A . . . AP(yn, w> A Q(Y~, 4 =+ Qb ~>1
together with n instances described by
P(al,b), Q(al,c) -. . P(am,b), Q(anTc)
is sufficient to guarantee the base-level rule
`W(x, b)=j Q(x,41.
The meaning of the exten ded determination (wemight call it
determinationn) is clearly seen if we rewrite it:

\JW,Yl,-,Yn,

~[P(~l,w)AQ(yl,z)A...

AP(ynL, w> A Q(Y~, z> 3
`WP(x, 4 * Q(x, 411

Roughly this can be interpreted as follows "All enumerative inductions from n instances, with P as antecedent and Q as consequent, succeed." This regularity can be confirmed by a history of such successful inductions, and thus the induction
in question, Vx[P(x, b) 3 Q(x, c)] becomes justified. As an example, consider again the case of inducing the rule
"all emeralds are green", given n green instances. Formally, we write this as

Vx[JeweZType(x,

Emerald) + CoZour(z, Green)].

Now many jewel types are not uniform in colour (diamonds, for example, come in black, yellow, blue, pink and white) so the determination "jewel type determines colour" does not hold and we cannot perform a single-instance induction. However, as we explain below, the extended determination does still hold, so the n-instance induction is justified.
If we have successfully induced the rules "all sapphires are blue", "all rubies are red", "all amethysts are purple" from collections of instances, then these will be positive instances of the extended determination, so it will be well-confirmed. But in the case of classes such as diamonds, the left-hand side of the extended determination isn't satisfied, since it is unlikely that n instances of a variegated class are all the same colour; thus diamonds are not a disconfirming instance of the extended determination, and it remains well-supported.

If, on the other hand, the Colour predicate admitted arguments like `gruezsss' (green until 2086, blue thereafter), then the extended determination would have disconfirming instances, since the left-hand side would be satisfied by colours such as gruels72 but the universal on the right-hand side would be false.
It is important to note that extended determinations are actually much weaker than determinations, and we basically expect them to be satisfied, more or less, for any `reasonable' P and Q.

VI COMPARISON WITH GOODMAN'S
THEORY OF PROJECTIBILITY
Goodman's theory of induction has been the most influential contribution to the field in recent times. We will therefore take the time to briefly outline his theory here, and then reexpress it in our terms.
Goodman defines the act of projection as the assumption of a general rule from some collection of instances; a rule is projectible if this can be done legitimately. The last part of his excellent book, "Fact, Fiction and Forecast" ([Goodman 831, first published 1955) is devoted to an attempt to elucidate the criteria for deciding projectibility.
In this theory, rules derive projectibility from three sources: 1) the earned entrenchment of the predicates involved; 2) the inherited entrenchment which the predicates derive
from their parent predicates; 3) the projectibility of their overhypotheses. We define these terms below.

A. Entrenchment

Goodman's principal requirement for the projectibility of

a rule Vx[P(z) + Q(X)] is that the predicates P and Q be

well-entrenched.

A predicate P becomes well-entrenched as

an antecedent as a result of frequent past projections of other

rules with P as antecedent; similarly for Q as consequent. Thus

`green' is well-entrenched, whilst `grue' is not.

B. Parent predicates
The notion of a parent predicate is used in defining both inherited entrenchment and overhypotheses. A predicate R is a parent of S iff
1) R is a predicate applying to classes of individuals. 2) Among the classes to which R applies is the extension
of S. Thus `uniform in colour', which applies to any group of individuals all of the same colour, is a parent of `green'. Similarly, `type of jewel' is a parent of `emerald'.
C. Inherited entrenchment
A predicate inherits entrenchment from its parent predicates. Thus if `uniform in colour' is well-entrenched, `green' derives further entrenchment from it.

D. Overhypotheses
An overhypothesis of P + Q is a rule R + S such that R is a parent of P and S is a parent of Q. Thus an overhypothesis of "all emeralds are green" is "all types of jewels are uniform in colour" . If the overhypothesis is projectible, this adds to llte projectibility of its underhypothesis. Here, for example, both R and S are reasonably entrenched, and the overhypothesis is fairly well supported, e.g. by "all sapphires are blue", "all rubies are red". A given rule can have many overhypotheses, and each may in turn be supported in turn by further overhypotheses at the next level.

LEARNING / -tXl

E. Analysis
We will now attempt to analyze Goodman's theory in our terms. By formalizing each of his notions, we can fit them into the general framework of the confirmation of rules by higherlevel regularities.
The entrenchment of a predicate P corresponds approximately to an observed second-order regularity of the form

VQVXl . . - xn[[P(xd A Q(xl) A . - - A P(G) A Q(xn>l
=+`J4JW =+Q~x>ll
which bears close resemblance to the definition of extended determination given above. The difference is that because Goodman is working exclusively with unary predicates, he is forced to quantify over the predicate Q (in defining the entrenchment of P) in order to satisfy the external evidence requirement, thus requiring that P be a successfully projected predicate regardless of the consequent Q. The use of binary predicates allows us to quantify just over their second argument, giving the more fine-grained notion of successful projection of similar rules, rather than just rules with the same antecedent.

The notion of a parent predicate is a little tricky to formalize using unary predicates; it would look something like this:

A is a parent of B iff 3S[A(S) A Vx[x E S M B(x)]]

A more natural way to write it is to use a binary predicate:

A is a parent of B iff Vz[B(z) x=+A(z,B)]

which amounts to reifying B. For example, we write

Vx[EmeraZd(x)

u JeweEType(x, Emerald)]

Viewed in this light, an overhypothesis is essentially a determination.

Clearly, there is a great deal of overlap in the two approaches. There are, however, some slight differences in emphasis, stemming mainly, one may conjecture, from the differing requirements of philosophy and artificial intelligence.
Goodman is trying to systematize human practice; he does not attempt, for example, to jzlstifv the entrenchment criterion. When written formally, we see entrenchment (and the other notions) as codifications of higher-level regularities, which push back the inevitable point at which we must simply appeal to an unjustifiable, naked principle of enumerative induction. (As is
pointed out in [Quine gL Ullian 701, in the human case we may be able to push it back far enough such that the evolutionary process itself may be `credited' with performing such inductions.) The main commonality of the two theories, and the revolutionary aspect of Goodman's work, is that we no longer have to make such an appeal within the base-level induction itself.
In Goodman's theory, predicates derive entrenchment from actual past projections, taking the form of (not necessarily spoken) linguistic utterances and corresponding to projections performed in the history of the culture rather than just the individual. This is essentially a psychological theory about exactly what evidence humans take into account in making new projections. In our approach, we try to identify all the evidence that should logically be taken into account, which may entail making further inductions `on demand' as well as

noticing past inductions. l Because we use binary predicates and an exhaustive
generator, we are able to produce a much richer hierarchy of `overhypotheses'. Both theories, however, rely on the existence of a rich taxonomic vocabulary to facilitate expression of the desired regularities. This leads us naturally into a study of the relation between language and induction.

VII REPRESENTATION

AND INDUCTION

An implicit hypothesis of Goodman's theory is that everyday terms will tend to be well-entrenched, since otherwise they would drop out of use. (He states (p. 97) that "entrenchment and familiarity are not the same . . . a very familiar predicate may be rather poorly entrenched," but gives no examples.) The key idea behind analyzing this hypothesis is to understand the process by which terms become familiar parts of the language. If we can capture the conditions under which new words are acquired, then we can give a semantics to the presence of a word in our language, as well as to the word itself. * Thus the fact that green is a primitive attribute in our language, as weIl as being a physiological primitive of our observation apparatus, suggests that greenness is a commonlyoccurring property in the world, and, more importantly, that greenness is a good predictor for various other properties, such
as whether something is animal or vegetable, ripe or unripe. If we limit our acquisition and retention of terms to those which manifest such useful properties, then we are guaranteed that familiar terms will tend to be entrenched, and thus that rules using t,hem will be projectible. The language-evolution aspect of this idea finds strong echoes in the theory of induction given in [Christensen 641; the reflection of properties and regularities of the world in our neurological development is one of the prin-
ciple themes of Roger Shepard's work, described in [Shepard 84, 861. Although we have barely scratched the surface of the enormous topic of the interrelationship of language, representation and learning, it seems that the analysis of the semantics of the presence of words in a language, via the analysis of the processes of acquisition and retention, may be a profitable approach.

VIII APPLICATIONS
We will first describe how we propose to build systems utilizing the ideas given above; we wiIl then discuss possible applications to some induction projects, past and present.
The scenario we envisage is that of an autonomous intelligent agent engaged in the continuous process of investigating its environment and attempting to fulfil its various goals. The system may need to assess the degree of confirmation of a proposed rule for one of three reasons:
1) it needs a rule for concluding some goal, and has none available;
2) it has some theoretical reasons for believing the rule plausible;
3) it has noticed that the rule is empirically plausible.

* Rendell, in [Rendell 861, talks about the "semantics of the constraint imposed by the language" as part of an attempt to understand the bias inherent in version-space systems (the ungrounded premise to which we alluded earlier); this is another aspect of the same idea.

482 i SCIENCE

To evaluate the proposed rule, the system performs the following tasks:
a Assess the direct empirical support for the rule; if necessary, this may involve experimentation.
l Instantiate the known classes of higher-level regularity so that they apply to the rule in question; if the system already knows the degree of confirmation of the instantiated regularities, take that into account; if not, call the evaluation procedure recursively to compute their confirmation.
l Repeat the same process for any plausible competing hypotheses.
If the proposed rule is well-supported by its higher-level regularities, and clearly better than any conflicting hypothesis, then it can be adopted (subject to revision).
From our investigations to date in the space of regularities, it seems that we can capture most of the relevant information using just three basic classes: simple implicative rules, determinations and extended determinations. These seem to provide the justification for the basic types of argument on common use. As mentioned above, as long as there are a small number of types it is reasonable to build specialized `regularitynoticing' demons to spread the computation load, rather than using `lazy evaluation'. The higher-level rules we thus accumulate are also useful for suggesting new, plausible base-level
Our proposed architecture seems closest to that of AM and EURISKO ([L enat 761, [Lenat 83a,83b]), which actively performs experiments in order to confirm its conjectures inductively. EURISKO can be said to use higher-level regularities of a sort, since it has a heuristic which essentially leads it to consider conjectures similar t,o those which have already proven successful. Recalling the basic task of inferring facts from a mass of ground data, it is clear that when we add the ability to recognize a new class of higher-level regularities we actually expand the set of inferences the system can make. Most inductive systems in AI use only simple, associative regularities. We therefore hypothesize that with the degree of synergy afforded by the addition of multiple layers of regularities, EURISKO's performance can be considerably enhanced.
A system which uses theoretical (causal, explanatory) support as well as direct empirical support for its proposed rules is described in [Doyle 851. In the light of the theory given above, we would argue that there are forms of further, indirect empirical support which are in no sense causal, yet offer more power than the simple `associationist' approach. Other systems which conduct large-scale inductive investigations are the RX system ([slum 82]), and UNIMEM/RESEARCHER ([Lebowitz 861); th e same arguments apply in these cases.
IX CONCLUSIONS AND FUTURE
RESEARCH DIRECTIONS
We have shown that the requirement for a theory of induction is not that it render enumerative induction valid, but that it elucidate the way in which the plausibility of an induction is affected by the presence of further evidence, distinct from its direct positive and negative instances. The relationship between the direct and indirect evidence is a formal one, as required, and we have given a method for identifying all general classes of such evidence. We have constructed a system which applies the method to discover some novel and, we

believe, important classes of regularity. The result of the synergistic interplay of induction and deduction is that we can now distinguish plausible from spurious inductions, and can maximize the usefulness of the observational knowledge a system possesses. The `punchline' is simply this: fhe more classes of

regularity a system is equipped to observe, the more inferences

it can make from a given collection of data.

A major weakness which we would like to address is that the theory as described only allows first-order regularities. Although we glossed over the point in the exposition above, an extended determination need not use only an exact number n for all its inductions -- n really just means `many', and this is
how it will be implemented in the real system. The model of analogy by similarity in [Russell 861 suggests that there may be other useful non-first-order regularities, for example in the definitions of natural kinds ([Rosch 781) and in the distributional variation of attribute values in a population ([Medin & Smith 841). At present it is not clear how to cope with these problems.

Potentially fruitful areas for further investigation include:

l studying the interaction of language and induction via the semantic analysis of the process of representational evolution;

l empirical experiments to establish what are the useful, commonly-occurring classes of regularity in any given world;

l quantification of the contributions of higher-level larities to a base-level rule, especially regularities less than 100% confirmation;

reguwith

l construction of robust systems, using the principles outlined above, that are able to acquire, organize and use

effectively knowledge of a complex environment, even in the absence of any a priori knowledge of the environ-

ment; although such systems seem somewhat beyond our present abilities, it is hoped that we have begun to

dismantle one of the theoretical barriers to their creation.

ACKNOWLEDGEMENTS
I would like to thank my advisors Doug Lenat and Mike Genesereth and colleagues Todd Davies (SRI), Devika Subramanian and David Wilkins (Stanford) and all the members of the Logic Group of the Stanford Knowledge Systems Laboratory for fruitful discussions, constructive criticism and moral support.

References

[Barker & Achinstein 601
Barker, S. F. & Peter Achinstein. "On the New Riddle of Induction". In Philosophical Review, vol. 69, pp. 511-22; 1960.

[Blum 821 Blum, R. L. Discovery and representation of causal
ships from a large time-oriented clinical database: project. Ph. D. thesis, Stanford University, 1982.

relationthe RX

[Christensen 641 Christensen, Ronald. Berkeley: 1964.

Foundations

of Inductive Reasoning.

[Davies 851 Davies, Todd. Analogy.

Informal Note No. IN-CSLI-85-4,

LEARNING / 483

Center for the Study of Language and Information, Stanford University; 1985.

[Davies & Russell 861 Davies, Todd & Stuart Russell. A Logical Approach to Reasoning by Analogy. Stanford CS Report (forthcoming) and Technical Note 385, AI Center, SRI International; June, 1986.

[Dietterich 861 Dietterich, Thomas G. Lenrning at the Knowledge LeveE. Technical Report No. 86-30-1, Computer Science Department, Oregon State University; 1986.

[Doyle 851 Doyle, Richard J. The Construction and Refinement of Jus-
tified Causal Models through Variable-level Explanation and Perception, and Experimenting. Ph.D. thesis proposal. Massachusetts Institute of Technology; 1985.

[Goodman 461 Goodman, Nelson. "A Query on Confirmation". of Philosophy, Vol. 43, pp. 383-5; 1946.

In Journal

[Goodman 831 Goodman, Nelson. Fact, Fiction Cambridge, MA and London: 1983. (First published 1955).

and Forecast, 4th edition. Harvard University Press;

[Holland et al. 861 Holland J., Holyoak K., Nisbett R. & Thagard P. Induction: Processes of Inference, Learning and Discovery. In press.

PJow4 Hoppe, Arthur. "Our perfect economy". In Sun Francisco Chronicle. San Francisco: Date unknown.

[Lebowitz 861 Lebowitz, Michael. "Concept Domain: Generalization-based Michalski, Jaime G. Carbonell

Learning in a Rich Input Memory". In Ryszard S. & Tom M. Mitchell (Eds.),

Machine Learning: an Artificial Intelligence Approach; Volume II. Los Altos, CA: Morgann Kaufmann, 1986.

[Lenat 761 Lenat, D. B. AM: An artificial intelligence approach covery in mathematics as heuristic search. Ph.D. Stanford University, 1976.

to disthesis,

[Lenat 83a] Lenat D. B. "Theory formation by heuristic search. The nature of heuristics II: Background and Examples". In Artificial Intelligence, Vol. 21, Nos. 1,2; 1983.

[Lenat 83b] Lenat D. B. "EURISKO: A Program That Heuristics and Domain Concepts. The Nature III: Program Design and Results". In Artificial Vol. 21, Nos. 1,2; 1983.

Learns New of Heuristics
Intelligence,

[Lenat et al. 791 Lenat, D. B., Hayes-Roth, omy. RAND Technical Monica, CA: The RAND

F. and Klahr, P. Cognitive Report No. N-1185-NSF. Corporation; 1979.

EconSanta

[Lenat et al. 861 Lenat D., Mayank P. and Shepherd M.. "CYC: Using Common Sense Knowledge to Overcome Brittleness and Knowledge Acquisition Bottlenecks." AI Magazine Vol. 6 No. 4; Winter 1986.

[Medin & Smith 841

Medin D. L. & Smith E. E. "Concepts and Concept Formation." In Annual Review of Psychology Vol. 35; 1984.
[Michalski 831 Michalski R. S. "A Theory and Methodology of Inductive Learning." In Artificial Intelligence, Vol. 20, No. 2; Feb 1983.

[Mitchell 781 Mitchell, Tom M. Version Spaces: an Approach to Concept Learning. Ph.D. thesis, Stanford University, 1978.

[Mitchell et al. 861 Mitchell, T. M., Keller R. M., Kedar-Cabelli S. T. "Explanation-based Generalization: a Unifying View". Machine Learning Journal Vol.1 No. 1; 1986.

In

[Quine & Ullian 701
Quine W. V. & Ullian J. S. The Web of Belief. Random House; 1970.

New York:

[Rendell 861 Rendell, Larry. "A General Framework for Induction and a Study of Selective Induction." In Machine Learning Journal Vol. 1 No. 2; 1986.

[Rosch 781 Rosch, E. "Principles of categorization". In Cognition and Categorization, Rosch E. and Lloyd B. B. (Eds.). Hillsdale: Lawrence Erlbaum Associates; 1978.

[Russell 861 Russell, Stuart J. "A Q uantitative Analysis of Analogy Similarity". In Proceedings of the National Conference Artificial Intelligence. Philadelphia: AAAI; 1986.

by on

[Salmon 741 Salmon, Wesley. "Russell on Scientific Inference". G. Nakhnikian (Ed.), Bertrand Russell's PhiEosophy. York: Barnes and Noble; 1974.

In New

[Sanford 701 Sanford, David H. "Disjunctive Predicates". In American Philosophical Quarterly, Vol. 7, pp. 162-70; 1970.

[Shepard 841 Shepard, Roger. "Ecological Constraints on Internal Rep-
resentation: Resonant Kinematics of Perceiving, Imagining, Thinking and Dreaming". In Psychological Review Vol. 91,
No. 4. October, 1984.

[Shepard 861 Shepard, Roger. Mind and World. Forthcoming.

[Swinburne 731 Swinburne, Richard. An Introduction ory. London: Methuen; 1973.

to Confirmation

The-

[Utgoff 841 Utgoff P. E. Adjusting Bias in Concept
thesis, Rutgers University, 1984.

Learning.

Ph.D.

484 / SCIENCE

