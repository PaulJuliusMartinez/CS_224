From: ISMB-93 Proceedings. Copyright © 1993, AAAI (www.aaai.org). All rights reserved.
DiscoveringSequenceSimilarity by the AlgorithmicSignificance Method
Aleksandar Milosavljevid Genome Structure Group Biological and Medical Research Division Argonne National Laboratory Argonne, Illinois 60439-4833 e-mail: milosav@anl.gov

Abstract

limit the time needed for straightforward counting

of occurrences of words or to limit the size of the

The minimal-length encoding approach is applied to Markov model for the sequence. (Both variables

define concept of sequence similarity. Asequence is grow exponentially with the length of the words

defined to be similar to another sequence or to a set considered.) In this paper, we eliminate the as-

of keywords if it can be encoded in a small number sumption about fixed word length by applying the

of bits by taking advantage of commonsubwords. directed acyclic word graph [3] data structure and

Minimal-length encoding of a sequence is computed a linear-time data compression algorithm that emin linear time, using a data compression algorithm ploys a dynamic programming strategy.

that is based on a dynamic programming strategy

Thesignificance of sequencesimilarity is typically

and the directed acyclic word graph data structure. determined by more or less ad-hoc methods that are

No assumptions about commonword ("k-tuple") valid only under oversimplified assumptions about

length are made in advance, and commonwords the distributional properties of the occurrences of

of any length are considered. The newly proposed words in sequences [13]. Indeed, the overall sub-

algorithmic significance method provides an exact word similarity of two sequences is a very complex

upper bound on the probability that sequence sim- statistic having distributional properties that are

ilarity has occurred by chance, thus eliminating the hard to determine, except in the most restricted

need for any arbitrary choice of similarity thresh- cases. In this paper, weshowthat significance of se-

olds. Preliminary experiments indicate that a small quence similarity can be rigorously determined un-

number of keywords can positively identify a DNA der very few assumptions by applying the recently

sequence, which is extremely relevant in the context introduced algorithmic significance method[11].

of partial sequencing by hybridization.

Massive hybridization experiments that are per-

formed as part of the partial sequencing by hy-

1 Introduction

bridization project [5] are producing information

about presence of particular words within a huge

The search for sequence similarity based on subword number of cloned DNAsequences. A partial se-

composition is a commonconcept now. Pevzner [12] quence consisting of a set of keywords can be used

recently reviewed manydifferent methods based on to recognize the similarity of clones to knownDNA

this concept. In the following, we present several sequences without having to sequence the clones

improvements over current methods that are based completely. In this paper we propose a method to

on the minimal length encoding approach.

discover sequences that maybe similar not only to

Subwordsimilarity searching is typically based another complete sequence but also to a set of key-

on words ("k-tuples") that do not exceed a speci- words that may come from a partially sequenced

fied length. The wordlength is restricted in order to clone.

284 ISMB-93

2 Minimal Encoding Length and Let us nowcount the exact numberof bits needed

Similarity

to encode letters and pointers. Wemay assume that the encoding of a sequence consists of units,

The main idea behind the approach presented in each of which corresponds either to a letter or to a this paper is that similarity canbe defined via min- pointer. Every unit contains a (log 5)-bit field that

imal encoding length. Weask whether or not a either indicates a letter or announces a pointer. A particular sequence which we call the target can be unit representing a pointer contains two additional concisely encoded using another sequence or a set fields with positive integers indicating the position of keywords, which we call the source. If there is no and length of a word. These two integers do not similarity, then the knowledge of the source does exceed n, the length of the source sequence. Thus,

not help, but if we succeed in using the source to a unit can be encodedin log 5 bits in case of a letter find an encoding of the target sequence that is much or in log 5 -t- 2 log n bits in case of a pointer.

shorter than is likely by chance, then we can prove If it takes more bits to encode a pointer then at a high significance level that the source and the to encode the word letter by letter, then it does target are related. For a broader introduction to not pay off to use the pointer. Thus, the encoding

minimal length encoding see [4].

length of a pointer determines the minimumlength

A target sequence is defined to be similar to a of commonwords replaced by pointers. In order to source sequence if it can be encoded concisely by take advantage of shorter commonwords, we must
replacing some words in it by pointers to the oc- encode the pointers more concisely.
currences of the same words in the source. This The pointers can be encoded more concisely un-

is a standard technique in data compression [14]. der two plausible assumptions. The first assump-

Consider an example where the target sequence is tion is that the commonwords occur in similar or-

der in the target as in the source, in which case

GATTACCGATGAGCTAAT

the position of the commonword in the source can be indicated relative to the previous commonword;

and the source sequence is

this relative distance mayfall into a smaller range than the absolute position and thus it maybe repre-

ATTACATGAGCATAAT

sented in fewer bits. The second assumption is that the lengths of the commown ords fall into a smaller

The occurrences of somewords in the target maybe range. Under these two assumptions, one may en-

replaced by pointers indicating the beginning and code a pointer in muchless than log 5-)-2 log n bits.

the length of the occurrences of the same words in If a word to be replaced by a pointer occurs more

the source. In the following, a pointer is denoted by a pair of integers in parentheses, the first indicating the position of occurrence in the source and the second the length of the commonword. For

than once in the source, then the information about the particular occurrence contained in the pointer
maybe more than is necessary. If the pointer could specify only the set of occurrences and not any par-

example,

ticular occurrence, then the pointer itself wouldre-

quire fewer bits. Wewill comeback to the problem

G(1,4)CCG(6,6)(13,4)

of pointer size later in the experimental section. Consider the case of a target sequence that is en-

One can think of the encoded sequence as being coded using a set of keywords as the source. A parsed into words that are replaced by pointers and sequence is in this case encoded using a pointer

into the letters that do not belong to such words. that consists of three numbers:an index of the key-

One may then represent the encoding of a sequence word and the beginning and the end of the subword by inserting dashes to indicate the parsing. For the within the keyword.

encoding above, the parsing is indicated as follows: Consider the following target sequence:

G-ATTA-C-C-G-ATGAGC-TAAT

GATTACCGATGAGCTAAT

and the source keywords: I AAAAGGGGGG 2 ATTACATG 3 AGCATAAT 4 ATGAGCATA

Theorem 1 For any distribution of probabilities Po over sequences and for any decoding algorithm A,
P{- log po (t) - IA (t) >_d} -d
where po(t) is the probability assigned to sequence t by distribution Po and In(t) is the length of encoding of sequence t using algorithm A.

The following is an encoding of the target sequence Proof of Theorem1 can be found in [11]. (Similar

relative to the source keywords:

theorems are proven in the context of competitive

encoding[4].)

G(2,1,4)CCG(4,1,6)(3,5,4)

This theorem enables us to use algorithm A as an

alternative hypothesis to refute the null hypothesis

It is easy to see from these two examples that one P0 at the significance level 2-d. Applying the in-

can construct a decoding algorithm that within it contains a source sequence or source keywords and that reconstructs the target sequence from its encoding.

equality above to our example, the probability that a target sequence t will have an encoding d = 7
bits less than - log po(t) = - ~: n~: log p=(t) is less than 2-7, which is less than the standard signifi-
cance threshold of 0.01.

3 Algorithmic

The exponential relationship between encoding
Significance length and probability allows us to establish signif-

Method

icance even whenvery large sequence libraries are searched. If the sequence library searched contains

Let A denote a decoding algorithm that can recon- sequences of total length L, then to refute the null struct the target sequence. Wemayassume that the hypothesis at the significance level of 0.01 for any source (sequence or set of keywords) is part of the sequence in the library, d = 7 + log L bits would

algorithm A so that only the encoded target needs suffice (but maynot be necessary).

to be supplied. Weexpect that the targets that are The algorithmic significance methodis conceptu-

similar to the source will have short encodings. By ally very similar to the conceptof statistical signif-

IA(t) we denote the length of the encoded target t. icance in the Neyman-Pearson hypothesis testing
Let P0 denote the null hypothesis, i.e., the distri- framework(see, e.g., [9]). The main difference
bution of probabilities under the assumption that that the alternative hypothesis is nowrepresented
the target isequence is independent from the source. by a decoding algorithm instead by an explicit disLet po(t) be the probability assigned to a target tribution of probabilities.
by the null hypothesis. For example, if we assume In contrast to the concept of statistical signifithat every letter is generated independently with cance that is based on the approximate (asympprobability px, where z E {A, G, C, T} denotes the totic) estimation of tails of distributions ("p-value') letter, then the probability of a target sequence t of statistics like length of the longest commown ord is po(t) = I-I~p~~(t), where n~(t) is the numberof or number of commonwords (see, e.g., [8]), the
occurrences of letter x in t. If we assume a Markov algorithmic significance method provides an exact

dependency, then the probability of a sequence can significance value. Moreover, algorithmic signifi-

efficiently be computedfor the given Markovmodel. cance is directly applicable for any null hypothe-

The following theorem states that a target se- sis for which po(t) can be computed, as opposed

quence t is unlikely to have an encoding much the statistical significance value whichis applicable

shorter than - log po(t).

only for a specific distribution.

286 ISMB-93

4 Minimal Length Encoding Al- the HumanTissue Plasminogen Activator (TPA)

gorithm

gene [6]. Three kinds of sources were used: the complete Alu consensus sequence [7] and keyword

Short encodings are not only significant, but they sets consisting of eight and four 8-mers chosen to

can also be computedefficiently. In this section we be evenly distributed along the consensus.

present a minimal length encoding algorithm, which The complete TPA gene, GenBank [2] acces-

is a slight variant of the algorithm for discovering sion number K03021, containing 36,594 bases was

simple sequences [11] and which is frequently used searched. The sequence was considered one window

in data compression [14].

at a time, with windowsof length 350 and an over-

The algorithm takes as an input a target sequence lap between adjacent windows of 175. The value

t and the encoding length p > 1 of a pointer and of log p0(t) was. computed under the assumption computes a minimal length encoding of t for a given that letters are generated independently by a uni-

source s (here s denotes either a source sequence or form distribution. An encoding length threshold of

keywords). Since it is only the ratio between the 22 > 7+log 36594 bits was chosen so that the prob-

pointer length and the encoding length of a letter ability of any windowhaving short encoding would

that matters, we assume, without loss of generality, be guaranteed not to exceed the value of 0.01.

that the encoding length of a letter is 1.
Let n be the length of sequence t and let tk denote
the (n - k + 1)-letter suffix of t that starts in the kth position. Using a suffix notation, we can write

The only difference in program input between the three experiments (except, of course, the source itself) was the pointer size. Whenthe source was the complete Alu consensus sequence, a pointer length

tl instead of t. By I(tk) we denote the minimal
encoding length of the suffix tk. Finally, let l(i),
where 1 < i < n, denote the length of the longest wordthat starts at the i th position in target t and

of 8 bits was chosen under the assumption that the distance between consecutive commonwords and commonword length can each be encoded using

that also occurs in the source s. If the letter at position i does not occur in the source, then l(i) 0. Using this notation, we maynowstate the main recurrence:

4 bits on average. In the case of keyword sets, the pointer size was chosen as the binary logarithm of the number of keywords plus 2 bits to locate a
subword within a keyword. One may argue that more bits would be required to locate a subword;

I(t~) = rain(1 + I(ti+l),p+ /(ti+z(O))

our choice of fewer bits can be justified by the fact that only the subwords that exceed a certain length

Proof of this recurrence can be found in [14].

need to be located, and also that short subwords

Based on this recurrence, the minimal encoding are likely to have multiple occurrences, so that a

length can now be computed in linear time by the pointer to any particular occurrence would contain

following two-step algorithm. In the first step, the excess information.

values l(i), 1 < i < ar e computed inlin ear tim e by using a directed acyclic word graph data structure that contains the source s [3]. In the second step, the minimal encoding length I(t) = I(tl) is computedin linear time in a right-to left pass using the recurrence above.

The windowsthat could be encoded in 22 bits less than postulated by the null hypothesis were merged to obtain a set of non-overlapping regions. Table 1 contains a comparison of occurrences of Alu and half-Alu sequences in the TPAgene in direct orientation with the regions identified as Alu-like. There

were no false positive matches.

5 Implementation and Experi-

Figure 1 contains an example of a windowparsed

ments

using a complete Alu consensus sequence as a source, together with an alignment of the Alu con-

The algorithm above was implemented in C+q- on sensus with a segment within the window.Figure 2

a Sun Sparcstation under UNIX. The program was contains the eight- and four-keyword sets used and

applied to identify occurrences of Alu sequences in a windowparsed using the four-keyword set.

Mllosavljevic 287

Parsed window 22226-22575 from the TPA gene:

C-T-CAGTG-C-C-T-G-TCAAAA-G-T-A-T-G-T-GCTGAGGC-T-G-G-A-A-G-GTGGTG-C-A-T -GCCTGT-G-ATCCCAGCACTTT-A-GGAGGCC-A-A-G-G-TGGGAGG-G-TCGCT-G-G-A-G-CCCG GGAG-T-T-C-A-AGACCA-A-T-CTGGGC-A-AACAT-A-G-C-A-A-G-T-C-C-C-C-T-GTCTCTA C-A-AAAAATA-A-AAAAATTAGCC-AGACC-T-G-G-T-A-T-G-T-A-G-TCCCA-A-C-T-A-C-TT GGGAGG-T-TGAGGCAG-A-A-GGATCAC-T-TGAGCC-CAGGAGTT-GGAGGCTG-C-A-GTAATC-TA-C-G-A-T-T-A-T-GCCACTGCA-T-T-T-C-A-A-C-C-T-CAGTGA-C-A-G-G-G-C-A-A-G-C -C-C-TCACCT-CTAAAA-C-A-A-A-ACAAAA-CAACA-C-A-A-ACAAAAA-CAAAAA-C-ACAGA-A -A-A-G-C-C-C

Ali~rnment (Alu consensus is on top and a fragment from the parsed window is on the bottom):

@10 @20 @30 @40 @50 @60 @70 GGCCGGGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGGCGGGCGGATCACCTGAGG
GGCTGG--AAGGTGGTGCATGCCTGTGATCCCAGCACTTTAGGAGGCCAAGGTGGGAGGGTCGCTGGAGC @30 @40 @50 @60 ¢70 @80 @90

@80 @90

@I00

@110

@120

@130

TCAGGAGTTCGAGACCAGCCT-GGCCAACATGGTGAAACCCC-GTCTCTACTAAAAATACAAAAATTAGC

CCGGGAGTTCAAGACCAATCTGGGCAAACATAGCAAGTCCCCTGTCTCTACAAAAAATAAAAAAATTAGC

@100

@110

@120

@130

@140

@150

@160

@140

@150

@160

@170

@180

@190

@200

CGGGCGTGGTGGCGCGCGCCTGTAATCCCAGCTACTCGGGAGGCTGAGGCAGGAGAATCGCTTGAACCCG

CAGACCTGGTA.........TGTAGTCCCAACTACTTGGGAGGTTGAGGCAGAAGGATCACTTGAGCCCA

@170

@180

@190

@200

@210

@210

@220

@230

~240

~250

@260

@270

GGAGGCGGAGGTTGCAGTGAGCCGAGATCGCGCCACTGCACTCCAGCCTGGGCGACAGAGCGAGACTCCG

GGAGTTGGAGGCTGCAGTAATCTACGATTATGCCACTGCATTTCAACCTCAGTGACAGGGCAAGCCCTCA

@220

@230

@240

@250

@260

@270

@280

@280 TCTCAAAAAAAA

CCTCTAAAACAA @290

Figure 1: Parsing of window 22226- 22575 from the TPA gene. 288 ISMB-93

Aiu occurrence

I Alu consensus

740...1033

526...1225

8864...9176

8576...9275

10067...10365

9801...10500

16794...17125, 17170...17466 16626...17675

18879...19178

18726...19425

20946...21259,21280...21578 20826...21700

22253...22545

22051...22750

25620...25911

25376...26075

26524...26821,26941...27239 26251...27475

27880,.28145

27651...28350

28804...29100,29297...29431 28526...29575

32921...33220

32726...33425

34234...34525

33951...34650

identified Alu regions Eight 8-mers
526...1225 875i...9275
9976....10500 16976...17500 18726...19250 20826...21700 22226...22575 25551...25900 26426...26926,26927...27475 27826...28350 28701...29575 32726...33425 34126...34650

Four 8-mers 701...1050
16976...17325 18901...19250 21176...21700
26426...26775
32901...33250

Table 1: Occurrences of Alu sequences in the TPA gene and the identified Alu regions. Some rows correspond to pairs of Alu sequences that occur close together. There were no false positive matches.

A1u keywordsets used in search:

Eight8-mers: 1GGCCGGGC 5 AAAAATTA 2 AGCACTTT 6 TAATCCCA 3 CTGAGGTC 7 GAATCGCT 4 ACATGGTG 8 GTGAGCCG

Four 8-mers: 1GGCCGGGC 2 CTGAGGTC 3 AAAAATTA 4 GAATCGCT

Window 18901-19250from the TPA gene parsedusing the set of four 8-mersas a source:

T-G-T-AATC-T-C-A-G-C-A-C-T-T-T-GGG-A-GGCCG-AGGT-G-G-GAGG-ATCGCT-TGAG-C -C-C-AGG-A-G-T-T-G-GAG-A-C-C-A-GTC-T-GGGC-ART-A-T-A-G-TGAG-A-T-GCT-GTC -T-C-T-A-C-A-AAAAATT-T-AAAAATTA-GCCGGG-T-G-T-A-C-T-A-G-T-A-T-G-C-A-C-C TG-T-GGTC-C-C-A-GCT-A-C-T-C-A-G-GAGG-CTGAGG-CGGG-AGG-ATCGCT-T-A-A-G-TT-C-A-G-GAGGT-T-GGG-A-C-T-T-C-A-G-TGAG-A-T-A-T-G-ATTA-CGC-C-AAT-G-C-AC-T-C-C-A-GCC-T-GGG-TGA-C-AAA-CTGAG-ATC-CTG-T-C-T-C-AAAAA-AAAAA-AAAAAAAAA-G-AAAAA-GGC-AAT-G-C-A-A-G-T-GCC-A-TGAG-C-C-A-C-A-G-C-A-GAGG-C-AAA -CTG-C-C-C-T-C-A-T-GGT-GCC-T-A-C-T-C-T-C-T-A-G-CTGA

Figure 2:Alu keyword sets used in the search and an example of a window parsed using the l~t off our keywords.
Milosavljevi6 289

6 Discussion

domains like DNAsequence analysis, in contrast to the more standard statistical approaches which

The experiments indicate that a surprisingly small have mostly been motivated by real-valued mea-

number of keywords suffice to identify Alu se- surements. Instead of focusing on a particular pa-

quences. The exact number of necessary keywords rameter (e.g., length of the longest repeated word),

maydepend on the degree of similarity between se- the algorithmic significance approach enables us to

quences of a particular class, but it seems that 10 focus on the information content (as measured by

or less 8-mers wouldsuffice to identify a similarity the encoding length), which is a muchmore widely

of 80%in sequences about 300 long. This means applicable parameter.

that the sequence similarity of many cloned DNA

sequences to known sequences may be determined 7 Acknowledgements
without the exact knowledge of their complete se-

quence; a partial sequence consisting of a set of key- Discussions with Radoje Drmanac, Ivan Labat, words that have been identified in the clone may Radomir Crkvenjakov, Jerzy Jurka, and Thomas

suffice [10] [5].

Cover have greatly contributed to this work.

The method described in this paper has also been This work was supported in part by U.S. Depart-

succesfully used for rapid screening for sequence ment of Energy, Office of Health and Environmen-

similarity by the Pythia email server for identifi- tal Research, under Contract W-31-109-Eng-38and

cation of Humanrepetitive DNA(for more infor- in part by U.S. Department of Energy grant DE-

mation about Pythia, send "help" in Subject-line FG03-91ER61152.

to Internet address pythia~anl.gov).

Current methods typically require two arbitrary assumptions to be made for each similarity search:

References

one about the length of the longest commonword that is to be considered and the other about the threshold of similarity for significant matches. At the sametime, the exact significance of the match is not computed. The method proposed in this paper

[1]L. Allison and C.N. Yee. Minimummessage
length encoding and the comparison of macro-
molecules. Bulletin of Mathematical Biology,
52:431-453, 1990.

removesthe need for any restrictions on word length while keeping the computation time linear, and it also provides an exact bound on significance, thus removing need for any arbitrary thresholds. Experiments indicate that this systematic approach can eliminate false positive matcheswhile retaining sensitivity.
The algorithmic significance method can also be applied to discover similarity based on sequence

H.S. Bilofsky and C. Burks. The GenBank(R) genetic sequence data bank. Nucleic Acids Research, 16:1861-1864, 1988.
A. Blumer, J. Blumer, D. Haussler, A. Ehrenfeucht, M.T. Chen, and J. Seiferas. The smallest automaton recognizing the subwords of a text. Theoretical ComputerScience, 40:31-55, 1985.

alignment. For this case, the target sequence may have to be encoded using a set of edit operations.
A minimal length encoding approach to sequence alignment has been discussed in [1]; the coding techniques presented there can be combined in conjunc-

T. Cover and J. Thomas. Elements of Information Theory. Wiley, 1991.
[5]R. Drmanac, G. Lennon, S. Drmanac, I. La-
bat, R. Crkvenjakov, and H. Lehrach. Par-

tion with the algorithmic significance methodto ob-

tiai sequencing by hybridization: Concept

tain exact bounds on significance.

and applications in genome analysis. In In:

The applications mentioned in this paper are just a small sample of possible applications of the con-

The First International Conference on Electrophoresis, Supereomputing and the Human

cept of algorithmic significance. The key feature

Genome,pages 60-74. World Scientific, Singa-

of the concept is its applicability in combinatorial

pore, 1991.

290 ISMB-93

[6] S.J. Friezner-Degen, B. Rajput, and E. Reich. The human tissue plasminogen activator gene. Journal of Biological Chemistry, 261:6972-6985, 1986.
[7] J. Jurk~ and A. Milosavljevi~. Reconstruction and analysis of human Alu genes. Journal of Molecular Evolution, 32:105-121, 1991.
[8] S. Karlin, F. Ost, and B.E. Blaisdell. Mathematical Methods for DNASequences, chapter Patterns in DNAand Amino Acid Sequences and their Statistical Significance. CRCPress, Boca Raton, Florida, 1989.
[9] J.C. Kiefer. Introduction to Statistical Inference. Springer-Verlag, 1987.
[10] G.G. Lennon and H. Lehrach. Hybridization analyses of arrayed cDNAlibraries. Trends in Genetics, 7(10):314-317, 1991.
[11] A. Milosavljevi~ and J. Jurka. Discovering simple DNAsequences by the algorithmic significance method. Computer Applications in Biosciences, in press.
[12] P.A. Pevzner. Satistical distance between texts and filtration methods in sequence comparison. Computer Applications in Biosciences, 8(2):121-127, 1992.
[13] P.A. Pevzner, M.Y. Borodovsky, and A.A. Mironov. Linguistics of nucleotide sequences I: The significance of deviations from mean statistical characteristics and prediction of the frequencies of occurrence of words. Journal of Biomolecular Structure and Dynamics, 6:10131026, 1989.
[14] J.A. Storer. Data Compression: Methods and Theory. Computer Science Press, 1988.

MHosavUevi~ 291

