Artificial Agents, Good Care, and Modernity 

Prof. Mark Coeckelbergh, Centre for Computing and Social Responsibility, De Montfort University, 5.79 Gateway House,  

The Gateway, Leicester LE1 9BH, UK, mark.coeckelbergh@dmu.ac.uk 

 

Mark Coeckelbergh 

 
Abstract.  When is it ethically acceptable to use artificial agents in 
health care? This paper articulates some criteria for good care and 
then discusses whether machines as artificial agents can meet these 
criteria. Particular attention is paid to intuitions about the meaning 
of  “care”  but  also  to  the  care  process  as  a  labour  process  in  a 
modern  organizational  and  financial-economical  context.  It  is 
argued  that  while  there  is  in  principle  no  objection  to  using 
machines in medicine and health care, the idea of them functioning 
and  appearing  as  “care  agents”  raises  serious  problems.  It  is 
recommended  that  the  discussion  about  MCAs  be  connected  to  a 
broader  discussion  about  the  impact  of  technology  on  human 
relations in the context of modernity. 
 
1 INTRODUCTION 
 

Is  it  ethically  acceptable  to  use  artificial  agents  in  health  care, 
and  if  so,  when,  under  what  conditions?  While  most  philosophers 
recognize  that  there  is  a  potential  tension  between  the  quality  of 
care  and  the  use  of  machines  in  health  care,  some  are  more 
optimistic than others about the possibility to bridge that gap. For 
instance, while some think that the solution lies in trying to create 
ethical  machines  (Anderson  and  Anderson    2007;  Wallach  and 
Allen  2008),  whereas  others  have  voiced  concerns  about  the 
reduction  of  human  contact  (Sharkey  and  Sharkey  2010;  Sparrow 
and  Sparrow  2006),  which  seems  especially  problematic  in  the 
case  of  vulnerable  people  such  as  people  who  are  ill,  young 
children, and elderly people (Whitby 2011).  

In  this  paper  I  side  with  the  latter  concerns,  but  further  discuss 
what  specific  role  machine  can  or  cannot  be  given  within  health 
care (when exactly is it not acceptable to use a machine – even an 
intelligent one  and  one  that  can be  trained),  and draw  attention  to 
what has usually been neglected in discussions within the field: the 
relation  between  the  quality  of  care  and  the  labour  process,  and 
more  broadly,  the  relation  between  the  quality  of  care  and 
modernity. 

First  I  articulate  some  criteria  for  good  care  and  then  discuss 

whether machines as artificial agents can meet these criteria. 
 
2 GOOD CARE 

Let me articulate a normative ideal of good care: 

Good care involves a significant amount of human contact.   
Good  care  does  not  only  mean  physical  care  but  has  also 
psychological  and  relational,  e.g.  emotional  dimensions.  For 
example,  a  nurse  talking  to  a  patient  is  not  something  that  stands 
outside the care process but that should be part of it.  
Good  care  is  not  only  professional  care  but  should  also  involve 
relatives, friends, loved ones to a significant degree.  

Good  care  is  not  (only)  experienced  as  a  burden  but  is  also 
experienced as meaningful and valuable. 
Good  care  involves  skilled  engagement  with  the  patient  (know-
how),  next  to  more  formal  forms  of  expertise  (know-that). 
Elsewhere I have called this “care craftsmanship” (Author 2013). 
Good  care  requires  an  organizational  context  in  which  there  are 
limits  to  the  division  of  labour  so  as  to  not  make  the  previous 
criterion impossible to meet. 
Good  care  involves  an  organizational  context  in  which  financial-
economic  considerations  are  not  the  only  or  not  even  the  main 
criterion in the organization of care. 
Good  care  requires  of  the  patient  to  accept  some  degree  of 
vulnerability and dependency on others. 
These  criteria  of  good  care  are  not  uncontroversial;  there  are 
certainly  less  broad  definitions,  and  some  readers  will  disagree 
with  one  or  more  criteria.  But  for  the  sake  of  argument  let  us 
assume  this  rich  normative  ideal.  What  does  this  mean  for  the 
question regarding MCAs? 
 
3 ARTIFICIAL AGENTS AND CARE 

Let  us  now  evaluate  the  idea  to  introduce  MCAs.  By  itself,  the 
involvement of technology is not problematic. Medicine and health 
care  have  always  used  tools.  The  key  question,  however,  is  what 
happens in a situation where machines  appear as artificial agents. 
Of course all artefacts  may have a  minimal  form of  agency in the 
sense  of  having  some  influence  on  how  things  are  done  and  even 
on  what  is  done.  But  the  “MCAs”  concept includes  a  far  stronger 
idea  of  “agency”,  one  that  is  similar  to  human  agency.  As  the 
introductory  text  of  the  symposium  says,  we  are  considering 
machines  here  that  will  be  “working  with  people”.  This  raises  a 
number of problems in relation to the criteria just articulated. 

First,  even  philosophers  who  argue  that  we  should have  MCAs 
or  ethical  machines  in  health  care  will  not  want  a  situation  in 
which there are only machines in medicine and health care. Human 
contact  is  necessary.  Moreover,  most  philosophers  will  agree  that 
emotional and relational contact also belongs to good care. Now if 
this is right, then it means that MCAs are not acceptable in so far 
as they take over this particular human task. And this happens in so 
far  as  they  appear  as  agents.  If  the  robot  is  perceived  as  a  tool, 
then  the  agency  of  the  human  care  giver  and  the  corresponding 
responsibility to provide human contact and “care” in the sense of 
“care  about”,  concern,  remains  intact.  Then  the  care  giver  gives 
care with the tool, with technology. The machine mediates but does 
not have agency. But in so far as the machine takes on the role of a 
care agent, even if only in appearance, then it seems that something 
would be expected from the machine that the machine cannot give, 
and  that  in  a  situation  of  time  scarcity  (which  is  the  condition  in 

CONCLUSION 

To  conclude,  using  machines  in  health  care  is  in  principle 
acceptable,  but  in  so  far  as  they  function  and  appear  as  “agents” 
which  are  supposed  to  take  over  some  of  the  essential  care 
responsibilities identified they further threaten the fulfilment of the 
criteria  of  good  care,  which  are already  hard  to  meet  in  a  modern 
context.  The  design  and  use  of  machines  in  medicine  and  health 
care should therefore be re-directed to avoid these problems. If we 
want to use machines in ethical way, we should not make artificial 
agents  more  ethical;  we  should  tackle  the  problems  of  modern 
health care, and find a better role for machines in it. 

REFERENCES 
 Anderson,  Michael  and  Anderson,  Susan  Leigh.  2007.  Machine  Ethics: 

Creating an Ethical Intelligent Agent. AI Magazine 28(4): 15-26.  

Sharkey, Amanda and Noel Sharkey. 2010. Granny and the robots: Ethical 

issues in robot care for the elderly. Ethics and Information Technology 

14(1): 27-40.  

Sparrow, Robert and Linda Sparrow. 2006. In the hands of machines? The 

future of aged care. Minds and Machines 16: 141-161.  

Wallach,  Wendell  and  Allen,  Collin.  2008.  Moral  Machines:  Teaching 
Robots Right from Wrong. Oxford/New York: Oxford University Press. 

Whitby,  Blay.  2011.  Do  you  want  a  robot  lover?  In  Robot  ethics:  the 

ethical  and  social  implications  of  robotics.  Intelligent  robotics  and 
autonomous agents, 233-249. Cambridge, Mass: MIT Press. 

 

this  world)  time  is  taken  away  from  the  human  care  giver  to  take 
up this role and responsibility.  

Of  course  this  argument  assumes  that  machines  do  not  have 
emotions,  cannot  be  really  concerned.  Some  philosophers  might 
disagree,  but  they  have  the  burden  of  proof.  Note  also  that  this 
argument  does  not  exclude  the  use  of  robotic  pets  or  similar 
artefacts,  which  function  and  appear  as  agents  indeed,  but  do  not 
take  the  role  of  the  care  giver;  rather,  they  are  recipient  of  care. 
This is a different problem, which has been discussed elsewhere – 
including by the author. 

Second,  even  without  explicitly  considering 

the  role  of 
technology, current health care is highly professionalized, is often 
experienced  as  a  burden,  seems  to  have  an  emphasis  on  formal 
forms  of  expertise  rather  than  know-how  and  craftsmanship,  is 
usually  done  in  an organizational  context  in  which  there  is  a high 
degree  of  division  of  labour,  and  is  often  discussed  in  financial-
economic terms alone.  

relation 

This  development  must  be  understood  as  part  of  the  cultural-
material process and experience that is usually named “modernity”, 
which  has  its  brighter  and  its  darker  sides.  Contemporary  health 
care as “modern” health care means, for instance, that care giving 
work is divided into small units, is calculated, is professionalized, 
formalized  and  regulated.  As  Marx,  Weber,  and  other  classic 
theorists  of  modernity  have  pointed  out,  this  inevitably  leads  to 
objectification (or reification) and alienation. For health care work, 
this  means  that  care  has  become  “labour”  which  involves  an 
employment 
(with  professionalization,  disciplining, 
formalization  of  the  work,  management  etc.)  and  a  relation 
between care giver and care receiver in which the receiver appears 
to the care giver as an object (a thing rather than a human person, a 
subject)  and  which  makes  care  into  a  commodity,  a  product  or  a 
service.  Patients  and  other  vulnerable  people  are  managed  and 
processed.  This  degrades  not  only  the  care  receiver,  it  also 
alienates the care giver from her work and from the care  receiver. 
The care receiver encounters only a … “robot” care giver, a “robot 
nurse” or “robot doctor” who does only her small part of labour in 
the health care machine. In so far as this happens in contemporary 
health care, that is, in so far as contemporary health care is modern 
care,  the  quality  of  care  is  already  seriously  jeopardised  even 
without considering the role of the machine. 

labour 

into  small  units 

The  machine,  in  this  context,  is  usually  used  to  automate  the 
“production”.  The  division  of 
is 
accompanied  by,  or  perhaps  made  possible  or  increased,  by 
technology.  In  this  case,  the  worry  is  that  the  machine  is  used  to 
automate  health  care  as  part  of  its  further  modernization.  As  in 
historical  labour  processes,  this  means  that  human  workers  are 
replaced  by  machines.  Then  the  machine  indeed  takes  up  the  role 
of a care agent; then we encounter again the issue of replacement 
which is ethically problematic. Again, in so far as that happens, the 
criteria  of  good  care  are  not  met.  Perhaps  machines  can  be  given 
different  roles,  but  then  those  roles  or  functions  are  better  not 
“agency” ones. 

Finally, accepting vulnerability and dependency on others seems 
to be a precondition of human care, but in modernity we are very 
keen to keep our autonomy. We are so attached to it, that some of 
us  would  prefer  “machine  care”.  By  doing  this,  however,  we  risk 
to lose the humanity and dignity we were seeking to preserve. 

