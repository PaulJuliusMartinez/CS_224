From: AAAI-94 Proceedings. Copyright © 1994, AAAI (www.aaai.org). All rights reserved.

Symbolic Causal Networks

Adnan Darwiche Rockwell International Science Center
444 High Street Palo Alto, CA 94301
darwiche@rpal.rockwell.com

Judea Pearl Computer Science Department
University of California Los Angeles, CA 90024
pearl@cs.ucla.edu

Abstract
For a logical database to faithfully represent our beliefs about the world, one should not only insist on its logical consistency but also on its causal consistency. Intuitively, a database is causally inconsistent if it supports belief changes that contradict with our perceptions of causal influences - for example, coming to conclude that it must have rained only because the sprinkler was observed to be on. In this paper, we (1) suggest the notion of a causal structure to represent our perceptions of causal influences; (2) provide a formal definition of when a database is causally consistent with a given causal structure; (3) introduce symbolic causal networks as a tool for constructing databases that are guaranteed to be causally consistent; and (4) discuss various applications of causal consistency and symbolic causal networks, including nonmonotonic reasoning, Dempster-Shafer reasoning, truth maintenance, and reasoning about actions.

Introduction Consider the database,

A= wet-ground
sprinkler-was-on

1 it-rained 1 wet-ground,

which entails no beliefs about whether it rained last

night: A k it-rained and A &c=lit-rained.

If we tell

this database that the sprinkler was on, it surprisingly

jumps to the conclusion that it must have rained last

night: A U (sprinkler-was-on)

j= it-rained. This change

in belief is counterintuitive! Given that we perceive

no causal connection between the sprinkler and rain,

we would not come to believe that it rained only be-

cause we observed the sprinkler on. That is, database

A supports a belief change that contradicts common

perceptions of causal influences, hence, it will be la-

beled causally inconsistent.

For another example of causal inconsistency, con-

sider the database,

I? = kind > popular, fat > -popular.

Initially, this database is ignorant about whether the

person is kind: I' p kind and A k -kind.

How-

ever, once we tell the database that John is fat, it

jumps to the strange result that John must be unkind: I'U {fat) k -kind. Here also, the database contradicts
common perceptions of causal influences according to which no causal connection exists between kindness
and weight. Therefore, database I'is also causally in-
consistent. As it turns out, it is not uncommon for domain ex-
perts to construct databases that contradict with their
own perceptions of causal influences, especially when the database is large enough and has multiple authors.
The reason is that domain experts tend to focus on the plausibility of individual sentences rather than on the interactions among these sentences or how they would
respond to future information. But even when an expert is careful enough to con-
struct a causally consistent database, it is not uncom-
mon to turn it into a causally inconsistent one in the process of augmenting it with default assumptions. For example, an expert could have constructed the following database,

A= wet-ground A -rabl

> it-rained

sprinkler-was-on A la b2 > wet-ground,

which is causally consistent because it remains ignorant about rain given information about the sprinkler. However, a nonmonotonic formalism that minimizes
abnormalities would turn A into the database,

TabI /\ laba

A' = wet-ground A labI

> it-rained

sprinkler-was-on A la b2 > wet-ground,

which is causally inconsistent because it finds

sprinkler-was-on

a sufficient evidence for it-rained:

A' k it-rained and A' U {sprinkler-was-on}

b it-rained.

In fact, we shall see later that causally inconsistent

databases are also not uncommon in ATMS implemen-

tations of diagnosis systems and Dempster-Shafer rea-

soning, thus leading to counterintuitive results (Laskey

& Lehner 1989; Pearl 1990).

Given the importance of causal consistency, and

given the tendency to generate causally inconsistent

databases, we shall concern ourselves in this paper

with formalizing this notion in order to support do-

238 Causal Reasoning

Figure 1: A causal structure.
Figure 2: A causal structure.
main experts and commonsense formalisms in avoiding causally inconsistent databases.' In particular, we shall suggest the notion of a causal structure to represent perceptions of causal influences; provide a formal definition of when a database is causally consistent with a given causal structure; introduce symbolic causal networks as a tool for constructing causally consistent databases; and, finally, discuss various applications of symbolic causal networks, including nonmonotonic reasoning, truth maintenance, and reasoning about actions.
Causality and Belief Change Since causal consistency is relative to specific perceptions of causal influences, formalizing causal consistency requires one to represent these perceptions formally. For this purpose, we will adopt causal structures, which are directed acyclic graphs that have been used extensively in the probabilistic literature for the same purpose (Pearl 1988b; Spirtes, Glymour, & Schienes 1993) - see Figures 1 and 2.2
The parents of a proposition p in a causal structure are those perceived to be its direct causes.
`The discussion in this paper is restricted to propositional databases.
2The results in this paper do not depend on a graphical representation of causal influences. For example, one can introduce a predicate Direc+Cause and proceed to axiomatize the contents of a causal structure.

The descendants of p are called its effects and the

non-descendants of p are called its non-effects. In

the structure of Figure 2, drunk and injured are the

direct causes of unable-to-stand;

unable-to-stand

and

whiskey-bottle are the effects of drunk; while injured

and bloodstains are its non-effects.

Propositions that are relevant to the .domain un-

der consideration but do not appear in a causal struc-

ture are called the exogenous propositions of that

structure. Exogenous propositions are the source of

uncertainty in causal influences. They appear as ab-

normality predicates in nonmonotonic reasoning (Re-

iter 1987), as assumption symbols in ATMSs (de Kleer

1986), and as random disturbances in probabilistic

models of causality (Pearl & Verma 1991). Each state

of exogenous propositions will be referred to as an ex-

tension. For example, if abl and ab2 are the exoge-

nous propositions of the structure in Figure 1, then

labI A ab2 is an extension of that structure. Given

an extension of a causal structure, there would be no

longer any uncertainty about the causal influences it

portrays.

The basic premise of this paper is that changes in our

beliefs are typically constrained by the causal struc-

tures we perceive (Pearl 1988a). And the purpose of

this section is to make these constraints precise so that

a database is said to be consistent with a causal struc-

ture precisely when it does not contradict such con-

straints. The key to formalizing these constraints is

the following interpretation of causal structures:

The truth of each proposition in a causal structure is functionally determined by (a) the truth of its
direct causes and (b) the truth of all exogenous propositions.

Following are some constraints on belief changes that are suggested by the above interpretation of causal structures (Pearl 1988b):
Common causes: In Figure 3a, the belief in c2 should be independent of information about cl assuming that no information is available about e and that all exogenous propositions are known.
Indirect eflects: In Figure 3b, the belief in e should be independent of information about c whenever proposition m and all exogenous propositions are known.
Common e$ects: In Figure 3c, the belief in e2 should be independent of information about el given that proposition c and all exogenous propositions are known.
These constraints on belief changes and others are summarized by the principle of causal independence, which is a version of the Markovian Condition in the probabilistic literature (Pearl 198813; Spirtes, Glymour, & Schienes 1993). In a nutshell, the principle says that "once exogenous propositions and the direct causes of a proposition are known, the belief in that proposition should become independent

Causal Reasoning 239

Figure 3: Causal interactions.

of information about its non-effects."3 We will formalize this principle in the remainder of
this section and then use it later in defining causal consistency. But first, we need to define when database A finds X conditionally independent of Y given 2, that is, when adding information about Y to A does not change its belief in any information about X4 given that A has full information about Z.5 The following definition captures exactly this intuition:

Definition 1 (Conditional Independence)

Let

X, Y, and Z be disjoint sets of atomic propositions

and let X,Y, and Z be instantiations of these propo-

sitions, respectively. Database A finds X independent

of Y g,i.venh Z precisely hwhnen the logical consistency of

AU(Z,X)

and AU(Z,Y)

implies the logical consis-

tency of A U {2, ?, 2).

This is equivalent to saying that if A has full information about Z, then the addition of information about
Y to A will not change its belief in any information about X.6 For example, the database

it-rained V sprinkler-was-on E wet-ground

finds {it-rained} independent of (sprinkler-was-on),

but

finds them dependent given {wet-ground}.

Similarly,

the database,

it-rained > wet-ground,

wet-ground 3 slippery-ground,

finds (slippery-ground}

dependent on {it-rained}, but

finds them independent given {wet-ground}.

Finally,

3The requirement of knowing exogenous propositions
renders this principle applicable to incomplete causal structures and constitutes, in fact, a definition of what information ought to be summarized by the exogenous variables.
4By informati on about a set of atomic propositions
we mean a logical sentence constructed from these propositions.
5Database A has full information about atomic propositions 2 if for each p in 2, A entails p or entails lp.
`This notion of independence is isomorphic to the one known in the literature on relational databases as multivalued embedded dependencies. Therefore, this notion of independence satisfies the graphoid axioms (Pearl 1988b),
which include symmetry (X is independent of Y given 2 precisely when Y is independent of X given 2).

the database,

battery-is-ok > lights-on, ibattery-is-ok

1 lcar-starts,

finds {lights-on) dependent on {car_starts), but finds them independent given {battery-is-ok}.
We are now ready to state the principle of causal independence formally:

Definition 2 (Causal Independence)

Database A

satisfies the principle of causal independence with re-

spect to causal structure G precisely when (a) A is logi-

cally consistent and (b) for every extension E of G that

is logically consistent with A, the database A U (8)

finds each proposition in 6 conditionally independent

of its non-e$ects given its direct causes.

Causal Consistency Consider the following database,

A=

wet-ground A labI

>

sprinkler-was-on A la b2 >

it-rained wet-ground.

This database does not satisfy the principle of causal independence with respect to the structure in Figure 1 because it finds sprinkler-was-on a sufficient evidence for it-rained under the extension -rabl A laba.
Note, however, that although database A does not
satisfy the principle of causal independence, it does not contradict it either. Specifically, the extended database AU {a bl V ab2) satisfies the principle because the added sentence abl V ab2 rules out the only extension, TabI A laba, under which the database violates the principle. This suggests the following definition:

Definition 3 (Causal Consistency) Let A be a database and let G be a causal structure. An extension C of G is causally consistent with A precisely when A U (8) satisfies the principle of causal independence with respect to g.
That is, the extension TabI A laba above is causally inconsistent with database A, while the remaining extensions TabI A abz, abl A -rabz, and abl A abz are causally consistent with it.
We can further define a database as causally consistent precisely when it has at least one causally consistent extension. A definition of causal consistency was given in (Goldszmidt & Pearl 1992) for databases

240 Causal Reasoning

containing defeasible conditionals (defaults) and was based on a probabilistic semantics of defeasible conditionals. Definition 3 is based on standard propositional semantics, which makes it directly applicable to commonsense formalisms based on classical logic. Moreover, causal consistency as we have defined it here is a semantical notion, independent of database syntax.
As we mentioned earlier, even when a domain expert is careful enough to construct a causally consistent database, it is not uncommon for a nonmonotonic formalism to turn it into a causally inconsistent one. Consider, for example, the database

whiskey-bottle A labI

1 drunk

A= drunk A labs

1 unable-to-stand

unable-to-stand A labs > injured

injured A lab4

r> bloodstains,

which could easily be authored by a person perceiv-

ing the causal structure in Figure 2. When this

database is fed to a nonmonotonic formalism that min-

imizes abnormalities, the formalism ends up augment-

ing it with the extension 8 = (la bl , la b2, la ba, -raba},

which is causally inconsistent with A. Specifically,

AuE jumps to the conclusion bloodstains only because

whiskey-bottle was observed: A U E /& bloodstains and

A U I U (whiskey-bottle)

b bloodstains.

With respect to the structure in Figure 2, database

A has sixteen extensions corresponding to the different

instantiations of the four abnormality predicates. As

it turns out, all extensions containing --rab% A ia ba are

causally inconsistent, including the extension in which

all abnormalities are minimized.

One way to avoid selecting these counterintuitive ex-

tensions is to inform nonmonotonic formalisms about

causal consistency and provide them access to causal

structures. A nonmonotonic formalism would then in-

sist that only causally consistent extensions are se-

lected. This approach should then lead to causal

versions of existing nonmonotonic formalisms - for

example, causal circumscription, causal default logic,

and so on - in which each theory has a causal struc-

ture associated with it (Goldszmidt & Pearl 1992).

Another solution is to feed nonmonotonic formalisms

databases that already satisfy the principle of causal

independence. In this case, nonmonotonic formalisms

need not know about causality; they are guaranteed to

stay out of danger because any extension that is logi-

cally consistent with the database is also causally con-

sistent with it. For example, the database A U {abz V

aba} satisfies the principle of causal independence be-

cause the four extensions that are causally inconsistent

are also logically inconsistent with the database. We

will provide in the next section a systematic method

for constructing databases that satisfy the principle of

causal independence, thus eliminating the need to test

for the causal consistency of extensions.

The connection between causality and nonmono-

tonic reasoning was discussed in (Pearl 1988a), where a

system, called C-E, has been proposed for ensuring the

faithfulness of default inferences to causal perceptions.

In the C-E system, causality is represented by classify-

ing defaults into either causal or evidential rules. We

observe, however, that by classifying rules as such, one

is indirectly communicating a causal structure. For

example, the C-E rules wet-ground -E

it-rained and

sprinkler-was-on WC wet-ground implicitly encode the

causal structure in Figure 1. In the C-E system, a

causal structure is used procedurally to block default

inferences that contradict with the structure. In the

approach described here, a causal structure is used

declaratively to classify extensions into those consis-

tent with the structure and those inconsistent with it.

Separating the causal structure from the rule syntax

has a number of merits. First, it keeps one within the

realm of classical logic, which makes the approach ap-

plicable to logic-based formalisms such as circumscrip-

tion and ATMSs. Next, using rules to communicate a

causal structure may overburden domain experts. For

example, to express the sentence -sprinkler,was-on

A

lit-rained

> lwet-ground,

one needs three C-E

rules: lsprinkler-was-onAlit_rained

--+c -wet,ground,

wet-ground A lit-rained -+E sprinkler-was-on, and

wet-ground A isprinkler-was-on

BE it-rained. Finally,

it is not always clear whether a rule is causal or ev-

idential. For example, given the rules it-rained --+c

-cprinkler-was-on7

and wet-ground -J-J it-rained, it is

not clear whether the rule lit-rained A wet-ground b

sprinkler-was-on is evidential or causal.

Symbolic Causal Networks
We will concern ourselves in this section with providing a systematic procedure that is guaranteed to generate databases that are not only causally consistent, but also satisfy the principle of causal independence. Therefore, the generated databases can be given to nonmonotonic formalisms without having to worry about whether adding assumptions will make them causally inconsistent.
The procedure we propose is that of constructing a symbolic causal network: a propositional database that is annotated by a causal structure.
A symbolic causal network has two components: A causal structure 6 that captures perceptions of causal influences and a set of micro theories capturing logical relationships between propositions and their direct causes - see Figures 4 and 5.
A micro theory for p is a set of clauses 6, where
1. each clause in 6 refers only to p, its direct causes, and `to exogenous propositions;
2. if S entails a clause that does not mention p, then that clause must be vacuous.
Condition 1 ensures the locality of a micro theory to a proposition and its direct causes, while Condition 2
`We have a device that deactivates the sprinkler when it detects rain.

Causal Reasoning

241

al => battery-ok

key-turned & battery-ok & a2 => car-starts -battery-ok Jz a3 => -car starts

Figure 4: A symbolic causal network.

prohibits a micro theory for p from specifying a relationship between the direct causes of P.~
One can ensure the previous conditions by adhering to micro theories that contain only two types of material implications: $ A cy > p and q5A ,O > lp, where
1. $Jand 4 are constructed from the direct causes of p;
2. o and p are constructed from exogenous propositions; and

3. o A p is unsatisfiable whenever 1c,A 4 is satisfiable.

For example, the sentences kind A labI > popular and fat A lab2 > -popular do not constitute a micro

theory for popular since -rabl A -rabz and kind A fat

are both satisfiable. This leads to the relationship

-ablAlabzAfat

> -kind between weight and kindness,

thus violating Condition 2 of micro theories.

We stress here that micro theories do not appeal

to the distinction between evidential and causal rules.

Formally, a micro theory contains standard proposi-

tional sentences and is constrained only by its local-

ity (to specific propositions) and by what it can ex-

press about these propositions, both are characteristic

of causal modeling. For example, one typically does

not specify a relationship between the inputs to a dig-

ital gate by stating that certain input combinations

would lead to conflicting predictions about the output.

If one induces a propositional database using a sym-

bolic causal network - that is, by associating micro

theories with the propositions of a causal structure -

then one is guaranteed the following:

Theorem 1 Let A be a database bolic causal network having causal A satisfies the principle of causal respect to 6.

induced by a symstructure $?. Then independence with

`The satisfaction of such local conditions permits us to predict feasible scenarios in a backtrack-free manner (Dechter & Pearl 1991).

As a representational language, symbolic causal networks are complete with respect to databases that do not constrain the state of exogenous propositions:
Theorem 2 Let A be a database satisfying the principle of causal independence with respect to a causal
structure s. If A is logically consistent with every
extension of g, then A can be induced by a symbolic causal network that h.as 6 as its causal structure.
Applications of Symbolic Causal Networks
The basic motivation behind symbolic causal networks has been their ability to guarantee causal consistency. But symbolic causal networks can be viewed as the logical analogue of probabilistic causal networks; see Table 1. Therefore, many of the applications of probabilistic causal networks have counterparts in symbolic causal networks. We elaborate on some of these applications in this section. Other applications, such as diagnosis, are discussed elsewhere (Darwiche 1993).

Logical consistency

One of the celebrated features

of probabilistic causal networks is their ability to en-

sure the global consistency of the probability distri-

bution they represent as long as the probabilities as-

sociated with each proposition in a causal structure

are locally consistent. Symbolic causal networks pro-

vide a similar guarantee: As long 1 the micro theories

associated with individual proposi-r Ion.. satisfy their lo-

cal conditions, the global database is guaranteed to be

logically consistent. This is a corollary of Theorem 1.

Causal truth maintenance

In the same way that

probabilistic causal networks are supported by algo-

rithms that compute probabilities (Pearl 1988b), sym-

bolic causal networks are supported by algorithms that

compute ATMS labels (Darwiche 1993; de Kleer 1986;

242 Causal Reasoning

Represents Graphically Encodes Guarantees
Computes

Probabilistic causal network probability distribution + effects of actions probabilistic independences + causal structure
probabilistic consistency Markovian condition
probabilities

Symbolic causal network
propositional database + effects of actions logical independences + causal structure logical consistency causal independence
arguments (ATMS labels)

Table 1: Analogous notions in probabilistic and symbolic causal networks.

Reiter & de Kleer 1987).' Therefore, symbolic causal networks inherit the applications of ATMSs. The important difference with traditional ATMSs, however, is that the database formed by a symbolic causal network is guaranteed (by satisfying causal independence) to protect us from conclusions that clash with our causal understanding of the domain. The importance of this property is best illustrated by an example that uses ATMSs to implement Dempster-Shafer reasoning (Laskey & Lehner 1989; Pearl 1990). Specifically,
the Dempster-Shafer rules, wet-ground z it-rained
and sprinkler-was-on 2 wet-ground, are typically reasoned about in an ATMS framework by constructing the database,

A=

wet-ground A al

>

sprinkler-was-on A a2 >

it-rained wet-ground,

and attaching probabilities .7 and .9 to the assump-

tions al and a2 (Laskey & Lehner 1989). Initially, the

ATMS label of it-rained is empty and, hence, the belief in it-rained is zero. After observing sprinkler-was-on, however, the ATMS label of it-rained becomes al A as,
which raises the belief in it-rained to .7* .9 = .63. That

is, the belief in it-rained increased from zero to .63 only because sprinkler-was-on was observed; see (Pearl 1990)

for more related examples.

We get this counterintuitive behavior here because

database A does not satisfy the principle of causal in-

dependence with respect to the causal structure in Fig-

ure 1. If the database satisfies this principle, the ATMS

label of it-rained is guaranteed not to change as a result

of adding sprinkler-was-on to the database - see (Dar-

wiche 1993) for more details on this guarantee. For

example, the database A U {la1 V la2) satisfies the

principle of causal independence with respect to the

causal structure in Figure 1. Therefore, the ATMS la-

bel it assigns to it-rained is empty and so is the label

that A U {sprinkler-was-on}

assigns to it-rained. This

guarantees that Dempster-Shafer belief in it-rained re-

mains zero after sprinkler-was-on is observed.

`More precisely, symbolic causal networks compute argzsmepzts,which are logically equivalent to ATMS labels but
are not necessarily put in canonical form (Darwiche 1993). Computing arguments is easier than computing ATMS labels. In fact, the complexity of computing arguments in
symbolic causal networks is symmetric to the complexity of computing probabilities in probabilistic causal networks
(Darwiche 1992; 1993).

PLeasoning about actions

Our focus so far has

been the enforcement of causal constraints on be-

lief changes that result from observations (belief re-

visions). But perceptions of causal influences also con-

strain (and in fact are often defined by) belief changes

that result from interventions (named belief updates

in (Katsuno & Mendelzon 1991)). For example, if we

connect C in the first circuit of Figure 5 to a high volt-

age, we would come to believe that A and D will be

set to OFF. But if we perform the same action on the

second circuit, we would not come to the same belief.

Note, however, that the two circuits have the same

logical description, and do not mention external inter-

ventions explicitly, which means that they would lead

to equivalent belief changes under all observations.

The reason why the same action leads to different results from two logically equivalent descriptions is that the descriptions are accompanied by different causal structures. It is the constraints encoded by these structures that govern our expectations regarding interventions in these circuits (Goldszmidt & Pearl 1992). A related paper (Darwiche & Pearl 1994) provides a specific proposal for predicting the effect of action when domain knowledge is represented using a symbolic causal network, showing also how the frame, ramification and concurrency problems can be handled effectively in this context. The key idea is that micro theories allow one to organize causal knowledge efficiently in terms of just a few basic mechanisms, each involving a relatively small number of propositions. Each external elementary action overrules just one mechanism leaving the others unaltered. The specification of an action then requires only the identification of the mechanism which is overruled by that action. Once this is identified, the overall effect of the action (or combinations thereof) can be computed from the immediate effect of the action, combined with the constraints imposed by the remaining mechanisms. Thus, in addition to encoding a set of current beliefs, and belief changes due to hypothetical observations, a causal database constrains how future beliefs would change in response to every hypothetical action or actions combination (Pearl 1993). These latter constraints can in fact be viewed as the defining characteristic of causal relationships, of which the Markovian condition is a byproduct (Pearl & Verma 1991).
CausaI Reasoning 243

r
C&ok(X)=>-A -C&ok(X)=>A

\ AB

I A&B&ok(Y)=>D -(A&B) & okqY) => -D

A&ok(X)=>4 -A&ok(X)=>C I

A&B&ok(Y)=>D -(A&B)&ok(Y)=>-D

Figure 5: Different symbolic causal networks leading to logically equivalent databases.

Conclusion
If a classical logic database is to faithfully represent our beliefs about the world, the database must be consistent with our perceptions of causal influences. In this paper, we proposed a language for representing such perceptions and then formalized the consistency of a logical database relative to a given causal structure. We also introduced symbolic causal networks as tools for constructing databases that are guaranteed to be causally consistent. Finally, we discussed other applications of symbolic causal networks, including the maintenance of logical consistency, nonmonotonic reasoning, Dempster-Shafer reasoning, truth maintenance, and reasoning about actions and change.
Acknowledgments
The research was partially supported by ARPA contract #F30602-91-C-0031, Air Force grant #AFOSR 90 0136, NSF grant #IRI-9200918, and NorthropRockwell Micro grant #93-124. This work benefitted from discussions with Moises Goldszmidt and SekWah Tan.
References
Darwiche, A., and Pearl, J. 1994. Symbolic causal networks for reasoning about actions and plans. Working notes: AAAI Spring Symposium on Decision-Theoretic Planning.
Darwiche, A. 1992. A Symbolic Generalization of Probability Theory. Ph.D. Dissertation, Stanford University.
Darwiche, A. 1993. Argument calculus and networks. In Proceedings of the Ninth Conference on Uncertainty in Artificial Intelligence (UAI), 420-427.
de Kleer, J. 1986. An assumption-based TMS. Artificial Intelligence 28:127-162.
Dechter, R., and Pearl, J. 1991. Directed constraint networks: A relational framework for causal modeling. In Proceedings, 12th International Joint Conference of Artificial Intelligence (IJCAI-91), 1164-1170.

Goldszmidt, M., and Pearl, J. 1992. Rank-based systems: A simple approach to belief revision, belief update and reasoning about evidence and actions. In
Proceedings of the Third Conference on Principles of Knowledge Representation and Reasoning, 661-672. Morgan Kaufmann Publishers, Inc., San Mateo, California.
Katsuno, H., and Mendelzon, A. 1991. On the difference between updating a knowledge base and revising it. In Principles of Knowledge Representation and
Reasoning: Proceedings of the Second International
Conference, 387-394.
Laskey, K. B., and Lehner, P. E. 1989. Assumptions, beliefs, and probabilities. Artificial Intelligence 41( 1):65-77.
Pearl, J., and Verma, T. 1991. A theory of inferred causation. In Principles of Knowledge Representation and Reasoning: Proceedings of the Second International Conference, 441-452.
Pearl, J. 1988a. Embracing causality in default reasoning. Artificial Intelligence 35:259-271.
Pearl, J. 1988b. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann Publishers, Inc., San Mateo, California.
Pearl, J. 1990. Which is more believable, the probably provable or the provably probable. In Proceedings, CSCSI-90, 8th Canadian Conference on AI, l-7.
Pearl, J. 1993. From bayesian networks to causal networks. Technical Report R-195-LLL, Cognetive Systems Laboratory, UCLA. (Short version in Statistical Science, Vol. 8, No. 3 (1993), pp. 266-269.).
Reiter, R., and de Kleer, J. 1987. Foundations of assumption-based truth maintenance systems: Preliminary report. In Proceedings of AAAI, 182 -188. AAAI.
Reiter, R. 1987. Nonmonotonic reasoning. Ann. Rev. Comput. Sci 2~147-186.
Spirtes, P.; Glymour, C.; and Schienes, R. 1993. Causation, Prediction, and Search. New York: SpringerVerlag .

244 Causal Reasoning

