13TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, VOL. 1, JULY 1998

1

Texture Classification Using Nonparametric Markov Random Fields
R. Paget, I. D. Longstaff, and B. Lovell

Abstract-- We present a nonparametric Markov Random Field model for classifying texture in images. This model can capture the characteristics of a wide variety of textures, varying from the highly structured to the stochastic. The power of our modelling technique is evident in that only a small training image is required, even when the training texture contains long range characteristics. We show how this model can be used for unsupervised segmentation and classification of images containing textures for which we have no prior knowledge of the constituent texture types. This technique can therefore be used to find a specific texture in a background of unknown textures.
I. Introduction
The process of classifying textures in an image usually requires prior knowledge of all textures that may occur [1]. Where this is known, texture models need capture only sufficient characteristics to discriminate between the set of known textures, and then discriminant analysis for instance may be used [2]. However, for images where not all textural types are known, a texture model needs to capture all relevant features that characterise a particular texture. Then to segment and classify an image, the model of a known texture can be statistically compared with regions in the image to determine the probability that the region matches the known texture. This sort of modelling is also required when discriminant analysis can not be used because background textures in an image are non-uniform.
As yet, texture recognition is not a fully understood problem and the characteristics needed to differentiate textures have not been fully delineated. Therefore, deriving a model to capture all relevant characteristics that differentiate a particular texture from any other remains an open prob-
The authors are with the Department of Electrical and Computer Engineering, University of Queensland, QLD 4072 AUSTRALIA. E-mail: {paget,idl,lovell}@elec.uq.edu.au
This work was supported by the Cooperative Research Centre for Sensor, Signal, and Information Processing.

lem [3].
A reasonable way to test whether a texture model has captured all relevant characteristics is to synthesise a texture from the model and evaluate how similar it is to the original. How to evaluate similarity is an open-ended problem; it requires us to set the criteria for similarity. (Clearly white noise with odd parity would be statistically different from white noise with even parity.) One benchmark test of similarity is a subjective comparison, by eye, of the synthesised texture with the training texture. We assume that if the texture synthesised from the model is indistinguishable by eye from the training texture then the model is adequate for most applications. Current models such as auto-models, autoregressive (AR) models, moving average (MA) models and autoregressive moving average (ARMA) models have not been shown to realistically synthesise natural textures [4] such as those in the Brodatz album [5]. However, we [6], [7] have recently used a nonparametric Markov Random Field (MRF) model to successfully synthesise realistic representations of structured and stochastic textures with minimal phase discontinuities.
In this paper, we present a new approach: using the nonparametric MRF model to model just one texture and then using that model to map the probability of each pixel in an image being of the given texture. This approach is similar to that used by Greenspan et al. [8] to produce a probability map locating all texture in an image similar to a given texture. We show that our model captures enough relevant characteristics of a given texture to determine the probability of each pixel in an image being that texture without using discriminant analysis. With this model, we can segment and classify an image containing an undefined number of different texture types.

2 13TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, VOL. 1, JULY 1998

II. Texture Model
MRF models have been used in image restoration, region segmentation, and texture synthesis [9]. The property of a MRF is that a variable Xs on a lattice S = {s = (i, j) : 0  i, j < N } may have its value xs set to any value, but the probability of Xs = xs is conditional upon the values xr at its neighbouring sites r  Ns. A Local Conditional Probability Density Function (LCPDF) defined over these neighbouring sites r  Ns determines the probability of Xs = xs as,

histogram with dimensions L0, L1, where L0 represents the pixel value xs and L1 represents the relative neighbouring pixel value xs-1. We initialise F (L0, L1) = 0  L0, L1. Then by raster scanning the image, we increment the variable F (L0 = xs, L1 = xs-1) for each site s  S, Ns  S. The simple estimate of the LCPDF is then given by

P^(xs|xs-1) =

F (L0 = xs, L1 = xs-1) . L0 F (L0, L1 = xs-1)

(3)

F(L 0,L 1)

P (Xs = xs|Xr = xr, r  Ns) s  S, (1)
which in turn defines the MRF [10]. To model an image as a MRF, we consider each
pixel in the image to be a site on a lattice, and the grey scale value of that pixel as the value of that site. If the image is all of one texture, then the derived LCPDF is the model that defines the texture.

(a) (b)

(c)

Fig. 1. Neighbourhoods. (a) The first order neighbourhood (c = 1) or "nearest-neighbour" neighbourhood for the site s = (i, j) = `·' and r = (k, l)  Ns = `'; (b) second order neighbourhood (c = 2); (c) eighth order neighbourhood (c = 8).

We used the neighbourhood Nsc of Geman [11], [3], defined as

xs-1 xs (a)

7
L0 00 (b)

7 L1

Fig. 2. Neighbourhood and its 2-D histogram

Data obtained from the image to build a multi-dimensional histogram are not independent and identically distributed (i.i.d.). However, the pseudo-likelihood estimate [12] of the LCPDF uses the same non i.i.d. data. Geman and Graffigne [13] proved that the pseudo-likelihood estimate converged to the true LCPDF with probability 1 as the image size increased to infinity. We use this evidence to justify use of non i.i.d. data for estimating our non-parametric version of the LCPDF.
The true LCPDF is given by a histogram built from an infinite amount of sample data. Therefore, the true LCPDF needs to be estimated from a multi-dimensional histogram. Where a domain is only sparsely populated with sample data, it is advantageous to use a non-parametric density estimator [14].

Nsc = {r = (k, l)  S : 0 < (k - i)2 + (l - j)2  c}, (2)
where c refers to the order of the neighbourhood system. Neighbourhood systems for c = 1, 2 and 8 are shown in Fig. 1 (a), (b), and (c) respectively.
Given an image of a homogeneous texture and a predefined neighbourhood system, we can gain a non-parametric estimate of the LCPDF by building a multi-dimensional histogram of the image.
For example, if we choose a neighbourhood Ns = {s - 1} as shown in Fig. 2(a). To estimate the respective LCPDF, we build a 2-dimensional

A. Parzen Window Density Estimator

The Parzen-window density estimator [14] has
the effect of smoothing each sample data point in
a multi-dimensional histogram over a larger area. Denoting the sample data as Zs = Col[xs, xr, r 
Ns] s  S, Ns  S, for a column vector z = Col[L0, Lnr , r  Ns], the Parzen-window density estimated frequency F^(z) of the frequency F in
(3) is

F^(z)

=

1 nhd

K

1 h

(z

-

Zs)

,

sS,NsS

(4)

PAGET, LONGSTAFF AND LOVELL: TEXTURE CLASSIFICATION USING NONPARAMETRIC MRFS

3

where n is the number of sample data Zs, h is the window parameter, and d = |Ns| + 1 equals the number of elements in the vector z [14, p 76].
The shape of the smoothing is defined by the kernel function K. We choose K as the standard multi-dimensional Gaussian density function,

K (z)

=

1 (2)d/2

exp(-

1 2

zTz).

(5)

The size of K is defined by the window parameter h. We aim to choose h so as to obtain the best estimate of the frequency distribution F^ for the LCPDF. Silverman [14, p 85] provides an optimal window parameter:

A. Probability measurement
The probability (xr, r  Ws) as defined by (7) was found to give poor classification results. This was because our nonparametric LCPDF tended to give low probabilities for the neighbourhood configurations in the classification window, which resulted in (xr, r  Ws) being too susceptible to any minor fluctuations in these neighbourhood probabilities. Instead, we used the set of probabilities defined by the LCPDF for the window Ws and compared them directly to the set of probabilities obtainable from the sample texture.
Probability P (xr, xt, t  Nr) is calculated from (4) and (5) as

hopt = 

4 1/(d+4) ,
n(2d + 1)

(6)

where 2 is the average marginal variance. In our
case, marginal variance is the same in each dimension and therefore 2 equals the variance associ-
ated with the one-dimensional histogram.

III. Texture Classification
In our classification method, each individual pixel in an image is assessed for its probability of being the original texture. In a more sophisticated version of this method, we could reasonably assume that pixels close to each other exhibit similar probabilities. It may also be prudent to incorporate boundary detection as part of a constrained optimisation of the probability map as discussed by Geman et al. [15]. Such improvement are application-driven. Here, we limit ourselves to outlining the simple version of our classification method.
For cases when the image was not all of one texture, Geman and Graffigne [13] assumed that small areas of the image were homogeneous and of one texture. They classified on the basis that the product of the joint probabilities for a neighbourhood over the area of concern resembles the joint probability for the area, that is,

(xr, r  Ws)

P (xr, xt, t  Nr), (7)

r:Nr Ws

where Ws is the window of sites, centred at s, which are to be used for the classification of xs.

P (xr, xt, t  Nr) =

1 nhd(2)d/2

exp

pSy ,

-

1 2h2opt

(z

-

Zp)T(z

-

Zp)

,

NpSy

(8)

where z = Col[xr, xt, t  Nr] and Zp are samples taken from the sample texture y defined on the
lattice Sy. The samples of the LCPDF, taken from the window Ws  S, are the set of probabilities {P (xr, xt, t  Nr), r : Nr  Ws}.
We calculate the probabilities for sample texture y for every site q  Sy, Nq  Sy in a similar fashion to (8), except for a pixel q  Sy we do not include the sample data Zp = Col[yq, yt, t  Nq] in the calculation. This is done to prevent the probability P (yq, yt, t  Nq) from being biased.
With the set of probabilities {P (xr, xt, t  Nr), r : Nr  Ws} from the window to be classified, and the set of probabilities {P (yq, yt, t  Nq), q  Sy, Nq  Sy} from the sample texture, we are now able to determine the classification proba-
bility. The null hypothesis is that the distribution
of probabilities from the window is the same as the
distribution from the sample texture. For this test
we use the nonparametric Kruskal-Wallis test [16].
The sampling distribution of the Kruskal-Wallis
statistic K is approximately chi-squared with 1 de-
gree of freedom. Given K, the accepted practice
is to accept or reject the null hypothesis on the
basis of a particular significance level . In our
approach we wished to find the confidence associ-
ated with accepting the null hypothesis. This con-
fidence, for a particular window Ws, is denoted as

4 13TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, VOL. 1, JULY 1998

PWs :

PWs = P (k  K),

(9)

where k is chi-squared distributed with one degree
of freedom. It is this probability/confidence PWs with which we plot our probability map.

IV. Results
We use a neighbourhood system of order 2 in our model to obtain the probability maps of Fig. 3. These probability maps show that with our texture model it is possible to segment and classify windows of texture with respect to just one sample texture and without prior knowledge of other types of textures present in the image. As the segmentation/classification method is able to distinguish those textures similar to the sample texture from those that are dissimilar, this indicates that our model has captured all relevant features needed to characterise a particular texture.

ages," IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 6, no. 6, pp. 721­741, 1984. [12] Julian E. Besag and P. A. P. Moran, "Efficiency of pseudo­likelihood estimation for simple Gaussian fields," Biometrika, vol. 64, pp. 616­618, 1977. [13] S. Geman and C. Graffigne, "Markov random field image models and their applications to computer vision," Proceedings of the International Congress of Mathematicians, pp. 1496­1517, 1986. [14] B. W. Silverman, Density estimation for statistics and data analysis, Chapman and Hall, London, 1986. [15] Donald Geman, Stuart Geman, Christine Graffigne, and Ping Dong, "Boundary detection by constrained optimization," IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 12, no. 7, pp. 609­628, 1990. [16] Lawrence L. Lapin, Probability and Statistics for Modern Engineering, PWS­KENT, Boston, 1990.

References
[1] Rama Chellappa and Shankar Chatterjee, "Classification of textures using Gaussian Markov random fields," IEEE Transactions on Acoustics, Speech, and Signal Processing, vol. ASSP­33, no. 4, pp. 959­963, 1985.
[2] Richard O. Duda and Peter E. Hart, Pattern Classification and Scene Analysis, John Wiley, Stanford Reseach Institute, Menlo Park, California, 1973.
[3] D. Geman, "Random fields and inverse problems in imaging," in Lecture Notes in Mathematics, vol. 1427, pp. 113­ 193. Springer­Verlag, 1991.
[4] Michal Haindl, "Texture synthesis," CWI Quarterly, vol. 4, pp. 305­331, 1991.
[5] P. Brodatz, Textures ­ a photographic album for artists and designers, Dover Publications Inc., New York, 1966.
[6] Rupert Paget and Dennis Longstaff, "Texture synthesis via a nonparametric Markov random field," in Proceedings of DICTA­95, Digital Image Computing: Techniques and Applications, Anthony Maeder and Brian Lovell, Eds., Brisbane, Australia, Dec. 1995, vol. 1, pp. 547­552, Australian Pattern Recognition Society, http://www.vision. ee.ethz.ch/~rpaget.
[7] Rupert Paget, Dennis Longstaff, and Brian Lovell, "Multiscale texture segmentation of synthetic aperture radar images," IEEE ICASSP­94, International Conference on Acoustics, Speech and Signal Processing ­ student presentation, Apr. 1994.
[8] H. Greenspan, R. Goodman, R. Chellappa, and C. H. Anderson, "Learning texture discrimination rules in multiresolution system," IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 16, no. 9, pp. 894­901, 1994.
[9] Richard C. Dubes and Anil K. Jain, "Random field models in image analysis," Journal of Applied Statistics, vol. 16, no. 2, pp. 131­164, 1989.
[10] Julian E. Besag, "Spatial interaction and the statistical analysis of lattice systems," Journal of the Royal Statistical Society, series B, vol. 36, pp. 192­326, 1974.
[11] Stuart Geman and Donald Geman, "Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of im-

PAGET, LONGSTAFF AND LOVELL: TEXTURE CLASSIFICATION USING NONPARAMETRIC MRFS

5

(a.1)

(a.2)

(b.1)

(b.2)

(a.3) (b.3)

(c.1) Probability scale

(c.2) 0

(c.3)

1

Fig. 3. Probability maps of medical images: (a) lymphoid follicle in the cervix; (b) small myoma; (c) focus of stromal differentiation in the myometrium. Sample textures (a.1) (b.1) (c.1) were used to segment and classify medical images (a.2) (b.2) (c.2) producing the probability maps (a.3) (b.3) (c.3), respectively.

