LPG: A Planner Based on Local Search for Planning Graphs with Action Costs

Dipartimento di Elettronica per l’Automazione, Universit`a degli Studi di Brescia

Alfonso Gerevini and Ivan Serina

Via Branze 38, I-25123 Brescia, Italy

{gerevini,serina}@ing.unibs.it

Abstract

We present LPG, a fast planner using local search for solving
planning graphs. LPG can use various heuristics based on
a parametrized objective function. These parameters weight
different types of inconsistencies in the partial plan repre-
sented by the current search state, and are dynamically eval-
uated during search using Lagrange multipliers. LPG’s basic
heuristic was inspired by Walksat, which in Kautz and Sel-
man’s Blackbox can be used to solve the SAT-encoding of
a planning graph. An advantage of LPG is that its heuris-
tics exploit the structure of the planning graph, while Black-
box relies on general heuristics for SAT-problems, and re-
quires the translation of the planning graph into propositional
clauses. Another major difference is that LPG can handle ac-
tion costs to produce good quality plans. This is achieved by
an “anytime” process minimizing an objective function based
on the number of inconsistencies in the partial plan and on
its overall cost. The objective function can also take into ac-
count the number of parallel steps and the overall plan du-
ration. Experimental results illustrate the efﬁciency of our
approach showing, in particular, that for a set of well-known
benchmark domains LPG is signiﬁcantly faster than existing
Graphplan-style planners.

Introduction

Blum and Furst’s “planning graph analysis” (1997) has be-
come a popular approach to planning on which various
planners are based (e.g., (Blum and Furst 1997; Fox and
Long 1998; Kautz and Selman 1999; Koehler et al. 1997;
Kambhampati, Minh and Do 2001; Smith and Weld 1999)).
In this paper we present LPG, a planner based on lo-
cal search and planning graphs, which considerably extends
preliminary techniques introduced in (Gerevini and Serina
1999). The search space of LPG is formed by particular
subgraphs of a planning graph, called action graphs, repre-
senting partial plans. The operators for moving from one
search state to the next one are some graph modiﬁcations
corresponding to particular revisions of the represented par-
tial plan.

LPG uses various heuristics based on a parametrized eval-
uation function, where the parameters weight different types
of inconsistencies in an action graph, and are dynamically
Copyright c(cid:1) 2002, American Association for Artiﬁcial Intelli-
gence (www.aaai.org). All rights reserved.

evaluated using Lagrange multipliers. LPG’s basic heuris-
tic, Walkplan, was inspired by Walksat (Selman, Kautz, and
Cohen 1994), a stochastic local search procedure which in
Kautz and Selman’s Blackbox (1999) can be used to solve
the SAT-encoding of a planning graph (Kautz, McAllester,
and Selman 1996).

An advantage of Walkplan with respect to Blackbox is
that it operates directly on the planning graph. The search
neighborhood of Walkplan is deﬁned and evaluated by ex-
ploiting the structure of the graph, which in the SAT-
translation of the graph is lost, or hidden. Another differ-
ence regards the number of parallel steps in the plan (length
of the plan). LPG can increment the length of the plan dur-
ing the search process, while in SAT-based planners this is
done off-line.

Most existing planners have a limited notion of plan qual-
ity that is based on the number of actions, or parallel time
steps. LPG handles a more accurate notion taking into ac-
count the execution cost of an action. Execution costs are
represented as numbers associated with the actions. The
search uses this information to produce plans of good qual-
ity by minimizing an objective function including a term for
the evaluation of the overall execution cost of a plan. This is
performed through an “anytime” process generating a suc-
cession of plans, each of which improves the previous ones.
A similar process can be used to generate plans of good qual-
ity in terms of their number of parallel steps or their overall
duration.

Experimental results illustrate the efﬁciency of our ap-
proach for plan generation indicating, in particular, that LPG
is signiﬁcantly faster than four other planners based on plan-
ning graphs: IPP4.1 (Koehler et al. 1997), STAN3s (Fox and
Long 1998), GP-CSP (Kambhampati, Minh and Do 2001),
and the recent version 3.9 of Blackbox. Other experimental
results show the effectiveness of our incremental process for
generating good quality plans.

The second section introduces our basic local search tech-
niques for planning graphs; the third section presents some
techniques improving the search process; the fourth section
concerns plan quality in LPG; the ﬁfth section gives our ex-
perimental results; the ﬁnal section gives conclusions and
mentions further work.

AIPS 2002    13  

Local Search in the Space of Action Graphs

In this section we give the necessary background on plan-
ning graphs (Blum and Furst 1997), action graphs, and the
basic local search techniques introduced in (Gerevini and
Serina 1999).

Planning Graphs and Action Graphs
A planning graph is a directed acyclic levelled graph with
two kinds of nodes and three kinds of edges. The levels
alternate between a fact level, containing fact nodes, and
an action level containing action nodes. An action node at
level t represents an action (instantiated operator) that can
be planned at time step t. A fact node represents a proposi-
tion corresponding to a precondition of one or more actions
at time step t, or to an effect of one or more actions at time
step t − 1. The fact nodes of level 0 represent the positive
facts of the initial state of the planning problem (every fact
that is not mentioned in the initial state is assumed false).

In the following, we indicate with [u] the proposition (ac-
tion) represented by the fact node (action node) u. The edges
in a planning graph connect action nodes and fact nodes. In
particular, an action node a of level i is connected by: pre-
condition edges from the fact nodes of level i representing
the preconditions of [a]; add-edges to the fact nodes of level
i + 1 representing the positive effects of [a]; delete-edges to
the fact nodes of level i + 1 representing the negative effects
of [a]. Each fact node f at a level l is associated with a no-
op action node at the same level, which represents a dummy
action having [f] as its only precondition and effect.

A fact node q of level i is supported in a subgraph G(cid:1)

Two action nodes a and b are marked as mutually exclu-
sive in the graph when one of the actions deletes a precondi-
tion or add-effect of the other (interference), or when a pre-
condition node of a and a precondition node of b are marked
as mutually exclusive (competing needs). Two proposition
nodes p and q in a proposition level are marked as exclusive
if all ways of making proposition [p] true are exclusive with
all ways of making [q] true (each action node a having an
add-edge to p is marked as exclusive of each action node
b having an add-edge to q). When two facts or actions are
marked as mutually exclusive, we say that there is a mutex
relation between them.
of a
planning graph G if either (i) in G(cid:1)
there is an action node at
level i − 1 representing an action with (positive) effect [q],
or (ii) i = 0 (i.e., [q] is a proposition of the initial state).
Given a planning problem Π, the corresponding plan-
ning graph G can be incrementally constructed level by level
starting from level 0 using a polynomial algorithm. The last
level of the graph is a propositional level where the goal
nodes are present, and there is no mutex relation between
them. Without loss of generality, we will assume that the
goal nodes of the last level represent preconditions of a spe-
cial action [aend], which is the last action in any valid plan.
An action graph (A-graph) A of G is a subgraph of G
containing aend and such that, if a is an action node of G
in A, then also the fact nodes of G corresponding to the
preconditions and positive effects of [a] are in A, together
with the edges connecting them to a.

14    AIPS 2002

A solution graph for G is an action graph As of G such
that all precondition nodes of the actions in As are sup-
ported, and there is no mutex relation between action nodes
of As.
A solution graph for G represents a valid plan for Π. If
the search for a solution graph fails, G can be iteratively
expanded by adding an extra level, and performing a new
search using the resultant graph.

Basic Search Neighborhood and Heuristics
Given a planning graph G, the local search process starts
from an initial A-graph A of G (i.e., a partial plan), and
transforms it into a solution graph through the iterative ap-
plication of some graph modiﬁcations improving the current
partial plan. The two basic modiﬁcations consist of adding
a new action node to the current A-graph, or removing an
action node from it (together with the relevant edges).

At any step of the search process, which produces a new
A-graph, the set of actions that can be added or removed is
determined by the constraint violations that are present in the
current A-graph. A constraint violation (or inconsistency)
is either a mutex relation involving action nodes in the cur-
rent A-graph, or an unsupported fact which is precondition
of an action in the current partial plan.

The general scheme for searching a solution graph (a ﬁnal
state of the search) consists of two main steps. The ﬁrst step
is an initialization of the search in which we construct an ini-
tial A-graph. The second step is a local search process in the
space of all A-graphs, starting from the initial A-graph. We
can generate an initial A-graph in several ways. Three pos-
sibilities that can be performed in polynomial time, and that
we have implemented in LPG are: (i) a randomly generated
A-graph; (ii) an A-graph where all precondition facts are
supported (but in which there may be some violated mutex
relations); an A-graph obtained from an existing plan given
in input to the process.

Once we have computed an initial A-graph, each basic
search step randomly chooses an inconsistency in the current
A-graph. If this is an unsupported fact node, then in order to
resolve (eliminate) it, we can either add an action node that
supports it, or we can remove an action node which is con-
nected to that fact node by a precondition edge. If the chosen
inconsistency is a mutex relation, then we can remove one
of the action nodes of the mutex relation. When we add (re-
move) an action node to deal with an inconsistency, we also
add (remove) all edges connecting the action node with the
corresponding precondition and effect nodes in the planning
graph.
Given a planning graph G, an action graph A of G and a
constraint violation s in A, the neighborhood N(s,A) of s
in A is the set of action graphs obtained from A by applying
a graph modiﬁcation that resolves s. At each step of the
local search, the elements in the neighborhood are weighted
according to an evaluation function, and an element with the
best evaluation is then chosen as the possible next subgraph
(search state). Given an action subgraph A of a planning
graph G, the general evaluation function F of A is deﬁned
as follows:

F (A) =

(cid:1)
a∈G

where:

mutex(a,A) + precond(a,A)

(cid:2)
(cid:2)

mutex(a,A) =

precond(a,A) =

0
me(a,A)
0
pre(a,A)

if a (cid:1)∈ A
if a ∈ A
if a (cid:1)∈ A
if a ∈ A

and me(a,A) is the number of action nodes in A which are
mutually exclusive with a, while pre(a,A) is the number
of precondition facts of a which are not supported in A. It
is easy to see that, when the search reaches an A-graph for
which F is zero, this is a solution graph.

The simple use of the general function to guide the local
search has the drawback that it can lead to local minima from
which the search can not escape. For this reason, instead of
using F , we use a parametrized action evaluation function
E which allows to specify different types of heuristics. This
function speciﬁes the cost of inserting (Ei) and of remov-
ing (Er) an action [a] in the partial plan represented by the
current action subgraph A:
E([a],A)i = αi·pre(a,A)+βi·me(a,A)+γi·unsup(a,A)
E([a],A)r = αr·pre(a,A)+βr·me(a,A)+γr·sup(a,A),
where me(a,A) and pre(a,A) are deﬁned as in F ;
unsup(a,A) is the number of unsupported precondition
facts in A that become supported by adding a to A;
sup(a,A) is the number of supported precondition facts in
A that become unsupported by removing a from A; α, β
and γ are parameters specializing the function.

By appropriately setting the values of these coefﬁcients
we can implement different heuristic methods aimed at mak-
ing the search less inﬂuenced by local minima. Their values
have to satisfy the following constraints: αi, βi > 0 and
γi ≤ 0 in Ei; αr, βr ≤ 0 and γr > 0 in Er. Note that
the positive coefﬁcients of E (αi, βi and γr) determine an
increment of E which is related to an increment of the num-
ber of inconsistencies. Analogously, the non-positive coefﬁ-
cients of E determines a decrement of E which is related to
a decrement of the number of inconsistencies.

In (Gerevini and Serina 1999) we proposed three basic
heuristics to guide the local search: Walkplan, Tabuplan and
T-Walkplan. In this paper we focus on Walkplan, which is
similar to the heuristic used by Walksat (Selman, Kautz, and
Cohen 1994). In Walkplan we have γi = 0, αr = 0, and
βr = 0, i.e., the action evaluation function is

E([a],A)i = αi · pre(a,A) + βi · me(a,A)

E([a],A)r = γr · sup(a,A).

The best element in the neighborhood is the A-graph intro-
ducing the fewest new constraint violations (Walkplan does
not consider the constraint violations of the current A-graph
that are resolved). Like Walksat, Walkplan uses a noise pa-
rameter p: given an A-graph A and a (randomly chosen)

constraint violation, if there is a modiﬁcation that does not
introduce new constraint violations, then the corresponding
A-graph in N(s,A) is chosen as the next A-graph; other-
wise, with probability p one of the graphs in N(s,A) is cho-
sen randomly, and with probability 1− p the next A-graph is
chosen according to the minimum value of the action evalu-
ation function.

Neighborhood Reﬁnements

In this section we present some improvements of the basic
local search technique described in the previous section.

Dynamic Heuristics Based on Lagrange Multipliers
As shown in (Gerevini and Serina 2001) the values of the
coefﬁcients α, β and γ in E can signiﬁcantly affect the ef-
ﬁciency of the search. Since their value is static, the op-
timal performance can be obtained only when their val-
ues are appropriately tuned before search. Moreover, the
best parameter setting can be different for different plan-
ning domains, or even for different problems in the same
domain.
In order to cope with this drawback, we have
revised the evaluation functions by weighting their terms
with dynamic coefﬁcients similar to the Lagrange multipli-
ers for discrete problems that have been used for solving
SAT problems (Shang and Wah 1998; Wah and Wu 1999;
Wu and Wah 2000).

The use of these multipliers gives two important improve-
ments to our local search. First, the revised cost function is
more informative, and can discriminate more accurately the
elements in the neighborhood. Secondly, the new cost func-
tion does not depend on any static coefﬁcient (the α, β and
γ coefﬁcients can be omitted, and the initial default value of
all new multipliers is scarcely important).

The general idea is that each constraint violation is asso-
ciated with a dynamic multiplier that weights it. If the value
of the multiplier is high, then the corresponding constraint
violation is considered “difﬁcult”, while if the value is low it
is considered “easy”. Using these multipliers, the quality of
an A-graph will be estimated not only in terms of the num-
ber of constraint violations that are present in it, but also in
terms of an estimation of the difﬁculty to solve the particular
constraint violations that are present.

Since the number of constraint violations that can arise
during the search can be very high, instead of maintaining a
distinct multiplier for each of them, our technique assigns a
multiplier to a set of constraint violations associated with the
same action. Speciﬁcally, for each action a, we have a multi-
plier λa
m for all mutex relations involving a, and a multiplier
λa
p for all preconditions of a. Intuitively, these multipliers
estimate the difﬁculty of satisfying all preconditions of an
action, and of avoiding to have that a is mutually exclusive
with any other action in the A-graph. The multipliers can
be used to reﬁne the cost E([a],A)i of inserting the action
node a and the cost E([a],A)r of removing a. In particular,
the evaluation function for Walkplan becomes

Eλ([a],A)i = λa

p

· pre(a,A) + λa
Eλ([a],A)r = ∆−
a ,

m

· me(a,A)

AIPS 2002    15  

a is the sum of the supported preconditions in A
where ∆−
that become unsupported by removing a, weighted by λaj
p ,
(cid:1)
i.e.,
· (pre(aj,A − [a]) − pre(aj,A)).
∆−
a =

λaj
p

aj∈A−{a}

The multipliers have all the same default initial value,
which is dynamically updated during the search. Intuitively,
we want to increase the multipliers associated with actions
introducing constraint violations that turn out to be difﬁcult
to solve, while we want to decrease the multipliers associ-
ated with actions whose constraint violations tend to be eas-
ier. These will lead to prefer graphs in the neighborhood that
appear to be globally easier so solve (i.e., that are closer to a
solution graph).

The update of the multipliers is performed whenever the
local search reaches a local minimum or a plateau (i.e., when
all the elements in the neighborhood have Eλ greater than
zero). The values of the multipliers of the actions that are
responsible of the constraint violations present in the current
action graph are then increased by a certain small quantity
δ+, while the multipliers of the actions that do not determine
any constraint violation are decreased by δ
. For example,
if a is in the current A-graph and is involved in a mutex re-
lation with another action in the graph, then λa
m is increased
by a predeﬁned positive small quantity δ+ (otherwise it is
decreased by δ

).1

−

−

No-op Propagation
This technique is based on the observation that, whenever an
action is added to the current plan (action graph), its effects
can be propagated to the next time steps (levels), unless there
is an action interfering with them. Suppose that P is one of
the effects of an action a at time step (level) t. P is propa-
gated to the next levels by adding the corresponding no-ops,
until we reach a level where the no-op for P is mutually ex-
clusive with some other action in the current plan. Notice
that in order to guarantee soundness, whenever we add an
action at some time step after t which is mutex with a prop-
agated no-op, it is necessary to “block” this no-op at level
t. Similarly, when an action that blocks a no-op is removed,
this no-op can be further propagated (unless there is another
action blocking it). The no-op propagation can be efﬁciently
maintained by exploiting the data structures of the planning
graph.

Clearly, the propagation is useful because it can eliminate
further inconsistencies (an action is added to support a spe-
ciﬁc precondition, but the effects of this action could also

1In order to make the increment of λa

p more accurate, in our
implementation δ+ is weighted by taking into account the propor-
tion k of unsupported preconditions of a with respect to the total
number of unsupported preconditions in the action graph (i.e, λa
is increased by k · δ+). Similarly, when we increase λa
p
m, δ+ is
weighted by the proportion of mutex involving a with respect to
the total number of mutex in the graph. Moreover, the unbounded
increase or decrease of a multiplier is prevented by imposing max-
imum and minimum values to them. The default values for δ+ and
−
δ

−6 respectively.

−3 and 5 · 10

used in our tests are 10

16    AIPS 2002

support additional preconditions through the propagation of
their no-ops). Moreover, the no-op propagation can be ex-
ploited to extend the search neighborhood, and possibly re-
duce the number of search steps. Given an unsupported pre-
condition Q of and action a at level l of an A-graph A, the
basic neighborhood of A for Q consists of the graphs de-
rived from A by either removing a or adding an action at
level l − 1 which supports Q. In principle, among these ac-
tions we could use the no-op for Q (if available), which cor-
responds to assuming that Q is achieved by an earlier action
(possibly the initial state), and persists up to the time step
when a is executed. Instead of using this no-op, we use an
action at an earlier level which has Q as one of its effects,
and such that Q can be propagated up to l. When there is
more than one of such actions, the neighborhood includes
all corresponding action graphs derived by adding any one
of them.

Experimental results showed that the use of the no-op
propagation can signiﬁcantly reduce both the number of
search steps and the CPU-time required to ﬁnd a solution
graph.

Action Ordering and Incremental Graph Length
In general, local search methods do not examine the search
space in an exhaustive way, and the hence also the search
techniques described in the previous section can not deter-
mine when it is necessary to increase the length (number of
levels) of the current planning graph. Originally, we over-
came this limitation by automatically expanding the graph
after a certain number of search steps. However, this has the
drawback that, when the graph is extended several times, a
signiﬁcant amount of CPU-time is wasted for searching the
sequence of expanded graphs that are generated before the
last expansion.

Recently, we have developed an alternative method for
expanding the graph during search that leads to better per-
formance. In particular, we have extended the search neigh-
borhood with A-graphs derived by two new types of graph
modiﬁcations that are based on ordering mutex actions and
possibly expanding the graph. Given two actions that are
mutex at time step i, we examine if this inconsistency can
be eliminated by postponing to time step i + 1 one of the ac-
tions, or by anticipating it a step i− 1. We say that an action
a at step i can be postponed to step i + 1 of A if the action
graph obtained by moving a from i to i + 1 does not contain
new inconsistencies with respect to A.2 The condition for
anticipating a to i − 1 is analogous.

When one of the actions involved in a mutex relation can
be postponed or anticipated, the corresponding action graph
is always chosen from the neighborhood. If more than one
of these modiﬁcations is possible, we choose randomly one
of the corresponding A-graphs. If none of the two actions
can be postponed (or anticipated), we try to postpone (antic-
ipate) one of them in combination with a graph extension.

2In order to simplify the notation, in this and the next sections
we indicate with a (f) both an action node (fact node) and the
corresponding represented action (fact). The actual meaning of the
notation will be clear from the context.

P6

P10

P11

P9

P5

noop

a

4

noop

noop

P6

P7

P8

P9

P5
P5

mutex

a
1

P1

P2

a

2

P3

a

3

noop

P4

P5

P6

1a

P10

P11

P9

P5

a

4

noop

noop

(a)

level
i+1

level
i

(b)

level
i+1

(c)

level
i+2

level
i+1

P6

P10

P11

P9

P5

noop

a
4

noop

noop

P6

1a

P8

P9

P5

noop

noop

noop

P1

P2

P7

P8

P9

P5P5

P1

P2

P7

P8

P9

P5P5

noop

noop

level
i

P1

P2

a

2

P3

a

3

noop

level
i

noop

noop

P4

P5

P1

P2

a
2

P3

a
3

P4

noop

P5

Figure 1: Examples of action ordering and increment of
graph length to deal with a mutex relation.

Speciﬁcally, ﬁrst we extend the planning graph of one level;
then we shift forward all actions from step i + 1 (i − 1); ﬁ-
nally we move one of the two actions to step i + 1 (i − 1),
provided that this move does not introduce new inconsisten-
cies (e.g., the moved action blocks a no-op that is used to
support a precondition at a later step). If none of the two
actions can be moved even after a graph extension, the ac-
tion graphs of the neighborhood are those derived by simply
removing one of the two actions.

For example, in Figure 1(a) we have that actions a1 and
a2 are mutex at level i. Assume that a1 has two supported
preconditions P1 and P2, and one additive effect P6 that is
needed by other actions in the following levels of the graph.
Fact P8 is supported by a2 and is a precondition of a4; fact
P7 is not used to support any precondition. Figure 1(b) illus-
trates a case in which a1 can be postponed to level i+1. This
is possible because there is no mutex relation between (1) a1
and a4, (2) a1 and the no-ops for P5 and P9, (3) the no-ops
supporting the preconditions of a1 and any other action at
level i.

Figure 1(c) illustrates a case in which a1 can not be post-
poned to level i + 1 (because, for example, a4 deletes a pre-
condition of a1), but it can be postponed in combination with
a graph expansion. This is possible because there is no mu-
tex relation between (1) a1 and the no-ops of P5, P8, P9, (2)
between the no-ops supporting the preconditions of a1 and
any other action of level i.

Heuristic Precondition Costs
The heuristic functions E and Eλ previously described eval-
uate the A-graphs in the neighborhood by considering their
number of unsupported preconditions and unsatisﬁed mu-
tex relations. An experimental analysis revealed that, while
computing this functions is quite fast, sometimes a more ac-

curate evaluation can be very useful. In fact, it can be the
case that, although the insertion of a new action a1 leads to
fewer new unsupported preconditions than those introduced
by an alternative action a2, the unsupported preconditions
of a1 are more difﬁcult to satisfy (support) than those of
a2 (i.e., the inconsistencies that a1 would introduce require
more search steps than the inconsistencies of a2). For this
reason we have reﬁned Eλ by using an heuristic estimation
(H) of the difﬁculty of supporting a precondition which ex-
ploits information stored in the structure of the underlying
planning graph. More precisely, Eλ(a,A)i becomes
EH(a,A)i = λa
· me(a,A),
where H(f,A) is the heuristic cost of supporting f, and is
recursively deﬁned in the following way:

H(f,A) + λa

· M AX
f∈pre(a)

m

p

(cid:1)

0
H(f
M AX
f(cid:1)∈pre(af )

if f is supported
,A) if af is no-op with precondition f
(cid:1)
,A) + me(af ,A) + 1 otherw.

H(f

(cid:1)




H(f,A) =

where

(cid:7)

(cid:1)
E(a

,A)i

(cid:8)

af = ARGM IN

{a(cid:1)∈Af}

and Af is the set of action nodes of the planning graph at
the level preceding the level of f, that have f as one their
effects nodes.
Informally, the heuristic cost of an unsup-
ported fact f is determined by considering all actions at the
level preceding the level of f whose insertion would support
f. Among these actions, we choose the one with the best
evaluation (af ) according to the original action evaluation
function E.3 H(f,A) is recursively computed by summing
the number of mutex relations introduced by af to the max-
imum of the heuristic costs of its unsupported preconditions
,A)). The last term “+1” takes into account the inser-
(H(f
tion of af to support f.
Similarly, we reﬁne the cost of removing an action a from
A by considering the maximum heuristic cost of supporting
a fact that becomes unsupported when a is removed. More
precisely,

(cid:1)

EH(a,A)r = M AX
(cid:3)f,aj(cid:4)∈K

λaj
p

· H(f,A − a)

where K is the set of pairs (cid:4)f, aj(cid:5) such that f is a precon-
dition of an action node aj which becomes unsupported by
removing a from A.

In Figure 2 we give an example illustrating H. Each ac-
tion node is associated with a pair of numbers (in brackets)
indicating the number of unsupported preconditions and the
number of mutex relations involving the node. For example,
a3 at level l + 1 has two unsupported preconditions and is
involved in 5 mutex relations. Each fact node is associated
with a number specifying the heuristic cost of supporting it.
Suppose we want to determine the heuristic cost of the un-
supported precondition P1 at level l + 2. The action with

3When more than one action with minimum cost exists, if the
no-op is one of these actions, then we choose it, otherwise we
choose randomly among them.

AIPS 2002    17  

Graph levels

l+2

a (2,0)

P1 [5]

P2 [3]

l+1

a1 (3,1)

a2 (1,1)

a3 (2,5)

a7 (3,3)

a8 (0,2)

a9 (2,4)

P3 [3]

P4 [0]

l

a4  (3,1)

a5 (0,2)

a6 (2,1)

noop(0, 0)

 

P5  [0]

P6  [0]

P4 [0]

Figure 2: Example illustrating the heuristic cost of un-
supported preconditions. Dashed boxes correspond to ac-
tions/facts which do not belong to A

minimum cost achieving P1 is a2. The action with mini-
mum cost achieving P3 is a5, which has all preconditions
supported. Thus we have
H(P3,A) = M AX
,A)+me(a5,A)+1 = 0+2+1.
f(cid:1)∈pre(a5)
Since H(P4,A) = 0, we have
H(P1,A) = M AX
(cid:1)
f(cid:1)∈pre(a2)

,A)+me(a2,A)+1 = 3+1+1.

H(f

H(f

(cid:1)

Modelling Plan Quality

In this section we extend our techniques to manage plans
where each action has an arbitrary number associated with it
representing, for example, its execution cost. While taking
this information into account is practically very important to
produce good quality plans, most of the domain-independent
planners in the literature neglect it, and use the number of ac-
tions (or parallel steps) as a simple measure of plan quality.
In our framework execution costs can be easily modelled by
extending the objective function of the local search with a
term evaluating the overall execution cost of a plan (action
graph), which is naturally deﬁned as the sum of the costs of
its actions. Similarly, we can easily model the number of
parallel steps in a plan, and use this criterion as a measure of
plan quality.

The user can weight the “optimization” terms of the
revised objective function (execution cost and number of
steps) according to the relative importance. More formally,
the general evaluation function F can be revised to
F +(A) = µC ·
Cost(a) + µS · Steps(A) +
(cid:1)
· mutex(a,A) + λa
a∈A

(cid:1)
a∈A
(λa
m

· precond(a,A))

+

p

18    AIPS 2002

where Cost(a) is the execution cost of a, µC and µS are
non-negative coefﬁcients set by the user to weight the rel-
ative importance of execution cost and number of parallel
steps (µC +µS ≤ 1), and Steps(A) is the number of steps in
the A-graph A containing at least one action different from
no-ops. The evaluation function EH deﬁned in the previous
section is reﬁned to E+
H in the following way (U denotes the
set of preconditions achieved by a that become unsupported
by removing a):
H(a,A)i = µC
E+
maxCS
+ µS

HC(f,A)) +
· (Steps(A + a) − Steps(A) +
HS(f,A)) +

· (Cost(a) + M AX
f∈pre(a)

maxCS

M AX
f∈pre(a)

+

1

maxE

· EH(a,A)i

H(a,A)r = µC
E+
maxCS
+ µS

maxCS

+

1

maxE

· (−Cost(a) + M AX
f∈ U

HC(f,A − a)) +

· (Steps(A − a) − Steps(A) +
HS(f,A − a)) +

M AX
f∈ U
· EH(a,A)r

where HC(f,A) and HS(f,A) are an estimation of the in-
crease of the overall execution cost and parallel steps, re-
spectively, that is required to support the fact f in A. HC
and HS are recursively deﬁned in a way similar to the deﬁ-
nition of H given in the previous section: if f is supported
in A, then HC(f,A) = 0 and HS(f,A) = 0, otherwise
HC(f,A) = Cost(af ) + M AX
f(cid:1)∈pre(af )

HC(f

,A)

(cid:1)

,A)

(cid:1)

HS(f

HS(f,A) = Steps(A+af )−Steps(A) + M AX
f(cid:1)∈pre(af )
in which af is deﬁned as in the deﬁnition of H. For example,
consider again Figure 2 and suppose that Cost(a2) = 10
and Cost(a5) = 30. We have that HC(P1,A) = 40.
The factors 1/maxCS, and 1/maxE are used to normal-
H to a value less than or equal to 1.
ize each term of E+
Without this normalization the values of the terms corre-
sponding to the execution cost (ﬁrst term) could be much
higher than the value corresponding to the constraint vio-
lations (third term). This would guide the search towards
good quality plans without paying sufﬁcient attention to
their validity. On the contrary, especially when the cur-
rent partial plan contains many constraint violations, we
would like that the search give more importance to satis-
fying these logical constraints. The value of maxCS is de-
ﬁned as µC · maxC + µS · maxS, where maxC (maxS) is
the maximum value of the ﬁrst (second) term of E+
H over all
A-graphs (partial plans) in the neighborhood, multiplied by
the number κ of constraint violations in the current action

graph; maxE is deﬁned as the maximum value of EH over
all possible action insertions/removals that eliminate the in-
consistency under consideration.4

The revised heuristic function E+

H can be used to produce
a succession of valid plans where each plan is an improve-
ment of the previous ones in terms of execution cost or par-
allel steps. The ﬁrst of these plans is the ﬁrst plan π without
constraint violations that is generated (i.e., the third term of
F + is zero). π is then used to initialize a second search
which is terminated when a new valid plan π
that is bet-
ter than π is generated. π
is then used to initialize a third
search, and so on. This is an anytime process that incre-
mentally improves the quality of the plans, and that can be
stopped at any time to give the best plan computed so far.
Each time we start a new search some inconsistencies are
forced in the initial plan by randomly removing some of its
actions. Similarly, some random inconsistencies are intro-
duced during search when a valid plan that does not improve
the plan of the previous search is reached.

(cid:1)

(cid:1)

D(a

(cid:1))),

This method of modelling plan quality can be extended to
deal with a limited form of temporal planning where each
action a is associated with a temporal duration D(a). Under
the assumption that the execution of all actions at each step
of the plan terminates before starting executing the actions at
the next step, we can search for parallel plans with the short-
est possible duration by including in F + a new term that is
proportional to the sum of the longest action at each step of
the current partial plan. Let Delay(a,A) be the temporal
delay determined by a in the A-graph A, i.e.,
Delay(a,A) = M AX(0, D(a)− M AX
a(cid:1)∈S

where S is the set of actions at the same level of a in A
(except a). The new terms in E+
H to handle plan duration
are proportional to

H(a,A)i

HD(f,A), in E+
HD(f,A − a), in E+

+Delay(a,A) + M AX
f∈pre(a)
H(a,A)r
−Delay(a,A) + M AX
f∈ U
where HD(f,A) is a heuristic estimation of the increase of
the overall plan duration that is required to support f (the
formal deﬁnition of HD(f,A) is similar to the deﬁnition of
HC(f,A)).
Despite the previous assumption could be relaxed in the
computed plan by considering its causal structure (depen-
dencies between action effects and preconditions), in gen-
eral, it is not guaranteed that minimizing the duration term of
F + always leads to the shortest possible parallel plans. On
the other hand, when the domain admits only linear plans,
minimizing the duration term corresponds to searching for
optimal plans. Hence, our simple approach for duration op-
timization should be seen as an approximate technique.

4The role of κ is to decrease the importance of the ﬁrst two
optimization terms when the current plan contains many constraint
violations, and to increase it when the search approaches a valid
plan. For lack of space we omit further details on the formalization
of maxC, maxS and maxE.

Experimental Results

Our techniques are implemented in a system called LPG
(Local search for Planning Graphs). Using LPG we have
conducted three experiments. The ﬁrst experiment was
aimed at comparing the performance of Walkplan in LPG
and other planners based on planning graphs for some
well-known benchmark problems. We considered Black-
box 3.9 with solvers Walksat and Chaff (Moskewicz et al.
2001); GP-CSP (Kambhampati, Minh and Do 2001); IPP4.1
(Koehler et al. 1997); and STAN3s (Fox and Long 1998;
1999).5

The results of this experiment are in Table 1. The 2nd and
the 3rd columns of the table give the total time required by
LPG, and the search time of Walksat for the SAT-encoding
of the planning graph with the minimum number of levels
that is sufﬁcient to solve the problem.6 Walkplan performed
always better than Walksat, and was up to four orders of
magnitude faster. The fourth column of Table 1 gives the
results for Blackbox using the recent solver Chaff instead
of Walksat, which currently is the fastest systematic SAT
solver. LPG was signiﬁcantly faster than Blackbox also in
this case. The remaining columns of the table give the CPU-
times for GP-CSP, IPP and STAN, which were up to 3 or 4
orders of magnitude slower than LPG. (However, it should
be noted that these planners, as well as Blackbox with Chaff,
compute plans with minimal number of steps.)

In the second experiment we tested the performance of
LPG for some problems of the AIPS-98/00 competition set
with respect to the planner that won the last competition, FF
(Hoffmann and Nebel 2001). The results are in Table 2.7 In
terms of CPU-time LPG was comparable to FF. In Logistics
LPG performed better than FF; in Elevator (m10-problems)
FF performed better than LPG; while in Mprime we have
mixed results.8 For mprime-05 FF required more than 600
seconds, while LPG determined that the problem is not solv-
able without search (this was detected during the construc-
tion of the planning graph). In terms of number of actions

5All tests were run on a Pentium II 400 MHz with 768 Mbytes.
We did not use version 4 of STAN because it uses methods alterna-
tive to planning graphs.

6Without this information the times required by Blackbox us-
ing Walksat were signiﬁcantly higher than those in the table. The
parameters of Walksat (noise and cutoff) were set to the combina-
tion of values that gave the best performance over many tries. For
Blocks-world and Gripper we used cutoff 5000000, various values
of noise and several restarts. For log-d and bw-large-a/b we
used the the option “compact -b 8”, because it made the prob-
lems easier to solve. In this and in the next experiments the noise
factor for Walkplan was always 0.1; the cutoff was initially set to
500, and then automatically incremented at each restart by a factor
of 1.1.

7However, note that comparing these two systems is not com-
pletely fair, because FF computes linear plans while LPG com-
putes parallel plans, and hence they solve (computationally) differ-
ent problems.

8We considered a slight modiﬁcation of Mprime where operator
parameters with different names are bound to different constants,
which is an implicit assumption in the implementation of both FF
and LPG.

AIPS 2002    19  

2

3

4

5

6

7

8

9

0 1

2

3

4

5

6
6

7

8

9

0

1

Source

package_3
City_1_3

0

1

2

3

4

5

6

7

8

9

Source

package_3
City_1_3

City_8_1
package_4

City_5_9
package_2

City_9_8

package_1

0

1
2
3
4
5
6
7
8
9

0
1
2

3
4
5
6
7

8
9

City_8_1
package_4

City_5_9

package_2

City_9_8

package_1

0
1
2
3
4
5
6
7
8
9

Source

package_3
City_1_3

City_5_9

package_2

City_8_1
package_4

City_9_8

package_1

(a)

Airplane1
Arplane2

Global cost = 4019

(b)

Airplane1
Arplane2

Global cost = 2664

(c)

Airplane1
Arplane2

Global cost = 2369

Figure 3: Three plans and the relative execution costs computed by FF (1st picture) and by LPG (2nd and 3rd pictures) for a
simple logistics problem with action costs.

Blackbox

LPG
Planning
Wplan Wsat
problem
1.25
0.05
rocket-a
1.51
0.06
rocket-b
3.21
0.22
log-a
5.76
0.28
log-b
0.32
14.28
log-c
35.10
0.42
log-d
2.06
bw-large-a 0.24
131.0
bw-large-b 0.61
0.14
0.02
TSP-7
0.03
0.72
TSP-10
31.23 —
0.07
TSP-15
—
0.39
TSP-30
out
—
0.31 —
gripper10
0.74 —
—
gripper12

GP-
Chaff CSP
1.55
5.99
3.02
6.16
1.60
5.93
22.7
6.74
7.19
28.8 —
98.0 —
11.5
6.82
0.69
783
51.6
0.13
0.11
6.47
8.48
—
—
—
—

IPP

20.2
38.83
777.8
341.0

0.17
12.39
0.04
1.96
419.0
—
40.38
330.1

STAN

6.49
4.24
0.24
1.11
896.6
—
0.21
5.4
0.01
0.04
0.26
11.9
36.3
810.2

Planning
problem
log-35-0
log-36-0
log-37-0
log-38-0
log-39-0
m10-s20-0
m10-s21-0
m10-s22-0
m10-s23-0
m10-s24-0
mprime-01
mprime-02
mprime-03
mprime-04
mprime-05

LPG

Time
5.57 (4.76)
6.15 (4.79)
15.46 (7.36)
10.25 (7.46)
22.94 (7.49)
1.51 (0.81)
1.81 (0.94)
2.31 (1.10)
2.76 (1.26)
3.24 (1.45)
0.10 (1.92)
0.50 (8.72)
0.03 (3.90)
0.02 (1.56)
0.0 (2.43)

Steps Act.
246.5
100.5
263.8
100.2
308.3
110.7
289.1
105.0
117.6
313.0
74.61
65.74
80.57
72.71
83.96
75.32
88.70
79.81
84.56
92.72
7.5
5.9
12.3
7.6
4.0
4.0
9.7
7.2
—
—

FF

Act.
Time
193
19.19
209
14.74
237
26.48
224
25.75
239
66.74
64
0.29
70
0.40
73
0.47
76
0.52
79
0.55
5
0.03
10
0.16
4
0.05
0.02
10
> 600 —

Table 1: Average CPU-seconds over 25 runs required by
LPG using Walkplan (Wplan) with EH and other planners
based on planning graph (Wsat indicates Walksat). The
times for LPG are total search times; the times for Walk-
sat refer only to the planning graph with the minimum num-
ber of levels where a solution exists; the times for Chaff and
GP-CSP are the total times using the relative default settings,
except for Gripper and the hardest TSP problems, where for
Chaff we used the settings suggested by Blackbox for hard
problems. “—” means that the planner did not ﬁnd a solu-
tion after 1500 seconds (in these cases the average was over
8 runs); “out” that the system went out of memory.

for the problems of Table 2, FF-plans are better than LPG-
plans except in 2 cases. We believe there are several rea-
sons for this: LPG considers only one inconsistency at each
search step, and in this sense its search is “more local” than
FF search, whose heuristic considers all the problem goals;
Walkplan, like Walksat, does not distinguish elements in the
search neighborhood that improve the current A-graph; in
this experiment the coefﬁcient of the action cost term in EH
was set to a low value, because we were interested in the fast

20    AIPS 2002

Table 2: CPU-seconds, number of steps and number of ac-
tions for LPG (Walkplan) and FF for some problems of the
AIPS competitions. The data for LPG are averages over 25
runs. The CPU-time in brackets is the time required for con-
structing the graph. This is largely dominated by the instan-
tiation of the operators (especially for Mprime), which in
FF’s implementation is very fast and in LPG can be drasti-
cally reduced by using a similar implementation.

computation of the ﬁrst solution.

However, as we have described in the previous section,
LPG can generate good quality plans in a more general sense
by minimizing the heuristic evaluation function E+
H. The
third experiment that we have conducted concerns the use
of E+
H in LPG to produce plans of good quality. In particu-
lar, we have tested LPG with a modiﬁcation of the Logistics
domain where each action has an execution cost associated
with it. Figure 3 shows three plans computed by FF and LPG
for a simple problem in this domain (for the sake of clarity
we show only the ﬂy actions). We have two airplanes, four
packages, and four cities, each of which has an airport, a

Plan cost for TSP 7

Plan cost for Logistics-b

650

600

550

500

450

400

350

300

250

0.1

FF solution

70000

60000

50000

40000

30000

20000

FF solution

1

CPU-SECONDS (log scale)

Optimal cost

10

10000

0.1

Optimal cost

1
CPU-SECONDS (log scale)

10

100

Plan cost for Logistics-16

70000

60000

50000

40000

30000

20000

10000

1
CPU-SECONDS (log scale)

10

2000

1800

1600

1400

1200

1000

800

600

Plan duration for Logistics-16 in mixed optimization

1

10

CPU-SECONDS (log scale)

Plan cost for Logistics-b with connections
80000

70000

60000

50000

40000

30000

20000

100000

90000

80000

70000

60000

50000

40000

30000

20000

FF solution

Optimal cost

0.1

1

10

CPU-SECONDS (log scale)

Plan cost for Logistics-16 in mixed optimization

1

10

CPU-SECONDS (log scale)

Figure 4: Incremental quality of the plans computed by LPG and relative CPU-time. The ﬁrst three pictures plots refer to
single problem instances (10 runs of LPG for each problem). Each of the other three pictures plots average measures (cost or
duration) for 10 variants of logistics-16. For each variant we considered the sequence of the ﬁrst 11 plans generated. The
points connected refer to the average cost or duration for the same variant. Average data are over 25 runs of the incremental
optimization process, for a total of 2750 plans in each picture.

port and a truck. Initially, all packages and airplanes are at
the source city; the ﬁnal locations of the packages is shown
in the pictures of the ﬁgure. Cities and airports are placed in
a grid, and the cost of ﬂying between two airports depends
the relative Euclidean distance in the grid (e.g., the distance
between city 9 8 to city 1 3 in Figure 3(a) is the distance
between points (9,8) and (1,3) on the grid). The cost of ﬂy-
ing by Airplane1 (ﬂy1) is the travel distance times 100,
while the cost of ﬂying by Airplane2 (ﬂy2) is the travel
distance times 50 (i.e., ﬂy1 is twice as expensive as ﬂy2);
loading and unloading packages on/from trucks or airplanes
have cost 1, driving a truck between the port and the airport
of a city has cost 10.

Figure 3(a) shows the ﬂy actions of the airplanes in the
plan computed by FF, which does not take into account ac-
tion costs, and produces a plan with overall cost 4019. Fig-
ures 3(b/c) show the ﬂy actions in the ﬁrst two plans com-
puted by a run of LPG. The ﬁrst plan has overall cost 2664,
the second 2369. On average the optimal plan for this prob-
lem is computed by LPG in 0.85 seconds.

Figure 4 gives results for a TSP problem with 7 cities and
further logistics problems. The horizontal lines indicate the
optimal execution costs, and the cost of the solution com-

puted by FF. In TSP-7 and logistics-b cities and the rel-
ative airports were randomly placed in a grid of 100×100 lo-
cations, and the action costs were determined as in Figure 3.
The third picture regards a modiﬁcation of logistics-b
in which only 60% of all possible pairs of cities are con-
nected by direct ﬂights (in the original version there is a di-
rect ﬂight between each pair of cities). This problem was
automatically generated by a program that randomly gener-
ates variants of a Logistics problem by augmenting it with
ﬂight connections, and ensuring that each pair of cities is
connected via some path of possible ﬂights.

The plots of the ﬁrst three pictures show the increasing
plan quality in terms of execution cost for 10 runs of LPG
H with µC = 1.0), indicating that LPG quickly
(using E+
found the optimal solution, or a solution close to the optimal
one.

The fourth picture of Figure 4 plots the average execution
costs for 10 randomly generated variants of a more difﬁcult
problem from the AIPS-00 competition (logistics-16).
The variants differ in the initial position of the airports and
cities on a grid of 100×100 locations, which was randomly
determined. These results show that the incremental process
for generating better quality plans on average signiﬁcantly

AIPS 2002    21  

improves the ﬁrst plans produced (the more time is dedicated
to LPG, the better the plan is).

The last two pictures of Figure 4 concern the minimiza-
tion of plan duration and execution cost, respectively, when
both these terms are included in the evaluation function E+
H.
Action durations were determined in the following way:
load/unload actions have duration 1; the duration of ﬂying
Airplane1 (the expensive one) is the same as the travel dis-
tance; the duration of ﬂying Airplane2 is twice the travel
distance.

Improving plan duration and execution cost simultane-
ously led to sequences of plans where these criteria do not
always decrease monotonically, if considered independently.
This is because in some cases less expensive plans might re-
quire longer execution. In general, when we have multiple
optimization criteria, there is tradeoff among the different
criteria to consider. In LPG this tradeoff can be taken into
account by appropriately weighting the optimization terms
of the evaluation function (in the tests of last 2 plots of Fig-
ure 4 µC was 0.05 and the weight for the temporal term 0.5).

Conclusions

We have presented a collection of techniques for local search
on planning graphs that are implemented in LPG. The basic
search scheme of LPG is similar to the stochastic search of
Walksat, but has a different search space. While Walksat
uses simple general heuristics for SAT problems, LPG uses
several techniques to deﬁne and evaluate the search neigh-
borhood that exploit the structure of the underlying graph.
These include Lagrange multipliers, no-op propagation, ac-
tion ordering and incremental graph length, and heuristic
precondition costs.

In our framework each action can be associated with a
number representing its cost. The overall plan cost can be
easily modeled by using an appropriate evaluation function,
which can be incrementally minimized through an anytime
process. Similarly, LPG can produce plans of good quality
in terms of the number of parallel steps in the plan, and the
overall duration of the plan.

Experimental results in several benchmark domains give
an empirical demonstration of the efﬁciency of our ap-
proach, showing, in particular, that LPG can be orders of
magnitude faster than other existing planners based on plan-
ning graphs. On the other hand, the ﬁrst plan computed by
LPG can be of poor quality. When this is the case, LPG
produces additional plans that incrementally improve plan
quality in terms of one or more criteria speciﬁed in the eval-
uation function.

Current work include further experiments to test other
local search schemes implemented in LPG (Tabuplan and
T-Walkplan), and the development of new types of graph
modiﬁcations and heuristics to guide the search. Finally,
very recently an extended version of LPG handling complex
PDDL2.1 domains involving numerical quantities and ac-
tion durations (http://prometeo.ing.unibs.it/lpg) participated
in the 3rd International Planning Competition, and it was
awarded for “distinguished performance of the ﬁrst order”.9

9http://www.dur.ac.uk/d.p.long/competition.html

22    AIPS 2002

References

Blum, A., and Furst, M. 1997. Fast planning through plan-
ning graph analysis. Artiﬁcial Intelligence 90:281–300.
Fox, M., and Long, D. 1998. Efﬁcient implementation of
the Plan Graph in STAN. Journal of Artiﬁcial Intelligence
research (JAIR), vol. 10, 87–115.
Fox, M., and Long, D. 1999. The detection and exploita-
tion of symmetry in planning problems. In Proc. of the 16th
Int. Joint Conf. on Artiﬁcial Intelligence (IJCAI-99).
Gerevini, A., and Serina, I. 1999. Fast planning through
greedy action graphs. In Proc. of the 16th Nat. Conf. of the
Am. Assoc. for Artiﬁcial Intelligence (AAAI-99).
Gerevini, A., and Serina, I. 2001. Lagrange multipliers for
local search on planning graphs. In Proc. of the ECAI-2000
Workshop on Local Search for Planning and Scheduling.
Springer-Verlag.
Hoffmann, J., and Nebel, B. 2001. The FF planning sys-
tem: Fast plan generation through heuristic search. Journal
of Artiﬁcial Intelligence research (JAIR) 14:253–302.
Kautz, H., and Selman, B. 1999. Unifying SAT-based and
graph-based planning.
In Proc. of the 16th International
Joint Conference on Artiﬁcial Intelligence (IJCAI-99).
Kautz, H.; McAllester, D.; and Selman, B. 1996. Encoding
plans in propositional logic. In Proc. of the 5th Int. Conf.
on Principles of Knowledge Representation and Reasoning
(KR’96).
Koehler, J.; Nebel, B.; Hoffmann, J.; and Dimopoulos,
Y. 1997. Extending planning graphs to an ADL sub-
set. In Proc. of Fourth European Conference on Planning
(ECP’97). Springer Verlag.
Moskewicz, M.; Madigan, C.; Zhao, Y.; Zhang, L.; and
Malik, S. 2001. Chaff: Engineering an efﬁcient SAT solver.
In Proc. of 39th Design Automation Conference.
Kambhampati, R.; Minh, S.; and Do, B. 2001. Planning
as Constraint Satisfaction: Solving the planning graph by
compiling it into CSP. Artiﬁcial Intelligence 132(2):151–
182.
Selman, B.; Kautz, H.; and Cohen, B. 1994. Noise strate-
gies for improving local search.
In Proc. of the Twelfth
Nat. Conference of the American Association for Artiﬁcial
Intelligence (AAAI-94) , 337–343.
Shang, Y., and Wah, B. 1998. A discrete Lagrangian-based
global-search method for solving satisﬁability problems.
Journal of Global Optimization 12,1:61–99.
Smith, D., and Weld, D. 1999. Temporal planning with mu-
tual exclusion reasoning. In Proc. of the 16th International
Joint Conference on Artiﬁcial Intelligence (IJCAI-99).
Wah, B. W., and Wu, Z. Oct. 1999. The Theory of Discrete
Lagrange Multipliers for Nonlinear Discrete Optimization.
In Proc. of Principles and Practice of Constraint Program-
ming. Springer-Verlag.
Wu, Z., and Wah, B. 2000. An efﬁcient global-search
strategy in discrete Lagrangian methods for solving hard
satisﬁability problems. In Proc. of the 17th Nat. Conf. of
the American Assoc. for Artiﬁcial Intelligence (AAAI-00).

