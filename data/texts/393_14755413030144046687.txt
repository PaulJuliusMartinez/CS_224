DSM/SPhT-T06/074 http://www-spht.cea.fr/articles/T06/074/

Bernd A. Berg, Department of Physics, Florida State University Alain Billoire, Service de physique th´eorique, CEA Saclay

MARKOV CHAIN MONTE CARLO SIMULATIONS
J. Webster (ed.), Wiley Encyclopedia of Computer Science and Engineering Online Copyright 2006 by John Wiley & Sons, Inc. All rights reserved.

Markov Chain Monte Carlo (MCMC) simulations are widely used in many branches of science. They are nearly as old as computers themselves, since they started in earnest with a 1953 paper by Nicholas Metropolis, Arianna Rosenbluth, Marshall Rosenbluth, Augusta Teller and Edward Teller [1] at the Los Alamos National Laboratory, New Mexico, USA. These authors invented what is nowadays called the Metropolis algorithm. Various applications and the history of the basic ideas are reviewed in the proceedings [2] of the 2003 Los Alamos conference, which celebrated the 50th anniversary of the Metropolis algorithm.

Overview
The Monte Carlo method to compute integrals [3] amounts to approximate an integral  dµ(X)O(X), inside a volume , where dµ(X) is some integration measure and  dµ(X) < , by sampling. Without loss of generality, one can assume that  dµ(X) = 1, and consider accordingly dµ(X) as a probability measure. Drawing independently Nsamples values of X   according to this probability measure, one has



dµ(X )O(X )



1 Nsamples

Nsamples s=1

O(Xs) ,

(1)

where Xs is the s'th random variable drawn. The right hand side of Eq. 1 is an unbiased estimator of the integral, namely it is exact in average, for any Nsamples. It converges towards the correct value when Nsamples  , with a 1/ Nsamples leading correction. This method is of practical use if one can easily draw, in a computer program, random values Xs   according to the measure dµ(X). This is the case in particular if one integrates inside a N

dimensional hyper cube with the flat measure dµflat(X)  Nk=1dX(k), where the X(k)'s are the Cartesian components of X, or when the integral reduces to a finite sum. This is not

the case in the situation where this simple measure is multiplied by a non trivial function

(X) of the components X(k). If (X) is a smooth function in  with a limited range of

variations, one can still draw values of X according to the simple measure dµflat and write

(assuming without loss of generality that  dµ(X) = 1 and  dµflat(X) = 1)

dµ(X)O(X) =




dµf lat (X )(X )O(X )



1 Nsamples

Nsamples s=1

(Xs)O(Xs) .

1

(2)

- () in: Wiley Encyclopedia of Computer Science and Engineering Online

DSM/SPhT-T06/074 http://www-spht.cea.fr/articles/T06/074/

If the function (X) has a very large range of variations with one or several sharp peaks, the sum in Eq. 2 is dominated by a few rare configurations, and the Monte Carlo method does not work (most samples are drawn in vain). This is the case of the problem considered in [1], where (X) is a Boltzmann weight, the exponential of N times a function of order one, with N the number of molecules in a box, a notoriously large number.
The Markov Chain Monte Carlo method allows overcoming this problem by generating a set of random X  , distributed according to the full measure dµ(X), using an auxiliary Markov Chain. Note that often, in particular in the physics literature, Monte Carlo is used as a short name for Markov Chain Monte Carlo. MCMC is sometimes called dynamic Monte Carlo, in order to distinguish it from the usual, "static", Monte Carlo. Many probability distributions, which cannot be sampled directly, allow for MCMC sampling. From now on we write formula for a discrete space  with Kst states, although the results can be generalized. A Markov chain [4] is a sequence of random variables X1, X2, X3, . . ., that can be viewed as the successive states of a system as a function of a discrete time t, with a transition probability P(Xt+1 = r|Xt = s) = Wr,s that is a function of r and s only. The next future state Xt+1 is a function of the present state Xt alone. Andrey Markov [5] was the first to analyze these processes. In order to analyze Markov chains, one introduces an ensemble of chains with an initial probability distribution P(X0 = s). By multiplying this vector by the transition matrix repeatedly, one obtains P(X1 = s), then P(X2 = s), . . . , successively. The natural question is whether this sequence converges. One says that a probability distribution w = {ws}s is an equilibrium distribution of a Markov Chain if it is let invariant by the chain, namely if

Kst

Wr,ss = r

(3)

s=1

This condition is called balance in the physics literature. A Markov Chain is said to be

ergodic (more precisely irreducible and aperiodic) if for all states r, s   there is a Nr,s such that for all t > Nr,s the probability (W t)s,r to go from r to s in t steps is non zero. If an
equilibrium distribution exists and if the chain is irreducible and aperiodic, one can show [4]

that, starting from any distribution P(X0 = s), the distribution after t steps P(Xt = s) converges when t   towards the equilibrium configuration s.
The Metropolis Algorithm (see next section) offers a practical way to generate a Markov

chain with a desired equilibrium distribution, on a computer using a pseudo random numbers

generator. Starting from an initial configuration X0, successive configurations are generated. In most cases the convergence of P(Xt = s) towards s is exponential in t and one can safely assume that after some number of steps teq, "equilibrium is reached" and that the configurations Xteq+1, Xteq+2, . . . are distributed according to (X).
Whereas the random samples used in a conventional Monte Carlo (MC) integration

are obviously statistically independent, those used in MCMC are correlated. The effective

number of independent events generated by an equilibrated Markov chain is given by the

number of steps done divided by a quantity called "integrated autocorrelation time", int. In

2

- () in: Wiley Encyclopedia of Computer Science and Engineering Online

DSM/SPhT-T06/074 http://www-spht.cea.fr/articles/T06/074/

most cases int does not depend on the quantity O measured, but there are exceptions like e.g. the vicinity of a second order (continuous) phase transition. The algorithm will fail if int is too big. In practice it can be quite difficult to estimate int reliably and there can also be a residual effect of the starting position. More sophisticated MCMC-based algorithms such as "coupling from the past" [6] produce independent samples rigorously, but at the cost of additional computation and an unbounded (though finite on average) running time.
The method was originally developed to investigate a statistical physics problem. Suitable applications arise as well in computational biology, chemistry, physics, economics, and other sciences. MCMC calculations have also revolutionized the field of Bayesian statistics.
Most concepts of modern MCMC simulation were originally developed by physicists and chemists, who still seem to be at the cutting edge of new innovative developments into which mathematician, computer scientists and statisticians have joined. Their interest developed mainly after a paper by Hastings [7], who generalized the accept/reject step of the Metropolis method. Unfortunately a language barrier developed, that inhibits cross fertilization. For instance the "heat bath" algorithm, which may be applied when the conditional distributions can be sampled exactly, was introduced by physicist in [8, 9]. Then it was rediscovered in the context of Bayesian restoration of images under the name "Gibbs sampler" [10]. Another example is the "umbrella sampling" algorithm [35] that was invented in Chemical Physics and later rediscovered and improved by physicists. This is just two of many examples how different names for the same method emerged. The reader should be aware that this article was written by physicists, so that their notations and views are dominant in this article. The book by Liu [11] tries to some extent to bridge the language barrier. Other textbooks are Robert and Casella [12] for the more mathematically minded reader, Landau and Binder [13] for statistical physicists, Berg [14] is written from a physicist point of view, but covers statistics too and comes with extensive computer code (in Fortran). Kendall, Liang and Wang [16] edited a book that combines expositions from physicists, statisticians and computer scientists.
In the following we will first explain the basic method and illustrate it for a simple statistical physics system, the Ising ferromagnet in two dimensions, followed by a few remarks on autocorrelations and cluster algorithms. An overview of MCMC updating scheme is subsequently given. The final section of this article focuses on so called generalized ensemble algorithms.
MCMC and Statistical Physics
As mentioned before, the MCMC algorithm was invented to investigate problems in statistical physics. The aim of statistical physics is to predict the average macroscopic properties of systems made of many constituents, that can be e.g. molecules in a box (as in the original article of Metropolis et al), magnetic moments (called spins) at fixed locations in a piece of materials, or polymer chains in a solvent. If one considers the so called canonical ensemble, where the system has a fixed temperature T, one knows that the probability to observe a given microscopic configuration (or micro state) s (defined in the three examples
3
- () in: Wiley Encyclopedia of Computer Science and Engineering Online

DSM/SPhT-T06/074 http://www-spht.cea.fr/articles/T06/074/

given above by the positions and velocities of all molecules; the orientations of all the spins; and the exact configuration of the all polymer chains respectively) is proportional to the Boltzmann weight exp(-Es/kBT ), where Es is the energy of the configuration s, kB the Boltzmann constant and T the temperature (In the following we will use a unit of temperature such that kB = 1). The average value of any macroscopic observable O (e.g. the average energy) is given by the sum over all possible configurations s of Os (the value of O computed in configuration s), weighted by the Boltzmann weight of the configuration. This sum (or integral if one has continuous variables) is to be normalized by the sum over all configurations of the Boltzmann weight (the so called partition function Z(T )), namely

Kst
O = O(T ) = O = Z-1(T ) Os e-Es/T ,
s=1

(4)

where Z(T ) =

Kst s=1

exp(-Es/T ).The

index

s

=

1, . . . , Kst

labels

the

configurations

(states)

of the system.

A particularly simple system is the Ising model for which the energy is given by

E = - si sj .
<ij>

(5)

Here the sum is over the nearest neighbor sites of a hyper-cubic D-dimensional lattice and the

Ising spins take the values si = ±1 with equal probability independently for i = 1, . . . , N for

a system of N =

D i=1

Li

spins.

Periodic

boundary

conditions

are

used

in

most

simulations.

The energy per spin is e = E/N . The model describes a ferromagnet for which the magnetic

moments are simplified to ±1 spins at the sites of the lattice. In the N   limit (and

for D > 1) this model has two phases separated by a phase transition (a singularity) at

the critical temperature T = Tc. This is a second order (continuous) phase transition. This model can be solved analytically when D=2 (This means that one can obtain exact

analytical expressions for the thermodynamic quantities, e.g. the energy per spin, as a

function of temperature, in the N   limit.). This makes the 2dimensional Ising model

an ideal test bed for MCMC algorithms.

The number of configurations of the Ising model is Kst = 2N , because each spin can occur in two states (up or down). Already for a moderately sized lattice, say linear dimension

L1 = L2 = 100 in D = 2, Kst is a tremendously large number. With the exception of very small systems, it is therefore impossible to do the sums in Eq. 4 explicitly. Instead, the large

value of Kst suggests a statistical evaluation.

Importance Sampling through MCMC
As explained in the introduction, one needs a procedure that generates configurations s with the Boltzmann probability

PB,s = cB wB,s = cBe-Es ,

(6)

4

- () in: Wiley Encyclopedia of Computer Science and Engineering Online

DSM/SPhT-T06/074 http://www-spht.cea.fr/articles/T06/074/

where the constant cB is determined by the condition s PB,s = 1. The vector PB := {PB,s} is called the Boltzmann state. When configurations are generated with the probability PB,s, the expectation values (Eq. 4) are estimated by the arithmetic averages:

O

=

lim
Kst

1 Kst

Kst
Os
s=1

.

(7)

With the MCMC algorithm, this is obtained from a Markov Chain with the following properties:

(i) Irreducibility and aperiodicity (Ergodicity in the physics literature): For any two configurations r and s, an integer Nr,s exists such that for all n > Nr,s, the probability (W n)r,s is non zero;
(ii) Normalization: r Wr,s = 1.
(iii) Stationarity of the Boltzmann distribution (Balance in the physics literature): The Boltzmann state (Eq. 6) is an equilibrium distribution, namely a right eigenvector of the matrix W with eigenvalue one, i.e., s Wr,se-Es = e-Er holds.
There are many ways to construct a Markov process satisfying (i), (ii), and (iii). In practice, MCMC algorithms are often based on a stronger condition than (iii), namely,

(iii') Detailed balance:

Wr,se-Es = Ws,re-Er

r, s .

(8)

Metropolis Algorithm and Illustration for the Ising Model

Detailed balance obviously does not uniquely fix the transition probabilities Wr,s. The original Metropolis algorithm [1] has remained a popular choice because of its generality (it can be applied straightforwardly to any statistical physics model) and its computational simplicity. The original formulation generates configurations with the Boltzmann weights. It generalizes immediately to arbitrary weights (see the last section of this article). Given a configuration s, the algorithm proposes a new configuration r with a priori probabilities f (r, s). This new configuration r is accepted with probability

ar,s

=

min

1,

PB,r PB,s

=

1 for Er < Es , e-(Er-Es) for Er > Es .

(9)

If the new configuration is rejected, the old configuration is kept and counted again. For such decisions one uses normally a pseudo random number generator, which delivers uniformly distributed pseudo random numbers in the range [0, 1), see [13, 14] for examples, and [15]

5

- () in: Wiley Encyclopedia of Computer Science and Engineering Online

DSM/SPhT-T06/074 http://www-spht.cea.fr/articles/T06/074/

for the mathematics involved. The Metropolis algorithm gives then rise to the transition probabilities

Wr,s = f (r, s) ar,s r = s and
Ws,s = f (s, s) + f (r, s) (1 - ar,s) .
r=s
Therefore, the ratio Wr,s/Ws,r satisfies the detailed balance condition (Eq. 8) if
f (r, s) = f (s, r)

(10) (11)
(12)

holds. This condition can be generalized when also the acceptance probability is changed [7]. In particular such "biased" Metropolis algorithms allow to approach the heat-bath updating scheme [17].
For the Ising model, the new putative configuration differs from the old one by the flip of a single spin. Such a "single spin update" requires a number of operations of order one, and leads to a ratio PB,r/PB,s in Eq. 9 or order one too. This is fundamental in order to have an efficient MCMC algorithm. The spin itself maybe chosen at random, although some sequential procedure is normally more efficient [14]. The later procedure violates the detailed balance condition, but fulfill the balance condition, and thus does lead to the probability of states approaching the Boltzmann distribution (Eq. 6). The unit of Monte Carlo time is usually defined by N single spin update, aka a lattice sweep or "an update per spin". Many ways to generate initial configurations exist. Two easy to implement choices are

1. Use random sampling to generate a configuration of ±1 spins.

2. Generate a completely ordered configuration, either all spin +1 or -1.

Figure 1 shows two Metropolis energy time series (the successive values of the energy as a function of the discrete Monte Carlo time) of 6000 updates per spin for a 2D Ising model on a 100 × 100 lattice at  = 0.44, whichis close to the (infinite volume) phase transition temperature of this model (c = ln(1 + 2)/2 = 0.44068 . . .). One can compare with the exact value for e [18] on this system size, which is indicated by the straight line in Fig. 1. The time series corresponding to the ordered start begins at e = -2 and approaches the exact value from below, whereas the other time series begins (up to statistical fluctuation) at e = 0 and approaches the exact value from above. It takes a rather long MCMC time of about 3000 to 4000 updates per spin until the two time series start to mix. For estimating equilibrium expectation values measurements should only be counted from there on. A serious error analysis for the subsequent equilibrium simulation find an integrated autocorrelation time int  1 700 updates per spin. This long autocorrelation time is related to the proximity of the phase transition (this is the so called critical slowing down of the dynamics). One can show that, at the transition point, int diverges like a power of N .
6

- () in: Wiley Encyclopedia of Computer Science and Engineering Online

DSM/SPhT-T06/074 http://www-spht.cea.fr/articles/T06/074/ e

-1.2 -1.25
-1.3 -1.35
-1.4 -1.45
-1.5 -1.55
-1.6 0

Random Start Ordered Start
Exact
1000 2000 3000 4000 5000 6000 updates per spin

Figure 1: 2D Ising model: Two initial Metropolis time series for the energy per spin e.

For this model and a number of other systems with second order phase transitions, cluster algorithms [19, 20] are known, which have much shorter autocorrelation times, in simulations close to the phase transition point. For the simulation of Fig. 1 int  5 updates per spin instead of 1 700. Furthermore, with cluster algorithms int grows much slower with the system size N than with the Metropolis algorithm. This happens because these algorithms allow for the instantaneous flip of large clusters of spins (still with order one acceptance probability) in contrast to the local updates of single spins done in the Metropolis and heat-bath type algorithms. Unfortunately such nonlocal updating algorithms have remained confined to special situations. The interested reader can reproduce these Ising model simulations discussed here using the code that comes with Ref. [14].
Updating Schemes
We give an overview of MCMC updating schemes that is, however, not complete at all.
1. We have already discussed the Metropolis scheme [1] and its generalization by Hastings [7]. Variables of the system are locally updated.
2. Within such local schemes the heat-bath method [8, 9, 10] is usually the most efficient. In practice it can be approximated by tabulating Metropolis-Hastings probabilities [17].
3. For simulations at (very) low temperatures event driven simulations [21, 22], also known as "N-fold way", are most efficient. They are based on Metropolis or heat-bath schemes.

7

- () in: Wiley Encyclopedia of Computer Science and Engineering Online

DSM/SPhT-T06/074 http://www-spht.cea.fr/articles/T06/074/

4. As already introduced, for a number of models with second order phase transitions the MCMC efficiency is greatly improved by using nonlocal cluster updating [19].
5. Molecular dynamics (MD) moves can be used as proposals in MCMC updating [23, 26], a scheme called "hybrid MC", see [27] for a review of MD simulations.
More examples can be found in W. Krauth contribution in [25] and A. D. Sokal in[24].
Generalized Ensembles for MCMC Simulations
The MCMC method, that we discussed for the Ising model, generates configurations distributed according to the Boltzmann-Gibbs canonical ensemble, with weights PB,s. Mean values of physical observables at the temperature chosen are obtained as arithmetic averages of the measurements made (Eq. 7). There are however, in statistical physics, circumstances where another ensemble (other weights PNB,s) can be more convenient. One case is the computation of the partition function Z(T ) as a function of temperature. Another is the investigation of configurations of physical interest that are rare in the canonical ensemble. Finally the efficiency of the Markov process, i.e., the computer time needed to obtain a desired accuracy can depend greatly on the ensemble in which the simulations are performed. This is the case e.g. when, taking into account the Boltzmann weights, the phase space separates, loosely speaking, into several populated regions separated by mostly vacant regions, creating so called energy barriers for the Markov chain.
A first attempt to calculate the partition function by MCMC simulations dates back to a 1959 paper by Salsburg et al. [28]. As was already noticed by the authors their method is restricted to very small lattices. The reason is that their approach relies on what is called in the modern language "reweighting". It evaluates results at a given temperature from data taken at another temperature. The reweighting method has a long history. McDonald and Singer [29] were the first to use it to evaluate physical quantities over a range of temperatures from a simulation done at a single temperature. Thereafter dormant, the method was rediscovered in an article [30] focused on calculating complex zeros of the partition function. It remained to Ferrenberg and Swendsen [31] to formulate crystal-clear for what the method is particularly good, and for what it is not: The reweighting method allows to focus on maxima of appropriate observables, but it does not allow to cover a finite temperature range in the infinite volume limit.
To estimate the partition function over a finite energy density range e, i.e., E  N , one can patch the histograms from simulations at several temperatures. Such multihistogram methods have also a long tradition too. In 1972 Valleau and Card [32] proposed the use of overlapping bridging distributions and called their method "multistage sampling". Free energy and entropy calculations become possible when one can link the temperature region of interest with a point in configuration space for which exact values of these quantities are known. Modern work [33, 34] developed efficient techniques to combine the overlapping distributions into one estimate of the spectral density (E) (with Z(T ) =
8
- () in: Wiley Encyclopedia of Computer Science and Engineering Online

DSM/SPhT-T06/074 http://www-spht.cea.fr/articles/T06/074/

dE(E) exp(-E)) and to control the statistical errors of the estimate. However, the patching of histograms from canonical simulations faces a number of limitations:
 1. The number of canonical simulations needed diverges like N when one wants to cover
a finite, non-critical range of the energy density.
2. At a first order phase transition point, the canonical probability of configurations with an interface decreases exponentially with N .

One can cope with the difficulties of multi-histogram methods by allowing arbitrary sampling distributions instead of just the Boltzmann-Gibbs ensemble. This was first recognized by Torrie and Valleau [35] when they introduced umbrella sampling. However, for the next thirteen years the potentially very broad range of applications of the basic idea remained unrecognized. A major barrier, which prevented researchers from trying such extensions, was certainly the apparent lack of direct and straightforward ways of determining suitable weighting functions PNB,s for problems at hand. In the words of Li and Scheraga [36]: The difficulty of finding such weighting factors has prevented wide applications of the umbrella sampling method to many physical systems.
This changed with the introduction of the multicanonical ensemble [37], which focuses on well-defined weight functions and offers a variety of methods to find a "working approximation". Here a working approximation is defined as being accurate enough, so that the desired energy range will indeed be covered after the weight factors are fixed. A similar approach can also be constructed for cluster algorithms [40]. A typical simulation consists then of three parts:

1. Construct a working approximation of the weight function Pmuca. The Wang-Landau recursion [38] is an efficient approach. See [39] for a comparison with other methods.

2. Perform a conventional MCMC simulation with these weight factors.

3. Reweight the data to the desired ensemble:

O

=

limKst

1 Kst

Kst s=1

OsPB,s/Pmuca,s

Details can be found in [14].

Another class of algorithms appeared in a couple of years around 1991, in a number of papers [41, 42, 43, 44, 45], which all aimed at improving MCMC calculations by extending the confines of the canonical ensemble. Practically most important has been the replica exchange method, which is also known under the names parallel tempering and multiple Markov chains. In the context of spin glass simulations an exchange of partial lattice configurations at different temperatures was proposed by Swendsen and Wang [41]. But it was only recognized later [42, 45] that the special case for which entire configurations are exchanged is of utmost importance, see [14] for more details. Closely related is the Jump Walker (J-Walker) approach [49], which feeds replica from a higher temperature into a simulation at a lower temperature instead of exchanging them. Finally, and perhaps most

9

- () in: Wiley Encyclopedia of Computer Science and Engineering Online

DSM/SPhT-T06/074 http://www-spht.cea.fr/articles/T06/074/

multicanonical
1000

Histograms

500
702 lattice

canonical
0 1.0 1.5
-E/N
Figure 2: Multicanonical Pmuca(E) together with canonical P (E) energy distribution as obtained in Ref. [37] for the 2d 10-state Potts model on a 70×70 lattice. In the multicanonical ensemble, the gap between the two peaks present in P (E) is filled up, increasing considerably the dynamics of the Markov Chain.

Histograms

3e+06 2.5e+06
2e+06 1.5e+06

03412756========00000000........6777667757500912070336770202431301124069

1e+06

500000

0 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
2-E/N

Figure 3: Canonical energy distributions P (E) from a parallel tempering simulation with eight processes for the 2d 10-state Potts model on 20 × 20 lattices (Fig. 6.2 in [14]).

important: From about 1992 on, applications of generalized ensemble methods diversified tremendously as documented in a number of reviews [46, 47, 48].
Basic mechanisms for overcoming energy barriers with the multicanonical algorithm are best illustrated for first-order phase transitions (namely a transition with a non zero latent heat, like the ice-water transition), where one deals with a single barrier. To give an example, Fig. 2 shows for the 2d 10-state Potts model [50] the canonical energy histogram at a pseudocritical temperature versus the energy histogram of a multicanonical simulation on a 70 × 70 lattice [37]. The same barrier can also be overcome by a parallel tempering simulation, but in a quite different way. Figure 3 shows the histograms from a parallel tempering simulation with eight processes on a 20 × 20 lattices. The barrier can be "jumped" when there are

10

- () in: Wiley Encyclopedia of Computer Science and Engineering Online

DSM/SPhT-T06/074 http://www-spht.cea.fr/articles/T06/074/

on both sides of the barrier temperatures in the ensemble, which are sufficiently close to a pseudo-critical temperature for which the two peaks of the histogram are of competitive height. In complex systems with a rugged free energy landscape (spin glasses, biomolecules, . . . ) the barriers can no longer be explicitly controlled. Nevertheless it has turned out that switching to the discussed ensembles can greatly enhance the MCMC efficiency [47, 48]. For a recent discussion of ensemble optimization techniques see [51] and references given therein.
References
[1] N. Metropolis, A.W. Rosenbluth, M.N. Rosenbluth, A.H. Teller and E. Teller. Equation of State Calculations by Fast Computing Machines. J. Chem. Phys. 21: 1087­1092 (1953).
[2] J. Gubernatis (Editor). The Monte Carlo Method in the Physical Sciences: Celebrating the 50th Anniversary of the Metropolis Algorithm. AIP Conference Proceedings, Volume 690, Melville, NY 2003.
[3] N. Metropolis and S. Ulam. The Monte Carlo Method. J. Am. Stat. Assoc. 44: 335­341 (1949) and references given therein.
[4] J. G. Kemeny and J. L. Snell. Finite Markov Chains, Springer, New York, 1976; M. Iosifescu, Finite Markov Processes and Their Applications, Wiley, Chichester, 1980; K. L. Chung, Markov Chains with Stationary Transition Probabilities, 2nd ed. Springer, New York, 1967; E. Nummelin, General Irreducible Markov Chains and Non-Negative Operators, Cambridge Univ. Press, Cambridge, 1984.
[5] A.A. Markov. Rasprostranenie zakona bol'shih chisel na velichiny, zavisyaschie drug ot druga. Izvestiya Fiziko-matematicheskogo obschestva pri Kazanskom Universitete, 2-ya seriya, tom 15: 135­156 (1906).
[6] J.G. Propp and D.B. Wilson. Exact Sampling with Coupled Markov Chains and Applications in Statistical Mechanics. Random Structures and Algorithms 9: 223­252 (1996). Coupling from the Past User's Guide. DIMACS Series in Discrete Mathematics and Theoretical Computer Science (AMS) 41: 181­192 (1998).
[7] W.K. Hastings. Monte Carlo Sampling Methods Using Markov Chains and Their Applications. Biometrika 57: 97­109 (1970).
[8] R.J. Glauber. Time-Dependent Statistics of the Ising Model. J. Math. Phys. 4: 294­307 (1963).
[9] M. Creutz. Monte Carlo Study of Quantized SU (2) Gauge Theory. Phys. Rev. D 21: 2308­2315 (1980).
11
- () in: Wiley Encyclopedia of Computer Science and Engineering Online

DSM/SPhT-T06/074 http://www-spht.cea.fr/articles/T06/074/

[10] S. Geman and D. Geman. Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images. IEEE Transactions on Pattern Analysis and Machine Intelligence 6: 721­741 (1984).
[11] J.S. Liu. Monte Carlo Strategies in Scientific Computing. Springer, New York 2001.
[12] C.P. Robert and G. Casella. Monte Carlo Statistical Methods (second edition). Springer, New York 2005.
[13] D.P. Landau and K. Binder. A Guide to Monte Carlo Simulations in Statistical Physics. Cambridge University Press, Cambridge 2000.
[14] B.A. Berg. Markov Chain Monte Carlo Simulations and Their Statistical Analysis. World Scientific, Singapore 2004.
[15] D. Knuth. The Art of Computer Programming, Volume 2: Semi numerical Algorithms, Third Edition. Addison-Wesley, Reading (MA) 1997. Chapter 3, pp.1193
[16] W.S. Kendall, F. Liang, and J.-S. Wang (Editors). Markov Chain Monte Carlo: Innovations and Applications (Lecture Notes Series, Institute for Mathematical Sciences, National University of Singapore). World Scientific, Singapore 2005.
[17] A. Bazavov and B.A. Berg. Heat Bath Efficiency with Metropolis-Type Updating. Phys. Rev. D 71, 114506 (2005).
[18] A.E. Ferdinand and M.E. Fisher. Bounded and Inhomogeneous Ising Models. I. SpecificHeat Anomaly of a Finite Lattice. Phys. Rev. 185: 832­846 (1969).
[19] R.H. Swendsen and J.-S. Wang. Non-universal Critical Dynamics in Monte Carlo Simulations. Phys. Rev. Lett. 58: 86­88 (1987).
[20] U. Wolff. Collective Monte Carlo Updating for Spin Systems. Phys. Rev. Lett. 62: 361­ 363 (1989).
[21] A.B. Bortz, M.H. Kalos, and J.L. Lebowitz. A New Algorithm for Monte Carlo Simulation of Ising Spin Systems. J. Comp. Phys. 17: 10­18 (1975).
[22] M.A. Novotny. A Tutorial on Advanced Dynamic Monte Carlo Methods for Systems with Discrete State Spaces. Ann. Rev. Comp. Phys. 9: 153­210 (2001).
[23] S. Duane, A.D. Kennedy, B.J., Pendleton, and D. Roweth. Hybrid Monte Carlo. Phys. Lett. B 195: 216­222 (1987).
[24] K. Binder (Editor). Monte Carlo and Molecular Dynamics Simulations in Polymer Science, Oxford University Press 1996.
12
- () in: Wiley Encyclopedia of Computer Science and Engineering Online

DSM/SPhT-T06/074 http://www-spht.cea.fr/articles/T06/074/

[25] J. Kertesz and I. Kondor (Editors). Advances in Computer Simulation. Lecture Notes in Physics, Springer Verlag, Heidelberg 1998.
[26] B. Mehlig, D.W. Heermann, and B.M. Forrest. Hybrid Monte Carlo Methods for Condensed-Matter Systems. Phys. Rev. B 45: 679­685 (1992).
[27] D. Frenkel and B. Smit. Understanding Molecular Simulation. Academic Press, San Diego 1996.
[28] Z.W. Salsburg, J.D. Jacobson, W.S. Fickett, and W.W. Wood. Applications of the Monte Carlo Method to the Lattice-Gas Model. I. Two-Dimensional Triangular Lattice. J. Chem. Phys. 30: 65­72 (1959).
[29] I.R. McDonald and K. Singer. Calculation of Thermodynamic Properties of Liquid Argon from Lennard-Jones Parameters by a Monte Carlo Method. Discussions Faraday Soc. 43: 40­49 (1967).
[30] M. Falcioni, E. Marinari, L. Paciello, G. Parisi, and B. Taglienti. Complex Zeros in the Partition Function of Four-Dimensional SU (2) Lattice Gauge Model. Phys. Lett. B 108: 331­332 (1982).
[31] A.M. Ferrenberg and R.H. Swendsen. New Monte Carlo Technique for Studying Phase Transitions. Phys. Rev. Lett. 61: 2635­2638 (1988); 63: 1658 (1989).
[32] J.P. Valleau and D.N. Card. Monte Carlo Estimation of the Free Energy by Multistage Sampling. J. Chem. Phys. 37: 5457­5462 (1972).
[33] A.M. Ferrenberg and R.H. Swendsen. Optimized Monte Carlo Data Analysis. Phys. Rev. Lett. 63: 1195­1198 (1989).
[34] N.A. Alves, B.A. Berg, and R. Villanova. Ising-Model Monte Carlo Simulations: Density of States and Mass Gap. Phys. Rev. B 41: 383­394 (1990).
[35] G.M. Torrie and J.P. Valleau. Nonphysical Sampling Distributions in Monte Carlo Free Energy Estimation: Umbrella Sampling. J. Comp. Phys. 23: 187-199 (1977).
[36] Z. Li and H.A. Scheraga. Structure and Free Energy of Complex Thermodynamic Systems. J. Mol. Struct. (Theochem) 179, 333­352 (1988).
[37] B.A. Berg and T. Neuhaus. Multicanonical Ensemble: A New Approach to Simulate First-Order Phase Transitions. Phys. Rev. Lett. 68: 9­12 (1992).
[38] F. Wang and D.P. Landau. Efficient, Multiple-Range Random Walk Algorithm to Calculate the Density of States. Phys. Rev. Lett 86: 2050­2053 (2001).
13
- () in: Wiley Encyclopedia of Computer Science and Engineering Online

DSM/SPhT-T06/074 http://www-spht.cea.fr/articles/T06/074/

[39] Y. Okamoto. Metropolis Algorithms in Generalized Ensemble. In Ref. [2], pp. 248­260. On the web at http://arxiv.org/abs/cond-mat/0308119.
[40] W. Janke and S. Kappler. Multibondic Cluster Algorithm for Monte Carlo Simulations of First-Order Phase Transitions. Phys. Rev. Lett. 74: 212-215 (1985).
[41] R.H. Swendsen and J.-S. Wang. Replica Monte Carlo Simulations of Spin Glasses. Phys. Rev. Lett. 57: 2607­2609 (1986).
[42] C.J. Geyer. Markov Chain Monte Carlo Maximum Likelihood, in Computing Science and Statistics, Proceedings of the 23rd Symposium on the Interface, Keramidas, E.M. (Editor), Interface Foundation, Fairfax, Virginia, 1991, pp. 156­163; C.J. Geyer and E.A. Thompson. Annealing Markov Chain Monte Carlo with Applications to Ancestral Inference. J. Am. Stat. Ass. 90: 909-920 (1995).
[43] E. Marinari and G. Parisi. Simulated Tempering: A New Monte Carlo Scheme. Europhys. Lett. 19: 451­458 (1992).
[44] A.P. Lyubartsev, A.A. Martsinovski, S.V. Shevkanov, and P.N. Vorontsov-Velyaminov. New Approach to Monte Carlo Calculation of the Free Energy: Method of Expanded Ensembles. J. Chem. Phys. 96: 1776­1783 (1992).
[45] K. Hukusima and K. Nemoto. Exchange Monte Carlo Method and Applications to Spin Glass Simulations. J. Phys. Soc. Japan 65: 1604­1608 (1996).
[46] W. Janke. Multicanonical Monte Carlo Simulations. Physica A 254: 164­178 (1998).
[47] U.H. Hansmann and Y. Okamoto. The Generalized-Ensemble Approach for Protein Folding Simulations. Ann. Rev. Comp. Phys. 6: 129­157 (1999).
[48] A. Mitsutake, Y. Sugita, and Y. Okamoto. Generalized-Ensemble Algorithms for Molecular Simulations of Biopolymers. Biopolymers (Peptide Science) 60: 96­123 (2001).
[49] D.D. Frantz, D.L. Freemann, and J.D. Doll. Reducing Quasi-ergodic Behavior in Monte Carlo Simulations by J-walking: Applications to Atomic Clusters. J. Chem. Phys. 93: 2769­2784 (1990).
[50] F.Y. Wu. The Potts Model. Rev. Mod. Phys. 54: 235­268 (1982).
[51] S. Trebst, D.A. Huse, E. Gull, H.G. Katzgraber, U.H.E. Hansmann, and M. Troyer. Ensemble Optimization Techniques for the Simulation of Slowly Equilibrating Systems, Invited talk at the 19th Annual Workshop on Computer Simulation Studies in Condensed Matter Physics, Athens, GA, 20-24 February 2006, in D.P. Landau, S.P. Lewis, and H.-B. Schuettler (Editors). Springer Proceedings in Physics, Volume 115, (2007). On the Web at http://arxiv.org/abs/cond-mat/0606006.
14
- () in: Wiley Encyclopedia of Computer Science and Engineering Online

