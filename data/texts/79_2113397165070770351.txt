TWELVE DIFFERENT INTERPOLATION METHODS: A CASE STUDY OF SURFER 8.0

Chin-Shung Yang* Szu-Pyng Kao* Fen-Bin Lee** Pen-Shan Hung**

*National Chung Hsing University, Taichung, Taiwan, ROC yangchin@ms1.emax.net.tw

**Feng Chia University, Taichung, Taiwan, ROC

majorlfp@mail.apol.com.tw

KEY WORDS: DTM (digital terrain model), Interpolation

ABSTRACT

SURFER is a contouring and 3D surface mapping program, which quickly and easily transforms random surveying

data, using interpolation, into continuous curved face contours. In particular, the new version, SURFER 8.0,

provides over twelve interpolation methods, each having specific functions and related parameters. In this study, the

5 meter DTM was used as test data to compare the various interpolation results; the accuracy of these results was

then discussed and evaluated.

1. INTRODUCTION

following paper, we will introduce every

How to adequately use exist numerous

interpolation method in SURFER.

wide-distributed height points has been an important

2. SURFER INTERPOLATION METHODS

topic in the field of spatial information. Normally,

2.1 The Inverse Distance to a Power method

contouring is the way to accurately describe the

The Inverse Distance to a Power method is a

terrain relief by means of Scenography, Shading,

weighted average interpolator, which can be either

Hachure and Layer Tinting in a way which is best fit

exact or smoothing. With Inverse Distance to a

to the habit of human vision.

Power, data are weighted during interpolation, so

Presently, discretely collected height points have to

that the influence of one point, relative to another,

be interpolated to form curved faces, the selection of

declines with distance from the grid node. Weighting

spatial interpolation methods decide the quality,

is assigned to data through the use of a weighting

accuracy and follow-up analysis applications.

power, which controls how the weighting factors

Interpolation methods are used here to calculated the

drop off as distance from the grid node increases.

unknown heights of interested points by referring to

The greater the weighting power, the less effect the

the elevation information of neighboring points.

points, far removed from the grid node, have during

There are a great many commercial interpolation

interpolation. As the power increases, the grid node

software, however, most of them are tiny and

value approaches the value of the nearest point. For a

designed to solve specific problems with limited

smaller power, the weights are more evenly

versatility. The SURFER is a software developed by

distributed among the neighboring data points.

US GOLDEN company, and the newest version 8.0

Normally, Inverse Distance to a Power behaves as an

contains up to 12 interpolation methods to been free

exact interpolator. When calculating a grid node, the

chosen for various needs. Users are suggested to first

weights assigned to the data points are fractions, the

have the basic understanding of every interpolation

sum of all the weights being equal to 1.0. When a

methods before he or she can effectively select

particular observation is coincident with a grid node,

parameters in every interpolation methods. In the

the distance between that observation and the grid

node is 0.0, that observation is given a weight of 1.0; all other observations are given weights of 0.0. Thus, the grid node is assigned the value of the coincident observation. The smoothing parameter is a mechanism for buffering this behavior. When you assign a non-zero smoothing parameter, no point is given an overwhelming weight, meaning that no point is given a weighting factor equal to 1.0. One of the characteristics of Inverse Distance to a Power is the generation of "bull's-eyes" surrounding the observation position within the grid area. A smoothing parameter can be assigned during Inverse Distance to a Power to reduce the "bull's-eye" effect by smoothing the interpolated grid.
2.2 The Kriging Method Kriging is a geostatistical gridding method that has proven useful and popular in many fields. This method produces visually appealing maps from irregularly spaced data. Kriging attempts to express trends suggested in your data, so that, for example, high points might be connected along a ridge rather than isolated by bull's-eye type contours. Kriging is a very flexible gridding method. The Kriging defaults can be accepted to produce an accurate grid of your data, or Kriging can be custom-fit to a data set, by specifying the appropriate variogram model. Within SURFER, Kriging can be either an exact or a smoothing interpolator, depending on the user-specified parameters. It incorporates anisotropy and underlying trends in an efficient and natural manner.
2.3 The Minimum Curvature Method Minimum Curvature is widely used in the earth sciences. The interpolated surface generated by Minimum Curvature is analogous to a thin, linearly elastic plate passing through each of the data values, with a minimum amount of bending. Minimum Curvature generates the smoothest possible surface

while attempting to honor your data as closely as possible. Minimum Curvature is not an exact interpolator, however. This means that your data are not always honored exactly.
2.4 The Modified Shepard's Method The Modified Shepard's Method uses an inverse distance weighted least squares method. As such, Modified Shepard's Method is similar to the Inverse Distance to a Power interpolator, but the use of local least squares eliminates or reduces the "bull's-eye" appearance of the generated contours. Modified Shepard's Method can be either an exact or a smoothing interpolator. The Surfer algorithm implements Franke and Nielson's (1980) Modified Quadratic Shepard's Method with a full sector search as described in Renka (1988).
2.5 The Natural Neighbor Method The Natural Neighbor method is quite popular in some fields. What is the Natural Neighbor interpolation? Consider a set of Thiessen polygons (the dual of a Delaunay triangulation). If a new point (target) were added to the data set, these Thiessen polygons would be modified. In fact, some of the polygons would shrink in size, while none would increase in size. The area associated with the target's Thiessen polygon that was taken from an existing polygon is called the "borrowed area." The Natural Neighbor interpolation algorithm uses a weighted average of the neighboring observations, where the weights are proportional to the "borrowed area". The Natural Neighbor method does not extrapolate contours beyond the convex hull of the data locations (i.e. the outline of the Thiessen polygons).
2.6 The Nearest Neighbor Method The Nearest Neighbor method assigns the value of the nearest point to each grid node. This method is

useful when data are already evenly spaced, but need to be converted to a SURFER grid file. Alternatively, in cases where the data are close to being on a grid, with only a few missing values, this method is effective for filling in the holes in the data. Sometimes with nearly complete grids of data, there are areas of missing data that you want to exclude from the grid file. In this case, you can set the Search Ellipse to a certain value, so the areas of no data are assigned the blanking value in the grid file. By setting the search ellipse radii to values less than the distance between data values in your file, the blanking value is assigned at all grid nodes where data values do not exist. 2.7 The Polynomial Regression Method Polynomial Regression is used to define large-scale trends and patterns in your data. Polynomial Regression is not really an interpolator because it does not attempt to predict unknown Z values. There are several options you can use to define the type of trend surface.
2.8 The Radial Basis Function Interpolation Method Radial Basis Function interpolation is a diverse group of data interpolation methods. In terms of the ability to fit your data and produce a smooth surface, the Multiquadric method is considered by many to be the best. All of the Radial Basis Function methods are exact interpolators, so they attempt to honor your data. You can introduce a smoothing factor to all the methods in an attempt to produce a smoother surface.
2.9 The Triangulation with Linear Interpolation Method The Triangulation with Linear Interpolation method in SURFER uses the optimal Delaunay triangulation. This algorithm creates triangles by drawing lines

between data points. The original points are connected in such a way that no triangle edges are intersected by other triangles. The result is a patchwork of triangular faces over the extent of the grid. This method is an exact interpolator. Each triangle defines a plane over the grid nodes lying within the triangle, with the tilt and elevation of the triangle determined by the three original data points defining the triangle. All grid nodes within a given triangle are defined by the triangular surface. Because the original data are used to define the triangles, the data are honored very closely. Triangulation with Linear Interpolation works best when your data are evenly distributed over the grid area. Data sets containing sparse areas result in distinct triangular facets on the map.
2.10 The Moving Average Method The Moving Average method assigns values to grid nodes by averaging the data within the grid node's search ellipse. To use Moving Average, a search ellipse must be defined and the minimum number of data to use, specified. For each grid node, the neighboring data are identified by centering the search ellipse on the node. The output grid node value is set equal to the arithmetic average of the identified neighboring data. If there are fewer, than the specified minimum number of data within the neighborhood, the grid node is blanked.
2.11 The Data Metrics Methods The collection of data metrics methods creates grids of information about the data on a node-by-node basis. The data metrics methods are not, in general, weighted average interpolators of the Z-values. For example, you can obtain information such as: a) The number of data points used to interpolate each grid node.

If the number of data points used are fairly equal at each grid node, then the quality of the grid at each grid node can be interpreted. b) The standard deviation, variance, coefficient of variation, and median absolute deviation of the data at each grid node. These are measures of the variability in space of the grid, which is important information for statistical analysis. c) The distance to the nearest data point. For example, if the XY values of a data set are sampling locations, the Distance to the nearest data metric can be used to determine new sampling locations. A contour map of the distance to the nearest data point can quantify where higher sampling density may be desired.
2.12 The Local Polynomial Method The Local Polynomial method assigns values to grid nodes by using a weighted least squares fit, with data within the grid node's search ellipse.

3. EXPERIMENT DESIGN The purpose of this experiment was primarily to take a spatial interpolation method, with the assistance of SURFER software, to move the spatial interpolation of DTM from 40 m to 5 m, and to report comparisons and results. The actual operation made use of the Chen-Yu-Lan river region the ground 5 m DTM of the results, and not pass by the mathematics to calculate but the direct to take the 40 m DTM , again then this 40 meter manuscript input the interpolation of SURFER software put to compute 5 m DTM , and 5 meter manuscript ratio then right acquire its interpolation to put the analysis of error margin of the calculation. The flow charts and sketch maps of the experimental district were designed as follows:

Figure 1:Flowchart of experimental design

Figure 2:Sketch map of experiment district

4. COMPARISONS OF ACCURACY AND ANALYSIS
This experiment tries to make the district to on the spot measure 5 m DTM to manuscripts with the region of Chen-Yu-Lan river, and the total area is roughly 215 square kilometer, because of the

experiment the scope of district is big, and not easily present the difference of the result of calculation on the screen of computer, so only pick part of districts and establish the result of Layer Tinting and shadow to display as follows :

Source

Inverse Distance to a Power

Kriging

Minimum Curvature

Modified Shepard's Method

Natural Neighbor

Nearest Neighbor

Polynomial Regression

Radial Basis Function

Triangulation with Linear Interpolation

Moving Average

Data Metrics

Local Polynomial

The personal computer used in this experiment was

actions, the reference of the performance. Below

a Pentium 4,2GHz memory 768MB. record every

then for since 40 m DTM put to 5 m, and reduce the

kind of time that interpolation method use when

acquisition the covariance of result that get with 5 m

putting calculation, with the accuracy of conduct and

manuscript.

Interpolation method

Use time

Min.

Max.

Mean

STD. Dev.

Inverse Distance to a Power

00:23:06

-110.34

126.19

-0.023

8.227

Kriging

01:55:29

-104.93

128.63

-0.017

3.602

Minimum Curvature

00:02:55

-472.88

510.79

-0.023

10.641

Modified Shepard's Method

00:01:08

-119.6

144.34

-0.016

3.586

Natural Neighbor

00:11:57

-106.65

126.61

-0.019

3.880

Nearest Neighbor

00:01:21

-143.5

175.39

-0.068

8.495

Polynomial Regression

00:00:02

-697.88

956.95

0.304

304.533

Radial Basis Function

02:22:57

-114.57

132.4

-0.016

3.472

Triangulation with Linear

00:00:06

-106.31

126.76

-0.018

4.061

Interpolation

Moving Average

00:00:10

-83.86

113.16

0.015

13.612

Data Metrics

00:18:08

-138.04

154.02

-1.069

20.638

Local Polynomial

00:25:24

-161.73

149.95

-0.113

20.133

From statistics that above the form can get, all

the aspect of mean error, are impracticable margin

methods use the time most longer is Radial Basis

for error of Polynomial Regression biger outside, the

Function, and the shortest Polynomial Regression

rest of worth and all very small.

discrepancy very big, especially at the standard error

With the scope of error margin worth for horizontal

aspect, every kind of method have the obvious

sit the mark, and the quantity is for vertical sit to

margin as well, its inside than is interesting of is, at

mark as follows of histogram:

Local Polynomial

Inverse Distance to a Power

Kriging

Minimum Curvature

Modified Shepard's Method

Natural Neighbor

Nearest Neighbor

Polynomial Regression

Radial Basis Function

Triangulation with Linear

Moving Average

Data Metrics

Interpolation

Top each statistical chart of form in, put the

Regression, can then obviously find its distributing

method due to each interpolation horizontal sit to

the appearance not good, the rest sketch all make the

mark the scope all different, therefore can't directly

rule symmetry to distribute.

judge mutually the density of its distribute the

5. CONCLUSION

difference, but in the statistical chart of Polynomial

In this paper we compare 12 different interpolation

methods. For each method, we analyze its applicability, algorithm, efficiency and advantage. There is no absolutely best method but only the optimal choice under certain circumstances. One should first review the characteristic and theorem of each method as well as the property and spatial analysis of data before he or she can successfully select a spatial interpolation method which is relatively best in certain situation. However, the outcome should be evaluated by conscientious experiences. References: 1. Briggs IC. Machine Contouring Using Minimum Curvature [J], Geophysics, 1974,39(1):39.

2. Barnett V. Interpreting multivariate data [M]. NewYork, 1981:21. 3. Franke R. Scattered Data Interpolation: Test of Some Methods [J]. Mathematics of Computations, 1982,33(157):181. 4. Franke R, Nielson G. Smooth Interpolation of Large Sets of Scattered Data [J]. International Journal for Numerical Methods in Engineering, 1980,15(2):1691. 5. Lee DT, Schachter BJ. Two Algorithms for Constructing a Delaunay Triangulation, International Journal of Computer and Information Sciences [J].1980,9(3):219. 6. SURFER on-line manual

