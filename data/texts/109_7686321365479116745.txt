IEEE TRANSACTIONS ON COMPUTERS, VOL. C-31, NO. 11, NOVEMBER 1982

1099

[8] P. Denning, "Working sets past and present," IEEE Trans. Software Eng., vol. SE-6, Jan. 1980.
[9] M. Dubois and F. A. Briggs, "Efficient interprocessor communication for MIMD multiprocessor systems," in Proc. 8th Int. Symp. Comput. Architecture, May 1981.
[10] K. R. Kaplan and R. 0. Winder, "Cache-based computer systems," IEEE Computer, vol. 6, Mar. 1973.
[11] H. T. Kung, "The structure of parallel algorithms," in Advances in Computers, vol. 19, M. C. Youits, Ed. New York: Academic, 1980, pp.65-112.
[12] J. H. Saltzer, "A simple linear model of demand paging performance," Commun. Ass. Comput. Mach., vol. 17, Apr. 1974.
[13] M. Satyanarayanan, "Commercial multiprocessing systems," IEEE Computer, May 1980.
[14] J. R. Spirn, Program Behavior: Models and Measurements. New York: Elsevier, 1977.
[15] W. D. Strecker, "Cache memories for PDP-I I family computers," in Proc. 3rd Annu. Symp. Comput. Architecture, Jan. 1976.
[16] C. K. Tang, "Cache system design in the tightly coupled multiprocessor system," in Proc. AFIPS, 1976.
[17] L. C. Widdoes, "The S-I project: Development of high performance digital computers," in Dig. Paper, COMPCON '80, IEEE Comput. Soc., San Francisco, CA, Feb. 1980.
[18] C. Yeh, "Shared cache organization for multiple-stream computer systems," Univ. Illinois, Urbana-Champaign, Tech. Rep. R-904, CSL, Jan. 1981.

[19] W. C. Yen and K. S. Fu, "Memory organization and synchronization mechanism of multiprocessing computer systems," School Elec. Eng., Purdue Univ., West Lafayette, IN, Tech. Rep., TR-EE 81-34, Oct. 1981. Michel Dubois (S'79-M'81) was born in Charleroi, Belgium, in 1953. He received the Ingenieur Civil Electricien degree from the Facult6 Polytechnique de Mons, Belgium, the M.S. degree from the University of Minnesota, Minneapolis, in 1978, and the Ph.D. degree from Purdue University, West Lafayette, IN, in 1982, all in electrical engineering. During his studies in the U.S., he was funded by grants from the Facult6 Polytechnique de Mons and by research and teaching positions. He is now
with the Central Research Laboratory, Thomson-CSF, Domaine de Corbeville, France, where he designs architectures for very large scale integration. His main interests are in computer architecture and digital image processing. Faye A. Briggs (M'77), for a photograph and biography, see p. 982 of the October 1982 issue of this TRANSACTIONS.

Queueing Network Models for Parallel Processing with Asynchronous Tasks
PHILIP HEIDELBERGER, MEMBER, IEEE, AND KISHOR S. TRIVEDI

Abstract-Computer performance models of parallel processing systems in which a job subdivides into two or more tasks at some point during its execution are considered. Except for queueing effects, the tasks execute independently of one another and do not require synchronization. An approximate solution method is developed and results of the approximation are compared to those of simulations. Bounds on the performance improvement due to overlap are derived.
Index Terms-Approximate solution, computer systems modeling, multiprogramming, multitasking, parallel processing, performance evaluation, queueing network models.

I. INTRODUCTION

TToHfIcSerPtaAiPn EtyRpecsonosfidpearrasllceolmppruotceersspienrgfsoyrsmtaenmcse.

models In par-

ticular, we consider models in which a job subdivides into two

Manuscript received December 18, 1981; revised June 21, 1982. P. Heidelberger is with the IBM Thomas J. Watson Research Center, Yorktown Heights, NY 10598. K. S. Trivedi was on sabbatical at the IBM Thomas J. Watson Research Center Yorktown Heights, NY 10598. He is with the Department of Computer Science, Duke University, Durham NC 27706.

or more tasks at some point during its execution. Except for queueing effects, the tasks execute independently of one another and do not require synchronization. The performance of the system is analyzed using queueing network models. However, because of the parallelsim, the models do not have an analytically tractable solution. An approximate solution method is developed and results of the approximation are compared to those of simulations. The approximation is found to be quite accurate unless the system under consideration is highly imbalanced.
Two different applications of the model are described. The first application is a terminal-oriented system. In this system the model may be used to represent transactions that are split into two tasks. The terminal user must wait for completion of the first task before issuing the next transaction. However, the second task can execute concurrently with the first task and with the user's think time. Furthermore, the terminal user does not wait for the second task to complete before issuing the next transaction. An alternative interpretation of this model is that a user is allowed to submit a second processing request while

0018-9340/82/1100-1099$00.75 © 1982 IEEE

1100 IEEE TRANSACTIONS ON COMPUTERS, VOL. C-31, NO. 11, NOVEMBER 1982

the first is being processed. Most systems do allow users to statistically identical secondary tasks (labeled 2). The secon-

submit multiple requests in this way.

dary tasks are spawned by the primary task sometime during

The second application of our model is to CPU-I/O overlap its execution and execute concurrently with it, competing for

in a batch-oriented multiprogramming system. In this model system resources. A secondary task is otherwise assumed to

a job can issue I/O requests which are served either synchro- run independently of the primary task; in particular, we do not

nously or asynchronously. If the I/O request is asynchronous, account for any synchronization between tasks.

then the job can continue CPU processing concurrently with We assume that there is a specially designated node, node

execution of the I/O. Furthermore, the job never waits for an 0. A secondary task is spawned whenever a primary task enters

asynchronous I/O request to complete. I/O requests which node 0. The service time at this node is 0. For i = 1, 2, .. ,

write sequentially into write-only files-are examples of I/O's ViI denotes the average number of vists to node i per visit to

which could be done asynchronously.

node 0 by a primary task and let Vi2 denote the average num-

A general model which allows jobs to split into two or more ber of visits to node i by a secondary task. We assume that

synchronous tasks, all of which must complete execution before Vi2 < o and that a secondary task leaves the network after

the job may resume processing, is described in Heidelberger completing execution. Similarly, we assume that V1l <co. Let

and Trivedi [8]. Towsley, Chandy, and Browne [20] have Sij denote the average service time requirement of task type

studied models in which CPU and I/O (or I/O and I/O) ac- j per visit to node i. Each type of task does not require holding

tivity can be overlapped; however, their models require tight more than one resource at a time. Concurrency within a job

synchronization between the two concurrent tasks in the sense is allowed only through multitasking while several independent

that both the CPU and I/O (or the two I/O) tasks must jobs are allowed to execute concurrently and share system

complete before processing can continue. Furthermore, a job resources. The system is assumed to contain a fixed number,

can have, at most, two outstanding I/O requests at any one n, of primary tasks at all times.

time. Towsley et al. [20] conclude that the performance gain If the scheduling discipline at a node is FCFS (first-come-

due to this type of overlap is greatest for balanced systems and first-served), then we require that all tasks have an exponential

relatively low levels of multiprogramming. Price [ 14] considers service distribution at that node with a common mean. If the

performance models of multiple I/O buffering schemes. In Price's model there are a fixed number of buffers per file (or

scheduling discipline at a node is PS (processor sharing) or LCFS-PR (last-come-first-served, preemptive resume), or the

per user). A limiting case (as the number of buffers increases node is an IS (infinite server) node, an arbitrary differentiable

to infinity) of his model is obtained as a special case of our service time distribution is allowed and each task can have a

model by setting the parameters appropriately (f = 1, where distinct service time distribution.

f is defined in Section III). Price shows that performance im- Because of concurrency within a job, the queueing network

provements become insignificant as the size of the buffer pool model of the system under consideration does not belong to the

increases beyond 3 or 4 buffers and his results closely agree class of product-form networks (see Baskett, Chandy, Muntz,

with ours. Results obtained by our model also show that the and Palacios [1] and Chandy, Howard, and Towsley [5]). We

performance improvement due to overlap is maximized for describe an iterative technique for solving a sequence of

balanced systems and low multiprogramming levels. As more product-form queueing networks so that upon convergence,

of the work is offloaded to auxilliary processors, however, the the solution to the product-form network closely approximates

performance gains due to parallel processing will remain sig- the solution to the system under investigation. The assumptions

nificant and the modeling technique described in this paper on the service time distributions and the queueing disciplines

is applicable to such distributed systems. Other studies of guarantee that each network in the sequence has a product-

multitasking include Browne, Chandy, Hogarth, and Lee [3] form solution and is thus computationally tractable.

and Sauer and Chandy [ 16]. Both of these studies model ov- The queueing network model of the approximate system has

erlapped CPU processing in multiprocessor systems by ad- two chains, one closed and the other open. The closed chain

justing queue-dependent CPU processing rates.

models the behavior of primary tasks and hence the population

In Section II the general model, of overlap is described in of the closed chain is equal to the number of primary tasks, n.

detail. Section III contains a description of the terminal and The open chain models the behavior of secondary tasks and

batch models as well as reporting on the accuracy of the ap- hence we set the arrival rate of the open chain equal to the

proximation. Section IV derives bounds on the performance primary task throughput, at node 0, of the closed chain. Notice

gain that can be achieved by overlap and contains plots of that the approximation assumes that the arrival process of

performance improvements predicted by the model. Section primary tasks to node 0 is a Poisson process which is inde-

V summarizes the results and lists areas for further re- pendent of the state of the network. However, in general, this

search.

process is neither Poisson nor independent of the state of the

network. -Because of these two points, the method is an ap-

II. MODEL DESCRIPTION

proximation and not an exact method of solution. Since the throughput of the closed chain is itself a nonlinear function of

We assume that the system under consideration consists of m active resources such as processors and channels. The workload consists of a set of statistically identical jobs where each job consists of a primary task (labeled 1) and zero or more

the arrival rate of the open chain (recall that the two chains share system resources), a closed form solution is not available. A simple algorithm, e.g., regulafalsi (see Hamming [7]), may be used to iteratively solve this nonlinear equation. We applied

HEIDELBERGER AND TRIVEDI: QUEUEING NETWORK MODELS CONTENTIONCASAET B1 OTTLENECK

MODERNAOTECOCNOTNETNETNITCOIANOSNEAT2ATBOOTTTHLEERNEDCEKVICES

zz

1 101

OPEN CHAIN THROUGHPUT

OPEN CHAIN TRUHU

7 LITTNLOE CCOONNTTEENNTTICIOAONSNEAATT3 BOOTTHTELRENDEECVKICES

I_ L.
Cu
U U..I5 1.U 1.C5l 2.U11 1-1 21-1j.5. OPEN CHAIN THROUGHPUT
Fig. 1. Three types of behavior of the approximation method. The maximum open-chain throughput is 2.5.

this method to the models described in Section III and found it to converge very rapidly. On the average, only five iterations were required to achieve a maximum absolute difference of 0.001 between the throughputs of the open and closed chains, and the average model required less than one second of CPU time on an IBM 3033.
Let X2 and ,2, respectively, denote the arrival rate and the throughput (or departure rate) of the open chain. Note that if any of the queues are saturated, then the throughput /2 will be less than or equal to the given arrival rate X2. Let XI denote the throughput of the closed chain at node 0. We require that A2 = XI and for the stability of the network, we must have L2 = X2. It is clear therefore that we need to solve the following nonlinear equation:

X0(A2) = X2

(1)

where XI (X2) is the throughput of primary tasks (at node 0) when the secondary task throughput is X2. Equation (1) is a nonlinear function of the single variable X2 and for any fixed value of X2, X1(X2), may be evaluated by solving a productform queueing network with one open and one closed chain. Let XA and X* denote the solution to (1), i.e., X* = X*= X1(X*). The approximation uses X* as the secondary task arrival rate. At this point, the rate at which secondary tasks arrive (or are spawned) equals the throughput of primary tasks at node 0.
Any algorithm for solving nonlinear functions of a single variable may be used to solve (1) for the appropriate arrival rate X2. The properties of this equation are discussed next. Since the two chains share system resources, an increase in the value of X2 cannot imply an increase in X1; we conclude that XI is a monotone nonincreasing function of X2. Let X2 denote

the maximum throughput of the open chain. The condition of stability is

X2 < X2.

(2)

Then the condition for the existence of a stable solution, i.e., a solution in which no queue is saturated, for the nonlinear equation (1) is given by

liMr X(X2)<X2.
X2tA2

(3)

By the monotonicity property it follows that if a stable solution exists it will be unique. If this condition is not satisfied, then the primary tasks can generate secondary tasks at a rate which exceeds the system capacity.
The maximum possible throughput of the open chain is determined by the node which presents a bottleneck (see Kleinrock [10, p. 218]). The index of this node is

I = argmaxlViV2S12

(4)

where argmax denotes the index of the largest element in a set. Hence,

A2 = V12SI2

(5)

Depending on network parameters, three different types of behavior can be identified (see Fig. 1). The first case results when the node labeled I is utilized by the primary task, i.e.,

VIISII > 0,

(6)

since in this case when the queue length of node I grows without bound due to an excessive open-chain arrival rate, the

1102 IEEE TRANSACTIONS ON COMPUTERS, VOL. C-31, NO. 11, NOVEMBER 1982

3(D 4(D 5(D
(a)

0---'O-.-
Po I sson Soursce

40

(b) Fig. 2. (a) The central server model without overlapped 1/0. (b) The
central server model with overlapped 1/0. closed-chain throughput will approach zero. If condition (6)
is not satisfied, but some of the other network nodes are shared by the two chains, then either case two or case three results depending upon the degree of sharing. Since case two does yield a unique solution to (1), we conclude that (6) is a sufficient but not necessary condition for convergence while condition (3) is both necessary and sufficient. However, the advantage of condition (6) over condition (3) is that the former is testable prior to the solution of the network while the latter is not.
The approximation may be generalized to include cases in which more than one type of secondary task may be spawned. Suppose that whenever a primary task passes through node 0 a secondary task of type k (k = 2, * , K) is spawned with probability Pk. The secondary tasks may be modeled by K - 1 open chains, each with arrival rate Xk. Let X = K Xk denote
k=2
the total arrival rate of secondary tasks. The individual arrival rates are constrained so that Xk = PkX for k > 2. The total throughput of secondary tasks is set equal to the throughput of the primary tasks at node 0. This defines a nonlinear equation of the single variable X, similar to (1), which must be solved.
III. ACCURACY OF THE APPROXIMATION
In this section we investigate the accuracy of the approximation by comparing performance measures obtained by the approximation to those obtained by simulation. Computer performance models of two general types were considered:

central server models (see Buzen [4]) and models of terminal oriented timesharing computer systems, (see, e.g., Sauer and Chandy [17, p. 1 6]). The accuracy of the approximation was studied for device utilizations, throughputs, mean queue lengths, and, when appropriate, mean response times. The comparison was performed for a wide range of input parameter settings for these two general model types. In all, the comparison was performed for over 400 individual models. The average relative error over all models and all performance measures was 2.5 percent, and 90 percent of the relative errors were less than or equal to 6.1 percent.
The standard central server model, without overlap, is pictured in Fig. 2(a). Server number 1 represents a CPU and servers 2, 3, 4, and 5 represent I/O devices such as disks. In the model with overlap, there are a fixed number, n, of primary tasks. We assume that a primary task has a random CPU processing service time with mean Sp and that whenever a primary task finishes this processing a secondary task is spawned with probabilityf. If the secondary task is spawned, the primary task returns to the CPU for continued processing (with mean Sp) and the secondary task begins processing at
the CPU for a random period of time with mean SI2. Upon
leaving the CPU the secondary task moves to I/O device i with probability Pi2. The secondary task then returns to the CPU with probability P2 or exits the system with probability 1 - P2. If the primary task completes CPU processing and does not
spawn a secondary task (with probability 1 -J), it begins an
overhead period of CPU processing with mean So. Upon completion of this overhead processing the primary task moves
to I/O device i with probability Pi, and then returns to the
CPU. We assume that the CPU has the PS discipline and that all I/O devices are FCFS and that the service times at I/O device i are exponentially distributed with mean Si.
The model has the interpretation that the primary task can issue I/O requests which are handled by the secondary task and continue processing without waiting for those I/O requests
to complete. IfSo = S1 2, then using this interpretation So =
S12 is the average time to initiate the I/O request. In the
notation of the previous section, S11 = Sp + (1 -f)So. Each
secondary task has an average of 1/(1 - P2) I/O's in it and thus the fraction of all I/O's which are overlapped with the primary task is

0o( f)fo+lf/=(I - P2)

~~~~~~~~(7)

Notice that if P2 = 0, thenfol = f The benefit of overlapping
the I/O can be studied by comparing this model to one in whichf = 0 and there is no overlap.

The approximation for the central server model with overlap

is pictured in Fig. 2(b). We insert an extra node, node 0, in the

model. The service time at node 0 is 0. When the primary task leaves the CPU it is routed to node 0 with probabilityf and to
I/O device i with probability (1 - f)p,i. The throughput of
primary tasks at node 0 is the rate at which secondary tasks are spawned. The secondary tasks are modeled by an open chain with all arrivals routed to the CPU. The Poisson arrival
rate, X2, of the open chain is set so that it equals the throughput of the closed chain of primary tasks at node 0. The routing in

HEIDELBERGER AND TRIVEDI: QUEUEING NETWORK MODELS

1103

TABLE I PARAMETERS FOR CENTRAL SERVER MODELS

Model Set

S2=S3=54

55 P21=P22 Ps1=P52 P31 =P32 P41 =P42

P2

0
6

1 0.04 0.04 0.25 0.25 0.00 II 0.04 0.04 0.25 0.25 0.50 111 0.04 0.04 0.30 0.10 0.00 IV 0.04 0.10 0.30 0.10 0.00 V 0.04 0.20 0.30 0.10 0.00 VI 0.04 0.40 0.30 0.10 0.00

2(D /
3(D

the open chain of secondary tasks is as described earlier; a secondary task leaves the CPU and enters I/O device i with probability Pi2 and then returns to the CPU with probability
P2 or exits the system with probability 1 - P2. Notice that, for
any fixed arrival rate X2, this approximate model of overlap satisfies the conditions for product form and thus has a computationally tractable solution. The stability conditions for this
mixed open and closed network are that X2Si2Vi2 < 1 for all
iwhere V12= 1/( -P2) andV2 =pi/(l -p2)fori> 1.If the X2 for which X2 = X1 does not satisfy these conditions, then
the primary tasks are able to generate more secondary tasks than the system can handle and the mean queue length of secondary tasks at at least one device will be infinite.
We considered six sets of central server models with a total of 60 models in each set. Each set contained cases with only moderate utilizations at the devices as well as heavily CPU and/or I/O bound cases. Each set contained a range of values of multiprogramming levels, n, CPU service time, Sp, and overlap factors, f. In particular, each model within a set was
parameterized by the triplet (n, Sp, f) where n = 1, 3, 5,
Sp = 0.002, 0.01, 0.02, 0.10, 0.20, andf = 0.1, 0.25, 0.50, 0.75.
The sets differed in the branching probabilities, Pj and P2, and
in the I/O service times. In all models the overhead processing time So = S12 = 0.0008. The pattern of I/O accesses ranged from an even distribution to a highly skewed distribution and the mean service times of the least active I/O device (i.e., the
device i with the smallest values of pij) varied in an interval
about the mean service times of the other I/O devices. Table I lists the input parameters for each set of 60 central server models.
The second class of models tested were those of terminaloriented timesharing systems. This model is pictured in Fig. 3(a). It is essentially the same as the central server model except that it has an extra node, node 6, which is an infinite server queue representing a finite number of terminals. The mean service time at this node, S61, is the mean think time. There are a fixed number of terminals, n, submitting primary tasks to the computer system. A primary task uses the CPU and then
enters I/O device i with probability Pi,. Upon completion of
an I/O the primary task returns to the CPU with probability P I or enters the terminals for the think state with probability 1 - p . We assume that a secondary task is spawned sometime during the execution of a primary task. The secondary task executes independently of the primary task (except for queueing effects) and in particular can execute during the

(a)
(b) Fig. 3. (a) Terminal model without overlapped tasks. (b) Terminal
model with overlapped tasks.
think time of its corresponding primary task. The routing and service times of the secondary task are the same as in the central server model. The approximate model of this overlap situation is shown in Fig. 3(b). Node 0, with 0 service time, is inserted in the model between the I/O devices and the terminals. The throughputs at the terminals and at node 0 are thus equal. The secondary tasks are modeled by an open chain with arrivals entering the system at the CPU. The arrival rate of this chain, X2, is set equal to the throughput of the primary tasks at node 0. The stability conditions of this model are, as before,
that X2S12/(l - P2) < 1 and X2Si2/( - P2) < 1 for all
i>i.
The interpretation of this model is that each terminal interaction can be split into two tasks. The terminal user must wait for the completion of the primary task, but does not wait for the completion of the secondary task. Certain operating system overhead associated with processing a transaction may be overlaped and thus modeled this way. We considered 47 models of this general type. The parameter settings for these models are described in Table II.
Each of the models was simulated using the IBM Research
Queueing package RESQ (see Sauer and MacNair [18] and
Sauer, MacNair, and Salza [19]). The overlap of jobs was modeled using "split nodes," a RESQ node type that splits a

1104 IEEE TRANSACTIONS ON COMPUTERS, VOL. C-31, NO. 11, NOVEMBER 1982

TABLE I1 PARAMETERS FOR TERMINAL MODELS

S61 SI1 =S12

Si

Pij

Pl=P2

n

TABLE IV COMPARISON OF SIMULATION AND ANALYTIC APPROXIMATION
FOR CENTRAL SERVER MODELS WITH IMBALANCED I/O SUBSYSTEM

10 0.010

0.04

0.25

0.10

1,5,10,20,30,40,50,

Models

60,70,80,90,100

CPU Disk Disk, CPU Disk

Disk Through-

Ut. 2 Ut. 3-5 Ut.

Q.L. 2 Q.L. 3-5 Q.L.

put

10 0.015

0.04

0.25

0.10 1,5,10,20,30,40,50, 60,70,80,90,100

Set Absolute Error I[1 Mean

0.003

0.007

0.003

0.010

0.060

0.004 0.050

0.9 Percentile 0.010 0.024 0.007 0.023 0.205

0.009 0.159

15 0.002 0.04 0.25 0.10 25,50,100

Maximum (0.0)25 0.076 0.025 0.101 0.799

0.065 0.631

15 0.010 0.04 0.25 0.10 25,50,100 15 0.020 0.04 0.25 0.10 25,50,100

Relative Error Mean 1.2 1.4 1.9 2.9 3.8
09 Percentile 3.7 3.9 5.1 13.6 10.6 Maximum 14.7 14.4 13.9 27.7 18.3

2.0 1.3 4.4 3.6 13.1 14.3

15 0.020 0.08 0.25 0.02 1,5,10,20,30,40,50

Set Absolute Error

15 0.030 0.08 0.25

0.02 1,5,10,20,30,40,50

IV

Mean 0.003 0.007 0.007 0.010 0.044

0.030 0.055

0.9 Percentile 0.011 0.027 0.021 0.033 0.135

0.097 0.222

Maximum 0.029 0.078 0.069 0.095 0.555

0.323 0.636

TABLE III COMPARISON OF SIMULATION AND ANALYTIC APPROXIMATION FOR CENTRAL SERVER MODELS WITH BALANCED I/O SUBSYSTEM

Relative Error
Mean 1.4 1.6 2.1 2.9 3.1 0.9 Percentile 4.3 4.3 4.7 13.8 7.4
Maximum 15.8 16.2 17.4 27.0 13.6

4.2 1.4 9.3 4.1 29.2 15.9

Models

Through-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Models

CPUCPU

Disk

CPU

Disk Through-

Ut. Ut. Q.L. Q.L. put

Set Absolute Error V Mean 0.9 Percentile Maximum

0.003 0.012 0.024

0.005 0.014 0.059

0.008 0.020 0.102

0.009 0.025 0.065

0.043 0.092 0.878

0.394 0.924 5.499

0.039 0.093 0.490

Set Absolute Error Mean
0.9 Percentile Maximum
Relative Error Mean
0.9 Percentile Maximum

0.003 0.011 0.026
1.2 3.9 15.9

0.006 0.024 0.071
1.5 4.4 15.4

0.011 0.031 0.110
2.8 13.3 26.2

0.044 0.137 0.457
3.2
8.3
16.2

0.056 0.233 0.710
1.3 3.9 15.5

Set Absolute Error II Mean 0.9 Percentile Maximum Relative Error Mean 0.9 Percentile Maximum

0.003 0.010 0.020
1.0 2.7 9.2

0.005 0.015 0.054
1.1 2.7 8.7

0.009 0.028 0.073
2.8 13.2 25.0

0.072 0.249 0.670
3.1 8.5 15.1

0.034 0.099 0.317
1.0 2.9 9.0

Relative Error Mean 1.4 1.5 1.6 3.1 3.2
0.9 Percentile 3.9 3.6 4.5 13.5 8.4 Maximum 15.6 15.3 15.9 28.7 37.4

Set Absolute Error
Vt Mean
0.9 Percentile Maximum
Relative Error Mean
0.9 Percentile Maximum

0.002 0.006 0.011
1.0 3.0 72

0.002 0.005 0.180
1.2 2.9 7.2

0.007 0.019 0.067
1.3 3.4 8.1

0.008 0.021 0.032
4.0 16.1 29.8

0.041 0.145 0.394
7.4 25.3 47.9

11.4 1.4 31.6 3.8 73.2 15.3

0.592 2.415 4.224

0.019 0.045 0.149

13.7 1.1 39.2 2.7 89.0 7.1

TABLE V COMPARISON OF SIMULATION AND ANALYTIC APPROXIMATION
FOR TERMINAL MODELS WITH BALANCED I/O SUBSYSTEM

job into two tasks which then proceed independently through the network. Confidence intervals for each estimate were formed using the regenerative method, e.g., Iglehart [9]. The length of each simulation was determined by the sequential stopping rule described in Lavenberg and Sauer [ 12]. Using this rule, each model was simulated until a 90 percent confidence interval for the mean queue length at each device (and mean response time for the terminal models) had a relative half-width of 1 percent or until a maximum CPU time (5 and 10 min of IBM 3033 time for each central server and terminal model, respectively) had been reached. If the CPU limit was reached before the 1 percent desired accuracy was achieved, confidence intervals with a relative half-width of generally less than 10 percent were obtained. However, for some parameter settings, no regenerative cycles were observed during the course of the entire simulation in which case no confidence intervals were produced. This does not necessarily imply that the estimates obtained from these simulations were highly inaccurate, but merely that the mean time to return to the fixed regenerative state was extremely long. We felt that the CPU-limits of 5 and 10 min were sufficient to obtain estimates of reasonable accuracy for comparison with the analytic approximation.
Tables III, IV, and V report the results of the comparison. Both absolute errors (absolute value of simulation estimate

Models

CPU Disk CPU Disk Term. Through- Response

Ut. Ut. Q.L. Q.L. Q.L.

put Time

Terminal
Models

Absolute Error Mean
0.9 Percentile Maximum
Relative Error Mean
0.9 Percentile Maximum

0.002 0.004 0.010
0.3 0.7 1.4

0.002 0.004 0.008
0.4 0.8 1.5

0.429 1.285 2.261
3.0 7.3 13.4

0.056 0.201 0.421
1.4 3.9 4.5

0.115 0.302 0.674
0.6 1.6 2.7

0.010 0.026 0.036

0.228 0.783 1.141

0.7 1.7 1.7 4.1 2.2 5.4

minus approximation value) and percent relative errors (100 percent times absolute value of simulation estimate minus approximation value divided by simulation estimate) are reported. For each set of models, the mean, 90th percentile, and maximum absolute and relative errors are listed for utilizations, queue lengths, throughputs, and response times (for the terminal models). If the utilizations or queue lengths for different devices were known to be identical due to symmetries in the model, the simulation estimates for these quantities were averaged prior to performing the comparison; this reduces statistical fluctuations.
The approximation is particularly accurate for estimating utilizations and throughputs. For these quantities the mean relative error is 1.3 percent, 90 percent of the errors are less than 3.2 percent, and the maximum relative error is 17.4 percent. Estimates of mean queue lengths are somewhat less

HEIDELBERGER AND TRIVEDI: QUEUEING NETWORK MODELS

1105

accurate (the approximation tends to overestimate mean queue For comparison purposes, the network of Fig. 2(a) should

lengths); the mean relative error is 4.2 percent, and 90 percent have branching probabilities adjusted in such a way that Bi's, of the errors are less than 12.0 percent. However, the maxi- are kept the same as in the case with overlap. This can be done

mum relative error is as large as 89 percent. These large errors by setting the branching probabilities, qi, in the network of Fig.
always occur in very imbalanced systems, such as central server 2(a) as

model sets V and VI, with extreme values of the overlap factor (f,ol = 0.5, 0.75). For the better balanced models (central server

qi = ((1 -f)Pil +fPi2).

(12)

model sets I, II, III, IV, and the terminal models) the ap- The minimum possible throughput is achieved when jobs are

proximation is quite accurate; for these cases the mean relative processed sequentially as follows:

error for all performance measures is 1.9 percent, 90 percent of the relative errors are less than 4.0 percent, and the maxi-

Tmi. 1

(13)

mum relative error is 29.2 percent. The errors in the terminal models are particularly low. The

m
E

Bi

i=l

parameters for these models were chosen so that all disks were equally utilized. Furthermore, Lavenberg [ 11 ] has shown that an IS source in a closed product-form network with large population sizes behaves like a Poisson source. In this case, the flow of jobs returning to the terminals in the unoverlapped model is approximately Poisson since it corresponds to an exit point of a Jackson network, e.g., Beutler and Melamed [2].

This latter case occurs when there is no sharing of resources either among distinct jobs or by parts of the same job. Multiprogramming increases throughput by promoting sharing of the first type and overlapped I/O increases throughput by promoting sharing of the second type. In any case, maximum possible throughput improvement factor is given by

Thus, in the overlapped model, the times at which secondary tasks are spawned define a point process which should be ap-

Tmax Tmin

(14)

proximately Poisson. Since the approximation assumes that the arrival stream of overlapped tasks is a Poisson process, the approximation should be quite accurate in this case.

The advantage of overlapped job execution over multiprogramming is the possible saving in main store size since two tasks working on the same job will likely require less main store

space than two independent job running concurrently. Also,

IV. PERFORMANCE IMPROVEMENT
We now consider the performance gain by multitasking. First we consider the benefit of overlapping I/O with computation in the central server model. The maximum possible throughput is obtained when the bottlenecked server is fully utilized. Recall that the bottleneck is presented by the server with the highest relative utilization. For convenience, we will assume that P2 = 0. Further, since performance comparison is made with the case with no overlap-the model of Fig. 2(a) in which node 0 is nonexistent-it is more convenient to measure throughput at the output of CPU and reinitialize all visit counts. In other words, we now define a job that is com-

note that neither technique will accrue much benefit in case
the bottleneck device, defined by I = argmax 1Bi} presents a severe bottleneck; that is, BI >> Bi for all i # I, since then Tmin _ Tmax. Thus overlapping I/O with computation can
provide an appreciable performance benefit if the utilizations of the active resources are nearly balanced and the MPL is rather low. Note that (14) represents the combined gain from overlapped I/O and multiprogramming. Furthermore, expression (14) above does not take into account the limitation in gain imposed by a small value off.
In order to obtain a tighter upper bound on the gain due to overlapped I/O, we let

prised of a CPU burst and one I/O service (on exactly one of the m -1 I/O devices). Thus,

V l = V12 = 1.

(8)

Tun(n)

=

Em

n
Bi +

Qun

i=l

(15)

Note that per visit to the CPU made by the primary task, the probability of spawning a secondary task isf. Then the average CPU time required for the primary task is SI I = (Sp + (1 f)So) while that required by the secondary task is So. Then the total CPU time per job completion is

B1 = V11SIl +fYV2S12= (Sp + SO).

(9)

denote the throughput at MPL n with all I/O activity unov-
erlapped (see Reiser and Lavenberg [ 15] ). The quantity Qun
denotes the queueing delay due to other jobs competing for the same resources. Since the network without any overlapped I/O is a product-form network, (15) is easily computable.
Similarly, T01(n), the throughput at MPL = n with overlapping satisfies the inequality

Similarly, the average time needed per job completion on
server i, i > 1 is
Bi = (1 -f)VilSil +JVyi2S2 = ((1 -J)Pil +fPi2)Si. (10)
Given fixed values of Bi's, the maximum possible job throughput is given by

T01(n) < S11

+

Zm (1

n
-J)Sipil

+ Qo,

i=2

(16)

where Q0i denotes the queueing delay due to other primary
tasks when all secondary tasks have been removed from the network. Note that this bound is easily computable since the

Tmax 1/max 3BA.(1

(I 1) resulting network has a product-form solution. Another and

1106

IEEE TRANSACTIONS ON COMPUTERS, VOL. c-31, NO. 11, NOVEMBER 1982

EQUAL BRANCHING PROBABILITIES, EQUAL I/O SERVICE TIMES
o N=1 + N=3 x N=5

C.j OVERLAP FACTOR= 0.1

OVERLAP FACTOR= 0.25

I
o O0o

I

I_
mzZ @,o '_Z

z_

0a. _. :

0 0.2 0.4 0.6 0.8 1.0 MILLIONS OF INSTRUCTIONS/START 10
CN OVERLAP FACTOR= 0.5

0 0.2 0.4 0.6 0.8 1.0 MILUONS OF INSTRUCTIONS/START 10
4 - OVERLAP FACTOR= 0.75

II

z
*..,,
Li

z
S L

~x ~

~

~

~

~ ~ ~~

Fig. 4.

0 0.2 0.4 0.6 0.8 1.0 MILLIONS OF INSTRUCTIONS/START 10

0 0.2 0.4 0.6 0.8 1.0
MILLIONS OF INSTRUCTIONS/START 10

Throughput improvement due to overlapped 1/0 in central server model with balanced 1/0 subsystem (parameter set 1).

UNEQUAL BRANCHING PROBABILITIES, S(4)=0.4
o N=1 + N=3 x N-5

OVERLAP FACTOR= 0.1

C, OVERLAP FACTOR= 0.25

0
ZI

0 0.2 0.4 0.6 0.8 1.0
MILLIONS OF INSTRUCTIONS/START iO
0
0C -0. OVER.LAP0FA.CTOR= 0.5
a--

0
0 I>

0.2 0.4 0.6 0.8 1.0
MILLIONS OF INSTRUCTIONS/START IO N-OVERLA FACTOR= 0.75

0-

Fig. 5.

0 0.2 0.4 0.6 0.8 1.0 MILLIONS OF INSTRUCTIONS/START 10

0 0.2 0.4 0.6 0.8 1.0 MILLIONS OF INSTRUCTIONS/START 10

Throughput improvement due to overlapped 1/0 in central server model with imbalanced 1/0 subsystem (parameter set VI).

HEIDELBERGER AND TRIVEDI: QUEUEING NETWORK MODELS
OVERCLOAMPPPAERDISOANNDOFUNOTVEERRMLINAAPLPEDMODTERLASNSAWCITTIHONS
0-;r
Un m
il
I

1107

If NUMBER OF TERMINALS o OVERAPPED TRANSACTIONS * LNOVERLAPPED TRANSACTIONS

20 40 60 80
NUMBER OF TERMINALS

100

°~r o *

UNOOVVEERRLLAAPPPPEEDD TTRRAANNSSAACCTTIIOONNSS

/F5 ~5

20 40 60
NUMBER OF TERMINALS

100

20 40 60
NUMBER OF TERMINALS

Fig. 6. Performance improvement due to overlapped tasks in terminal model.

even simpler upper bound on the throughput with overlapping is obtained when one of the servers is fully utilized as follows:

TO/(n) < max$Bi, = Tmax. Thus, the gain due to overlapping at MPl n is

(17)

G(n) = T(n)
T.n(n)

m
, Bi + Qun
< i=l

(18)

max jn/Tmax, (S11 + (1 -) E PiiSi + Qol I ~~~~~i=2
By using the homogeneity (see Price [13]) and the monotonicity property (see Trivedi and Sigmon [21]) of the throughput function of a closed queueing network, we can show that if none of the devices is fully utilized, then (18) is bounded above by 1/(1 -).
Next assume that some device approaches 100 percent utilization. Then the denominator of (18) equals n/TTmax =
n X max IBiI. Consider T01(n) as a function of IB' and fix the values of lB,, i > 2}. Set B* = max IBi, i > 21 and let g(n, B1 ) = Tmax/Tun(n, B1). For B1 < B*, g(n, B1) = II(B*Tun(n,
B1)) is monotonically increasing since throughput is a mono-
tonically decreasing function of B1. For B1 > B*, g(n, BI) = 1/(BI T"n(n, B1)) can be shown to be monotonically decreasing
using [6, eq. 3.1.5.]. Thus g(n, B1) is maximized at B*. Fur-

thermore, g(n, B*) is maximized by setting all Bi = B* (for
i = 1, 2, , m). In this case, Tu,(n) = n/lB*(n + m-1)j, and
the upper bound on G(n) is (n + m 1)/n. Combining the two bounds together, we have

G(n) < min I ,n + m--1

(19)

For the interesting special case of balanced utilization of all I/O devices, i.e., Bi = B for i > 2, a closed-form expression for the upper bound (18) can be given as follows:

n-i

n

G(n) <

E
i=O

aixi

E
j=O

bjyi

n n-I

(1 -) E bixi E ajy

i=O j=O

(20)

where

Sp + (1 -J)So
A((I -f)B

Sp + So

Y=

B

=-=n - k+rm - 3
ak
,

and
n - k+m - 2)

In this inequality, inequality (16) is used to bound T01(n). In this special case, both Tun(n) and the right-hand side of in-

1108 IEEE TRANSACTIONS ON COMPUTERS, VOL. c-31, NO. 11, NOVEMBER 1982

equality (16) may be evaluated explicitly using the expression for the normalizing constant, C(n), of a single-chain product-form queueing network with n jobs and the fact that the
throughput for such a network is proportional to C(n -1)/
C(n). In our example, with m = 5, bound (19) gives improvement
factors 1.1 1, 1.33, 2.0, and 4.0, respectively, for n = 1 andf = 0.10, 0.25, 0.5, and 0.75. The corresponding bounds for n = 3 are 1.11, 1.33, 2.0, and 2.33, while those for n = 5 are 1.11, 1.33, 1.8, and 1.8.
Figs. 4 and 5 show the gain in throughput as a function of the mean CPU processing time, Sp, for data sets I and VI, respectively. In these figures the units for the x axis are millions of instructions between I/O's, and a CPU processing rate of 5 million instructions per second is assumed. Each of these ,figures is drawn in four parts:f = 0.1, 0.25, 0.5, and 0.75. Each part of the figure shows the effect of the multiprogramming level as a parameter. Notice that the improvement factor is greatest for the balanced set of models (set I in Fig. 4) with low MPL.
In the terminal-oriented system, the bound (18) is modified as follows:

G(n) = TTu.1,((nn))
<

S61 + Em Bi + Qun
=1

* (21)

max jn/Tmax (S61 + Sll + E VilSil + Qoi)

where

Tmax = min,Bi.

S61 +

n
m
E

}
VilSil

i=1

(22)

and Bi = Vi SiI + Vi2Si2 for all i. Notice that if the think time,
S61, is the dominant term in (21), then the gain in throughput will be close to one. However, if n is large, even a small gain in throughput results in a substantial reduction in response time. On the other hand, if S61 is close to zero, then we obtain
the bound in (19) if for all i,f = V,2S12/B1. A bound similar
to (20) is obtained if Bi = B for all i. Fig. 6 gives the response time, CPU utilization, and the ratios of throughputs, and response times with and without multitasking. The parameters for this figure are listed in the first row of Table II.

VI. SUMMARY
Performance models of parallel processing in which jobs divide into two or more asynchronous tasks have been developed. Because of the parallelism, the resulting queueing network does not have a product-form solution. An approximate solution method is described which iterates through a sequence
of product-form networks. The condition for convergence of this method are given. The accuracy of the approximation is studied through extensive comparisons with simulations. The

approximation is found to be very accurate for systems which are not highly imbalanced. Bounds are developed on the gain in performance due to overlapped tasks and the performance gains predicted by the model are given for several systems.
Future topics for research include investigating the existence, uniqueness, and accuracy of approximate solutions to models which have heterogeneous job types, each of which may spawn one or more asynchronous tasks.
REFERENCES [11 F. Baskett, K. M. Chandy, R. R. Muntz, and F. G. Palacios, "Open,
closed, and mixed networks of queues with different classes of customers," J. Ass. Comput. Mach., vol. 22, pp. 248-260, 1975.
[21 F. J. Beutler and B. Melamed, "Decomposition and customer streams
of feedback networks of queues in equilibrium," Operations Res., vol. 26, pp. 1059-1072, 1978.
[31 J. C. Browne, K. M. Chandy, J. Hogarth, and C. C.-A. Lee, "The effect on throughput of multiprocessing in a multiprogramming environment,"
IEEE Trans. Comput., vol. C-22, pp. 728-735, 1973. [4] J. P. Buzen, "Queueing network models of multiprogramming," Ph.D.
dissertation, Div. Eng. Appl. Sci., Harvard Univ., Cambridge, MA, 1971.
[5] K. M. Chandy, J. H. Howard Jr., and D. F. Towsley, "Product form and
local balance in queueing networks," J. Ass. Comput. Mach., vol. 24, pp. 250-263, 1977.
161 K. D. Gordon and L. W. Dowdy, "The impact of certain-parameter estimation errors in queueing network models," in Proc. Performance '80,
1980, pp. 3-9; see also Performance Eval. Rev., vol. 9. [7] R. W. Hamming, Numerical Methods for Scientists and Engineers,
2nd ed. New York: McGraw-Hill, 1973. [8] P. Heidelberger and K. S. Trivedi, "Analytic queueing models for pro-
grams with internal concurrency," Yorktown Heights, NY, IBM Res Rep. RC 9194, 1982; also IEEE Trans. Comput., to be published.
[9] D. L. Iglehart, "The regenerative method for simulation analysis," in Current Trends in Programming Methodology, Vol. III: Software Engineering, K. M. Chandy and R. T. Yeh, Eds. Englewood Cliffs,
NJ: Prentice-Hall, 1978.
[101 L. Kleinrock, QueueingSystems, Volume II ComputerApplications.
New York: Wiley, 1976. [11] S. S. Lavenberg, "Closed multichain product form queueing networks
with large population sizes," Yorktown Heights, NY, IBM Res. Rep. RC 8496, 1980. [12] S. S. Lavenberg and C. H. Sauer, "Sequential stopping rules for the regenerative method of simulation," IBM J. Res. Develop., vol. 21, pp. 545-558, 1977. [13] T. G. Price, "Probability models of multiprogrammed computer systems," Ph.D. dissertation, Dep. Elec. Eng., Stanford Univ., Palo Alto, CA, 1974.
[14] -, "Models of multiprogrammed computer systems with 1/O buffering," in Proc. 4th Texas Conf. Comput. Syst., Univ. Texas, Austin,
1975.
[15] M. Reiser and S. S. Lavenberg, "Mean-value analysis of closed multichain queueing networks," J. Ass. Comput. Mach., vol. 27, pp. 313-322,
1980.
[16] C. H. Sauer and K. M. Chandy, "The impact of distributions and disciplines on multiple processor systems," Commun. Ass. Comput. Mach., vol. 22, pp. 25-34, 1979.
[17] , Computer Systems Performance Modeling. Englewood Cliffs, NJ: Prentice-Hall, 1981.
[18] C. H. Sauer and E. A. MacNair, "Queueing network software for systems modelling," in Software-Practice and Experience, vol. 9, pp. 369-380, 1979.
[19] C. H. Sauer, E. A. MacNair, and S. Salza, "A language for extended queueing network models," IBM J. Res. Develop., vol. 24, pp. 747-755, 1980.
[20] D. Towsley, K. M. Chandy, and J. C. Browne, "Models for parallel processing within programs: Applications to CPU:l/O and 1/0:1/0 overlap," Commun. Ass. Comput. Mach., vol. 21, pp. 821-831, 1978.
[211 K. S. Trivedi and T. M. Sigmon, "Optimal design of linear storage hierarchies," J. Ass. Comput. Mach., vol. 28, pp. 270-288, 1981.

IEEE TRANSACTIONS ON COMPUTERS, VOL. c-31, NO. 11, NOVEMBER 1982

1109

Philip Heidelberger (M'82) received the B.A. degree in mathematics from Oberlin College, Ober-
lin, OH, in 1974 and the Ph.D. degree in opera-
tions research from Stanford University, Stanford, CA, in 1978.
He has been a Research Staff member at the IBM Thomas J. Watson Research Center, Yorktown Heights, NY, since 1978. His current research interests include computer performance
modeling and statistical analysis of simulation
output. Dr. Heidelberger is a member of the Operations Research Society of America and the Association for Computing Machinery.

Kishor S. Trivedi received the B.Tech. degree from

the Indian Institute of Technology and the M.S.

and Ph.D. University

odfegIrlleiensoisi,n Ucrobmapnuat.er

science

from

the

Presently, he is an Associate Professor of Com-

puter Science and Electrical Engineering at Duke

University, Durham, NC. He is the author of the

book Probability and Statistics with Reliability,

4 pQuubeluiesihnegd, bayndPreCnotmipceu-tHearll.ScHieencheasApspelrivceadtioasns,a

Principal Investigator on various NSF- and

NASA-funded projects and as a consultant to industry and research labora-

tories. He has published in the areas of computer arithmetic, computer ar-

chitecture, memory management, and performance evaluation.

Dr. Trivedi is an ACM National Lecturer and has been a Distinguished

Visitor of the IEEE Computer Society.

Correspondence.

Pin Limitations and Partitioning of VLSI Interconnection Networks
MARK A. FRANKLIN, DONALD F. WANN, AND WILLIAM J. THOMAS
Abstract-Multiple processor interconnection networks can be characterized as having N' inputs and N' outputs, each being B' bits wide. A major implementation constraint of large networks in the VLSI environment is the
number of pins available on a chip, N,. Construction of large networks requires
partitioning of the N' * N' * B' network into a collection of N * N switch modules with each input and output port being B (B S B') bits wide. If each module corresponds to a single chip, then a large network can be implemented by interconnecting the chips in a particular manner. This correspondence presents a methodology for selecting the optimum values of N and B given values
of N', B', Np, and the number of control lines per port. Models for both banyan
and crossbar networks are developed and arrangements yielding minimum: I) number of chips, 2) average delay through the network, and 3) product of number of chips and delay, are presented.
Index Terms-Banyan, crossbar, interconnection networks, pin limitations, multiprocessors, synchronization.
1. INTRODUCTION Recently a variety of physically local, closely coupled multiple processor computer systems have been proposed and, in some cases,
built [II- [4]. One key issue in the design of such systems concerns
the communications network used by these multiprocessor systems. Various studies have focused on the functional properties of such networks (i.e., permutations, control algorithms), on their complexity, and on performance issues [5]-[9]. Network complexity has often been measured by the number of elementary switching components needed, while performance has been determined by the average number of components through which a message must pass (i.e.,
Manuscript received January 11, 1982; revised June 17, 1982. This work was supported in part by NSF under Grant MCS-78-20731 and ONR under Contract N00014-80-0761.
The authors are with the Department of Electrical Engineering, Washington University, St. Louis, MO 63130.

average delay). Complexity and performance questions have been

examined in the context of VLSI implementation of such intercon-

nection networks. Franklin [10] has compared crossbar and banyan

networks operating in circuit-switched mode in terms of their space

(area) and time (delay) requirements. Wise [II] presents a three-

dimensional VLSI layout arrangement for banyan networks.

Thompson [12] and Padmanabhan [13] derive lower bounds on the

area and time complexity for a number of networks.

Closer examination of VLSI network implementation problems

however show that pin limitations, rather than chip area or logical

component limitations, are a major constraint in designing very large

networks. Consider a network with N' inputs, M' outputs, and with

each output being B' bits wide (N' pin connections (ignoring power,

g*rMo'un*d,B'a).ndThgeenneurmalbecronotfrorle)qufiorread

single chip implementation is given by B'(N' + M'). For a square

network of size thirty-two, with B' = 16, the number of pins required

would thus be 1024. This is much larger than is commonly available

on commercial integrated circuit carriers and is near the limits of

advanced ceramic modules where the entire area of one module sur-

face is used for pin placement.

This correspondence focuses on two important problems encoun-

tered in the design of interconnecting networks. First we examine how

partitioning the network can be used to overcome the pin limitation

constraint. We develop relations for optimum partition configurations

as a function of the major network parameters including total number

of integrated circuit chips and average message delay through the

network. Secondly, we identify an unusual problem, called word in-

consistency, that is created when local control of the partitioned

network (which may be highly desirable for its ease of modular ex-

pansion/contraction) is used, and propose a control structure and

protocol that overcomes this problem.

One approach to partitioning is to implement a large network (N'

* N') requiring many pins as an interconnected set of smaller sub-

networks (N * N) where each smaller subnetwork can be contained

on a single chip whose packaging design meets the pin constraints.

Another approach is to slice the network so that one creates a set

of network planes with each plane handling one or more bits (e.g., B

bits) of the B' wide data path. It is this bit slicing procedure which

can lead to synchronization problems. Consider the situation where

message routing through the network is via local control logic present

0018-9340/82/1100-1109$00.75 © 1982 IEEE

