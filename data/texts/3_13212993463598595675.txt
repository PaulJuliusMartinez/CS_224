On the Statistics of Natural Images
by Ting-Li Chen B.A., National Taiwan University, 1994 M.S., National Taiwan University, 1996
Thesis Submitted in partial fulfillment of the requirements for
the Degree of Doctor of Philosophy in the Division of Applied Mathematics at Brown University
Ph.D. Advisor: Stuart Geman
PROVIDENCE, RHODE ISLAND May 2005

c Copyright 2005 Ting-Li Chen

This dissertation by Ting-Li Chen is accepted in its present form by the Division of Applied Mathematics as satisfying the dissertation requirement for the degree of Doctor of Philosophy

Date . . . . . . . . . . . . . . . . . . . . . .

................................................ Stuart Geman

Recommended to the Graduate Council

Date . . . . . . . . . . . . . . . . . . . . . .

................................................ Basilis Gidas

Date . . . . . . . . . . . . . . . . . . . . . .

................................................ Donald E. McClure

Approved by the Graduate Council

Date . . . . . . . . . . . . . . . . . . . . . .

................................................ Karen Newman, Ph.D Dean of the Graduate School

iii

The Vita of Ting-Li Chen Ting-Li Chen was born in the City of Keelung, Taiwan on January 26th 1972. He graduated from Chieh-Kuo Senior High School in Taipei, Taiwan. In 1990, he began his undergraduate study in National Taiwan University, and received a Bachelor of Sciences degree in Mathematics in 1994. He completed his Master's degree in Mathematics from National Taiwan University in 1996, then worked as a research assistant in the Department of Mathematics, National Taiwan University. Since the year of 1997, he has been attending the Ph.D. program in the Division of Applied Mathematics at Brown University. This dissertation was defended and completed in October 2004
iv

Abstract of "On the Statistics of Natural Images," by Ting-Li Chen, Ph.D., Brown University, May 2005
This thesis studies the statistics of natural images. It contains two chapters. Chapter 1 is on the scale invariance, a mysterious property of natural images. Chapter 2 is on the compression related to statistics of natural images.
Chapter 1 explores evidence of scale invariance of natural images, and explains why natural images have this nice property.
Chapter 2 studies an image compression algorithm "LOCO", and establish some useful properties of residual entropy, which can provide a more efficient compression.

Acknowledgments
I want to thank all those who have helped me to complete this thesis. Most of all, I want to express my deepest gratitude to my advisor, Professor Stuart
Geman, for directing my research and also for supporting me throughout my time at Brown. He gave many stimulating ideas and valuable suggestions all the time. He also offered many additional help in preparing for the manuscript. This thesis would not be possible without his help.
I also want to thank my committee members, Professor Donald E. McClure and Professor Basilis Gidas, for being my thesis readers and giving valuable comments.
I want to give my best regards to Professor Chii-Ruey Hwang in Academia Sinica in Taiwan, who was my advisor for my Master's thesis. I want to thank him for introducing me to Brown University, for his continuous encourgaments and also for his help both in my research and my personal life.
My many thanks to Matthew Harrison, my officemate, and to all people in the Applied Mathematics for helping me in every aspect. I am also very grateful to my parents and my wife for their love and support.
v

Contents

Acknowledgments

v

1 On the Scale Invariance of Natural Images 1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.2 Definition and Examples of Scale Invariance . . . . . . . . . . . . . . 1.2.1 Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.2.2 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.3 The size of objects in the natural images . . . . . . . . . . . . . . . . 1.3.1 Mathematical considerations: the 1/r3 law . . . . . . . . . . . 1.3.2 The area law . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.3.3 The flat-earth explanation for object scaling . . . . . . . . . . 1.4 The scale invariance of local statistics . . . . . . . . . . . . . . . . . . 1.4.1 Explanation by the projection effect . . . . . . . . . . . . . . . 1.4.2 Evidence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.4.3 Proposal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.4.4 Distance effect . . . . . . . . . . . . . . . . . . . . . . . . . . 1.4.5 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1 2 4 4 6 19 19 21 26 42 42 43 48 56 56

2 On the Use of of Natural Image Statistics for Compression 2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.2 Definitions and Assumptions . . . . . . . . . . . . . . . . . . . . . . .

63 64 66

vi

2.3 Minimizing Residual Entropy . . . . . . . . . . . . . . . . . . . . . . 2.4 Application . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.5 Extension . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

68 81 83

vii

List of Tables
1.1 regression coefficients  of images from Figure 1.1 for different k's . . 26 2.1 Entropies of Empirical Residual Distributions . . . . . . . . . . . . . 83
viii

List of Figures

1.1 Nine sample images . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.2 Logarithms of marginal distributions of different filters for picture-1
from Figure 1. Solid curve:I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI. . . . . . . . . . . . 1.3 Logarithms of marginal distributions of different filters for picture-2 from Figure 1. Solid curve: I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI. . . . . . . . . . . . 1.4 Logarithms of marginal distributions of different filters for picture-3 from Figure 1. Solid curve: I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI. . . . . . . . . . . . 1.5 Logarithms of marginal distributions of different filters for picture-4 from Figure 1. Solid curve: I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI. . . . . . . . . . . . 1.6 Logarithms of marginal distributions of different filters for picture-5 from Figure 1. Solid curve: I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI. . . . . . . . . . . . 1.7 Logarithms of marginal distributions of different filters for picture-6 from Figure 1. Solid curve: I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI. . . . . . . . . . . .

7 9 10 11 12 13 14

ix

1.8 Logarithms of marginal distributions of different filters for picture-7 from Figure 1. Solid curve: I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI. . . . . . . . . . . .
1.9 Logarithms of marginal distributions of different filters for picture-8 from Figure 1. Solid curve: I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI. . . . . . . . . . . .
1.10 Logarithms of marginal distributions of different filters for picture-9 from Figure 1. Solid curve: I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI. . . . . . . . . . . .
1.11 Logarithms of marginal distributions of different filters for the ensemble images of all pictures from Figure 1. Solid curve: I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI. .
1.12 (a) Histogram of gray level values. (b) Histogram of the logarithm of gray level values. (c) Logarithm of histogram of xI. Solid curve: gray level values < 2000, dotted curve: gray level values > 4000. (d) Logarithm of histogram of x log I. Solid curve: gray level values < 6.4, dotted curve: gray level values > 7.2. . . . . . . . . . . . . . .
1.13 The distribution of area of image-1 and k = 5. Both x-axis and y-axis are in logarithm scale. . . . . . . . . . . . . . . . . . . . . . . . . . .
1.14 log(range+1) for images from "Brown Range Image Database" . . . . 1.15 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.16 (a) the distribution of the distance of objects. (b) the log distribution
of the distance of objects . . . . . . . . . . . . . . . . . . . . . . . . .

15
16
17
18
24 25 34 35 37

x

1.17 Solid curve: the empirical conditional density function. Dotted curve: the fitted curve to the 3D-world model. Dashed curve: the fitted curve to the flat-world model. (a) original scale (b) logarithm scale in y-axes (c) original scale restricted to the domain 16 <  < 30 (d) logarithm scale in y-axis, and the domain restricted to 16 <  < 30 (e) original scale restricted to the domain 30 <  < 60 (f) logarithm scale in y-axis, and the domain restricted to 30 <  < 60 . . . . . . . . . . . . . . . .
1.18 Logarithms of marginal distribution of x for texture images. Solid curve: xI, dashed curve: xI(2), and dotted curve: xI(4). . . . . .
1.19 Picture-2 from Figure-1.1, and strips from it. Histograms are logarithms of marginal distributions of x. Solid curve: xI, dashed curve: xI(2), and dotted curve: xI(4). . . . . . . . . . . . . . . . .
1.20 Logarithms of marginal distributions of x for simulated image from LOCO predictor. Solid curve: xI, dashed curve: xI(2), and dotted curve: xI(4). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.21 Logarithms of marginal distribution of x for a simulated image from N(128, 900). Solid curve:xI, dashed curve: xI(2), and dotted curve: xI(4). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.22 Logarithms of marginal distribution of x for simulated images from Cauchy distributions. Solid curve: xI, dashed curve: xI(2), and dotted curve: xI(4). . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.23 Logarithms of marginal distribution of x for a simulated image from TSGD(0.1). Solid curve: xI, dashed curve: xI(2), and dotted curve: xI(4). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.24 Logarithms of marginal distribution of x for an texture image and that image with TSGD noises. Solid curve: xI, dashed curve: xI(2), and dotted curve: xI(4). . . . . . . . . . . . . . . . . . . . . . . . .

38 44 46 47 49 50 51 52

xi

1.25 Logarithms of marginal distribution of x for simulations by mixing the ramp effect TSGD(0.2) and the noise effect TSGD(0.1). Solid curve: xI, dashed curve: xI(2), and dotted curve: xI(4). . . . . .
1.26 An image which does not scale well can have a good scale invariance by adding a proper noise. Solid curve: Logarithms of marginal distribution of xI, dashed curve: xI(2), and dotted curve: xI(4). . . .
1.27 (a) x to the real image. (b) x to the simulation mixed with distance effect 1/r. (c) x to the simulation mixed with the distance effect from range data. Solid curve: xI, dashed curve: xI(2), and dotted curve: xI(4). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

54 55 57

2.1 LOCO predictor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65 2.2 test images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82

xii

Chapter 1 On the Scale Invariance of Natural Images
1

1.1 Introduction

Scale invariance is a mysterious property of natural images. It refers to the phe-

nomenon that the distributions of many statistics of natural images are very close

to those of scaled ones. At the first thought, scale invariance seems a trivial phe-

nomenon. One might think that a scaled image can be produced by moving the

camera backward. However, this is not correct. When an object is at distance d1 to

the camera and the camera is moved distance d2 backward, the image of the object

is down-scaled

by a factor of

.d1
d1+d2

This

factor

varies with

respect

to d1.

Therefor,

unless all the objects are at the same distance to the camera, regardless of where we

place the camera, we can not get an image in which all objects are scaled down with

the same factor. In other words, a scaled image can not be viewed as another image

taken from a difference distance. Therefore, scale invariance is not as trivial as one

might think at the beginning.

When scale invariance of natural images is studied, a question quickly comes

to one's mind: Why do natural images have such a property? There are models

which explain scale invariance of natural images. For example, in the model given by

Ruderman [2] [3] [4], objects with random shapes and sizes are randomly placed in

an infinite image plane, and each object is independently painted with a gray tone

chosen from a distribution. It was argued that if these objects have a power-law

distribution of sizes, statistics of images of the plane also follow a power law, which

is related to scale invariance.

In the model given by Mumford and Gidas [5], objects in images are also randomly

placed and have random shapes and sizes. In contrast to the model given by Ruder-

man, Mumford and Gidas allowed for patterns of colors within each object. Images

composed of all categories of patterns together have scale invariant property.

There is also a model given in Chi [1], in which the world is flat, and the objects are

placed randomly not too far from the ground. Chi argued that the transformation of

object distances into object sizes in the image plane (i.e. on the film, retina, or CCD

2

array) produces a size distribution following the 1/r3 rule. Since this rule of sizes is necessary for perfect scale invariance, this "flat-earth" model suggests an explanation for scale invariance. We continue this work with more detailed calculations, and we claim that the size of objects does approximately follow the 1/r3 rule in the flat-world model. However, we also find some evidence of images having a good scale invariance without the projection effect. Therefore, we propose a new model to explain scale invariance.
We mention here some related referrences. Balboa et al. [6] discussed occlusion effect to scaling. Lee et al. [7] developed "dead leaves model", which takes occlusions into account. Thomson [8] described a measure and showed that there are statistical consistencies in the phase spectra of natural scenes. Grenander [9] and Srivastava [10] introduced a Bessel Kernel form for modeling the marginal probabilities of the spectral components of images. Turiel et al. [11] [12] showed multiscaling properties of natural scenes. Field [13] [14] and Olshausen [15] showed the relation of the response properties to the structure of natural images. Burton et al. [16] discussed structures in natural scene and methods of optimum image coding. van Hateren et al. [17] developed a theory of maximizing sensory information.
In the following, we review the mathematical definition of scale invariance, and provide some examples in section 2. In section 3, we derive the 1/r3 rule of the size of objects, and explain it using the flat-world model. In section 4, we present evidence to show that the projection effect may not be the key factor in scale invariance. Finally, we propose a new model to explain scale invariance in local statistics of natural images.
3

1.2 Definition and Examples of Scale Invariance

1.2.1 Definitions

A digital image I of size M × N with L integer gray levels is a matrix with M rows and N columns, where I(i, j)  {0, 1, 2, . . . , L - 1} is the gray level at pixel (i, j).
To scale down an image by k, we partition an image into disjoint blocks of size k × k, and take the average of gray level values of each block as its new value. More precisely, let I(k) be the down-scaled image by factor k, and block Bij = [(i - 1)k + 1, ik] × [(j - 1)k + 1, jk] for 1  i  M/k and 1  j  N/k . Then

I(k)(i, j) = 1 k

k
I((i - 1)k + n, (j - 1)k + m).

k2

n=1 m=1

We round off each average to an integer, so that the scaled image takes values in the same space as the original one does.
Real images are not truly scale invariant. But most, if not all, local statistics are found to be nearly scale invariant when tested on an ensemble of natural images. The phenomenon is surprisingly robust. Mathematically, this property is conveniently studied by pretending that images are truly scale invariant, meaning that the original image and the scaled image have the same distribution. However, since the size of the original image and that of the scaled one are different, the distributions of these two images can not be the same. In order to make a comparison between their distributions, we extend the image domain to R2 as follows.
Let (x, y) be a function defined on R2. We can think of  as the underlying continuous image of I. The value of the pixel (i, j) of I is the average of (x, y) over its corresponding block on R2. That is,

1

I(i, j) = d2

(x, y)dxdy,
[(i-1)d,id]×[(j-1)d,jd]

4

where d is the unit length. From the definition of I(k),

I(k)(i, j)

1k k = I((i - 1)k + n, (j - 1)k + m)
k2 n=1 m=1

1k k1

=

k2 d2 n=1 m=1

(x, y)dxdy
[((i-1)k+n-1)d,((i-1)k+n)d]×[((j-1)k+m-1)d,((j-1)k+m)d]

1 = (x, y)dxdy
k2d2 [(i-1)kd,ikd]×[(j-1)kd,jkd]

1 = (kx , ky )dx dy .
d2 [(i-1)d,id]×[(j-1)d,jd]

Therefore, we can view (kx, ky) as the underlying function of I(k)(i, j), while viewing

(x, y) as the underlying function of I(x, y). Now we can say that an image has scale

invariance if

(kx, ky) =D (x, y).

In practice, it is impossible to check whether two infinite-dimensional random fields (such as (kx, ky) and (x, y)) have the same distribution. However, the distribution of any filter should be the same for both fields. Furthermore, under the assumption of stationarity of images, it is shown in Chi[1] that the distribution of natural images itself is scale invariant if the marginal distribution of any filter is also scale invariant.
In the literature, the power spectrum of natural images is used to examine the property of scale invariance. Power spectrum S(k) is defined as

1 2

S(k) =

d

< (x)(x + y) > e-ikv()·ydy,

2 0

R2

where for fixed y, < (x)(x + y) > represents the expected value (with respect to the random field ) of the average of (x)(x + y) over all x, v() = (cos(), sin()), and k is the magnitude of the spatial frequency. It is well-known that the power

5

spectrum of natural images takes the form of a power-law in the spatial frequency [4]: A
S(k) = , k2-
where  is the "anomalous exponent" (usually small), and A is a constant which determines the overall image contrast. Indeed, under the assumption of ergodicity of the distribution of images,
< (x)(x + y) >= E((0)(y)),
where E is over all . Then, with scale invariance property, S(1)
S(k) = . k2
This is exactly the case of  = 0. The proof can be found, for example, in [1].
1.2.2 Examples
The images that we use in this section are from "The Dutch Image Database", which was first used in [18]. These images were obtained with a Kodak DCS420 digital camera. The size of each image is 1536 horizontal by 1024 vertical pixels. Each pixel is a 2-byte unsigned integer. The pixels are linear in intensity. The intensity scaling is determined by the settings of the camera for each image. We randomly choose nine images from the database, and examine the scale invariance of each individual image as well as the ensemble of all nine images. Figure 1.1 shows the nine images we use.
We experiment with several statistics on these images. The first two statistics we use are horizontal derivatives and vertical derivatives. For digital images, we take the difference of gray level values between a pixel and its neighboring pixels as its
6

Figure 1.1: Nine sample images 7

derivatives. More precisely,
xI(i, j) = I(i, j + 1) - I(i, j) yI(i, j) = I(i + 1, j) - I(i, j).
Similarly, we also consider the filter
xyI(i, j) = I(i, j) - I(i, j + 1) - I(i + 1, j) + I(i + 1, j + 1).
We also experiment with x of the logarithm of each image. For each image I, we create a new image J by
J(i, j) = log I(i, j).
Then we compute the marginal distributions of xJ, xJ(2) and xJ(4). Theoretically, the range of x's is from -65535 to 65535. However, x's rarely fall
outside [-2000,2000]. Therefore, when we compute the histogram of derivatives for each image, we use 201 bins which have equal width of 20 and are centered from -2000 to 2000. For the experiment xJ, we also use 201 bins but they are centered from -5 to 5. We normalize each histogram so that the sum is 1. Since most filter values are near 0, the histograms look very similar. We take logarithms of each histogram to explore more features.
Figure 1.2 to Figure 1.10 are the results for images from 1.1, and Figure 1.11 is that for the ensemble images. In each figure, (a) shows horizontal derivative xI(i, j), (b) shows vertical derivative yI(i, j), (c) shows xJ(i, j), and (d) shows xyI(i, j). In each sub-figure, the solid curve represents the empirical marginal distribution of the filter values of the original image I, the dashed curve represents that of the scaled image I(2), and the dotted curve represents that of the scaled image I(4).
For images with scale invariance property, we expect to see that the marginal distributions stay nearly the same after scaling. However, as shown in Figure 1.2 to
8

Figure 1.2: Logarithms of marginal distributions of different filters for picture-1 from Figure 1. Solid curve:I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI.
9

Figure 1.3: Logarithms of marginal distributions of different filters for picture-2 from Figure 1. Solid curve: I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI.
10

Figure 1.4: Logarithms of marginal distributions of different filters for picture-3 from Figure 1. Solid curve: I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI.
11

Figure 1.5: Logarithms of marginal distributions of different filters for picture-4 from Figure 1. Solid curve: I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI.
12

Figure 1.6: Logarithms of marginal distributions of different filters for picture-5 from Figure 1. Solid curve: I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI.
13

Figure 1.7: Logarithms of marginal distributions of different filters for picture-6 from Figure 1. Solid curve: I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI.
14

Figure 1.8: Logarithms of marginal distributions of different filters for picture-7 from Figure 1. Solid curve: I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI.
15

Figure 1.9: Logarithms of marginal distributions of different filters for picture-8 from Figure 1. Solid curve: I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI.
16

Figure 1.10: Logarithms of marginal distributions of different filters for picture-9 from Figure 1. Solid curve: I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI.
17

Figure 1.11: Logarithms of marginal distributions of different filters for the ensemble images of all pictures from Figure 1. Solid curve: I, dashed curve: I(2), and dotted curve: I(4). (a) xI, (b) yI, (c) xJ, and (d) xyI.
18

Figure 1.11, not all of the marginal distributions stay nearly the same. We observed that, among nine images, image 2, 5, 6, 9 demonstrate better scale invariance property. We also observed that these four images cover broader views and show richer features than the other five images do. In Section 4, we propose a model to explain why images with broader views and richer features have better scale invariance.
In fact, figure 1.2 to figure 1.11 show that all of the marginal distributions, including the four images with better scale invariance, have heavier tails after scaling. However, there was no such phenomenon observed by Chi [1] that the tails are heavier after scaling. Our explanation for this discrepancy is that the images we used were less noisy. In Section 4, we will discuss the noise effect on scale invariance. In general, the noisier an image is, the less heavy tail the marginal distribution has after scaling.
From Figure 1.2 to Figure 1.11, we also found that the behavior of the marginal distributions is very consistent with respect to different filters for each image. In other words, an image either has good scale invariance for every filter, or does not have good scale invariance for any filter.
1.3 The size of objects in the natural images
In this section, following an argument by Mumford (personal communication), we first derive the distribution that the size of objects has to obey in images with perfect scale invariance. Then we examine, empirically, the distribution of object sizes in natural images. Last, we build a model, which is an elaboration of the "flat-earth" model, to explain the distribution of sizes in natural images.
1.3.1 Mathematical considerations: the 1/r3 law
By perfect scale invariance with respect to the size of objects, we mean that the distribution of the size of objects in the image stays unchanged after the image gets scaled. In the following, we derive the distribution that the size of object has to follow
19

for perfect scale invariance.

Let N be the total number of objects in an image [0, l1] × [0, l2], and N (a, b) be the

expected number of objects of size between a and b. When we scale down this image

by

s,

the

scaled

image

has

size

[0,

l1 s

]

×

[0,

l2 s

],

and

objects

of

size

between

a

and

b

in

the

original

image become those

of size

between

a s

and

b s

in the

scaled

image.

Then

we create a new image of size [0, l1] × [0, l2], which consists of s × s identical scaled

images mentioned above. For perfect scale invariance, the statistics of this new image

should be the same as those of the original one. Then we have

a N(

,

b )

=

N (s)( a ,

b

)

=

s2N (a,

b),

ss ss

where N (s)(a, b) is the expected number of objects of size between a and b in the

scaled image. Note that the total number of objects in the new image is s2 times as

many as that in the original one. This will be addressed shortly, by putting a lower

bound on object size. Let f (r) be the density of objects of size r. The equality above

turns into

N·

b
s f (r)dr = N · s2

b
f (r)dr.

a s

a

Taking derivatives on both sides with respect to b, we obtain

1 s

f

(

b s

)

=

s2f

(b)



f

(

b s

)

=

s3f

(b)



f (r)



1 r3

The density has a non-integrable singularity at zero, so we put a lower bound on object size, say m. (This will also insure that the total number of objects is preserved under scaling, and shown below.) After normalizing, we get
2m2 f (r) = , r  [m, ).
r3

20

Now we examine whether the total number of objects is preserved under scaling. With the assumption of a lower bound m on object size, objects of size between m and s · m in the original image become invisible after we scale down the image by s. The number of objects of sizes between m and s · m in the original image is

s·m s2 - 1

N · f (r)dr = N ·

.

m s2

In

other

words,

there

are

only

N

·

1 s2

objects

visible

after

scaling.

Along

with

the

fact

that the total number of objects in the new image is s2 times as many as that in the

original

one,

there

are

s2

·N

·

1 s2

=

N

objects

in

the

new

image.

Therefore,

the

total

number of objects is preserved under scaling.

1.3.2 The area law
In the real world, objects have different shapes. Instead of examining the distribution of the size of objects in the image, it is easier to examine the area of objects. In this section, we will derive a rule with respect to the area of objects. This rule is equivalent to the rule that the size of objects follows 1/r3. Then we find evidences that the area of objects in natural images actually follows the rule.

Equivalence of size and area scaling rules

An equivalent statement to "the size of objects follows 1/r3 rule" is "the area of

objects in the image follows 1/A2 rule".

Let N be the total number of objects in an image [0, l1] × [0, l2], and NA(a, b) be

the expected number of objects of area between a and b in an image [0, l1] × [0, l2].

After

we

scale

down

this

image

by

s,

the

scaled

image

has

size

[0,

l1 s

]

×

[0,

l2 s

],

and

objects of area between a and b in the original image become those of area between

a s2

and

b s2

in the scaled image.

Then we create a new image of size [0, l1] × [0, l2],

which consists of s × s identical scaled images as mentioned above. For perfect scale

21

invariance, the statistics of this new image should be the same as those of the original one. By similar calculation in previous section, we have

a N( ,

b ) = s2N (a, b).

s2 s2

Let g(A) be the density of objects of area A. The equality above turns into

N·

b
s2 g(A)dA = N · s2

b
g(A)dA.

a s2

a

Taking derivatives on both sides with respect to b, we obtain

1 s2

g

(

b s2

)

=

s2g(b)



g(

b s

)

=

s2g(b)



g(A)



1 A2

.

Similarly, we put a lower bound on object area, say mA. After normalizing, we get

g(A) = mA , A2

A  [mA, ).

Evidence that the area of objects in the image follows 1/A2 rule

Experiments in Alvarez-Morel's paper [19]:

Consider a digital image I of size H × L, with G integer gray levels, and write

I(i, j) for the gray level at pixel (i, j). Let k be an integer less than G. Let N1 be

the

first

integer

such

that

more

than

HL k

pixels

have

a

gray

level

less

than

N1,

and

similarly,

Nl

be

the

first

integer

such

that

more

than

l

HL k

pixels

have

a

gray

level

less

than Nl. Define Il(i, j) by

 1 Il(i, j) =  0

if I(i, j)  [Nl-1, Nl) otherwise.

22

Alvarez and Morel call these images "k-bilevels of I." This method classifies all pixels in image I into k categories, and each category has approximately the same number of pixels.
In any of the k-bilevels of I, each connected component of 1's is viewed as an object. Alvarez and Morel then calculate f (s) as the number of connected components with area s in all k-bilevels of I. They consider both 4-connexity and 8-connexity.
For fixed k, consider the set of points

S = {(log(s), log(f (s))), 0  s  Tmax},

where

Tmax = inf{s : f (s) = 0} - 1.

Alvarez and Morel perform linear regressions on the set S to find the straight line (in

the log-log coordinates) (log(f (s))) = A -  log(s), which is the best fit to S in the

least squares sense.

They obtained the value of  between 1.5 and 3 for images of natural scenes, and

between

2.5

and

3.5

for texture

images.

In

the

ideal

case

f (A) =

C A2

,

the

value

of



is expected to be 2.

Our experiments:

In the experiment as described above [19], connected components are viewed as

objects. However, these connected components may be far from real objects in real

images. In order for connected components to look more like real objects, we consider

two neighbor pixels as connected if their absolute difference in gray level values is

smaller than k. We partition the whole image into disjoint connected components.

Each such connected component is viewed as an object, and the area of each object

is calculated. The last step of our experiment is to perform similar linear regressions.

We experiment with the nine images in Figure-1.1. Figure-1.12(a) shows that

there are much more pixels of low gray level values in these nine images. Figure-

23

Figure 1.12: (a) Histogram of gray level values. (b) Histogram of the logarithm of gray level values. (c) Logarithm of histogram of xI. Solid curve: gray level values < 2000, dotted curve: gray level values > 4000. (d) Logarithm of histogram of x log I. Solid curve: gray level values < 6.4, dotted curve: gray level values > 7.2.
1.12(b) shows that the histogram of the logarithm of gray level values is bell-shaped. In our experiment, we define two neighboring pixels as connected if their absolute difference is smaller than a fixed constant k. Under this setup, we hope to see that the percentage of two neighboring pixels being connected stays roughly the same regardless of the gray level values. Therefore, we compare the distribution of x on pixels of low gray level values with that on pixels of high gray level values. We calculate x when both the gray level values of neighbor pixels are less than 2000, and when both are greater than 6000, respectively. The result presented in Figure1.12(c) shows that x is much larger when both neighbor pixels are of high gray level values. We do the same calculations to the logarithm of the image, and the result presented in Figure-1.12(d) shows that, x from different gray level values are close
24

to each other. Therefore, throughout our experiment, we use the logarithm of images instead of original images.

Figure 1.13: The distribution of area of image-1 and k = 5. Both x-axis and y-axis are in logarithm scale.

We take the logarithm of each image I, then adjust the logarithms of gray level values to integers between 0 and 255. Explicitly, the new image J is

255

J = [log(I + 1) ·

].

max log(I + 1) - min log(I + 1)

Figure-1.13 shows the result of images presented in Figure-1.2, and using k = 5. We can see that points of (log(s), log(f (s))) distribute very close to a line. A linear regression model log(f (s)) = A -  log(s) is performed, and it gives that A^ = 12.62 and ^ = -2.22.
From Figure-1.13, we also observe the following. First, our linear model fits better when log(s) is smaller than when log(s) is larger. Second, most of (log(s), log(f (s))) lie under the fitted regression line when log(s) is smaller, while (log(s), log(f (s))) distribute both above and below the fitted regression line when log(s) is larger. These observations can be explained by the fact that we have less data of larger log(s). It is possible that, once the data of larger values of log(s)'s are removed, we can

25

k Picture-1 Picture-2 Picture-3 Picture-4 Picture-5 Picture-6 Picture-7 Picture-8 Picture-9

regression on S 5678 2.22 2.17 2.13 2.21 2.32 2.35 2.27 2.20 2.26 2.24 2.14 2.11 2.30 2.12 2.07 2.02 2.12 2.09 2.33 2.41 2.58 2.30 2.19 2.08 2.32 2.46 2.57 2.59 2.05 1.97 1.99 1.93 2.43 2.32 2.30 2.26

regression on S 5678 2.03 2.04 2.07 2.17 2.15 2.13 2.07 2.02 2.42 2.31 2.22 2.19 2.23 2.14 2.12 2.11 1.96 1.93 2.07 2.17 2.09 1.97 1.91 1.91 2.40 2.43 2.53 2.48 2.38 2.37 2.37 2.38 2.42 2.32 2.25 2.19

Table 1.1: regression coefficients  of images from Figure 1.1 for different k's

improve the over-estimation problem of our linear model for smaller values of log(s)'s. Therefore, in addition to a linear regression on

S = {(log(s), log(f (s))), 0  s  Tmax}

we also perform a linear regression on

S = {(log(s), log(f (s))), 0  s  15}.

Table-1.1 presents the regression coefficients  from the regression model (log(f (s))) = A -  log(s) on S and S , which are calculated from nine images shown in Figure-1.1, with k =5, 6, 7, 8, respectively. It show that  is indeed close to 2.

1.3.3 The flat-earth explanation for object scaling
Scaling of physical objects If the size of physical objects in the 3-D world follows the 1/r3 rule, then the size of objects in the image will also follow this rule. This is a strong assumption, and there is no evidence to support this assumption.

26

The effect of distance to the lens
We claim that the distance of objects is the key factor that the size of objects in a image follows the 1/r3 rule. In the following, we start with building up a "flat-earth" model (proposed by Chi [1]), then we derive the distribution of the distance of objects based on this model. With this distribution of distance, then we explain the property of scale invariance of object size. Derivation of the flat-earth model:
Assume that the world is flat and objects are placed randomly not too far from the ground. Explicitly, all objects are placed in the region V = R+ × R × [-H1, H2], where {z = -H1} is the ground, and {z = H2} is the upper bound plane. Assume that H2 > H1, which means the distance from the lens to the upper bound plane is larger than that to the ground. An ideal pinhole lens is placed on the origin, and an image film is placed on -1 × [-l1, l1] × [-l2, l2]. The centers of objects are distributed by a homogeneous Poisson process with density parameter µ, where µ is the expected number of occurrences in any region of volume 1. For each location (xi, yi, zi) generated from the Poisson process, an object is randomly sampled from a fixed distribution O. All objects in O are planar templates with different sizes and shapes. The object sampled is placed on the plane x = xi and centered at (xi, yi, zi). If an object o is not entirely in V , we only consider the part of object inside V , which is o V .
The previous paragraph describes the setup of our flat-earth model. Our goal is to derive the density function of the distances of objects to the lens. More explicitly, each pixel in the image film represents one part of an object, the ground, or the sky. We want to calculate the distribution of the distance from the lens to the corresponding object. The distance here means the distance in x-direction, or the projection of the distance to the x-axis.
Mathematically, we define a random variable X as follows: Randomly choose a pixel from the image film. Let a ray start from this pixel, go through the origin, and
27

go on until it hits something. Let X be the x-distance from the lens to the object or the ground which the ray hits. X =  if the ray does not hit anything. Our goal is to calculate the density function f (x) for X = x < , and Pr(X = ). Let d(i, j) be the x-distance from the lens to the corresponding object of pixel (i, j), and d~(y, z), the continuous version of d, be that of (-1, y, z) in the image film. Then

f (x)dx = Pr(x  X < x + dx)

expected number of{(i, j)|x  d(i, j) < x + dx} =
total pixels in the image film

=

l2 -l2

l1 -l1

1(xd~(y,z)<x+dx)dydz

4l1l2

Therefore, it suffices to calculate the expected area in the image film where x  d~(y, z) < x + dx.
When x  d~(y, z) < x+dx for some (y, z) in the image film, the ray from (-1, y, z)

through the lens (the origin) hits either an object or the ground at x-distance between

x and x + dx. If the ray hits an object, there is an object at (s, -sy, -sz) for some

s  [x, x + dx), and there is no object at (s, -sy, -sz) for all s < x. If the ray hits

the

ground,

the

location

where

the

ground

is

hit

is

(

H1 z

,

-H1 z

·y

,

-H1).

Moreover,

there

is

no

object

at

(s, -sy, -sz)

for

all

s<

H1 z

,

and

x



H1 z

<

x + dx.

In

both

scenarios

as mentioned above, we need the probability that there is no object along the ray

from the origin to any fixed point. This probability clearly depends on the density of

objects.

For

any

(x, y, z)



V,

let

r

be

the

ray

from

(x, y, z)

to

(x

+

1,

x+1 x

y,

x+1 x

z),

and

let  be the expected number of objects which the ray r intersects. Suppose that all

objects are of the same size and shape as some fixed o  O. Since o is planar, we can

describe it as o  R2, and place its center at the origin. On any x-plane, an object

centered at (x, u, v) covers the point (x, y, z), if (y - u, z - v)  o. Define

-o = {(-u, -v)|(u, v)  o}.

28

Then, for any (x, y, z)  V , an object will cover (x, y, z) if its center falls in

-o + (x, y, z)  {(x, y - u, z - v)|(u, v)  o}.

Therefore, the ray r intersects an object if the center of the object falls in
ss r - o  {(s, y - u, z - v)|x  s < x + 1 and (u, v)  o}.
xx
The volume of r - o is |o| × 1. Along with the assumption that centers of objects are distributed by a homogeneous Poisson process with density parameter µ, where µ is the expected number of occurrences in any region of volume 1, the expected number of centers in r - o is µ ×|o|. This is the expected number of objects which r intersects. We can run the same argument to any object o  O, then

 = µ · |o| · dm(o) = µ · |o| · dm(o),

where m is the probability measure on O. |o| · dm(o) is the mean areas of objects.

Let G(x, y, z) be the probability that there is no object at (sx, sy, sz) for all

0 < s < 1.

Let

v

be

a

vector

(x1, y1, z1),

and

Gv (x)



G(x, x

·

y1 x1

,

x

·

z1 x1

).

Then,

-dGv(x) = Gv(x) - Gv(x + dx) is the probability that there is no object in the

direction

v

before

(x,

x

·

y1 x1

,

x

·

z1 x1

),

and

there

are

some

objects

between

(x,

x·

,y1
x1

x·

z1 x1

)

and

(x

+

dx,

(x

+

dx)

·

y1 x1

,

(x

+

dx)

·

z1 x1

).

On

the

other

hand,

consider

r

as

the

ray

from

(x,

x

·

y1 x1

,

x

·

)z1
x1

to

(x

+

dx,

(x

+

dx)

·

y1 x1

,

(x

+

dx)

·

z1 x1

),

the

expected

number

of

objects

which r intersects is

 x1

dx.

r is a short ray with length |v| · dx.

Since objects are

distributed by a homogeneous Poisson process, the probability that r intersects more

than one object is o(·dx). Therefore, the probability that r intersects some objects is

 · dx. We have

-dGv(x) = Gv(x) ·  · dx.

29

Along with the fact Gv(0) = 1, the solution of the differential equation above is Gv(x) = e-x. Let x = x1, we have
G(x1, y1, z1) = Gv(x1) = e-x1 .
As discussed earlier, if d~ = x for some point in the image film, the ray from that point through the lens will hit either an object or the ground at x-distance x. We decompose f (x) into two parts. One is f1 when the ray hits an object, and the other is f2(x) is when it hits the ground. In the following, we will calculate f1(x) and f2(x) separately. Then we have f (x) as f1(x) + f2(x).
Consider the y - z plane at distance x. The region of this plane that is viewable in the image film is

x × [-l1x, l1x] × [max(-H1, -l2x), min(H2, l2x)]. The area of this region is

(l1x - (-l1x))(min(H2, l2x) - max(-H1, -l2x))

= 2l1x(min(H1, l2x) + min(H2, l2x))

=

2l1

l2x(min(

H1 l2

,

x)

+

min(

H2 l2

,

x)).

The expected number of objects in

[x, x + dx) × [-l1x, l1x] × [max(-H1, -l2x), min(H2, l2x)]

is

2l1l2

x(min(

H1 l2

,

x)

+

min(

H2 l2

,

x))

×

µdx.

Since the projection of a unit square at distance x onto the image is a square with

30

area

1 x2

,

the

expected

area

of

these

objects

in

the

image

film

ignoring

the

occlusion

effect and the boundary effect1 is

2l1l2x(min(

H1 l2

,

x)

+

min(

H2 l2

,

x))

×

dx/x2

=

2l1l2

(min(

H1 xl2

,

1)

+

min(

H2 xl2

,

1))dx.

Then f1(x)dx is the amount above times the occlusion effect G(x, y, z) = e-x, divided

by the total area of image film 4l1l2. Recall that H1 < H2. We have

  e-x

f1(x) = 

(1 H1
2 xl2

+

1)e-x

1 2

H1+H2 xl2

e-x

x<

H1 l2

H1 l2

x<

H2 l2

H2 l2

x

.

Next, we will derive f2(x). While objects from x-distance between x and x + dx can appear at any location in the image film, the ground from x-distance between x and x + dx has to appear in the region

-1

×

[-l1,

l1]

×

[

x

H1 + dx

,

H1 x

]

of the image film. The area of this region is

11

2l1

×

( x

-

x

+

dx )H1

=

2l1

H1 x(x +

dx)

dx.

1Some objects may exceed the boundary. Therefore, the expected area is smaller than the product of the expected number of objects and the mean area of objects. However, if we also distribute objects outside the boundary, some objects centered outside the boundary will have parts falling inside the boundary. Furthermore, if we distribute the outside objects with the same density as the inside objects, the expected outside area from objects centered inside the boundary is equal to the expected inside area from objects centered outside the boundary. Therefore, we have the expected area is exactly the same as the product of the expected number of objects and the mean area of objects.

31

Then f2(x)dx is this area times the occlusion effect G(x, y, z) = e-x, divided by he total area of image film 4l1l2. Therefore,

f2(x)

=

H1 e-x. 2x2l2

The

above

is

true

only

when

x

>

,H1
l2

since

the

projection

of

the

ground

at

x-distance

smaller

than

H1 l2

can

not

appear

in

the

image

film.

Combine both results of f1(x) and f2(x), we have

  e-x

f (x) = 

1 2

(

+

H1  xl2

+

H1 x2l2

)e-x

(1 H1
2 xl2

+

H2 xl2

+

H1 x2l2

)e-x

x<

H1 l2

H1 l2

x<

H2 l2

H2 l2



x

.

Last, we calculate Pr(X = ). When X = , the ray from a pixel through the origin does not hit anything. We can pretend that there is a ceiling z = H2, and every ray which does not hit anything will hit somewhere in the ceiling. Let f3(x) be the density function that d~(y, z) =  and the ray hits the ceiling at x-distance x. Using the same calculation as the derivation of f2(x), we have

f3(x)

=

H2 2x2l2

e-x.

for

x

>

.H2
l2

Therefore,



Pr(X = ) =

f3(x)dx

H2

l2

= H2  1 e-xdx.

2l2 xH2 2

l2

32

To summarize, under the flat-world model, the distribution of distance is

  e-x

f (x)

=



1 2

(

+

H1  xl2

+

H1 x2l2

)e-x

(1 H1
2 xl2

+

H2 xl2

+

H1 x2l2

)e-x

Pr(X = ) = H2  1 e-xdx. 2l2 xH2 2
l2

x

<

H1 l2

H1 l2

x<

H2 l2

H2 l2

x

We can double check that

 0

f (x)dx

=

1

-

Pr(X

=

):



f (x)dx

0

=

H1
l2 e-xdx +

H2 l2

1 (

+

H1

+

H1 )e-xdx

0

2H1
l2

xl2 x2l2

+  1 ( H1 + H2 + H1 )e-xdx

2H2 xl2
l2

xl2 x2l2

1 =

H1 l2

e-xdx

+

1


(

H1



+

H1

)e-xdx

20

2 H1 xl2 l2

x2l2

1 +

H2 l2

e-xdx

+

1

 H2 e-xdx

20

2 H2 xl2 l2

=

-

1 2

e-x

H1
| l2
x=0

-

H2 2xl2

e-x| x=

H1 l2

+


e-x(-

H1

)dx +

H1 2x2l2

 H1 e-xdx H1 2x2l2

2l2 2l2

-

1 2

e |-x

H2 l2

x=0

-

H2 2xl2

e-x| x=

H2 2l2

+


e-x(-

H2

)dx

H2 2x2l2

2l2

=

-

1

(e-

H1 l2

- 1) +

1

(e-

H1 l2

- 0)

22

-

1

(e-

H2 l2

- 1) +

1

(e-

H2 l2

- 0) -

 H2 e-xdx

22

H1 2x2l2

2l2

= 1 -  H2 e-xdx H1 2x2l2
2l2

= 1 - Pr(X = )

Evidence for flat-earth model:

33

Figure 1.14: log(range+1) for images from "Brown Range Image Database"
We use "Brown Range Image Database" to test whether the flat-earth model is a better fit to the real world. This database contains 197 range images collected by Ann Lee and Jinggang Huang. Some preliminary analysis on these images were presented in [20]. The images have been collected with a laser range-finder with a rotating mirror (3D imaging sensor LMS-Z210 by Riegl). Each image contains 444x1440 measurements with an angular separation of 0.18 deg. The field of view is thus 80 degrees vertically and 259 degrees horizontally. Each measurement is calculated from the time of flight of the laser beam. The operational range of the sensor is typically 2-200m. The laser wavelength of the range-finder is 0.9 mu m, which is in the near infra-red region. The data set consists of images which can be categorized as "forest", "residential", and "interior" scenes. We use all twenty-five images categorized as forest. Fig-1.14 shows these twenty-five images.
34

Figure 1.15:

The image matrices in this database were created uniformly in angle, and the

range is the actual distance , instead of the x-distance. In order to test the flat-

earth model with this data, we need to re-derive the distribution, this time for 

rather than x. Here, we only consider the upper half of these images, so that there is

no ground effect. Since the field of view of the whole image is 80 degrees vertically,

that of the upper half is 40 degrees. Then, in Fig-1.15, the angle of AOB is 40.

Let 1 = the length of OA and 2 be that of OC. Ignoring the occlusion effect, the

ratio of the expected area in the image film coming from distance /rho2 to that from

distance /rho1 is the ratio of the angle of COD to that of AOB. Since the angle of

COD

is

arcsin( H ), 0C

the

ratio

is

arcsin( H )
.0C
40

When

  1

=

H sin(40

)

,

the

expected

area

coming from distance  is a constant. In other words, the ratio to that from distance

35

1 is 1. Along with the occlusion effect e-, we have the new density function f as



 e-

f ()





earcsin(

H 

)

-

40

if





H sin(40 )

if



>

H sin(40 )

 arcsin(min(sin(40), H )) · e-. 

In the 3D-world model, the expected area coming from any distance  should be

a constant if the occlusion effect is ignored. With the occlusion effect, we have

f3D() = e- for any .

Note

that,

when



is

large,

arcsin

H 



H 

.

Therefore,

f ()



e- 

for

large

.

We calculate the empirical distribution of the distance of objects from these range

images. The result is presented in Figure-1.16. There are very few objects placed

near the camera. When  < 3.2 (meters), the number of objects decreases as 

approaches to zero. This contradicts to both the density function derived from the

flat-world model and that from the 3D-world model. However, this observation is

not surprising since objects near the camera are very likely avoided when pictures

are taken. In addition, we also found that the curve has two shapes with a break

point at around  = 20. The curve decreases with a faster rate for  > 20. This

observation is expected for the flat-world model, as the density function has different

forms for r



H sin(40 )

and

r

>

H sin(40

)

.

However,

this observation

is

not

expected

for

the 3D-world model.

In the following, we fit the curve in Figure-1.16 using the 3D-world model and

the flat-world model, respectively. As objects near the camera are very likely avoided

when pictures are taken, we only use the part of the data where  > 10. As shown

in Figure-1.17, the dotted line is the fitted curve using the 3D-world model, and

the dashed line is the one using the flat-world model. For the 3D-world model, the

conditional density function is

f3D() = e-(-10), 36

Figure 1.16: (a) the distribution of the distance of objects. (b) the log distribution of the distance of objects
37

Figure 1.17: Solid curve: the empirical conditional density function. Dotted curve: the fitted curve to the 3D-world model. Dashed curve: the fitted curve to the flatworld model. (a) original scale (b) logarithm scale in y-axes (c) original scale restricted to the domain 16 <  < 30 (d) logarithm scale in y-axis, and the domain restricted to 16 <  < 30 (e) original scale restricted to the domain 30 <  < 60 (f) logarithm scale in y-axis, and the domain restricted to 30 <  < 60 .
38

and the maximum likelihood estimate is ^ is 0.112. For the flat-world model, the conditional density function is

f () = c · arcsin(min(sin(40), H )) · e-, 

and the maximum likelihood estimates are H^ =13.50 and ^ = 0.099. Figure 1.17

shows that, the dashed curve fitted by the flat-world model not only is closer to the

empirical

curve,

but

also

capture

its

shape

(a

break

point

around

h sin(40 )



21).

Note:

The flat-earth model should have a better fit since it has one more parameter than

the 3D-world model does.

From the flat-earth model to the 1/r3 rule: 1/r3 rule says that, the density function of the size of objects in an invariant image
is proportional to 1/r3. Instead of calculating the expected numbers of objects with size r, it is easier to calculate the expected total area of objects with size r. Let g(r) be the density function of objects with size r. For simplicity, we define the object size r as the square root of the object area. If
g(r)  1/r3,

we have

b 2b
r2g(r)dr = r2g(r)dr,
a 2a

for any 0 < a < b. Furthermore, the converse is also ture. That is, statements in the

following are equivalent.

1. The size of objects follows 1/r3 rule.

2. The total area of objects with sizes between a and b is the same as that between 2a and 2b
In the following, we will show that (2) is asymptotically true under our flat-earth

39

model.

First, we assume that all physical objects in the 3-D world are of the same size,

say, 1. (This will be generalized shortly.) Recall that we define object size as the

square root of object area. Therefore, all physical objects of size 1 means all their

area

in

3-D

world

is

1.

An

object

from

distance

x

has

area

1 x2

in

the

image.

Then

its

size

r

in

the

image

is

1 x

.

Recall

that

the

density

function

of

the

distance

to

objects

is

  4l1l2e-x

f1(x)





2l1

(

H1 x

+

l2)e-x

2l1

H1

+H2 x

e-x

x

<

H1 l2

H1 l2

x

<

H2 l2

H2 l2

x

.

Note

that

x



H2 l2

is

equivalent

to

r



.l2
H2

Therefore,

if

a

<b



,l2
H2

the

total

area

of

objects with sizes between a and b is

N (a, b, ) =

b
f1(x)dx = C ·
a

b 1 e-xdx. ax

Similarly,

if

2a

<

2b



,l2
H2

N (2a, 2b, ) =

2b
f1(x)dx = C ·
2a

2b 1 e-xdx. 2a x

Since e-x  1 when  is small enough, we expect that N (a, b, )  N (2a, 2b, )

when



is

small

enough.

Precisely,

when

0

<

a

<

b



,l2
2H2

for

any

> 0, there exists

0 > 0, such that e-2b > 1 - for all  < 0. Therefore, we have

b b (1 - ) · C · dx < N (a, b, ) < C · dx
ax ax

2b 

2b 

(1 - ) · C ·

dx < N (2a, 2b, ) < C ·

dx.

2a x

2a x

Along with the fact

b  2b 

dx =

dx,

ax

2a x

40

we have

N (a, b, )

1

1- <

<.

N (2a, 2b, ) 1 -

That is,

N (a, b, ) lim = 1. 0 N (2a, 2b, )

Now, instead of assuming that all physical objects in 3-D are of size 1, we assume

all are of size m.

In

this

case,

an

object

from

distance

x

is

of

size

r

=

m x

in

the

image.

Hence,

the

condition

x



H2 l2

is

now

equivalent

to

r



.l2 ·m
H2

We

can

run

all

the

arguments

again,

and

obtain

a

similar

result

as

follows.

For

any

0

<

a

<

b



,l2 ·m
2H2

N (a, b, ) lim = 1. 0 N (2a, 2b, )

In general, assume that physical objects have sizes from a fixed distribution, and the minimal size is m0. Then we prove the following Theorem.

Theorem

1.1

For

any

0<a<b

,l2 ·m0
2H2

N (a, b, ) lim = 1 0 N (2a, 2b, )

Proof: For each size m, recall that

b b

(1 - ) · C · dx ax

< Nm(a, b, ) <

C · dx ax

2b 

2b 

(1 - ) · C ·

2a

dx x

< Nm(2a, 2b, ) <

C·

2a

dx. x

Since these inequalities are true for all m, we can integrate out m, and have

b b (1 - ) · C · dx < N (a, b, ) < C · dx
ax ax

2b 

2b 

(1 - ) · C ·

dx < N (2a, 2b, ) < C ·

dx.

2a x

2a x

41

Therefore,

N (a, b, )

1

1- <

<

N (2a, 2b, ) 1 -

when

0

<

a

<

b



l2 ·m 2H2

for

all

m.

And

this

condition

is

equivalent

to

0

<

a

<

b



l2·m0 2H2

2

Remark:

This

limit

is

1 2

for

3D-world

model.

1.4 The scale invariance of local statistics
In this section, we explain the scale invariance of local statistics in natural images. We first explain it using 1/r3 rule, which was established based on the projection effect in the previous section. Then we find evidence showing that the projection effect might not be the key reason for natural images to scale well. Therefore, we proceed with proposing a new model. This new model provides three effects to explain the property of scale invariance. We also claim that, even though the projection effect may not be a major factor, it still plays a role in improving the property of scale invariance.

1.4.1 Explanation by the projection effect
In the previous section, we built up a model, and explained that 1/r3 rule is asymptotically true as  approaches zero. In this model, the distance distribution based on the projection effect is the key that 1/r3 rule holds. Naturally, we want to investigate whether this model can also explain the scale invariance of local statistics in natural images.
In Ruderman [4], objects with random shapes and sizes are randomly placed in an infinite image plane, and each object is independently painted with a gray tone chosen from a distribution. It was argued that if these objects have a power-law distribution of sizes, images of the plane also follow a power law, which is related to scale invariance. Therefore, in the point of view of power-spectrum, the projection
42

effect can also be applied to explain scale invariance property. In the following, we explain scale invariance in the point of view of another defi-
nition: marginal distribution stays the same after scaling. Suppose that S is a local statistic (or filter). Let h(s) be the density function of S of the original image I, h(k)(s) be that of the scaled image I(k), f (x) be the density function of the x-distance described in previous section, and h(s|x) be the density function of S conditional on the x-distance x. Then

h(k)(s) = h(k)(s|x)f (x)dx x dx
= h(s|x )f ( ) kk dx
 h(s|x )kf (x ) k
= h(s|x )f (x )dx
= h(s).

(x = kx) c
(f (x)  ) x

Therefore,

based

on

f (x)



c x

derived

from

the

projection

effect,

h(k)(s)



h(s),

which

represents scale invariance.

1.4.2 Evidence
In the previous subsection, we explained scale invariance of local statistics based on the distance distribution derived from the projection effect. However, we do not know whether this is the key factor to the scale invariance of local statistics. In the following, we will present some kinds of images which do not involve distances still have good scale invariance property. Therefore, the distance effect may not be the main reason that images have good scale invariance. Texture images
To question whether the distance effect is the key factor to cause scale invariance, we explore features in images without the distance effect, and observe whether they
43

Figure 1.18: Logarithms of marginal distribution of x for texture images. Solid curve: xI, dashed curve: xI(2), and dotted curve: xI(4).
44

still scale well. For this purpose, we collect fourteen texture images from the internet. We choose S = x. The result is presented in Figure-1.18, where solid curves
represent xI, dashed curves represent xI(2), and dotted curves represent xI(4). Figure-1.18 shows that many texture images have good scale invariance property. Moreover, since these texture images do not involve the distance to the lens, this suggests that images without the distance effect can have scale invariance property. Strips of images
In addition to images without the distance effect, we take horizontal strips out of an image, so that all distances of all pixels in a strip represent objects located at nearly the same distances to the lens.
Among nine pictures in Figure-1.1, we choose picture-2 and take horizontal strips. We take one from row 501 to row 600, and another from row 541 to row 550. Here S is chosen to be xI, and the result is presented in Figure-1.19. This figure shows that strips of an image have even better scale invariance. The variation of x-distances to the lens is much smaller in strip images than that in the whole image. In strip images, the distance effect discussed in previous section do not provide a good explanation for the scale invariance. Therefore, this suggests that the distance effect may not be the key factor of scale invariance. Simulated image from LOCO predictor
LOCO (LOw COmplexity LOssless COmpression) is currently the best lossless compression algorithm. In short, it predicts a pixel value according to the past information, and it codes the residue, which is the difference between the prediction and the real value. The predictor is the median of I(i - 1, j), I(i, j - 1), and I(i - 1, j) + I(i, j - 1) - I(i - 1, j - 1), and the residue distribution is two-sided geometric distribution. The density function of TSGD(p) is

p q|x|-1 2-p

x = . . . , -2, -1, 0, 1, 2, . . . ,

where p = 1 - q. The LOCO algorithm implicitly defines a distribution on images,

45

Figure 1.19: Picture-2 from Figure-1.1, and strips from it. Histograms are logarithms of marginal distributions of x. Solid curve: xI, dashed curve: xI(2), and dotted curve: xI(4).
46

Figure 1.20: Logarithms of marginal distributions of x for simulated image from LOCO predictor. Solid curve: xI, dashed curve: xI(2), and dotted curve: xI(4).
47

from which we can simulate. We did this, and then experiment scale invariance in the simulated images.
The simulation procedure is as follows. For each pixel (i, j), we make a prediction as median(I(i - 1, j), I(i, j - 1), I(i - 1, j) + I(i, j - 1) - I(i - 1, j - 1)). Then the pixel value is this prediction plus a noise from TSGD(0.2). We also truncate the pixel value so that it falls on [0, 255]. The simulation result is presented in Figure-1.20. It shows that xI and xI(2) are very close, while xI(4) is a little far from them.
This simulated LOCO image has nothing to do with the distance to the lens. However, we still observe good scale invariance. Again, this suggests that images without the distance effect can have scale invariance property .

1.4.3 Proposal

In the following, we will discuss on effects which we deem important in the scale

invariance of local statistics.

Noise effect:

For a texture image composed of independent Gaussian noise only, the absolute

value of the derivatives will become smaller when we scale down the image. For ex-

ample, suppose I(i, j) are i.i.d. random variables from N (µ, 2), then the distribution

of xI is N (0, 22). By the definition, I(k)(i, j) are the average of k2 i.i.d. N (µ, 2),

which

is

N

(µ,

2 k2

).

Therefore,

the

distribution

of

x I k

is

N

(0,

2

2 k2

).

Since

2 2 k2

<

22,

we conclude that x of the scaled image I(k) is pointier than x of the original image.

Figure-1.21 presents such an experiment result. Let I(i, j) be i.i.d. N (128, 900).

S = x. We round off I(i, j) to be integers, and truncate them to [0,255]. As expected, Figure-1.21 shows that xI(4) is pointier than xI(2) and xI at 0. This demonstrates that images of independent Gaussian noises do not have scale invariance.

Next, we examine the Cauchy distribution. Cauchy distribution is a special dis-

tribution that may present scale invariance. The density function of Cauchy(, )

48

Figure 1.21: Logarithms of marginal distribution of x for a simulated image from N(128, 900). Solid curve:xI, dashed curve: xI(2), and dotted curve: xI(4).

is

11



·

1

+

(

x- 

)2

-  < x < ,

and its characteristic function

is

(t) = eit-|t|.

Since

(

t n

)n

=

(t),

the

average

of

any i.i.d. random variables from Cauchy(, ) is still Cauchy(, ). Therefore, if

I(i, j)'s follow i.i.d. Cauchy(, ) distribution, then I(k)(i, j)'s again follow Cauchy(,

) distribution. In other words, an image composed of i.i.d. Cauchy noises should

have perfect scale invariance property. However, the key reason for the invariant

distribution of the averaged Cauchy lies in its heavy tail property. This heavy tail

property does not exist in any image with bounded gray level values.

Figure-1.22 shows the result of our experiments in Cauchy noises. The first ex-

periment uses Cauchy(30,128), and the second one uses Cauchy(3,128). We round off

both experiments into integers, and truncate them to [0,255]. Figure-1.22 shows that

neither of the Cauchy distributions has scale invariance property.

In fact, for any bounded random variable, the Law of Large Numbers shows that

the average of such random variables converges to a constant as the number of random

variables tends to infinity. According to this fact, we therefore conclude the following:

49

Figure 1.22: Logarithms of marginal distribution of x for simulated images from Cauchy distributions. Solid curve: xI, dashed curve: xI(2), and dotted curve: x I (4) .
under the setup of finite gray levels, images composed of only i.i.d. noises do not have scale invariance property.
Another interesting noise is the two-sided geometric distribution. Figure-1.23 demonstrates an experiment for TSGD(0.1)+128. As expected, it does not present scale invariance property. However, comparing to the result of Gaussian noise in Figure-1.21, Figure-1.23 presents shapes closer to results from real images.
We experiment the noise effect by adding i.i.d. random variables from two-sided geometric distributions to a texture image. The result is presented in Figure-1.24. In
50

Figure 1.23: Logarithms of marginal distribution of x for a simulated image from TSGD(0.1). Solid curve: xI, dashed curve: xI(2), and dotted curve: xI(4).
the original image, the absolute values of the derivatives become larger after scaling. After adding noises TSGD(0.1), the image shows good scale invariance property. If adding larger noise TSGD(0.05), it shows that the absolute value of the derivatives are smaller after scaling. Therefore, adding proper noises can help in constructing an image with good scale invariance property. Ramp effect:
For Ramp effect, we mean that the intensity of a texture image is a linear (with respect to the location) without any noise. When scaling down the image, the absolute value of the derivative becomes larger. For example, if xI = s, then xI(k) = ks. Boundary effect:
In addition to the noise effect and the ramp effect, boundary may also play an important role to scale invariance. For simplicity, we assume that all boundaries are vertical lines and gray level values are constant within each region divided by boundaries. Look at any row of the image2, a boundary would fall in a pixel or between two pixels 3. In the following, we use the word "pair" to denote any two
2With these assumptions, the whole image is the same as any single row in some sense. 3One may think that a boundary should always fall between two pixels. However, this is not
51

Figure 1.24: Logarithms of marginal distribution of x for an texture image and that image with TSGD noises. Solid curve: xI, dashed curve: xI(2), and dotted curve: x I (4) .
52

adjacent pixels. Now we only consider pairs that there is a boundary passing through one of the pixels. For each such pair, we calculate x. Similarly, we calculate x for the scaled image. Because boundaries appear uniformly within each pair for both the original and the scaled image, we conclude that x of the original image and x of the scaled image are the same. Therefore, if we only look at those pixels involving boundaries, we have a perfect scale invariance of local statistics. However, there are more pixels involving boundaries in the scaled image than in the original image. Along with the fact that the absolute values of the derivatives involved boundaries are larger, boundaries increase the absolute values of the derivatives when we scale down an image. Proposal:
From the discussion above, we summarize our findings in the following. After we scale down an image, The noise effect lower the absolute values of the derivatives, while the ramp effect and the boundary effect increase them.
We claim that a texture image with good scale invariance is the one balancing the noise effect and the ramp effect. In a texture image, where there is no prominent boundary, xI can be roughly decomposed into X + Y , where X is the ramp effect, and Y is the noise effect. In the scaled image I(k), the ramp effect becomes kX, and the noise effect becomes the average of k2 i.i.d. Y . For example, if Y  N (0, 2), then Y  N (0, 2/k2). Since Y /k  N (0, 2/k2), Y has the distribution as Y /k. In this case, xI(k) = kX + Y /k. The image I will have good scale invariance if X + Y  kX + Y /k.
Assume that the ramp effect X is TSGD(1) and the noise effect Y is TSGD(2). We choose different pairs of (1, 2) and compare X + Y and kX + Y /k. The result of the experiment with (1 = 0.2, 2 = 0.1) is presented in Figure-1.25. It shows
true. A pixel represents a block, and the gray level value of that pixel is an average of that block. A boundary should fall uniformly in any location of any block. The probability that a boundary fall right between two pixels is zero.
53

Figure 1.25: Logarithms of marginal distribution of x for simulations by mixing the ramp effect TSGD(0.2) and the noise effect TSGD(0.1). Solid curve: xI, dashed curve: xI(2), and dotted curve: xI(4).
that with a proper combination of both effects, we get texture images which scale very well. In Figure-1.25, xI is very close to xI(2), but xI(4) is far from them. The reason that the absolute value of xI(4) is larger is that the ramp effect of I(4) is overrated. When it is calculated, we assume a local linear plane. Therefore, we have the ramp effect of I(k) is k times of that of I. However, when k becomes larger, the assumption of a linear plane may not be true. The ramp effect of I(k) should be smaller than k times of that of I.
As discussed earlier, Figure-1.24 also shows that, a proper combination of the noise effect and the ramp effect gives us texture images which scale very well .
We claim that an image with good scale invariance is the image which balances the noise, the ramp and the boundary effects. We experiment with adding noises to natural images. Since the noise effect will lower the absolute value of the derivative, we choose one image of which the absolute value of the derivative is larger after scaling. Among nine natural images we used earlier, we chose the one in Figure1.8 for experiment. With the same reason we mentioned earlier in our experiment regarding to object size, we use the logarithm of the image, instead of the original
54

Figure 1.26: An image which does not scale well can have a good scale invariance by adding a proper noise. Solid curve: Logarithms of marginal distribution of xI, dashed curve: xI(2), and dotted curve: xI(4).
55

image. The result is presented in Figure-1.26. We take the logarithm of the image, and
modify the pixel values to be integers within [0, 255]. Then we add three different noises TSGD(0.1), TSGD(0.8) and TSGD(0.05) into the image, respectively. Figure1.26 shows that the image mixed with TSGD(0.08) has good scale invariance, suggesting that with a proper combination of the noise, the ramp and the boundary effects, images can have good scale invariance property.

1.4.4 Distance effect

In previous subsections, we gave an explanation of the property of scale invariance

based on the distance effect. We also found evidences that the distance effect may

not be the key factor in the scale invariance of local statistics. In this subsection, we

simulate x from texture images mixed with the distance effect, in order to investigate how the distance effect affect scale invariance.

Our simulation proceeds as follows. Randomly pick a location from the texture

image and a distance r. Imagine that the texture image is placed at distance r, and

calculate x. For convenience, r  {1, 2, 3, 4, 5}. Figure-1.27 presents our simulation

result.

In

(b),

the

density

function

of

the

distance

is

c·

1 r

,

where

c

is

a

normalization

constant. In (c), the density function is from the range data. Figure-1.27 shows that

the distance effect helps produce a better scale invariance.

1.4.5 Conclusion
We can explain the property of scale invariance of local statistics using the following two models. The first model is based on the distance distribution derived from the projection effect. In previous sections, we have shown that the property of scale invariance can be explained by this projection effect. However, there is no strong evidence to support that the projection effect is the main cause of the property of

56

Figure 1.27: (a) x to the real image. (b) x to the simulation mixed with distance effect 1/r. (c) x to the simulation mixed with the distance effect from range data. Solid curve: xI, dashed curve: xI(2), and dotted curve: xI(4).
scale invariance. Moreover, there are images, such as texture images, which do not involve the distance, but still have good scale invariance property.
The second model is based on the noise effect, the ramp effect, and the boundary effect. In previous sections, we have also shown that the property of scale invariance can be explained by a proper combination of these three effects. However, again there is no strong evidence to support that these three effects are the main cause of the property of scale invariance. We can construct an image with good scale invariance by a proper combination of these three effects, but we are not able to claim that
57

any image with good scale invariance property must have such a proper combination. There is also no explanation why such a proper combination would exist in natural images.
We also explored to understand what types of images are more likely to have better scale invariance property. We observed that images that have more features tend to have better scale invariance. In other words, more textures and boundaries provide images with a better chance to scale well. Assume that all images can be decomposed into different features, and the effect of each feature on scale invariance is roughly additive. Let X be the effect of a feature on scale invariance. Suppose that X = 0 represents perfect scale invariance, and the large |X| represents poor scale invariance. Let µ be the mean of X. If µ = 0, the Law of Large Number shows that the average goes to 0 when the number of random variables goes to . While there is no reason that µ should be 0, |µ| is probably small as many natural images have good scale invariance. The Central Limit Theorem tells that, the larger the sample size is, the smaller variance the average of the random variables has. Therefore, we know that the variance of the effect of images with more features is smaller. Along with the assumption that |µ| is small, this explains why images having more features tend to scale better.
Our work so far still can not explain why ensemble images have good scale invariance property. However, our work has shown that, either the distance effect or a proper combination of the noise effect, the ramp effect and the boundary effect can improve the scale invariance property. As a result, we suggest that a combination of both models as described above may be the best explanation to the cause of the property of scale invariance.
In the end of this section, we summarize the reasons why natural images have the property of scale invariance.
1. There are three effects in natural images that are important factors to the property of scale invariance. These three effects are the noise effect, the ramp
58

effect and the boundary effect. Images with proper combinations of these three effects can show good scale invariance property. 2. Images with more features tend to have better scale invariance. This phenomenon can be well explained by the Central Limit Theorem. 3. The distance to the lens is also an important factor to scale invariance. An image that does not have good scale invariance can scale better after the distance effect is involved. Natural images usually have the distance effect, therefore usually show better scale invariance property.
59

Bibliography
[1] Z. Chi. Probability Models for Complex System: Chapter 7. Scale Invariance of Natural Images. Ph.D. Thesis, Brown University, 1999.
[2] D. L. Ruderman. The statistics of natural images Computation in Neural Systems 5(4), November 1994, pp. 517-548.
[3] D. L. Ruderman and W. Bialek. Statistics of natural images: Scaling in the woods. Physical Review Letters, 1994, pp. 814-817.
[4] D. L. Ruderman. Origins of Scaling in Natural Images. Vision Research, 37(23), 1997, pp. 3385-3398.
[5] D. Mumford and Basilis Gidas. Stochastic Models for Generic Images. Quarterly Appl. Math, 59, 2001, pp.85-111.
[6] Rosario M. Balboa, Christopher W. Tyler, Norberto M. Grzywacz. Occlusions contribute to scaling in natural images. Vision Research 41, 2001, pp.966-964.
[7] Ann B. Lee, David Mumford and Jinggan Huang. Occlusion Model for Natural Images: A statistical Study of a Scale-Invariant Dead Leaves Model. International Journal of Computer Vision 41(1/2), 2001, pp.35-39.
[8] M G A Thomson. Beats, kurtosis and visual coding. Computation in Neural Systems 12(3), Aug 2001, pp.271-287
60

[9] Ulf Grenander and Anuj Srivastava. Probability Models for Clutter in Natural Images. IEEE Transactions on Pattern Analysis and Machine Intellegence 23(4), APRIL 2001, pp.424-429
[10] Anuj Srivastava, Xiuwen Liu and Ulf Grenander. Universal Analytical Forms for Modeling Image Probabilities APPTS Report #01-4, Novermber 2001
[11] A. Turiel and N. Parga. The multifractal structure of contrast changes in natural images: From sharp edges to textures. Neural Computation 12(4), APR 2000, pp.763-793.
[12] A. Turiel, N. Parga, D. L. Ruderman and T. W. Cronin. Multiscaling and information content of natural color images. Physical Review E. 62(1), jul 2000, pp.1138-1148.
[13] D. J. Field. Relations between the statistics of natural images and the response properties of cortical cells. Journal of The Optical Society of America A, 4(12), Dec 1987, pp.2379-2394.
[14] D. J. Field. What is the Goal of Sensory Coding? Neural Computation 6(4), Jul 1994, pp.559-601.
[15] B. A. Olshausen and D. J. Field. Natural image statistics and efficient coding. Computation in Neural Systems 7(2), May 1996, p.333-339.
[16] G. J. Burton and Ian R. Moorhead. Color and spatial structure in natural scenes. Applied Optics 26(1), Jan 1987, pp.157-170
[17] J. H. van Hateren. A theory of maximizing sensory information. Biological Cybernetics 68, 1992, pp.23-29.
[18] J.H. van Hateren and A. van der Schaaf. Independent component filters of natural images compared with simple cells in primary visual cortex. Proc.R.Soc.Lond. B 265, 1998, pp. 359-366.
61

[19] L. Alvarez et J.-M. Morel. The size of objects in natural images. preprint du CMLA 9921, 1999.
[20] Ann B. Lee, Kim S. Pedersen and David Mumford. The Nonlinear Statistics of High-Contrast Patches in Natural Images. APPTS Report #01-3, June 2001
62

Chapter 2 On the Use of of Natural Image Statistics for Compression
63

2.1 Introduction
The goal of image compression is to create smaller files that use less space to store and less time to send. There are two types of compression: lossless and lossy. In lossless compression, the original image can be decompressed perfectly. In lossy compression, it allows for errors between the decompressed image and the original image. It sacrifices some details in the image to achieve significant gains in the compression ratio. However, in some critical applications (for example, military observation and medical imaging), any loss may not be tolerated. In this paper, we focus on lossless image compression.
To do lossless image compression, we need a good model. Most of the lossless image compression methods code images pixel by pixel in a pre-defined order, which is usually the raster-scan order (from left to right, and top to bottom). At each time t + 1, past information xt1 = x1x2 · · · xt are observed. Ideally, the best one can do is to code the next pixel xt+1 with - log Pr(xt+1|x1t )1 bits, where the logarithm here and later on is taken to the base 2. But practically, it is hard to model Pr(xt+1|xt1), since the dimension of xt1 is too large. Instead, many good lossless image compression methods make a prediction x^t+1 based on the past information x1t , then code the residual xt+1-x^t+1. Both LOCO (LOw COmplexity LOssless COmpression) [1][2] and CALIC (Context based Adaptive Lossless Image Codec) [3] [4] adopt this approach.
JPEG-LS, based on the LOCO algorithm, is the new lossless/near-lossless compression standard for continuous-tone images, ISO-14495-1/ITU-T.87. The LOCO prediction of a pixel is only based on its three neighboring pixels. In Figure-2.1, x is the pixel to predict, and the prediction is only based on a, b, and c. When c is between a and b, x is predicted by fitting a linear plane on a, b, and c. Therefore, x^ = a + b - c. When c is larger than both a and b, LOCO believes that there is an edge and predicts x^ = min(a, b). Similarly, x^ = max(a, b) when c < min(a, b).
1We use Pr(xt+1|x1t ) to denote Pr(Xt+1 = xt+1|X1t = xt1)
64

Figure 2.1: LOCO predictor

Equation-(2.1) gives the LOCO predictor:

  min(a, b)

x^LOCO

=



max(a, b) a+b-c

if c  max(a, b) if c  min(a, b). otherwise.

This equation can also be rewritten as

(2.1)

x^LOCO = median(a, b, a + b - c).
After predicting x as x^, LOCO codes the residual x - x^ by a two-sided geometric distribution (TSGD). It is a widely accepted observation that prediction residuals in continuous-tone images are well modelled by TSGD [5]. LOCO determines the context where x occurs according to its four neighboring pixels, a, b, c and d. They calculate (d - b, b - c, c - a), and classify these triples into 365 different contexts. In each context, a TSGD is estimated to model the residuals.
To summarize, LOCO compression scheme is as follows:
1. predict xt+1 according to past information xt1.
2. code the residual xt+1 - x^t+1 with different distributions depending on the type of past pixels.
65

In addition, LOCO uses several more steps to improve this scheme. For example, an adaptive correction according to the past prediction errors. In this paper, we will discuss why the scheme which makes predictions then sends residuals works well. Specifically, why is predicting then sending the residual a good approximation to Pr(xt+1|xt1)? We will also work on how to construct a good prediction according to the past information.
2.2 Definitions and Assumptions
In this section, we will discuss the general reasoning behind LOCO. We will also introduce some definitions and assumptions which will be used in the following sections.
As mentioned in the previous section, an ideal compression is to code xt+1 with - log Pr(xt+1|xt1) bits. Equivalently, the expected bits per pixel is H(Xt+1|X1t), where H denotes the entropy function. Let g be any prediction function of Xt+1 according to X1t. Since g(X1t)|X1t is deterministic, then
H(Xt+1|X1t) = H(Xt+1 - g(X1t)|X1t).
Therefore, the scheme to make predictions and to code the residuals has the same entropy as to code the actual Xt+1. From this observation, this scheme does not have any advantage.
In practice, it is impossible to code Xt+1 or Xt+1 - g(X1t) according to X1t, since we need the distribution on Xt+1 or Xt+1 - g(X1t) for every X1t. For example, to compress gray level images with intensities from 0 to 255, |range of X1t| = 256t. Even when t = 3, the range is too large. A realistic way is to introduce a function h, and to use Xt+1|h(X1t) to approximate Xt+1|X1t, where
1 < |range of h(X1t)| << |range of X1t|.
66

The function h here is usually referred as "context", as the distribution of Xt+1|X1t tends to be similar under the same context. For example, LOCO determines h according to (a - c, c - b, b - d). There are 365 contexts in LOCO. After introducing h,
H(Xt+1|h(X1t)) = H(Xt+1 - g(X1t)|h(X1t)).
Therefore, a good prediction function g is to make

H(Xt+1 - g(X1t)|h(X1t))
as small as possible. Note that as h becomes more fine-grained, the efficiency of this scheme approaches optimal for any predictor g, since

H(Xt+1 - g(X1t)|h(X1t))  H(Xt+1 - g(X1t)|X1t)

as h becomes arbitrarily fine.

More

generally,

given

X



R,

- Y



Rm,

we

study

how

to

choose

a

predictor,

f : Rm  R, to minimize

- H(X - f ( Y )).

Before deriving this "optimal"2 predictor, we will first give some necessary definitions -
and assumptions. In the following, we will assume that X and Y have joint density

- p(X, Y )

and conditional density -
for each X and Y .

- p(X| Y )

2in

the

sense

of

minimizing

H (X

-

- f (Y ))

67

Definition

2.1

A

distribution

P(X,

- Y)

on

Rm+1

is

conditionally

symmetric

and

unimodal (CSUM) if

p(x|-y )

is symmetric and unimodal in x for every -y .

Definition

2.2

A

distribution

P(X,

- Y)

on

Rm+1

is

shift

invariant

(SI)

if

p(x + s|-y + s) = p(x|-y )

for every (x, -y )  Rm+1, s  R (where here, and later, a vector plus a scaler is interpreted component by component).

CSUM is often observed in natural images. In fact, it is a widely accepted observation that prediction residuals in continuous-tone images are well modelled by TSGD [5]. The density function of TSGD(p) is

p q|x|-1 2-p

x = . . . , -2, -1, 0, 1, 2, . . . ,

where p = 1 - q. It is symmetric and unimodal. Therefore, the distribution of prediction residuals is CSUM.
SI is also widely observed in natural images, especially if work with the log of intensity. For examples, the logarithm of the light intensity is approximately SI.

2.3 Minimizing Residual Entropy
Our goal is to choose g(X1t) to minimize H((Xt+1 - g(X1t))|h(X1t)).

68

- On more general terms, we want to choose f ( Y ) to minimize
- H(X - f ( Y ))

for two random variables (x, -y )  Rm+1. Motivated by the statistics and properties of natural images mentioned above, we will prove the following:
- Theorem 2.3 If P (X, Y ) is CSUM, then

f

(-y )



median(X

- |Y

=

-y )

achieves

- min H(X - f ( Y )).

- Before we prove this theorem, we make the following observations. X - f ( Y ) is

a

mixture

of

(X

- - - f ( Y ))| Y

=

-y .

Since

- (X, Y )

is

CSUM,

and

since

(X - f (-Y ))|-y = X|-y - f (-y ),

(X - f (-Y ))|-y is symmetric and unimodal with median at median(X|-y - f (-y ). If

f

(-y )

=

median(X

- |Y

=

-y ),

the median of each conditional distribution is 0. Therefore, to prove this theorem, it suffices to show that the entropy of the mixture of a family of symmetric and unimodal distributions is minimized if their peaks are at the same position. We will first prove a discrete and finite version of the above statement in the following lemma, and we will generalize it to the continuous case later.
Lemma 2.4 Suppose {pi,j} is a positive measure (pi,j  0) defined on [-N, N ] ×

69

[-n, n]. And p·,j is unimodal and symmetric with median at 0. Let

qi = ri =

pi,j
j
pi+g(j),j
j

where g is any function mapping from Z onto Z. Then

H({qi})  H({ri}),

where

1 H({qi})  i (log qi ) · qi.

Note that {qi} and {ri} may not be probability measures. Therefore, we extend the domain of entropy function H by giving the same definition on positive measures.
For convenience, we will prove the case that {pi,j} is a probability measure. The proof for the case that {pi,j} is a positive measure is exactly the same. To prove Lemma 2.4, we will begin with another two lemmas. The first one in the following is very intuitive: If we move some probability from a state to another state with higher

probability, we lower the entropy.

Lemma 2.5 Let {pi} be a probability distribution. Define another probability distribution {qi} by q1 = p1 + s, q2 = p2 - s, qi = pi i =1, 2. If p1  p2 and 0 < s < p2, then
H({qi}) < H({pi}).

Proof: Since qi = pi i =1, 2, it suffices to prove

11 1 1

q1 log

q1

+ q2 log

q2

<

p1 log

p1

+ p2 log

. p2

70

Let

F (s)

=

(p1

+ s) log

1 p1+s

+ (p2

- s) log

1 p2-s

.

Then

F (s)

1

1

= log

+ log e - log

- log e

s p1 + s

p2 - s

= log p2 - s p1 + s

<0

s  (0, p2).

Hence, F (s) is decreasing for s > 0. That is

11 1 1

q1 log

q1

+ q2 log

q2

<

p1 log

p1

+ p2 log

. p2

2
In Lemma 2.4, we claim that the entropy of qi = pi,j is the smallest among
j

0 = {r = (r1, r2, · · · )|ri = pi+g(j),j for some function g}.
j
For any probability distribution r  0 which is not the same as q defined in Lemma 2.4, we attempt to apply Lemma 2.5 to create a new probability distribution with a lower entropy. However, this new probability distribution may not belong to 0. Therefore, we define a larger family of probability distributions 1  0 to make sure that the new probability distribution we create is always in 1. If |1| < , and if we can always find a new probability distribution with a lower entropy, the entropy of q is the smallest among 1. We present the above argument in the following lemma.

Lemma 2.6 Suppose {pi,j}, 1  i  N , 1  j  n, is a probability distribution with pi1,j  pi2,j whenever i1 < i2. Define 1 as a set of probability distributions by

1 = {s = (s1, · · · , sm)|s1  s2  · · ·  sm; sk = 1;
sk = pk,j,j; k1,j = k2,j whenever k1 = k2},
j

71

where k,j  {1, · · · , N, }, k,j can be  for more than one k, and p,j  0. In this setup, for any s  1, each sk is the summation of at most one element from each p·,j, and each pi,j appears in exactly one sk. Let

qi = pi,j,
j
then H(q) = min H(s).
s1
Proof: Since |1| < , it suffices to prove that s = q, there exists r such that H(r) <
H(s). Suppose that k1 < k2, pk1,j,j = pk2,j,j and k1,j > k2,j. then we will exchange the values of k1,j and k2,j. Therefore, we always have k1,j < k2,j whenever k1 < k2 and pk1,j,j = p ,k2,j,j without changing the value of each sk.
If 1,j = 1 for some j, then p1,j,j < p1,j, and then s1 < q1. Hence, if q1 = s1, we will have 1,j = 1. Now define  = min{k|qk = sk}, then we have k,j = k k <  and q > s. Since q > s, there exists j1 such that ,j1 =  and p,j1 ,j1 < p,j1. As p,j1 is not in any of sk k  , it is in some s with  > . Now, we define  as

,j1 =  ,j1 = ,j1 i,j = i,j

otherwise,

we also define another probability distribution r = (r1, · · · , rm) as

rk =

pk,j ,j .

j

72

Then we have

r = s + p,j1 - p,j1 ,j1

r = s - p,j1 + p,j1 ,j1

rj = sj

otherwise.

Since p -p,j1,j1 ,j1 < 0, by Lemma 2.5, we have H(r) < H(s). Note that r(r1, · · · , rm) may not satisfy
r1  r2  · · ·  rm.

However, we can always change the order of ri so that the condition above holds and the entropy stays unchanged. As a result, we have a new probability distribution in

1 with a lower entropy.

2

From the setup of 1, for any s  1, sk is the summation of at most one element from each p·,j. This lemma tells that, by grouping the largest pi,j in each p·,j together and grouping the second largest ones together, and so on, the entropy of the

distribution will be the smallest among all in 1. Note that p·,j in Lemma 2.6 is assumed to be decreasing, instead of unimodal and
symmetric as in Lemma 2.4. It is easier to prove Lemma 2.6 under this assumption

of decreasing p·,j. Proof of Lemma 2.4: To prove Lemma 2.4 using Lemma 2.6, we define a new distribution p on [1, 2N +

1] × [-n, -n] by

pi,j = {

pi/2,j

if i is even

p-(i-1)/2,j if i is odd.

73

That is, we rearrange p·,j in the order of 0, 1, -1, 2, -2, · · · , then pi1,j  pi2,j whenever i1 < i2. Similarly, define q as

qi = { qi/2

if i is even

q-(i-1)/2 if i is odd.

We have

qi =

pi,j .

j

From lemma 2.6, we know that the entropy of q is the smallest among all probability

distributions in 1. For any r in Lemma 2.4, rearrange r to r so that

r1  r2  · · ·  rN .

Then r is also in 1. By Lemma 2.6, we have

H(q)  H(r).

Then

H(q)  H(r).

2 In next lemma, we generalize the result of Lemma 2.4 from the finite case to the countable case.

Lemma 2.7 Suppose {pi,j} is a positive measure on Z2. And p·,j is unimodal and symmetric with 0. Let

qi = ri =

pi,j
j
pi+g(j ),j ,
j

74

where g is any function mapping from Z onto Z. Then

H({qi})  H({ri}).
Proof: Suppose there exists a r such that

H(r) < H(q) < .

Let = H(q) - H(r). Define p(n) as

p(i,nj) = { pi,j if -n  i, j  n 0 otherwise.
Define q(n) and r(n) as

Then,

qi(n) = ri(n) =

pi(,nj)
j
p(i+n)g(j),j .
j

lim H(q(n)) = H(q)
n
lim H(r(n)) = H(r).
n
From the continuity of entropy function H, there exists an N = N ( ) such that
q(n) = r(n),

75

and

Then

|H(q(N)) - H(q)| < 2
|H(r(N)) - H(r)| < . 2

H(q(N)) - H(r(N)) = (H(q(N)) - H(q)) + (H(q) - H(r)) + (H(r) - H(r(N)))
>- +- 22
= 0.

On the other hand, apply Lemma 2.4 to p(N), q(N) and r(N), we have H(q(N))  H(r(N)),

which leads to a contradiction. Therefore, there does not exist r such that

H(r) < H(q) < .

2
Proof of Theorem 2.3: As discussed earlier, it suffices to prove a continuous version of Lemma 2.4 or
Lemma 2.7. Without loss of generality, we assume that the dimension of -y is 1. The proof for a higher dimension is almost the same. Suppose p(x, y) is symmetric, unimodal with median at 0 in x for each y. Define {q(x, f )} as

q(x, f )  p(x - f (y), y)dy
y

76

where f : Rm  R. We need to show that

H({q(x, 0)})  H({q(x, f )})

for any function f . Suppose the statement above is not true, then there exists a function g such that

H({q(x, g)}) < H({q(x, 0)}) < .

Let = H({q(x, 0)}) - H({q(x, f )}). Define p(n)(x) and q(n)(x, g) as

p(n)(x)



[x · 2n] [y · 2n] p( , )

2n 2n

q(n)(x, f )  p(n)(x - f (y), y)dy,
y

where here and later, [x] denotes the nearest integer to x. Since

lim p(n)(x) = p(x),
n

then

lim q(n)(x, f ) = q(x, f ).
n

Along with the continuity of entropy function, we have

lim H({q(n)(x, f )}) = H({q(x, f )}).
n

Similarly, define f (n) as

f (n)



[f

·

2n] .

2n

Then

lim H({q(x, f (n))}) = H({q(x, f )}).
n

77

Therefore, there exist N = N (g) such that

Moreover,

|H({q(N)(x, 0)}) - H({q(x, 0)})| < 3
|H({q(N)(x, g)}) - H({q(x, g)})| < 3
|H({q(N)(x, g(N))}) - H({q(N)(x, g)})| < . 3

q(N)(x, f (N)) = = = =

p(N)(x - f (N)(y), y)dy

y

[(x - f (N)) · 2N ] [y · 2N ]

p( , )dy

y 2N

2N

y

[x · 2N ] p( 2N

-

f (N),

[y · 2N ] 2N )dy

[x p(

·

2N ]

-

f (N),

j

)·

1

2N 2N 2N

j

H({q(N)(x, f (N))}) = =

(log 1 ) · q(N)(x, f (N))dx x q(N)(x, f (N))

i

(log

1

q(N

)

(

i 2N

,

) f (N))

·

q(N)( i 2N

,

f (N))

·

1 2N

Define pi,j and qi(f (N)) as

ij 1

pi,j



p( , ) · 2N 2N 22N

qi(f (N))



q(N)( i , f (N)). 2N

78

Then

qi(f (N))

=

q(N)( i , f (N)) · 1 2N 2N

=

i p( 2N

- f (N),

j 2N ) ·

1 2N

·

1 2N

j

= pi-2N f (N),j
j

H({q(N)(x, f (N))}) =

i

(log

1

q(N

)

(

i 2N

,

) f (N))

·

q(N)( i 2N

,

f (N))

·

1 2N

=

i

(log

2N qi(f (N))

)

·

qi(f

(N

))

=

N+

i

(log

1 qi(f (N)) )

·

qi(f (N))

= N + H({qi(f (N))}).

Then

H({qi(0)}) - H({qi(g(n))}) = H({q(N)(x, 0)}) - H({q(N)(x, g(N))}) = (H({q(N)(x, 0)}) - H({q(x, 0)}))
+(H({q(x, 0)}) - H({q(x, g)})) +(H({q(x, g)}) - H({q(N)(x, g)})) +(H({q(N)(x, g)}) - H({q(N)(x, g(N))}))
>-+- - 3 33
= 0.

On the other hand, Lemma 2.7 shows that H({qi(0)})  H({qi(g(n))}),

79

which leads to a contradiction. Therefore, there does not exist g such that

H({q(x, g)}) < H({q(x, 0)}) < .

2

The next theorem shows how shift invariance can reduce the complexity of computing the conditional median.

Theorem

2.8

If

- P (X, Y )

is

CSUM

and

SI,

then

for

every

-y  Rm,

- median(X| Y

=

-y )

=

arg

max x

p-Y -X

(-y

-

x),

- where p-Y -X is the density of the distribution on Y - X.

Proof:

p-Y -X (-y - x)

=

Pr(X

=

x

+

t,

- Y

=

-y

+

t)

t

=

Pr(X

=

x

+

- t| Y

=

-y

+

t)

·

- Pr( Y

=

-y

+

t)

t

=

Pr(X

=

- x| Y

=

-y )

·

- Pr( Y

=

-y

+

t)

(S I )

t

=

Pr(X

=

- x| Y

=

-y )

·

- Pr( Y

=

-y

+

t)

t

=

Pr(X

=

- x| Y

=

-y ).

Since

- X|Y

=

-y

is

symmetric

and

unimodal,

- median(X| Y

=

-y )

=

arg

max

Pr(X

- |Y

=

-y )

x

=

arg

max x

p-Y -X

(-y

-

x)

80

2

Remarks:
1. In applications, construction of the conditional median requires first estimating an (m + 1)-dimensional density p(x, -y ), whereas p-Y -X has only m dimensions. This difference will be important in our experiments (see §4). -
2. If we think of each component of Y = (Y1, · · · , Ym) as a predictor of X, then Theorem 2 can be interpreted as a recipe for combining m predictors into 1 predictor, based on a likelihood principle.

2.4 Application
In this section, we apply Theorem 2 to construct a good predictor. Recall that x^LOCO = median(a, b, a + b - c) -
depends only on three pixels. In this case, the dimension of Y is 3. By Theorem 2, -
the best predictor g based on Y = (a, b, c) is

g(a,

b,

c)

=

arg

max x

p-Y -X

(a

-

x,

b

-

x,

c

-

x).

In practice, it costs too much to send the entire empirical joint residual distribution. Therefore, we estimate arg maxx p-Y -X(a - x, b - x, c - x) directly. We looked at the empirical joint residual distributions of several different images, and tried to figure out where the peak of p-Y -X(a - x, b - x, c - x) is for every (a, b, c). We found that the predictor of LOCO is usually near the peak. This explains why LOCO has a great success. However, we also found that x^LOCO has a better prediction when |a - b| is large than when it is small. To make the prediction closer to the peak, we modified the predictor a little bit when |a - b| is small. This should lower the entropy of prediction residuals.

81

Figure 2.2: test images

x^LOCO can be written as

  min(a, b)

x^LOCO

=



max(a, b) a+b-c

if c  max(a, b) if c  min(a, b) otherwise

We constructed a new predictor x^, such that x^ = x^LOCO when |a - b| > 15. When

|a - b|  15,





[

a+b+min(a,b) 3

]

x^

=



[

a+b+max(a,b) 3

]

[0.6  a + 0.6  b - 0.2  c]

if c  max(a, b) if c  min(a, b) otherwise,

where [t] denotes the nearest integer to t. We compared the modified predictor with LOCO predictor by calculating the entropy of the empirical residual distribution on six of ISO/JPEG test images. Figure-2.2 show the six images we used, and the result is presented in Table-2.1.
From Table-2.1, we can see that the modified predictor does better than the orig-
82

Image
Gold Hotel Water Woman Cmpnd1 Tools

LOCO
4.46 4.40 3.59 4.45 1.13 5.25

Modified
4.42 4.34 3.49 4.41 1.13 5.23

Optimum
4.36 4.19 3.43 4.36 1.03 5.07

Table 2.1: Entropies of Empirical Residual Distributions

inal predictor of LOCO. The column "Optimum" is the result of using the best predictor we constructed in the previous section. However, this predictor is based on the empirical joint residual distribution. In practice, we do not have the empirical joint residual distribution for free. Therefore, this is a bound which can never be achieved. Table-2.1 shows that the result from LOCO predictor is close to the bound. By creating a new prediction based on (a, b, c), one will not make a significant improvement in lowering the entropy.

2.5 Extension

In §3, we prove that

f

(-y )

=

arg

max x

p-Y -X

(-y

-

x)

achieves

- H(X - f ( Y )),

- if (X, Y ) is CSUM and SI. In this section, we will show that weaker assumptions can achieve similar results. We begin this section with more definitions. For any -y0 ,

define

D(-y0 )  {-y0 + s; s  R}.

83

For

any

-y



D(-y0 ),

if

- y

=

-y

+

s,

define

d-y0(-y )  s.

Definition

2.9

A

distribution

P(X,

- Y)

on

Rm+1

is

diagonally

symmetric

and

uni-

modal (DSUM) if

p(x - d-y0(-y )|-y  -y0 )

is symmetric and unimodal in x for every -y0 .

Define

F  {f : f (-y + s) = f (-y ) + s -y , s}.

We have a theorem similar to Theorem 2.3: -
Theorem 2.10 If P (X, Y ) is DSUM, then

f (-y )



median((X

-

- - d-y ( Y ))| Y



D(-y ))

achieves

- min H(X - f ( Y )).
f F

Proof:

First, we check that f  F:

f (-y + s)

=

median((X

-

- - d-y +s( Y ))| Y



D(-y

+

s))

=

median((X

-

- d-y ( Y )

+

- s)| Y



D(-y ))

=

median((X

-

- - d-y ( Y ))| Y



D(-y ))

+

s

= f (-y ) + s

- Then the proof is almost the same as that of Theorem 1. X - f ( Y ) is a mixture of

- - (X - f ( Y ))| Y



D(-y ).

It

suffice

to

check

that

- - meadian((X - f ( Y ))| Y



D(-y ))

=

84

0.

- X - f(Y )

=

X

-

(f (-y )

+

- d-y ( Y ))

=

X

-

- d-y ( Y )

-

f

(-y )

Since

f (-y )

=

median(X

-

- - d-y ( Y )| Y



D(-y )),

- the median of X - f ( Y ) is 0.

2

Next, present a result similar to Theorem 2.8, but with assumption DSUM, instead

of CSUM + SI.

Theorem

2.11

If

- (X, Y )

is

DSUM,

then

for

every

-y  Rm,

median((X

-

- - d-y ( Y ))| Y



D(-y ))

=

arg

max x

p-Y -X (-y

-

x),

- where p-Y -X is the density of the distribution on Y - X.

Proof:

p-Y -X (-y - x)

=

- Pr( Y

-

X

=

-y

-

x)

=

Pr(X

-

- Y

+

-y

=

x)

- = Pr(X - d-y ( Y ) = x).

Since (X - d-y (-Y ))|D(-y ) is symmetric and unimodal, we have

arg

max x

p-Y -X

(-y

-

x)

=

-

arg

max x

Pr(X

-

d-y ( Y

)

=

x)

=

arg

max x

Pr(X

-

- d-y ( Y )

=

- x| Y



D(-y ))

=

median(X

-

- d-y ( Y )

=

- x| Y



D(-y ))

85

Remark: CSUM + SI  DSUM, but the converse is not necessarily true.

2

86

Bibliography
[1] M. Weinberger, G. Seroussi, G. Sapiro. LOCO-I: A Low Complexity, ContextBased, Lossless Image Compression Algorithm. Proc. IEEE Data Compression Conference, Snowbird, Utah, March-April 1996.
[2] M. Weinberger, G. Seroussi, G. Sapiro. The LOCO-I Lossless Image Compression Algorithm: Principles and Standardization into JPEG-LS. Hewlett-Packard Laboratories Technical Report No. HPL-98-193R1, November 1998, revised October 1999. IEEE Trans. Image Processing, Vol. 9, August 2000, pp.1309-1324.
[3] X. Wu and N. D. Memon. Context-based, adaptive, lossless image coding. IEEE Trans. Commun. Vol. 45 (4), pp. 437-444, Apr. 1997.
[4] X. Wu. Efficient Lossless Compression of Continuous-tone Images via Context Selection, Quantization, and Modeling. IEEE Trans. Image Processing, Vol. IP-6, pp. 656-664, May 1997.
[5] A. Netravali and J. O. Limb. Picture coding: A review. Proc. IEEE, Vol. 68, pp. 366-406, 1980
[6] P. G. Howard and J. S. Vitter. Fast and efficient lossless image compression. Proc. 1993 Data Compression Conference, pp.351-360, Mar. 1993.
87

