PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON
GENETIC
ALGORITHMS
George Mason University June 4-7, 1989
Editor/Program Chair: J. David Schaffer
With support from: Navy Center for Applied Research in Arti:2..::.ial Intelligence, Naval Research Laboratory Philips LaboratOries, North American Phitps Corporation
Conference Committee:
Kenneth A. De jong, George Mason UniveT""'....i::)· (Conference Chair) John J. Grefenstette, Naval Research Laboraory (Finance) Lashon B. Booker, Naval Research LaborClt(Jry' (Local Arrangements) David E. Goldberg, Univenity of Alabama (F-.ublicity) J. David Schaffer, Philips Laboratories (Progr:o:m) 
 Lawrence Davis. Bolt, Beranek and Newmar.., lnc. 
 John H. Holland, University ofMichigan 
 George G. Robertson, Xerox PARC 
 Stephen F. Smith, Camegie~Mel1on Universi:::" 
 Stewart W. Wilson, Rowland Institute for Science 

Morgan Kaufmann Publishers, Inc. 
 San Mateo. California 


124
Using Genetic Algorithms to Solve NP.Complete Problems 


Kenneth A. De Jong 
 George Mason University 

KDEJONG@GMUVAX2.GMU.EDU 


William M. Spears 
 Navy Center for Applied Research in AI 

SPEARS@AIC.NRL.NAVY.M1L 


Abstract
. ,,~ A strategy for using Genetic Algorithms (GAs) to 
 solve NP-complete problems is presented. The key 
 aspect of the approach taken is to exploit the obser
 vation that, although all NP-complete problems are 
 equally difficult in a general computational sense, 
 some have much better GA representations than oth
 ers, leading to much more successful use of GAs on 
 some NP-complete problems than on others. Since 
 any NP-complete problem can be mapped into any 
 other one in polynomial time, the strategy described 
 here consists of identifying a canonical NP-complete 
 problem on which GAs work well, and solving other 
 NP-complete problems indirectly by mapping them 
 onto the canonical problem. Initial empirical results 
 are presented which support the claim that the 
 Boolean Satisfiability Problem (SAl) is a GA
 effective canonical problem, and that other NP
 complete problems with poor GA representations can 
 be solved efficiently by mapping them first onto SAT 
 problems. 

1. Introduction
One approach to discussing and comparing Al prob lem solving strategies is to categorize them using the terms "strong" and "weak" methods. Generally, a weak method is one which has the property of wide applicability but, because it makes few assumptions about the problem domain, can suffer from combinatorially explosive solu tion costs when scaling up to larger problems. State space search algorithms and random search are familiar exam ples of weak methods.
Frequently, scaling up problems can be avoided by making sufficiently strong assumptions about the problem domain and exploiting these assumptions in the problem solving method. Many expert systems fall into this category in that they require and use large amounts of domain- and problem-specific knowledge in order to efficiently find solutions in enormously complex spaces. The difficulty with strong methods, of course, is their lim ited domain of applicability leading, generally, to significant redesign even when applying them to related problems.

These characterizations tend to make one feel
trapped in the sense that one has to give up significant per
formance to achieve generality, and vice versa. However. it is becoming increasingly clear that there are at least two methodologies which fall in between these two extremes and offer in similar ways the possibility of powerful, yet general problem solving methods.
The two approaches we have in mind are Genetic Algorithms (GAs) and Neural Networks (NNs). They are similar in the sense that they achieve both power and gen erality by demanding that problems be mapped into their own particular representation in order to be solved. If a fairly natural mapping exists, impressive robust perfor mance results. On the other hand. if the mapping is awk ward and strained, both approaches behave much like the more traditional weak: methods yielding mediocre. unsatis fying results when scaling up.
These observations suggest two general issues which deserve further study. FIrSt, we need to understand how severe the mapping problem is. Are there large classes of problems for which effective mappings exist? Clearly. if we have to spend large amounts of time and effort in constructing a mapping for each new problem, we aren't any better off than the more traditional strong methods. The second major issue involves achieving a better understanding of the relationship between GAs and NNs. Are the representaLion issues and/or performance characteristics significantly different? Arc there classes of problems handled much more effectively by one approach than the other?
This paper is a first step in exploring these issues. It focuses on GAs and how they can be applied to a large, well-known class of combinatorially explosive problems: NP-complete problems. A parallel effort is underway using NNs to solve NP-complete problems. Although a conclusive study is not yet completed. We will describe some preliminary results which compare the performance of GAs and NNs on a family of very difficult NP-complete problems.
2. NP-Complete Problems
In complexity theory, NP denotes the set of all (decision) problems solvable by a non-deterministic

ICCA'S9IUsing Genetic Algorithms to Solve NP-Complete Problems

125

polynomial time algorithm. P denOleS the set of all (deci sion) problems solvable by a deterministic polynomial time algorithm. NP problems are considered -bard" in the sense that they are not currently solvable in deterministic
=polynomial time. It is an open question whether NP P.
The canonical example of a problem in NP is the boolean satisfiabiIity problem (SA1): Given an arbitrary boolean expression of n variables, does there exist an assignment to those variables such that the expression is uue? Other familiar examples include job shop schedul ing, bin packing, and traveling salesman problems.
The concept of NP-completeness comes from the observation that, althougb every problem L in NP can be transformed into an equivalent SAT problem in polyno mial time (Cooke's theorem), the reverse polynomial-time transformation may not exist Those problems in NP which do have 2-way transformations form an equivalence class of "equally hard" problems and have been called NP-complete problems [Garey79].
Although NP-complete problems are computation ally equivalent in this complexity theoretic sense, they do not appear to be equivalent at all with respect to how well they map onto GA (or NN) representations. For example, in the case of GAs, the SAT problem has a very natural representation while finding effective representations for bin packing. job shop scheduling. and traveling salesman problems seems to to be quite difficult [DeJong85. Gold berg85. Grefensteue85. Smith85. Davis85. Oliver87, Goldberg89].
These observations suggest the following intriguing . strategy. Suppose we are able to identify an l\l'-complete problem which has an effective representation in the ·.  methodology of interest (GAs or NNs) and develop an .efficient problem solver for that particular case. Other '"  NP-complete problems which don't have effective
representations can then be solved by transforming them into the canonical problem, solving it, and transforming the solution back to the original one.
We have explored this strategy in detail for GAs ,using SAT as the canonical NP-complete problem. A . ,similar effort is underway using NNs and will be presented .at a later date. 

,

3. Genetic Algorithms and Boolean Satisfiability Prob lems
. In order to apply GAs to a particular problem, we need to select an internal string representation for the solu tion space and define an external evaluation function
assigns utility to candidate solutions. Both com Jk>nents are critical to the SUCcess/failure of the GAs on the .iXl)ble,m of interest We have selected SAT as the choice
canonical NP-complete problernbecause it appears a highly d~irable string representation, Damely, strings of length N in which the i·th bit represents

the truth value of the i-th roolean variable of the N boolean variables present in the boolean expression. It is hard to imagine I representation much better suited for use with ~As: it is fixed length, binary, and context indepen dent m the sense that the meaning of one bit is unaffected by changing the value of other bits [DeJong85].
3.1. Choosing a PayolT Function
Somewhat more thought must be given to selecting an evaluation function. The simplest and most natural function assigns a payoff of 1 to a candidate solution (string) if the values specified by that string result in the boolean expression evaluating to TRUE, and 0 otherwise. A moment's thought., however, suggests that for problems of interest the payoff function would be 0 almost every where and would nOl support the formation of useful inter med~te buiI~ng b~ks. Even though in the real problem dOmaIn, partIal soluuons to SAT are not of much interest., they are critical components of a GA approach.
One approach to providing intermediate feedback would be to transform a given boolean expression into conjunctive normal form (CNF) and define the payoff to be the total number of top level conjuncts which evaluate to uue. While this makes some intuitive sense, one cannot in general perform such transformations in pOlynomial time without introducing a large number of additional boolean variables which, in turn, combinatorially increase the size of the search space.
An alternath-e would be to assign payoff to indivi dual clauses in the original expression and combine them in some way to generate a total payoff value. In this con text the most natural approach is to define the value of TRUE to be I, the value of FALSE to be 0, and to define the value of simple expressions as follows:
=lIol(NOT e) 1- val (e)
val(AND el ... e,.) =MIN(val(el) ... val(e,.))
=vol (OR el ·.· e,.) MAX (val (e 1) ·.. val(e,.»
Since any boolean expression can be broken down (parsed) into these basic elements. one has a systematic mechanism for assigning payoff. Unfortunately, as the astute reader has probably already noticed. this mechanism is no better than the original OQe since it still only assigns payoff values of 0 and 1 to both individual clauses and and the entire expression.
However, a minor change to this mechanism can generate differential payoffs, namely:
val(AND el ... e,.) =AVE (val(el) ··· 'val(e,.))
-This suggestiOn was made first by Smith [Smith79] . and intuitively justified by arguing that this would reward
"more nearly true" AND clauses. So, for example,

U6 De Jong md Spears

solutions to Ihe boolean expression

. .' ".,.

';.'

r.

X AND (X OR X; ) .
I I1

.would be assigned payoffs as rollows:

XI Xl

PAYOFF

=0 0 (AVE 0 (MAX (0 (1  0))) 0.5

=0 1 (AVE 0 (MAX (0 (1-1))) 0.0

=1 0 (AVE 1 (MAX (1 (1-0))) 1.0

=1 1 (AVE 1 (MAX (1 (1-1))) 1.0

Notice that both of the correct solutions (lines 3 and 4) arc assigned a payoff of 1 and, of the incorrect solutions (lines 1 and 2), line 1 gets higher payoff because it got half of the ANDrighL
This approach was used successfully by Smith and was initially adopted in our experiments.. However, there were a number of features of this payoff function that left us uncomfortable and which led to a more eareful exami nation of it
The fust and fairly obvious property of using AVE to evaluate AND clauses is that the payoff function is not invariant under standard boolean equivalency transforma tions. For example. it violates the associativity law:

val«XI AND Xl) AND X3) '¢ val(X 1AND (Xl AND X3»

since
(AVE (AVE Xl X2)X3) '¢(AVE Xl (AVE X2 X 3»
We have attempted to construct alternative differential payoff functions which have this ideal property of payoff invariance and have had no success. However. one could argue that a weaker form of invariance might be adequate for use with GAs, namely, truth invariance. By that we mean that the payoff function should assign the same value (typically 1. but could even be a set of values) to all correct solutions of the given boolean expression, and should map all incorrect solutions into a set of values (typ ically 0 S value < 1) which is distinct and lower than the correct ones. Since boolean transformations do not occur while the GAs are searching for solutions, the actual values assigned non-solutions would seem to be of much less importance than the fact that they are useful as a differential payoff to support the construction of partial solutions.
Unfortunately, the proposed payoff function does not even guarantee this second and weaker property of truth invariance as the following example shows:

by De Morgan

However,

. as we see in me following table:

XI X1 uJhide Right side

00

0

0

01 10

1 1

112 112

11

1

1

Notice that lines 2-4 are all solutions, but lines 2 and 3 are assigned a payoff of 1/2 after De Morgan's law has been
applied.

In genem1, it can be shown that, although the payoff does not assign the value of 1 to non-solutions. it fre quently assigns values < 1 to perfectly good solutions and can potentially give higher payoff to non-solutions!

A careful analysis, however, indicates that these problems only arise when De Morgan's laws are involved in introducing terms of the form (AND ··. ). This sug gests a simple fix: preprocess each boolean expression by systematically applying De Morgan's laws to remove such constructs. It also suggests another interesting opportun
ity. Constructs of the fonn (OR ··· ) are computed correctly. but only take on 0/1 values. By using De
Morgan's laws to convert these to AND constructs, we introduce additional difIerential payoff. Converting both fonns is equivalent to reducing the scope of all NOTS to simple variables. Fortunately, unlike the conversion to
CNF, this process has only linear complexity and can be done quickly and efficiently.

In summary, we feel that, with the addition of this preprocessing step. we now have an effective payoff func tion for applying GAs to boolean satisfiability problems. This payoff function has the following properties: 1) it assigns a payoff value of 1 if and only if the candidate solution is an actual solution; 2) it assigns values in the range 0 S value < 1 to all non-solutions; and 3) non solutions receive differential payoff on the basis of how near their AND clauses are to being satisfied.

3.2. Possible Improvements to tbe Payoff Function
One way to view the problems discussed in the pre vious section is to note that many of the undesirable
effects are due to the fact that, by choosing to evaluate
AND/OR clauses with AVE/MAX, we have broken the natural symmetry between AND and OR in the sense that AND clauSes will have differential payoffs assigned to them while OR clauses will only be assigned 0/1. An interesting observation is that evaluating AND nodes by raising AVE to some integer power p is still truth preserv ing (assuming the preprocessing step described above) and has several additional beneficial effects. F"JISl, it has the effect of reducing the AND lOR asymmetry by reducing the average score assigned to a false AND clause. In addi tion, it increases the differential between the payoff for
AND clauses with only a few Is and those which are

ICGA'891Using Genetic Algorithms to Solve NP-Complete Problems

U7

nearly rrue.
On the other hand, as p approaches infinity. the
function AVE P behaves more and more like MIN which
means we have again lost the differential payoff property.
an'Ibis suggests interesting optimization experiment to
determine a useful value for p. We will present our initial results on this in the next section.
4. Experimental Results
4.1. Implementation Details
AU of our experiments have been perfonned using a Lucid Common Lisp implementation of the GAs. In all
eases the population size has been held fixed at 100. the
standard 2-point crossover operator has been applied at a 60% rate, the mutation rate is 0.1%. and selection is per fonned via Baker's SUS algorithm [Baker87].
Having formulated SAT as an optimization prob lem. there are some interesting issues concerning conver gence to a solution. First of aU, whenever a candidate evaluates to 1. we know that a solution has been found and the search can be tenninated. Conversely, there is strong motivation to continue the search until a solution is found (since nearly true expressions are not generally of much interest to the person formulating the problem). The difficulty. of course. is that on any particular run there is no guarantee that a solution will be found in a reasonable amount of time due to the increasing homogeneity of the population as the "search proceeds.
One approach would be to take extra measures to guarantee continuing diversity (such as increasing muta tion. selection by ranking. introducing crowding factors. etc.). Unfonunately, these aU have additional side effects which would need to be studied and controlled as well. We have chosen a simpler approach. We use De Jong's measure of population homogeneity based on allele "con vergence" [DcJong75], and when that measure exceeds 90%, the GA is restarted with a new random population. Consequently, in the experimental data presented in the subsequent sections, the evaluation counts reflect aU of the
GA restarts. Although this technique might seem a bit
drastic, it appears to work quite well in practice.
Since the number of evaluations (uials) required to find a solution can vary quite a bit from one run to the next due to stochastic effects, all of the results presented here represent data averaged over at least 10 independent runs.

(AND Xl' ·· XII) OR (AND Xi ... X.;)
which have exactly two solutions (aU Os and aU Is). By varying the number n of boolean variables, one can
observe how the GAs perform as the size of the search
space increases exponentially while the number oC solu tions remains fixed.
Figure 1 presents the results of varying n between
10 and 90 (i.e., for search spaces ranging in size from 210 to 290). It is clear that the differential payoff function is working as intended, and that the GAs can locate solutions to TP problems without much difficulty.
To make things a bit more difficult, we changed the problem slightly by turning one of the solutions into a false peak (FP) as foUows:
x.:)(AND Xl'" X,,) OR (AND XI Xi ...
so that the previous all Os solution is now almost' correct and the only correct solution is that of allIs.
Figure 2 presents the results of applying GAs to the FP family with n ranging from 10 to 90. As before, we see that the GAs have no difficulty in finding the correct
2~------------------~
15000
Evals 10000
5000
o  20 40 60 80 # Variables =10g(Search Space)
5-------~~-----------------~
4
log(Evals)  3
2

4.2. Initial SAT Experiments

Our first set of experiments involves constructing

several families of boolean expressions Cor which we can

control the size and the difficulty of the problem. The first

family selected consists of two-peak (TP) expressions oC

the Corm:

.

l - L - -_______--~-----__-------~~
o  20 40 60 80
# Variables = 10g(Search Space)
Figure 1: Perfonnance of GAs on the TP Problems

128 De Jong and Spean

evensolution in Ihe presence of false peaks.
Since we are dealing with problems for which there are no blown polynomial-time algorilhms, we have been particularly interesled in the log-log graphs. Notice that. for both abc TP and FP problems.. a sub-linear curve is genetaled, indicating (as upecled) a subsranlial improve ment over ..systematic search. The fonn that these sub linear curves take give some indication of the speedup (over systematic search) obtained by using GAs. If, for eJtample. these curves are all logarithmic in form, we have a polynomial-time algorithm for SAn Additional discus sion of these curves will occur in a later section after more data has been presented.
With these initial encouraging results, we were eager to apply GAs to more naturally arising boolean expressions. However. we have found it difficult to find good examples of hard SAT problems (including those used by Smith [Smith79]). So. we have chosen instead to look at other NP-complcl.e problcms as possible sources. The first one we have ~lected is the famUy of hamiltonian
S~~-------------------;
Evals 20000 

10000 

0
 0 20 40 60 80
# Variables =10g(Search Space)
5
4

circuit poblems.
4.3. Solving Hamiltonilll Circuit Pa:ob1ems
The hamiltonian circuit (HC) problem consists oC finding a tour througb a directed graph that touches all nodes exactly once. acarly. if a graph is Cully c:onnected, this is an easy task. However, as edges are removed the problem becomes much more difficult. and the general problein is known to be NP..complete.
Attempting to solve this problem directly with GAs raises many of the same representation issues as in the case of traveling salesman problems [DeJong8S. Grefen stette8S1. However. it is not difficult to construct a polynomial-time ttansformation from He problems to SAT problems.
An example of the transformation we are using is given in Figure 3. The definition of the He problem implies that. for any solution. each node must have exactly one input edge and one output edge. If any tour violates this constraint. it cannot be a solution. Therefore. all equivalent boolean expression is simply the conjunction of terms indicaLing valid edge combinations for each node. As an example, consider node d. Node d has two output
«edges and one input edge. The OULput edge constraints are
given by the exclusive-or. db and de ) or ( d[j and de ).
The input edge is described simply by cd. The assign ments to the edge variables indicate which edges make up a LOur. with a value of 1 indicating an edge is included and a valuc of 0 if it is not This transformation is computed
a
ea
d de

10g(Evals)  3
2
1
0 20 40 60 80
# Variables =10g(Search Space)
Figure 2: Performance of GAs on the FP Problems

(and ab be ex! de ea (or (and db (not de))
eb»(and (not db) de)))
(or (and ea (not (and (not ea) eb»
eb»(Qr (and ab (001 db)( not eb». (and (not ab) db (not
( and, (not ab) (not db) eb))
Figure 3: Transforming He Problems to SAT Problems

ICGA'89/using Genetic Algorithms to Solve NP-Complete Problems

U9

in polynomial time, and a solution to the HC problem exists if and only if the boolean expression is satisfiable.
As before, we wish to systematically study the per formance of GAs on a series of increasingly difficult HC problems. Clearly, the complexity in this case is a func tion of both the number of nodes and the number of directed edges. For a given number N of nodes, problems with only a small number of edges (~ N) or nearly fully connected (approximately N 2 edges) are not very interest
ing. We feel that problems with approximately N22
edges would, in general, present the most difficult prob lems. In addition, to achieve some degree of uniform
difficulty and to allow for a direct comparison with some
of the results in the previous section, we wanted the prob lems to have exactly one solution. Consequently, we have defined the following family of HC problems for our experiments.
Consider a graph of n nodes, which are labeled using consecutive integers. Suppose the first node has directed edges to all nodes with larger labels (except for the last node). The next n-2 nodes have directed edges to all nodes with larger labels (including the last one). The last node has a directed edge back to the first node. A complete tour consists of following the node labels in increasing order, until you reach the last node. From the last node you travel back to the first. Because the edges are directed, it is clear that this is also the only legal tour.
Intuitively, such instances of HC problems should be difficult. Only one tour exists in each instance. In addi tion. there are a large number of solutions that are almost complete tours scattered throughout the search space. Fig ure 4 illustrates what the corresponding SAT payoff func tion looks like for an HC problem of this type with 7 nodes.
In summary, our experimental framework consists of varying the number N of nodes in the range 4 S; N S; 10 and, for each value of N, generating a directed graph of the
2.l.orm dcscn'bed above contam. m. g approxi.mateIy N 2
edges and exactly one solution. Each of these HC
0.8
0.6
EvahwiOll
0.4

problems is transformed into its equivalent SAT problem
rs.using the transformation described above. generating
search space sizes ranging from 26 to GAs are then used to solve each of Ihe corresponding SAT problems
which. in tum, describes a legal HC tour.
Figure 5 presents the results of these experiments. Notice that we have succeeded in generating significantly more difficult SAT problems in that the number of evalua tions required to find a solution is an order of magnitude higher that the earlier TP and FP problems. However, even with these difficult problems. the log-log plot is still sub-linear.

4.4. Improvements to the SAT PayolT Function
Although we were pleased with the results so far, we were very curious as to the effects of using AVE P in the payoff function for integer values of p > 1 for the rea sons discussed in section 3.2. Our hypothesis was that ini tial increases in the value of p would improve perfor mance, but that beyond a certain point performance would

le+06-r--------------------~

800000

600000 Evals 

400000 


200000

0 0 20 40 60 1# Vari:lbles = 10g{Search Space)
6

5

10g(Evals)

4 3

2

1
0 20 40 60 # Variables = 10g{Search Space)

000..

010_

100-

110_

111.

, ,H~

Figure

4:

SAT

Pa. y.off

function

for

a

7-node
.

HC

Pioblem

Figure 5: Performance of GAs on the HC Problems

130 De Jong and Spean

actually drop oil as AVE' began to more closely approxi mate MIN. :' ,
We tested this hypothesis by re-lUMing the GAs on the three families of problems (TP. FP, and HC) varying P
from 2lO S. and compared their performance with the ori ginal results with p = 1. Figure 6 presents the results of our e~~ents. Somewhat surprisingly, an optimum
~-r----------------~ AVE"S
AVE....
15000

Evals 10000

5000

0
0 20 40 60 80 # Variables = 10g(Search Space)

50000

AVE"S

40000
30000 Evals
20000

AVE"l AVE....

10000

0
0 20 40 60 80 # Variables = 10g(Search Space)

appeared already at P · 2. Accordingly. we have adopted that value for the remaining experimental wen we have performed.

4.5. Some Empirical Evidence o(Implicit Parallelism

One of the nice theoretical results in Holland', ori ginal analysis of the power of GAs is the "implicit paral
lelism" theorem whi:h sets a lower bound of an N'
speedup over systematic sequential search [Holland75}.
This suggeslS that, in Ihe worst case, GAs should not have to search more than the cube root of Ihe search space in order to find a soIutioo and, in general. should do much
better.

One of the unexpected benefilS of the experimental results presented here is substantial empirical evidence of just such speedups on SAT problems.

Figure 7 summa:izes the performance of the GAs on

the 3 families of SAT problems using AVE! in the payoff

function. As we noted earlier, the log-log curves appear to

be sub·linear. To get 2. better feeling for the form of these

curves, we have tried to fit both linear and quadratic

curves to the data. Fa each of the families of SAT prob

lems, a quadratic form produces a better fit and, by using

the coefficients of the quadratic form, we can calc,ulate the

observed speedup. The resullS are as follows:

TP speedup: FP speedup:

N N

'6..2251

HC speedup:

N2..94

Clearly, on the easier problems OF and FP) we are per

forming better than C-.e predicted lower bound. What is

particularly intriguing. however, is how well the empirical

resullS match the theoretical resullS for the HC family

which we have delib:::rately consuucted to be a class of

very difficult single-sc:ution problems.

5. Current Activities

100000
80000
60000 Evals
40000
20000

AVE"S 

AVE"l 
 AVE.... 

AVE"3 
 AVE"2 


0 0 10 20 30 40 # Variables = 10g(Search Space)

Figure 6: Perfonnance of GAs using AVE P

5.1. C and Parallelization
The experimer.:s reported here have been con· strained by our use o~ Lucid Common Lisp. While Lisp makes it easy to aULO::late the process of generating Lisp code for the various SAT families of problems. the Lucid Lisp compiler imposes intemallimits on the size and com plexity of the functions it can compile. We hit these limits when attempting to generate payoff functions for HC prob lems with more than 10-Il nodes. We are in the process of switching over to !.he Genesis system, a C implementa lion of GAs [Grefenst!Ue84], to avoid these limitations. A side benefit of this cOllversion is that Ihe experimenlS also run a order of magl"1:.ude faster! Since many GA sites already use Genesis, this step has the added advantage of creating an additional GA testbed for the GA community.
More exciting perhaps is the use of parallelism. Genesis is being co''lVerted for use on the Butterfly

ICGA'89IUsing Genetic Algorithms to Solve NP-Complete Problems 131

6
S
4 Log(Evals)
3
2 TPProblcml
1 0 20 40 60 80
=i# Variables 10g(Search Space)
6
5
4 Log(Evals)
3
2 FPProbI.....
1 0 20 40 60 80 ## Variables = 10g(Searcb Space)
6
5
4 Log(Evals)
3
2 HCProbI.....
1 0 20 40 60
i# Variables = 10g(Search Space)
Figure 7: Summary Perfonnance of GAs using AVE2
machine at NRL. The Butterfly is a MIMD machine with 128 68020-based nodes. Preliminary results suggests that the use of this machine could result in a two order of mag nitude speedup in execution time.
S.2. An NP.Complete Factorization Problem Although the GNs have performed well on TP. FP.
and HC problems. one can argue that the problems are

simply not interesting. since the TP and FP problems are somewhat artificial and there already exists specialized algorithms for HC problems which can out perfonn the GAs on the examples shown. What is perhaps needed at this point to evaluate the robustness of this approach is a problem which is known to be NP-complete, but for which few (if any) specialized algorithms have been developed.
An example of such a problem has come to us from
the cryptography community. Most cryptography systems make use of prime numbers and factorization [Rivest78].
Hoey [Hoey89] has devised an algorithm for converting a
factorization decision problem into an equivalent SAT problem. For example, a problem of the fonn:
"Does 689 have a 4 bit factor'!" can be converted to a boolean expression with 22 vari ables, lOS clauses, and 29S literals.
Such problems arc of interest 10 both the crypto graphic and complexity theory communities because they are generally highly intractable. We plan a set of exten sive experiments when we have completed the conver sions described in the previous section.
5.3. A Comparison witb Simulated Annealing
As mentioned earlier, we are also examining the use of neural networks (NNs) to solve NP-Complete p'roblems. In particular, we have developed a method for using simu lated annealing (a class of NNs (McClelland88]) to solve SAT problems. Although the details of the methodology will not be presented here, some experimental highlights are worth mentioning.
First, SA's work remarkably well on the TP prob lem, producing correct solutions in almost constant time (regardless of the size of the TP problem). In this case, SA's are essentially greedy algorithms. and the results are not surprising. Secondly, SA's appear to be reasonably competitive with GA's on HC problems, although they are consistently outperformed on the examples we have run so far (see Figure 8).
If we again use quadratic fits to the He data seen so far. the NN speedup is approximately N2.22 while the GA speedup (reported earlier) is N2.94. We will have a more comprehensive repon on these experiments in the near future.
6. Conclusions
This paper presents a series of initial results regard ing a strategy for using GAs to solve NP-complele prob lems. This strategy avoids many of the GA representation difficulties associated with various NP-complete problems by mapping them into SAT problems for which an effective GA representation exists.
These initial results suppon the view that GAs are an effective. robust search procedure for NP-complete

_ 13%

De Jons and Spean

..'

le+06 Evals 500000

I I
,'SA
I I I I I I
I

o 20 40 
 60 

=II Variables 10g(Search Space)

10g(Evals)

6 ,.SA
5
4
3
2I
I
1 0 20 40 60 

=## Variables 10g(Search Space)

Figure 8: GAs and SAs on the HC Problems

De Jong. K. A. (1975). An Analysis of the Behavior 0/ Q Class 0/ Genetic Adtzptive Systems, Doctoral c:Ussenation,
Dept. Computer and Communication Sciences, University of Michigan, Ann Arbor.
De Jong, K. A. (1985). Genetic Algorithms: a 10 Year
Perspective, Proc.ln!' I Conference on Genetic Algorithms and their Applications.
Garey, Michael R. & David S. Johnson (1979). Comput
ers and Intractability: A Guide to the Theory 0/ NP
Completeness, W. H. Freeman and Company, San Fran cisco,CA.
Goldberg, David E. and Robert Lingle, Jr. (1985). Alleles, Loci, and the Traveling Salesman Problem, Proc. Int'l Conference on Genetic Algorithms and their Applications.
Goldberg, David E. (1989). Genetic Algorithms in Search. Optimization &: Machine Learning, Addison-Wesley Pub lishing Company. Inc.
Grefcnsteue, John J. (I 984). GENESIS: A system for
using genetic search procedures. Proceedings 0/ the 1984
Conference on Intellige1l1 Systems and Machines, 161-165.
Gre[enstette,John J.,et al. (1985). Genetic Algorithms for the Traveling Salesman Problem. Proc. Int'I Conference on Genetic Algorithms and their Applications.
Hoey, Dan Navy CenJ.er for Applied Research in Artificial InteIligence. Private Communication.

problems in the sense that. although they may not outper form highly tuned, problem-specific algorithms, GAs can be easily applied to a broad range of NP-complete prob lems with performance characteristics no worse than the theoreti~ lower bound of an N3 speedup.
This paper also sets the stage for a direct com parison between GAs and NNs on NP-complete problems. We feel that such comparisons are important and encourage the research community to develop additional results on these and other problems of interest.

Holland, John H. (1975). Adaptation in Natural and Artificial Systems, The University of Michigan Press.
McClelland, James L and David E. Rumelhart (1988). ExPlorations in Parallel Distributed Processing, The MIT Press. Cambridge, MA.
Oliver, I. M., Smith, D. J. and J. R. C. Holland (1987). A Study of Permutation Crossover Operators on the Travel ing Salesman Problem, Proc. Int'l Conference on Genetic Algorithms and their Applications.

Rderences
Balcer, James E. (1987). Reducing Bias and Inefficiency in the Selection Algorithm, Proc. Int'l Conference on Genetic Algorithms and their Applications.
Davis, Lawrence (1985). Job Shop Scheduling with Genetic Algorithms, Proc. Int'l Conference on Genetic Algorithms and their Applications.

Rivest. R. L., et al (1978). A Method for Obtaining Digi tal Signatures and Public-key Cryptosystems, CACM, 21, 2,120-6.
Smith, Gerald H. (1979). Adaptive Genetic Algorithms and the Boolean Satisfiability Problem. Unpublished Work.
Smith, Derek (1985). Bin PaCking with Adaptive Search, Proc. Int'J Conference on Genetic Algorithms and their Applications.

