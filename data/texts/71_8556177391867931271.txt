Linear Hinge Loss and Average Margin

Claudio Gentile DSI, Universita' di Milano,
Via Comelico 39, 20135 Milano, Italy gentile@dsi.unimi.it

 
Manfred K. Warmuth Computer Science Department,
University of California, 95064 Santa Cruz, USA manfred@cse.ucsc.edu

Abstract
We describe a unifying method for proving relative loss bounds for online linear threshold classification algorithms, such as the Perceptron and the Winnow algorithms. For classification problems the discrete loss is used, i.e., the total number of prediction mistakes. We introduce a continuous loss function, called the "linear hinge loss", that can be employed to derive the updates of the algorithms. We first prove bounds w.r.t. the linear hinge loss and then convert them to the discrete loss. We introduce a notion of "average margin" of a set of examples . We show how relative loss bounds based on the linear hinge loss can be converted to relative loss bounds i.t.o. the discrete loss using the average margin.

1 Introduction

¡

Consider the classical Perceptron algorithm. The hypothesis of this algorithm at trial

¢¤£¦¥¨§©is a linear threshold function determined by a weight vector

. For an instance

 £ ¥§©  ¦£  ¢ £  £  the linear activation

is passed through a threshold function

#! " $which is on arguments less than the threshold and +1 otherwise. Thus the prediction

!#"&(% ')"of the algorithm is binary and

denote the two classes. The Perceptron algorithm

0  £ 2% 1 4£ 3 ¥is aimed at learning a classification problem where the examples have the form

§ ¤© 75 68#! "&%9)' "A@ .

B 0  £ C% 1 £43C9D EF£GIE H 1 FH QP ¦D  R S0T¢ HFPQUD After seeing examples

, the algorithm predicts with

 HIQP D 3  HIQP D 18 FH QP Don the next instance . If the algorithm's prediction agrees with the label

1 HIQP D  FH PQDon the instance , then its loss is zero. If the prediction and the label disagree,

then the loss is one. We call this loss the discrete loss.

The convergence of the Perceptron algorithm is established in the Perceptron convergence theorem. There is a second by now classical algorithm for learning with linear threshold functions: the Winnow algorithm of Nick Littlestone [Lit88]. This algorithm also maintains a weight vector and predicts with the same linear threshold function defined by the current
f ¢V£ ¤¢ £  X0 WG£ Y `D %bca acad%CeW G£ Y © 3weight vector . However, the update of the weight vector Supported by NSF grant CCR-9700201.

performed

by

the

two

algorithms is
Perceptron: Winnow:

radically
¢¨¦ §¤T£ PQW ¡D T£ QP    D(Y ©

different:
¢   £Q!£¦§ ¥¢ W b¤ G££ Y

©



£! £ ¢¤

£F£GY

©

b£ `0 &1  £ ! 1A£lTehaernPinegrcreaptteroanndalg¤ oreiqthumalsperforms a3 s im, wplheicahddliietisvienuS6p#!da"St%eR. (%T)' heA" @ b£p.aWramheente¤r ¢

 is

a

positive the pre-

diction of the algorithm is correct and no update occurs. Both the Perceptron algorithm and

Winnow update
1& £  ')" A1 £  #! " £  )' "is wrong. If

conservatively, and

i.e.,tthheenytuhpedaaltgeoorintlhymwohveenrsthhoetparneddi¤ction

of

the algorithm . This causes

 £ ¢ £ 1  £V #! "the Perceptron to subtract ¢ from the current weight . Similarly if

and

1 £  )' " ¢ £ ££   £ #! "  £current

then the weight

algorithm . We will

undershot and later interpret

¤ ¤

. Now the Perceptron adds ¢ to the
as a gradient of a loss function. Winnow

uses the same gradient but the update is done through the componentwise logarithm of the

weight vector. One can also rewrite Winnow's update as

eW £TP (D Y ©    We£GY © "!$##20 %! ¥¢ ¤ £  £GY © 3 %'&  "&% da acda %( %

so that the gradient appears in the exponents of factors that multiply the old weights. The factors are now used to correct the weights in the right direction when the algorithm under or overshot.

The algorithms are good for different purposes and, generally speaking, incomparable (see

[KWA97] for a discussion). In [KW97] a framework was introduced for deriving simple on-line learning updates. This framework has been applied to a variety of different learning

algorithms and differentiable loss functions [HKW95, KW98]. The updates are always

derived by approximately solving the following minimization problem
¢T£ QP D¡   argmin¢0) T0 ¢ 3 % where ) X0 ¢ 3 21 X0 ¢ 2% ¢V£ 3 '3¢ lossT0 &1 £ %   0T¢

  £ 3C3 a

(1)

Here loss denotes the chosen loss function. In our setting this would be the discrete loss.

1  £  R&X0 ¢ £   £ 3What is different now is that the prediction of the algorithm

and the

¢V£discrete loss are discontinuous in the weight vector . We will return to this point later

after discussing the other parts
T0 ¢7C% ¢ £43learning rate mentioned above

aonfdt,hme aobsot vime pmoirntiamntilzya,t1ion

problem. The parameter ¢ is the
is a divergence measuring

¢ ¢ £how far is from . The divergence function has two purposes. It motivates the update

and it becomes the potential function in the amortized analysis used to prove loss bounds

for the corresponding algorithm.

The use of an amortized analysis in the context of learning essentially goes back to [Lit89]

and the method for deriving updates based on the divergence was introduced in [KW97].

The divergence may be seen as a regularization term and may also serve as a barrier func-

tion in the optimization problem (1) for the purpose of keeping the weights in a particular

T0 7¢ %C¢ £ 3  ¢ ! ¢V£r1 egion.

Th5e a¨4d4 ditive

alg4¨4o76 r8 it hamsst,hseucdhivaesrggernadceie.nTthdiessccaenntbaenudstehde

Perceptron algorithm, use as a potential function for

the proof of the Perceptron convergence theorem. Multiplicative update algorithms such as

Winnow and various exponentiated gradient algorithms use entropy-based divergences as

eitpnhxogeatnemwnmp.tril.iaetnl.iff¢mour¢in.zlcTiiT£ tnnPQhigeoi2D asn) rsw  rT0[eo¢HgrkKr3¢ eswWs£ vsiei!09tohr5yn¢,t,hw0XKw¢eeWhdlT£ leQPi9vnwD8eht]rh.ge eenT£nlhtoc!heseesfA1 4¨luf4£o¢un3 sncstc!£0iftoui¢oAnnnc)£"ti4¨¢is4o6@innt£8h!£i(es1gs)¢ciqvoiX0 us¢enasvmr£ etehix nle oiamW£snsdi! izd0Tde¢ 1Aridof£ £f3wbe yr-e£Hdan£ oitfif! fafebu1rlep£en39d.67taFi atoetr-:,

Various exponentiated gradient algorithms [KW97] can be derived in the same way when entropic divergences are used instead. However, in our case we cannot differentiate the discrete loss since it is discontinuous.

We asked ourselves which loss function motivates the Perceptron and Winnow algorithms in this framework. We will see that the loss function that achieves this is continuous and

¢its gradient w.r.t. £ is ¤ £  £ , where ¤ £ ¥ 86 !#"&%R%()' "&@ . We call this loss the (linear) hinge

loss (HL) and we believe this is the key tool for understanding linear threshold algorithms

such as the Perceptron and Winnow. However, in the process of changing the discrete

loss to the HL we also changed our learning problem from a classification to a regression

problem. There are now two versions of each algorithm, a classification version and a

regression version. The classification version predicts with a binary label using its linearly

thresholded prediction. The loss function is the discrete loss. The regression version, on

 £  £  ¢ £   £the other hand, predicts on the next instance with its linear activation

. In the

1 £ #! " ')"classification problem the  £ ! 'problem the labels are

¡lab  elsand

o¢f 

the .

examples are We will see that

and both

, while in the regression versions of each algorithm

¢ £use the same rule to update the weight vector .

Another strong hint that the HL is related to Perceptron and Winnow comes from the fact
I that this loss may be seen as a limiting case of the entropic loss used in logistic regression.
In logistic regression the threshold function is replaced by the smooth tanh function. There is a technical way of associating a "matching loss function" with a given increasing transfer function [HKW95]. The matching loss for the tanh transfer function is the entropic loss. We will show that by making this transfer function steeper and by taking the right viewpoint of the matching loss, the entropic loss converges to the HL. In the limiting
 case the slope of the transfer function is infinite, i.e., it becomes the threshold function .

The question is whether this introduction of the HL buys us anything. We believe so. We can prove a unifying meta-theorem for the whole class of general additive algorithms [GLS97, KW98], when defined w.r.t. the HL. The bounds for the regression versions of the Perceptron and Winnow are simple special cases. These loss bounds can then be converted to loss bounds for the corresponding classification problems w.r.t. the discrete loss. This conversion is carried out through working with the "average margin" of a set of examples relative to a linear threshold classifier. The conversion of the HL described in this paper can then be considered a principled way of deriving average margin-based mistake bounds. The average margin reveals the inner structure of mistake bound results that have been proven thus far for conservative on-line algorithms. Previously used definitions, such as the deviation [FS98] and the attribute error [Lit91], can easily be related to the average margin or reinterpreted in terms of the HL and the average margin.

2 Preliminaries and the linear hinge loss£
V§ ©We define two subsets of : the weight domain

and the instance domain ¤

. The

 ¢weights maintained by the algorithms always lie in the weight £domain and the instances of the examples always lie in the instance domain. We require be convex.

A general additive algorithm and a divergence are defined in te£rms of a link function ¥ . S£ uch a function is a vector valued function from the interior int of the weight domain
¢ ¥ §V© D §© § 58T0 ¢ 3  A0T¢% 3 3iiFnsottrho£ aeninntg.yotrAa£lidnil.kei,nInftwktuiinsoftcfuhetnaaitocshy(tneipoto¥pon,treeoa¥ nxpt(theieBaarntlrsy)deagfttuhmhunaeantcdnitiqio)tousmdneJiavaiiencnrovgoebfefrrinsao encme§¥issif¦ unusctnthrc£i  tctihtolaynt©top1it¨o isn,i  ctiiil.n£vuete.d,£ed¥ sefi.tihnneWtitbe£eoeauvsn¨ esduryamrw yeho etfhrea£ ftoiin¥.sr

defined as [Bre67]: 1  0  2% ¢ 3    0! 3 "!   T0 ¢ 3 ! 0  ! ¢ 3  8¥ 0T¢ 3 a

(2)

0 U%2¢ 3 A0 3Thus 1  ! ¢ . Since ¥ has A0 2% ¢ 3  ¢strictly convex

is the difference between

a stric£ tly
over .

positive
Thus 1 

definite
 %$

#   and its first order Tay£ lor
Jacobian everywhere in int ,
 with equality holding iff 

expansion around
the potential   is
.

 § © A0 %2¢ 3  S0X!¢ 3¢  ¢ aT£ he

Perceptron algorithm is motivated by . The corresponding divergence

the
is 1



identity


link
¨4 4



¥

, with weight domain
4¨4 76 8 For Winnow the

HL¢ ¤ ¦  ¥¦ ¨

HL¢ ¤ ¦  ¦¥¨

)  =¡&¤ ¦£ ¨

¡

¦ =&¡ % '(0¤ 1) ¨

¦ =2¡ %3'(¤ )1 ¨



 

¦ 

 

¦

ML4685 7 !¤ 9)  ¥)  ¨

£¡ ¥¢ §¤ ¦©¨ 

£¡ ¢¥¤!©¦ ¨ # "$

) =&¡ §¤ ¦©¨

(0  %  3 Figure 1: HL as a function of for the two Figure 2: The matching loss

  0  3  !#" )' " T0 1 %81 3 acases

£,

 % 3 ©weight domain is

© QD ' W ! ¨¥ ¢ 0 U%2¢ 3#dA iv0© eB rDgeC n© c¨¦ e§FrH1EeGGlated%t© o

. ML@ 85 7

 thC is© .

lNin  oktefut.hnTactthinoeonlwiinsk thfuenu£ cnti-,onbnouritms tahliemzecudosmtrlepileoatininveneintewtn£itsreo. ployg1ar i!thm.

The

The following key property immediately follows from the definition of the divergence 1  .

¨¥Lemma 1 [KW98] For any  £

and ¢

D %C¢

6¥

£
int

:

1  0  %C¢ 6 3 ! 1  0! %C¢ D 3 ! 1  T0 ¢ D 2% ¢ 6 3  !0  ! ¤¢ D 3  0 ¥80T¢ D 3 ! S¥ X0 ¢ 6 323 a

In this paper we focus on a single neuron using a hard threshold as the transfer function (see

beginning of the introduction). We will view such a neuron in two ways. In the standard

1     0  3view the neuron is used for binary classification. It outputs

trying to predict the

1 $desired label using a threshold . In the new view the neuron is a regressor. It outputs the

 ¥V§  ¥V§linear activation

and is trying to predict

.

X0 I1 % 1  3  D 1 ! 1 ¥ 6 % "A@For classification $we use the linear

we use the discrete loss DL hinge loss (HL) parameterized

by

a

thr6es4 hold

4
:

7

. For regression

 %` ¥¤§ &0( %  3  D 0 R S 0  3 ! R 8 0  23 3 0  ! $ 3  T0 1 % 1 3  ! $ aFor any

  HL   6

DL 4 4

Note that the arguments in the two losses DL and HL are switched. This is intentional and

will be discussed later on.

 X0 ¢   %  3 ¢It can be R S0  23 3 ¢ ¢ & 0X¢   %  3 D 0 R S#! 0 " 3 !¨FS')0 " 3C3   0XF & 0( 3 !loss w.8r.t.

easily is

showHn Lthat

can only take the

HL three

values6

0,

is

convex , and

in

and that . Note

tthheatg¤ radient

of

this

mentioned in the introduction.

¢    $¤Strictly speaking, this gradient is not defined when

equals the threshold . But we

will show in the subsequent sections that even in that case has the properties we need.

 I Figure 1 provides a graphical representation of HL . The threshold function "transfers"

  ¢   1  86 !#&" 9% )' "A@the linear activation

to a prediction which is a hard classification in

.

(For the remaining discussion of this section we can assume with no loss of generality that
$the threshold is 0.) Smooth transfer functions such as the tanh are commonly used 1   0  3in neural networks, e.g., PIRQ T§ S , and relative loss bounds have been proven when

the comparison class consists of single neurons with any increasing differentiable transfer
function [HKW95, KW98]. However, for this to work a loss function that "matches" the transfer function has to be used. This loss is defined1 as follows [HKW95] (see Figure 2):

ML@

587

X0 1

8% 1 3

  @ 85 R7 WRY(X `
VU @ 85 7 W Ya`



c0 b

3

!

1

1 b 261 @ 85 7 0T1 % 1  3 a

 0 3 The matching loss for cb

b is the square loss (linear regression) and the matching

 0 3  0 3§loss for b dIRQ 2S cb is the entropic loss (logistic regression), which is defined as:

subs1cInrip[Ht rK%W' 9i5n]sttehaednooftar tioton

e 4Thf g2i1g6p q is used for the matching loss ML4587 stress a connection between the matching loss

hf 2g £i g6p q . We use here the and the divergence that

is discussed at the end of this section.

ML@ 85 7 X0 1 %81 3  d #! "&(% )' "¡  and 1

D 6

40 U" !
IQ

13 2§ QS 0



¦§


3

DD ¥ ¦¦

Y Y

X

40 !#' S" 6D(% )'40 " "

' 3

1
.

3 ¦§ 2D2D PP
These

a 1Y
Y X The entropic loss is finite when
1 1 are the ranges for and needed

¥
for

logistic regression. We now want to use this type of loss for classification with linear

1 % 1 ¥6S#! "S(% ')"&@threshold   D 04#! " 3e !increased

functions, i.e., when until in the limit it becomes

the

hard

and the threshold

slope ¢ of the ¤£ . Obviously,

tanh
¦

function
¡ 

is

 D 0 )' " 3  'and ¦

¢  for any slope ¢ . Thus the matching loss is infinite for all slopes.

Also, the known relative loss bounds based on the above notion of matching loss grow with

the slope of the transfer function. Thus it seems to be impossible to use the matching loss
when the transfer function is the hard threshold £ . However, we can still make sense of

the matching loss by viewing the neuron as a regressor. The matching loss is now rewritten

as another Bregman divergence:

¥
ML@

0(

%



3



¦ §X
§  c0 b 3 !

 0  301 b

 0where  @ is any function such that ©@ ¨
function tanh while keeping and

a bHoLve£ 0 lo%ss3 beco0 m £ e0s t3 w! ice£ t0h eC3 3li0(n e3!ar 

  @ 0( 3 "!  @ 0  3 ! 0  !  3  0  3  1 @ 0( %  3 % (3)  3   0  3 . We now increase the slope of the transfer fixed. In the limiting case (hard thr¥eshold £ ) the 0( %  3Vhinge loss with threshold zero, i.e., ML@ 3 a Finally, observe that the two views of the neuron

are related to a duality property [AW98] of Bregman divergences:

1 @ 85 7 T0 1 % 1  3 

ML@ 587 0X1I% 1  3 

¥
ML@

0(

%



3

21

@

0 

%



3

a

(4)

3 The algorithms

In this paper we always associate two general additive algorithms with a given

link function: a classification algorithm and a regression algorithm. Such algo-

rithms, given in the next table, correspond to the two views of a linear thresh-

old neuron discussed in the last section. For brevity, we will call the two al-

gorithms "the classification algorithm" and "the regression algorithm", respectively.

GFIPLnoraeserbntdae.inlc¡a:ctdieod:1An.£"&:c%¥ la£1% S6s£¥Vba s#! bai fi§aS" c(%F©a)' Sti0X"&o¢ @ n£Qa lgo£ 3rithm:

¡  S" %Gen. add.
For Instance:
 £Prediction:
Label:2

re£%g£¥barae §ass¢©io£n  1£ 



algorithm:
£

cwrliTilntahhhDUesimeD¢laspieirsdLficT£crfaPlacero0Xacet1acDrstettei£se:tvi%8iihovafi1len¥ote£ci¦ss3oraaseDtntl:ighgor¥Seone6D£X0ris.¢in4ast1Thlfii££gomh3non!e!irtpaiel1to6lrhg£"les`0am4osdA1 bri£fecirotl!tehrscmt1Aew£hi£ evwwi3 tehceistl£ hau1&ass£tsehliafieHbLUcseLaH¢iiplngt&diL1eT£no(00(aPa£ntorDC0e££ f¥ah%:3 l(£,1ign¥%£S6£aog¦3.!#nr.£eDTid&3 "StTlhh o(%8¥thmih')s0Tsee6¢Ds&"a:iu0 srs£4@pes3,tdguh! w0arreeeth6eds£siss30XiltsiFe!ohoc&fanrt 0(hettathe1 e£20le£e3grle!o£to wg32rs3Rirsote0FAhDsa&0ms£lL0ig#!£4oT0wo3C£2n1$3r3 i3£i.att%hhl£T1gm£ihot3 ess-,

are equivalent. The update of the regression algorithm is motivated by the minimization

problem:
¢ T£ QP D   

¢argmin

)

0T¢

3 where )

0T¢

3

1  0T¢

2% ¢

£43 '3¢ HLAT0 ¢

  £ %  4£ 3 a

By setting the gradient
pi¥ nl¦ agDcineS¥ gqX0 ¢u¢ il£4T£i3Pb!rD iu 6m 0X£F bSeyX0q¢ u a£T£ QPti Deon¢ £

of
2£th3 a! t£

) 0T¢ 3 R&h0 o l4£d23 s3
, i.e.,

w.r.t.

¢ £aT£ QPt aD

the
W e¥

¢ to zero we get 0T¢ 3minimum of ) :

th¢ e T£ PQfoD llow -

a¦ppD ro¥8x0TiV¢ m£a3 te!ly6

so0Xlv e0(th£ i3 s!

equ a0 ti£o3Cn3 

£by 

re-
a

2This is a short-hand meaning "!$&# (% ' if g $! #&%0) and "$! #213' if g !$#2(1 ) .

B¥8T0o¢ th3

 ¢versions and

o¥8f0T¢

th3 e 

Pe0 r¦c§ e0TpW trD o3 nb% ca caada n% ¦d§

0XW © 323Winnow are obtained , respectively.

by

using

the

link

functions

4 Relative loss bounds

The following lemma relates the hinge loss of the regression algorithm to the hinge loss of
an arbitrary linear predictor  .

LeHmLmAa0  

2
£

%

D

F4£o3 r 01

all  ¥ £ ! HLA0! A!0 U2% ¢ 4£ 3

!



,


¢



1

£ £% 0

¥

£

int
3'

£

, £ HL&0!

%2¢ £TQP Db3 ' 1

¥


 ¤ 0T¢

,
£

%







£

%2$)V¥ § 4£ 3

£ %C¢ T£ PQD 3C3



and ¡¢  

D
6

0`1 

£

!

:
1 £43 (0  £

"! 



4£ 3

(5)

¢¢

PT00r¢HooL£ fC3 S.73 0 W  £ e% 

hX0 £4¢a3 v£!e

!

H1 L !0 A3U 0!%2¢

6



£0



R3 £8 !% 0





1
£

£43 3

0 '

!

H%CR¢ LS£T&0 QP0!D£4323 3 ' 

££

1

%





T0 V¢ £ 4£ C3 3 6

a

C%0 ¢RS £T0PQ D 4£ 33 ! R0 &0 ! £ C3 ¢3
The first equality

(0 £ 3£  ! 0£¢ 
follows

T0 ¢  T£PQ2£D 3 3 !
Lemma

1

and the second
 (0  £9%  £ 3 ¥¤ (0  £ %  £ 3 ¦uses HL

follows from the as a divergence

u1 p@ date

rule

of the regression algorithm. The (see (4)) and again Lemma 1.

last

equality

¡ By summing the first equality of (5) over all trials we could relate the total HL of the regression algorithm to the total HL of the regressor  . However, our goal is to obtain

tbcoA loauis£HnnsBQtidefiD src6pD oar0`tne1i ot£ tnh! ealt1ngo£4uoo3 mr0iatbshe!mar .oliWfn mee aiur£s3sttaeh krteehssDeho§soe1nlcdA to!0hUcnelda%2c¢selsqaibD sfiu3 saei!lrfii,tcy1wa toii!0tofUhn(2%5t¢ha)leagIH nosQP adrDimts3 hue'mmt.hA urIept£H sQB oihsDvoetl1 hdrAea0T$r¢leluf£Bos%Cre¢ etdri£TnabQP alysbDtu:3©t¨rhaea l

 1& £  A1 £ ¢ T£ PQD  ¢ £Note that the sums in the above equality are unaffected by trials in which no mistake occurs.

In such trials,

and

. Thus the above is equivalent to the following, where

SmTA ihan£ekcieose srte6Dhame0`6D m1A`0s£13Aie s¦!£ttL!Vao£A1 kef£ 1et3t£4.r 3i Ta1 0lh£s! e0£ in1An! £68fwow&" rh%bh£aeiecvba!nhea2£ 3r¡C%ayB#2£¥m¨3@ iDsb¥ t§ea1D£katAhne§ 0ed1 owAsc1 eC%e!0cU¢tuh!0 or2%aD s¢fv3C%:te¢V!rDbi3 aHI1 'lPQAs0!DiAU n%3 %2$w£¢ hHIicPQwh1 D eAt3 hT0g'¢eetcA£ tlC% ha¢ £ess£TfiPQofiDblcl13©ao¨AtwiX0ao¢i¦nn£ga2% tl¢ hgeoT£ oPrriDteh3 m¨m:a



Throughout the rest of this
$ mance of a linear threshold

cselacstsioifinetrh e

cwlaitshsitfihcreastihoonldalgorit h.mWies

compared now apply

to the perforTheorem 3 to

¢ D  the Perceptron algorithm with

, giving a bound i.t.o. the average margin of a linear

threshold classifier  with threshold  on a trial sequence :

!  Y     "  D " A £  A1 £    £ .

Sdw4  eihnpbecey4r!ene)d1 4¨eY4£nct4.h#£e4 6 eoBrn(eyi¢nt' ,h ceaa6 fnnuofdcopresrdl¡esa¡ ttoe)¥¥urt1.u  lTeh2,X.0,4iAsS$$ t3 g5hi4 n£ievc.eelW4s.hiun1h.ssAe.Tt§0Tnh¢h6" e"w2eoX £7offe%2o6"r¢"3 $e5ltslhmo0o£TeQPlwv¨ 3D eii63nntega h qebiusoraA uaelinsnt£uyd altoriobnnfigtt%6rhT$iaenhr¨4 4eyne qouv"£urm4¨eea4 c66mbltieotyrr3,ofwof&i6 sr$me44airstetpal44kl0'eateahc6ss6 ee:t,

!  Y Note that in the usual mistake bound for the Perceptron algorithm the average  is re-

  ¡ £  1 £   £placed by §

 .3 Also, observe that the predictions of the Perceptron algorithm

$  ¢ D  with  and

are not affected by ¢ . Hence the previous bound holds for any

 ¢  .

Next, we apply Theorem 3 to a normalized version of Winnow. This version of Winnow

keeps weights in the probability simplex and is obtained by a slight modification of Win-

$   6  ¥ ¤§ ©  ¢  '£¢ @now's link function. We assume

 and choose ¤

  4¨4 4¨4 .

Unlike the Perceptron algorithm, a Winnow-like algorithm heavily depends on the learning

rate, so a careful tuning is needed. One can show (details omitted due to space limitations)

)! Y  ' ' ! § $ P D ¨  £¢ ¥¤ ¨¦ § ©that if ¢ is such that ¢ 

¢ '¦¨§

6

 then this normalized version of

Winnow achieves the bound

4

4

¢ !  Y

'3¢

1 ` 0  £' ¢

C% ¢ Db3 0! ¨¦ §

¥§ ¤

$

¨¦ § ©
6

PQD

¨

%

0 2% ¢ D 3 ¢ Dwhere 1  

is the relative entropy between the two probability vectors  and .

Conclusions: In the full paper we study the case when there is no consistent threshold 

more carefully and give more involved bounds for the Winnow and normalized Winnow
algorithms as well as for the -norm Perceptron algorithm [GLS97].

References

[AW98] [Bre67]

K. Azoury and M. K. Warmuth", "Relative loss bounds and the exponential family of distributions", "1998", Unpublished manuscript.
L.M. Bregman. The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming. USSR Computational Mathematics and Physics, 7:200­217, 1967.

[FS98] Y. Freund and R. Schapire. Large margin classification using the perceptron algorithm. In 11th COLT, pp. 209­217, ACM, 1998.
[GLS97] A. J. Grove, N. Littlestone, and D. Schuurmans. General convergence results for linear discriminant updates. In 10th COLT, pp. 171­183. ACM, 1997.
[HKW95] D. P. Helmbold, J. Kivinen, and M. K. Warmuth. Worst-case loss bounds for sigmoided linear neurons. In NIPS 1995, pp. 309­315. MIT Press, 1995.
[KW97] J. Kivinen and M. K. Warmuth. Additive versus exponentiated gradient updates for linear prediction. Inform. and Comput., 132(1):1­64, 1997.
[KW98] J. Kivinen and M. K. Warmuth. Relative loss bounds for multidimensional regression problems. In NIPS 10, pp. 287­293. MIT Press, 1998.

[KWA97] J. Kivinen, M. K. Warmuth, and P. Auer. The perceptron algorithm vs. winnow: linear vs. logarithmic mistake bounds when few input variables are relevant. Artificial Intelligence, 97:325­343, 1997.
[Lit88] N. Littlestone. Learning when irrelevant attributes abound: A new linearthreshold algorithm. Machine Learning, 2:285­318, 1988.

[Lit89] N. Littlestone. Mistake Bounds and Logarithmic Linear-threshold Learning Algorithms. PhD thesis, University of California Santa Cruz, 1989.

[Lit91] N. Littlestone. Redundant noisy attributes, attribute errors, and linear threshold learning using Winnow. In 4th COLT, pp. 147­156, Morgan Kaufmann, 1991.

  3The average margin p

may be positive even though is not consistent.

