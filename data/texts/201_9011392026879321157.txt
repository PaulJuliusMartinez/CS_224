From: AAAI-96 Proceedings. Copyright © 1996, AAAI (www.aaai.org). All rights reserved. 

Learning  to  Parse  Database  Queries 
Using  Inductive Logic  Programming 

Department  of  Mathematics  and  Computer  Science 

John  M.  Zelle 

Drake  University 

Des  Moines,  IA  50311 

jz60ilrQacad.drake.edu 

Abstract 

This  paper  presents  recent  work  using  the  CHILL 
the  con- 
parser  acquisition  system  to  automate 
struction  of a  natural-language 
interface  for  data- 
base  queries.  CHILL treats  parser  acquisition  as 
the  learning  of search-control  rules  within  a  logic 
program  representing  a  shift-reduce  parser  and 
uses  techniques  from  Inductive  Logic  Program- 
ming  to  learn  relational  control  knowledge.  Start- 
ing  with  a general  framework  for  constructing  a 
suitable  logical  form,  CHILL is  able  to  train  on  a 
corpus  comprising  sentences  paired  with database 
queries  and  induce  parsers  that  map  subsequent 
sentences  directly  into  executable  queries.  Exper- 
imental  results  with  a  complete  database-query 
application  for  U.S.  geography  show  that  CHILL 
is  able  to  learn  parsers  that  outperform  a  pre- 
existing,  hand-crafted  counterpart.  These  results 
demonstrate  the  ability  of a  corpus-based  system 
to  produce  more  than  purely  syntactic  represent- 
ations.  They  also  provide  direct  evidence  of  the 
utility  of  an  empirical  approach  at  the  level  of  a 
complete  natural  language  application. 

Introduction 

interest 

Recent  approaches 

Empirical  or  corpus-based  methods 
for  constructing 
natural 
language  systems  has  been  an  area  of  grow- 
ing  research 
in  the  last  several  years.  The 
empirical  approach  replaces  hand-generated  rules  with 
models  obtained  automatically  by  training  over  lan- 
to  constructing 
guage  corpora. 
from  corpora  primarily  use  statistical 
robust  parsers 
and  probabilistic  methods  such  as  stochastic  grammars 
(Black,  Lafferty,  &  Roukaos  1992;  Periera  &  Shabes 
1992;  Charniak  &  Carroll  1994)  or  transition  networks 
(Miller  et  al.  1994). 
Several  current  methods  learn 
some  symbolic  structures  such  as  decision  trees  (Black 
et  al.  1993;  Magerman  1994;  Kuhn  &  De  Mori  1995) 
and  transformations 
(Brill  1993).  Zelle  and  Mooney 
(1993,  1994)  h ave  proposed  a  method  called  CHILL 
based  on  the  relational 
learning  techniques  of Inductive 
Logic  Programming. 

1050  Natural Language 

Raymond  J.  Mooney 

Department  of  Computer  Sciences 

University  of  Texas 
Austin,  TX  78712 
mooneyQcs.utexas.edu 

To  date, 

information. 

these  systems  have  been  demonstrated 
primarily  on  the  problem  of  syntactic  parsing,  group- 
into  hierarchical  constitu- 
ing  the  words  of  a  sentence 
ent  structure.  Since  syntactic  analysis 
is  only  a  small 
part  of  the  overall  problem  of understanding, 
these  ap 
proaches  have  been  trained  on  corpora  that  are  “arti- 
ficially”  annotated  with  syntactic 
Simil- 
arly,  they  are  typically  evaluated  with  artificial  metrics 
of  parsing  accuracy.  While  such  metrics  can  provide 
rough  comparisons  of  relative  capabilities, 
it  is  not 
clear  to  what  extent  these  measures  reflect  differences 
in  performance  on  real  language-processing 
tasks.  The 
acid  test  for empirical  approaches  is whether  they  allow 
the  construction  of  better  natural  language  systems,  or 
perhaps  allow  for  the  construction  of  comparable  sys- 
tems  with  less  overall  effort.  This  paper  reports  on  the 
experience  of  using  CHILL  to  engineer  a  natural 
lan- 
guage  front-end 

for  a  database-query 

task. 

A  database-query 

task  was  a  natural  choice  as  it 

represents  a significant  real-world  language-processing 
problem  that  has  long  been  a  touch-stone 
in  NLP  re- 
search.  It  is  also  a  nontrivial  problem  of  tractable  size 
and  scope  for  actually  carrying  out  evaluations  of  em- 
pirical  approaches.  Finally,  and  perhaps  most  import- 
antly,  a  parser  for  database  queries  is  easily  evaluable. 
The  bottom  line  is  whether  the  system  produces  a  cor- 
rect  answer  for  a given  question,  a determination  which 
is  straight-forward 

for  many  database  domains. 

Learning  to  Parse  DB  queries 

Overview  of  CHILL 
Space  does  not  permit  a  complete  description  of  the 
CHILL system  here.  The  relevant  details  may  be  found 
in  (Zelle  &  Mooney  1993;  1994;  Zelle  1995).  What 
follows  is  a  brief  overview. 

The  input  to  CHILL is  a set  of training  instances  con- 
sisting  of sentences  paired  with  the  desired  parses.  The 
output  is  a shift-reduce  parser  that  maps  sentences  into 
parses.  CHILL treats  parser  induction  as  a  problem  of 
learning  rules  to  control  the  actions  of  a  shift-reduce 

as  definite-clause 

parser  expressed  as  a  Prolog  program.  Control-rules 
are  expressed 
concept  definitions. 
These  rules  are  induced  using  a general  concept  learn- 
ing  system  employing  techniques  from  Inductive  Logic 
(ILP)  a subfield  of machine  learning  that 
Programming 
addresses 
logic 
descriptions 
(Lavraz  &  Dz’eroski 1994; 
Muggleton  1992). 

the  problem  of  learning  definite-clause 

from  examples 

themselves. 

The  central 

For  example, 

is  syntactic  analysis, 

insight  in  CHILL  is  that  the  general  op- 
for  a  shift-reduce  parser  to  produce 
erators  required 
inferable 
a  given  set  of  sentence  analyses  are  directly 
if 
from  the  representations 
the  fact  the  the  parser 
the  target 
requires  a  reduction 
to  combine  a  determiner  and  a 
noun  to  form  an  NP  follows  directly  from  the  existence 
of  such  an  NP  in  the  training  examples.  However,  just 
inferring  an  appropriate  set  of operators  does  not  pro- 
duce  a  correct  parser,  because  more  knowledge  is  re- 
accurately  during  the  course 
quired  to  apply  operators 
of  parsing  an  example. 

The  current  context  of  a  parse  is  contained 

in  the 
contents  of  the  stack  and  the  remaining 
input  buffer. 
CHILL uses  parses  of the training  examples  to figure  out 
the  contexts 
in  which  each  of  the  inferred  operators  is 
and  is  not  applicable.  These  contexts  are  then  given  to 
a  general  induction  algorithm  that  learns  rules  to  clas- 
sify  the contexts  in which  each  operator  should  be used. 
Since  the  contexts  are  arbitrarily-complex  parser-states 
involving  nested  (partial)  constituents,  CHILL employs 
learning  algorithm  which  can  deal  with  struc- 
an  ILP 
tured 
inputs  and  produce  relational  concept  descrip- 
tions. 

Figure  1  shows  the  basic  components  of  CHILL. 
the  training  ex- 
During  Parser  Operator  Generation, 
to  formulate  an  overly-general 
amples  are  analyzed 
shift-reduce  parser  that  is  capable  of  producing  parses 
from  sentences.  The  initial  parser  is  overly-general 
in 
it  produces  a  great  many  spurious  analyses  for 
that 
any  given  input  sentence. 
the 
training  examples  are  parsed  using  the  overly-general 
parser  to  extract  contexts 
in  which  the  various  parsing 
operators  should  and  should  not  be  employed.  Control- 
then  employs  a  general  ILP  algorithm 
Rule  Induction 
to  learn  rules  that  characterize 
these  contexts.  Finally, 
“folds”  the  learned  control- 
Program  Specialization 
rules  back  into  the  overly-general  parser  to  produce  the 
final  parser. 

In  Example  Analysis, 

Previous  experiments  have  evaluated  CHILL'S per- 
formance  in  learning  parsers  to  perform  case-role  pars- 
ing  (Zelle  &  Mooney  1993)  and  syntactic  parsers  for 
(Zelle  &  Mooney  1994; 
portions  of  the  ATIS  corpus 
1996). 
that 
CHILL  works  as  well  or  better  than  neural-network  or 

These  experiments  have  demonstrated 

Control Exampks 

I 

Figure  1:  The  CHILL  Architecture 

statistical  approaches  on  comparable  corpora. 

The  query 
form  similar 

is  a  logical 
representation 

Parsing  DB  Queries 
For  the  database-query 
Overview  of  the  Problem 
task,  the  input  to  CHILL  consists  of  sentences  paired 
with  executable  database  queries. 
lan- 
guage  considered  here 
to 
typically  pro- 
the  types  of  meaning 
duced  by  logic  grammars 
(Warren  &  Pereira  1982; 
Abramson  8z  Dahl  1989).  The  semantics  of  the  rep- 
that  ex- 
resentation 
ecutes  queries  and  retrieves  relevant  information 
from 
the  database.  The  choice  of  a  logical  query  language 
rather  than  the  more  ubiquitous  SQL  was made  because 
the  former  provides  a  more  straight-forward, 
compos- 
itional  mapping  from  natural 
property 
for  the  CHILL  approach. 
The  process  of translating  from  an unambiguous  logical 
form  into  other  query  formats  is  easily  automated. 

is  grounded  in  a  query  interpreter 

language  utterances-a 

is  necessary 

that 

The  domain  of  the  chosen  database 

is  United  States 
geography.  The  choice  was  motivated  by  the  availabil- 
ity  of an existing  natural  language  interface  for  a simple 
geography  database.  This  system,  called  Geobase  was 
supplied  as  an  example  application  with  a  commercial 
Prolog  available  for  PCs,  specifically  Turbo  Prolog  2.0 
(Borland  International  1988).  Having  such  an  example 
provides  a database  already  coded  in  Prolog  for  which 
a  front-end  can  be  built;  it  also  serves  as  a  convenient 
benchmark  against  which  CHILL'S performance  can  be 
compared. 

Learning  1051 

What  is the capital of the state with the largest population? 
answer (C,  (capital  (S ,C) ,  largest  (P,  (state  6)  , 
population(S,P))))). 

What  are the major cities in Kansas? 
answer(C,  (major(C),  city(C), 
equal(S,stateid(kansas) 

1)). 

loc(C,S), 

Form 

Type 
country  countryid(Name) 
city 
state 
river 
place 

cityid(Name,  State) 
stateidclame) 
riverid(Name) 
placeid(Name) 

Example 
countryid(usa) 
cityid(austin,tx) 
stateidctexas) 
riverid(colorado1 
placeidcpacif 
ic) 

Figure  2:  Sample  Database  Queries 

Figure  3:  Basic  Objects 

in  Geoquery 

The  Geobase  data  contains  about  800  Prolog  facts 
tables  for  basic  information  about 
asserting  relational 
including:  population,  area,  capital  city, 
U.S.  states, 
neighboring 
states,  major 
rivers,  major  cities,  and 
highest  and  lowest  points  along  with  their  elevation. 
Figure  2  shows  some  sample  questions  and  associated 
query  representations. 

a  framework 

Development  of  the  database  application 

required 
for  parsing 
work  on  two  components: 
into  the  logical  query  representations, 
and  a  specific 
query  language  for  the  geography  database.  The  first 
component 
and  consists  of  al- 
gorithms  for  parsing  operator  generation  and  example 
analysis  to  infer  the  required  operators  and  parse  the 
training  examples.  The  resulting  parsing  framework  is 
quite  general  and  could  be  used  to  generate  parsers  for 
a  wide  range  of  logic-based  representations. 

is  domain-independent 

The  second  component,  which  is  domain  specific,  is 
a query  language  having  a  vocabulary  sufficient  for  ex- 
pressing 
interesting  questions  about  geography.  The 
database  application  itself  comprises  a parser  produced 
by  CHILL  coupled  with  an  interpreter 
for  the  query 
language.  The  specific  query  language  for  these  exper- 
iments  (hereafter  referred  to  as  Geoquery)  was  initially 
developed  by  considering  a  sample  of  50  sentences.  A 
simple  query 
interpreter  was  developed  concurrently 
with  the  query  language, thus  insuring  that  the  rep 
resentations  were  grounded  in  the  database-query 
task. 
The  query lan- 
The  Query  Language,  Geoquery 
guage  considered  here  is  basically  a  first-order 
logical 
form  augmented  with  some  higher-order  predicates  or 
for  handling  issues  such  as  quantifica- 
meta-predicates, 
tion  over  implicit  sets.  This  general  form  of representa- 
tion  is  useful  for  many  language  processing  tasks.  The 
particular  constructs  of  Geoquery,  however,  were  not 
designed  around  any  notion  of appropriateness 
for  rep 
language  in  general,  but  rather 
resentation  of  natural 
translating  Eng- 
as  a  direct  method  of  compositionally 
lish  sentences 
logic-oriented  data- 
base  queries. 

into  unambiguous, 

The  most  basic  constructs  of  the  query  representa- 
tion  are  the  terms  used  to  represent 
the  objects  refer- 
enced  in  the  database  and  the  basic  relations  between 
in  Figure  3.  The 
them.  The  basic  forms  are  listed 

1052  Natural Language 

objects  of  interest  are  states,  cities,  rivers  and  places 
(either  a  high-point  of  low-point  of  a  state).  Cities 
are  represented  using  a two  argument 
term  with  the 
second  argument  containing 
the  abbreviation  of  the 
state.  This 
since  dif- 
ferent  states  may  have  cities  of  the  same  name  (e.g. 
cityid(columbus,oh) vs.  cityid(columbus,ga)). 
This  convention  also  allows  a  natural  form  for  express- 
ing  partial 
information;  a city  known  only  by  name  is 
given  an  uninstantiated  variable  for  its  second  term. 

is  done  to  insure  uniqueness, 

Form 
capital(C) 
city(C) 
major(X) 
place  (PI 
river(R) 
state  6) 
capital(C) 
area6 
,A) 
capital  (S ,C) 
equal (V , C) 
density(S,D) 
elevation(P,E) 
high-point  (S ,P) 
higher(Pl,P2) 
loc(X,Y) 
low-point  (S ,P) 
len(R,L) 
next-to  61  ,S2) 
size(X,Y) 
traverse  (R, S) 

Predicate 
C is a capital (city). 
C is a city. 
X is major. 
P is a place. 
R is a river. 
S is a state. 
C is a capital (city). 
The area of S is A. 
The capital of S is C. 
variable V is ground term C. 
The  (population) density of S is P 
The elevation of P is E. 
The highest point of S is P. 
Pl’s elevation is greater than P2’s. 
X is located in Y. 
The lowest point of S is P. 
The length of R is L. 
Sl  is next to S2. 
The size of X is Y. 
R traverses S. 

Figure  4:  Basic  Predicates 

in  Geoquery 

The  basic  relations  are  shown  in  Figure  4.  The 
equal/2  predicate  is  used  to  indicate  that  a certain  vari- 
able  is  bound  to  a  ground  term  representing  an  object 
in  the  database.  For  example,  a  phrase  like  “the cap 
translates  to (capital(S,C), equal@, 
italofTexas” 
than  the  more  traditional 
stateid(texas) 
,C).  The  use  of  equal  al- 
capital(stateid(texas) 
to  be  introduced  at  the  point  where  they 
lows  objects 
are  actually  named  in  the  sentence. 

))  rather 

Although  the basic  predicates  provide  most  of the ex- 
pressiveness  of Geoquery,  meta-predicates  are  required 
to  form  complete  queries.  A  list  of  the  implemented 
is  shown  in  Figure  5.  These  predicates 
meta-predicates 

Form 
answer  (V , Goal) 
largest 

(V,  Goal) 

(V ,Goal) 
smallest 
highest 
(V ,Goal) 
lowest  (V ,Goal) 
longest 
shortest(V,Goal) 
c0udD,God,C) 

(V , Goal) 

most  (X,D,Goal) 

fewest  (X,D,Goal) 

(with  elevation). 

Explanation 
V is  the  variable  of  interest  in  Goal. 
Goal  produces  only  the  solution 
that  maximizes  the  size of  V 
Analogous  to  largest. 
Like  largest 
Analogous  to  highest. 
Like  largest 
Analogous  to  longest. 
c  is  count  of unique  bindings  for  D 
that  satisfy  Goal. 
Goal  produces  only  the  X 
that  maximizes  the  count  of  D 
Analogous  to  most. 

(with  length). 

Figure  5:  Meta-Predicates 

in  Geoquery 

is  answer/S. 

in  that  they  take  completely-formed 

of  the  meta-predicates 
serves  as  a  “wrapper” 

are  distinguished 
conjunctive  goals  as  one  of  their  arguments.  The  most 
important 
This 
for  query  goals  indic- 
predicate 
ating  the  variable  whose  binding  is  of  interest 
(i.e.  an- 
swers  the  question  posed).  The  other  meta-predicates 
provide  for  the  quantification  over  and  selection  of  ex- 
tremal  elements  from  implicit  sets. 
Although  the 
A  Parsing  Framework 
logical  representations 
look  very  differ- 
ent  from  parse-trees  or case-structures  on which  CHILL 
has  been  previously  demonstrated, 
they  are  amenable 
to  the  same  general  parsing  scheme  as  that  used  for 
the  shallower  representations.  Adapting  CHILL to  work 
with  this  representation 
requires  only  the  identification 
and  implementation  of  suitable  operators  for  the  con- 
struction  of  Geoquery-style 

of  Geoquery 

for  Queries 

analyses. 

into  operator  clauses 

The  parser  is  implemented  by  translating  parsing  ac- 
for  a  shift-reduce  parser. 
tions 
involves  three  dif- 
The  construction  of  logical  queries 
Initially,  a  word  or  phrase 
ferent  types  of  operators. 
at  the  front  of  the  input  buffer  suggests 
that  a  cer- 
tain  structure  should  be  part  of  the  result.  The  ap 
propriate  structure 
is  pushed  onto  the  stack.  For  ex- 
ample,  the  word  “capital”  might  cause  the  capital/2 
predicate  to  be  pushed  on  the  stack.  This  type  of  op 
eration 
Ini- 
tially,  such  structures  are  introduced  with  new  (not  co- 
referenced)  variables.  These  variables  may  be  unified 
with  variables  appearing 
in  other  stack  items  through 
operator.  For  example,  the  first  argu- 
a  co-reference 
ment  of  the  capital/2 
structure  may  be  unified  with 
I  pre- 
the  argument  of  a  previously 
dicate.  Finally,  a  stack 
into 
the  argument  of  another  stack  item  to  form  conjunct- 
ive  goals  inside  of  meta-predicates; 
this  is  performed 
by  a  conjoin 

is  performed  by  an  introduce 

item  may  be  embedded 

operation. 

operator. 

introduced 

state/ 

introduce 

inferred.  The  necessary 

For  each  class  of  operator, 

the  overly-general  op 
erators  required  to  parse  any  given  example  may  be 
easily 
operators 
are  determined  by  examining  what  structures  occur 
in  the  given  query  and  which  words  that  can  intro- 
duce  those  structures  appear  in  the  training  sentence. 
operators  are  constructed  by finding  the 
Co-reference 
each  shar- 
shared  variables 
ing  requires  an  appropriate  operator 
Fi- 
nally,  con join  operations  are  indicated  by  the  term- 
embedding  exhibited 
It  is 
important 
to  note  that  only  the  operator  generation 
phase  of  CHILL  is  modified  to  work  with  this  repres- 
entation;  the  control-rule 
learning  component  remains 
unchanged. 

in  the  training  examples. 

in  the  training  queries; 

instance. 

iox&. 

introduces  populat 

operators  for  the  variables 

is  on  the  top  of  the  stack, 

introduces  capital/a, 
“largest” 
introduces 

As  an  example  of  operator  generation, 

the  first 
oper- 
query  in  Figure  2  gives  rise  to  four  introduce 
intro- 
“state” 
ators:  “capital” 
duces  state/i, 
and 
largest/2 
“population” 
initial 
The 
parser-state  has  answer/2  on  the  stack,  so  its  intro- 
duction  is  not  required.  The  example  generates 
four 
(e.g.,  when 
co-reference 
capital/2 
its  second  ar- 
gument  may  be  unified  with  the  first  argument  of 
answer/Z,  which  is  below  it). 
the  example 
produces  four  conjoin 
is  on  the  top  of  the  stack,  state/i 
is  “lifted”  into  the 
second  argument  position  from  its  position  below  in the 
stack.  Conversely,  when  population/2 
is  on  the  top  of 
the  stack,  it  is  “dropped”  into  the  second  argument  of 
largest/2 
Similar  operators 
embed  capital/2 
into  the  conjunction 
that  is  the  second  argument  of  answer/Z. 

to  form  the  conjunction. 

operators.  When 

and  largest/2 

largest/2 

Finally, 

Experimental  Results 

Experiments 
A  corpus  of  250  sentences  was  gathered  by  submitting 
a  questionnaire 
to  50  uninformed  subjects.  For  evalu- 
ation  purposes,  the corpus  was split  into  training  sets  of 
225  examples  with  the  remaining  25  held-out  for  test- 
ing.  CHILL  was  run  using  default  values  for  various 
parameters. 

Each 

Testing  employed  the  most  stringent  standard  for ac- 
curacy,  namely  whether  the  application  produced  the 
correct  answer  to  a  question. 
test  sentence  was 
parsed  to  produce  a  query.  This  query  was  then  ex- 
ecuted  to  extract  an  answer  from  the  database.  The 
extracted 
to  the  answer 
produced  by  the  correct  query  associated  with  the  test 
sentence. 
Identical  answers  were  scored  as  a  correct 
parsing,  any  discrepancy  resulted  in  a failure.  Figure  6 
shows  the  average  accuracy  of  CHILL’S parsers  over  10 

answer  was  then  compared 

Learning  1053 

ably  does  not  represent  a  state-of-the-art 
standard  for 
natural  language  database  query  systems,  neither  is it  a 
“straw  man.”  Geobase  uses  a  semantics-based  parser 
which  scans  for  words corresponding 
to  the  entities  and 
relationships  encoded  in  the  database.  Rather  than  re- 
lying  on  extensive  syntactic  analysis, 
the  system  at- 
tempts  to  match  sequences  of  entities  and  associations 
in sentences  with  an entity-association  network  describ- 
ing the schemas  present  in  the  database.  The  result  is  a 
relatively  robust  parser,  since  many  words  can  simply 
be  ignored.  That  CHILL  performs  better  after  training 
on  a  relatively  small  corpus  is  an  encouraging  result. 

Related  Work 

learned 

interpretation. 

rather 

than  semantic 

As  noted  in  the  introduction,  most  work  on  corpus- 
based  parsing  has  focused  on  the  problem  of  syn- 
interpretation. 
tactic  analysis 
However,  a  number  of  groups  participating 
in  the 
for  speech  under- 
ARPA-sponsored  ATIS  benchmark 
to  perform  some 
standing  have  used 
rules 
semantic 
from 
(Pieraccini  et  al.  1992)  used  an  approach  based 
AT&T 
on  stochastic  grammars.  Another  approach  employ- 
is  the  Hidden  Understanding 
ing  statistical 
techniques 
Models  of  Miller,  et.  al. 
(1994).  Kuhn  and  De  Mori 
(1995)  have investigated  an  approach  utilizing  semantic 
classification 
trees,  a  variation  on  decision  trees  famil- 
iar  in  machine  learning. 

The  Chronus  system 

These  approaches  differ  from  work  reported  here  in 
that  learning  was  used  in  only  a  one  component  of  a 
larger  hand-crafted  grammar.  The  ATIS  benchmark 
is  not  an  ideal  setting  for  the  evaluation  of  empirical 
components  per  se,  as  overall  performance  may  be  sig- 
nificantly  affected  by  the  performance  of  other  com- 
ponents  in  the  system.  Additionally, 
the  hand-crafted 
portions  of  these  systems  encompassed  elements  that 
were  part  of the  learning  task  for  CHILL. CHILL  learns 
to  map  from  strings  of  words  directly 
into  query  rep- 
resentations  without  any  intermediate  analysis;  thus,  it 
essentially  automates  construction  of  virtually 
the  en- 
tire  linguistic  component.  We  also  believe  that  CHILL'S 
relational  learning  algorithms  make  the  approach  more 
flexible,  as  evidenced  by  the  range  of  representations 
for  which  CHILL has  successfully 
learned  parsers.  Ob- 
jective  comparison  of  various  approaches 
to  empirical 
NLP  is  an  important  area  for  future  research. 

Future  Work  and  Conclusions 

Clearly,  there  are  many  open  questions  regarding 
the 
practicality  of using  CHILL for  the  development  of NLP 
systems.  Experiments  with  larger  corpora  and  other 
domains  are  indicated.  Another 
interesting  avenue  of 
to  which  performance  can 
investigation 

is  the  extent 

Figure  6:  Geoquery:  Accuracy 

trials  using  different  random  splits  of training  and  test- 
ing data.  The  line  labeled  “Geobase”  shows the  average 
accuracy  of the  Geobase  system  on  these  10 testing  sets 
of  25  sentences.  The  curves  show  that  CHILL  outper- 
forms  the  existing  system  when  trained  on  175  or more 
examples. 
In  the  best  trial,  CHILL's induced  parser 
comprising  1100  lines  of  Prolog  code  achieved  84%  ac- 
curacy  in  answering  novel  queries. 

it  is  important 

In  this  application, 

to  distinguish 
between  two modes  of failure.  The  system  could  either 
fail  to  parse  a  sentence  entirely,  or  it  could  produce  a 
query  which  retrieves  an  incorrect  answer.  The  parsers 
learned  by  CHILL  for  Geoquery  produced  few  spuri- 
ous  parses.  At  175  training  examples,  CHILL produced 
3.2%  spurious  parses,  dropping  to  2.3%  at  200  ex- 
amples.  This  compares 
favorably  with  the  3.8%  rate 
for  Geobase. 

in  two  ways.  First, 

into  queries  without  intermediate 

Discussion 
These  results  are  interesting 
they 
show  the  ability  of  CHILL  to  learn  parsers  that  map 
sentences 
syntactic 
parsing  or  annotation.  This  is  an  important  consider- 
ation  for  empirical  systems  that  seek  to  reduce  the  lin- 
guistic  expertise  needed  to construct  NLP  applications. 
Annotating  corpora  with  useful  final  representations 
is 
a  much  easier  task  than  providing  detailed 
linguistic 
annotations.  One  can  even  imagine  the  construction  of 
suitable  corpora  occurring  as  a natural  side-effect  of at- 
tempting  to  automate  processes  that  are  currently  done 
manually  (e.g.  collecting  examples  of  the  queries  pro- 
duced  by  database  users  in  the  normal  course  of  their 
work). 

Second,  the  results  demonstrate 

the  utility  of an  em- 
pirical  approach  at  the  level  of  a  complete  natural- 
language  application.  While  the  Geobase  system  prob- 

1054  Natural  Language 

the  regularity 

in  the  training  corpus 

be  improved  by  corpus  “manufacturing.” 
Since  an  ini- 
tial  corpus  must  be  annotated  by  hand,  one  method 
of  increasing 
(and 
hence  the  generality  of  the  resulting  parser)  would  be 
to  allow  the  annotat0.r  to  introduce  related  sentences. 
Although 
this  approach  would  require  extra  effort  from 
the  annotator, 
it  would  be  far  easier  than  annotating  an 
equal  number  of  random  sentences  and  might  produce 
better  results. 

techniques 

of  automated 

The  development 

could  also  broaden 

the  generation  of  introduce 

icon  construction 
of  CHILL. Currently, 
erators  relies  on  a  hand-built 
words  can 
(1995)  has  demonstrated 
based  acquisition 
use  with  CHILL-Style parser  acquisition 

for  lex- 
the  applicability 
op- 
indicating  which 
Thompson 
an  initial  approach  to  corpus- 
of  lexical  mapping  rules  suitable  for 

various  predicates. 

introduce 

systems. 

lexicon 

We  have  described 

a  framework  using  ILP  to  learn 
parsers  that  map  sentences 
into  database  queries  us- 
ing  a  training  corpus  of  sentences  paired  with  queries. 
This  method  has  been  implemented 
tem,  which  treats  parser  acquisition  as  the  learning  of 
search-control 
rules  within  a  logic  program  represent- 
results  with 
ing  a  shift-reduce 
for  answering  questions  about 
a  complete  application 
show  that  CHILL's parsers  outperform 
U.S.  geography 
a  pre-existing  hand-crafted 
counterpart.  These  results 
demonstrate 
to  learn  semantic  map 
pings  and  the  utility  of  an  empirical  approach  at  the 
application.  We 
level  of  a  complete  natural-language 
hope  these  experiments  will  stimulate 
further  research 
in  corpus-based 

parser.  Experimental 

that  employ  ILP. 

CHILL's ability 

techniques 

in  the  CHILL sys- 

Acknowledgments 

Portions  of  this  research  were  supported  by  the  National 
Science  Foundation  under  grant IRI-9310819. 

References 

31-37. 

Linguistics, 

Abramson,  H.,  and  Dal&  V.  1989. Logic  Grammars.  New 
York:  Springer-Verlag. 
Black,  E.;  JeIineck,  F.;  Lafferty,  J.;  Magerman,  D.;  Mer- 
cer,  R.;  and  Roukos,  S.  1993. Towards  history-based 
grammars:  Using  richer  models  for  probabilistic  parsing. 
In  Proceedings  of  the  31st  Annual  Meeting  of  the  Associ- 
ation  for  Computational 
Black,  E.;  Lafferty,  J.;  and  Roukaos,  S.  1992.  Devel- 
opment  and  evaluation  of  a  broad-coverage  probabiIistic 
grammar  of  English-language  computer  manuals.  In  Pro- 
ceedings  of  the  30th  Annual  Meeting  of  the  Association 
for 
Computational 
Borland  International.  1988.  Turbo  Prolog  2.0  Reference 
Guide.  Scotts  Valley,  CA:  Borland  International. 
BriII,  E.  1993.  Automatic  grammar  induction  and  parsing 
free  text:  A  transformation-based  approach. 
In  Proceed- 
ings  of  the  31st  Annual  Meeting  of  the  Association  for 
Computational 

Linguistics,  185-192. 

Linguistics, 

259-265. 

25-32. 

Techniques  and  Applications. 

Inductive  Logic 
Ellis  Hor- 

Char&&,  E.,  and  Carroll,  G.  1994. Context-sensitive 
statistics  for  improved  grammatical  language  models.  In 
Proceedings  of  the  Twelfth  National  Conference  on  Art@- 
cial  Intelligence. 
Kuhn,  R.,  and  De  Mori,  R.  1995. The  application  of  se- 
mantic  classification  trees  to  natural  language  understand- 
ing.  IEEE  Transactions 
on  Pattern  Analysis  and  Machine 
Intelligence  17(5):449-460. 
Lavrae,  N.,  and  Dzeroski,  S.,  eds.  1994. 
Programming: 
wood. 
Magerman,  D.  M.  1994.  Natrual  Lagnuage  Parsing  as 
Statistical  Pattern  Recognition.  Ph.D.  Dissertation,  Stan- 
ford  University. 
Miller,  S.;  Bobrow,  R.;  Ingria,  R.;  and  Schwartz,  R.  1994. 
Hidden  understanding  models  of natural  language.  In Pro- 
ceedings  of  the  3Znd  Annual  Meeting  of  the  Association 
for 
Computational  Linguistics, 
Muggleton,  S. H.,  ed.  1992.  Inductive  Logic  Programming. 
New  York,  NY:  Academic  Press. 
Periera,  F.,  and  Shabes,  Y.  1992. Inside-outside  reestim- 
In  Proceedings  of 
ation  from  partially  bracketed  corpora. 
the  30th  Annual  Meeting  of  the  Association 
for  Computa- 
tional  Linguistics,  128-135. 
Pieraccini,  R.;  Tzoukermann,  E.;  Z.  Gorelov,  J.  L.  G.; 
Levin,  E.;  Lee,  C.  H.;  and  Wilpon,  J. 
1992.  A  speech 
understanding  system  based  on  statistical  representation 
of semantics.  In  Proceedings 
Thompson,  C.  A.  1995.  Acquisition  of  a  lexicon  from 
In  Proceeding  of 
semantic  representations  of  sentences. 
for  Computa- 
the  33rd  Annual  Meeting  of  the  Association 
tional  Linguistics,  335-337. 
Warren,  D.  H.  D.,  and  Pereira,  F.  C.  N.  1982.  An  efficient 
easily  adaptable  system  for  interpreting  natural  language 
queries.  American  Journal  of  Computational 
Linguistics 
8(3-4):110-122. 
Zelle,  J.  M.,  and  Mooney,  R.  J.  1993.  Learning  semantic 
grammars  with  constructive  inductive  logic  programming. 
In Proceedings  of  the  Eleventh  National  Conference  on  Ar- 
tificial  Intelligence,  817-822. 
Zelle,  J.  M.,  and  Mooney,  R.  J.  1994.  Inducing  determin- 
istic  Prolog  parsers  from  treebanks:  A  machine  learning 
approach.  In  Proceedings  of  the  Twelfth  National  Confer- 
ence  on  Artificial 
Zelle,  J.,  and  Mooney,  R.  1996.  Comparative  results  on 
using inductive  logic  programming  for corpus-based  parser 
construction. 
In  Wermter,  S.;  Riloff,  E.;  and  Scheler,  G., 
eds.,  Symbolic,  Connectionist, 
and  Statistical  Approaches 
for  Natural  Language  Processing.  Springer 
to  Learning 
Verlag. 
ZeIle,  J.  M.  1995. Using  Inductive  Logic  Programming 
of  Natural  Language  Pars- 
to  Automate 
ers.  Ph.D.  Dissertation,  University  of  Texas,  Austin,  TX. 
available  via  http://  cs.utexas.edu/users/ml. 

92.  1-193-I-196. 

the  Construction 

Intelligence, 

748-753. 

ICASSP 

Learning 

1055 

