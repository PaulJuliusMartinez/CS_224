Letters to the Editor

A New Horizon for Information Science
Sir:
In their article "Toward a New Horizon in Information Science" (JASLS, 46:6, July 199S), Hjorland and Albrechtsen make some curious statementsabout statistical and probabilistic retrieval. The authors seemto be unaware that in an ageof full-text retrieval where millions of full-text documents are often available for processing, the normal retrieval conditions (small collections of document abstracts with little linguistic context) are no longer valid.
As the authors say, "the meaning of a word can only be understood from the context in which it appears." But all the context one would want to have is now readily available. The result is that the language ambiguity problem is pretty well solved becausethe meaning of words becomes clear from the available local and global contexts (Callan, 1994; Kraus, Mittendorf, & Schauble, 1994; Salton & Buckley, 1991, 1993).
It is easy,for example, to distinguish information about Indira Gandhi, the former Indian prime minister, from text about the Mahatma Gandhi, even though both of thesepersonalities were well-known, Indian politicians with a close relationship betweenthem (Salton, Allan, Buckley, & Singhal, 1994). Analogously, there will be little problem distinguishing the various meanings of the term "gold" usedby the authors asan example.
Meaning resolution is not at all a thesaurus problem, becausethe large full-text collections available for analysis operate as an implicit thesaurus. The authors say that "statistical and probabilistic retrieval seem to be blind with regard to the problems of interpretations." In fact, there is no better approach to meaning interpretation than by using the large and small contexts now available with full-text in intelligent ways.
The authors end with a particularly ignorant and shortsighted statement, "little further improvement in retrieval effectiveness can be expected employing these approaches (statistical and probabilistic retrieval) ." Actually, asthe results of the objective TREC experiments have shown over the last 4 years, very large improvements (better than 20% in averagerecall and precision) have been obtained from year to year for the collections (800,000 full-text documents) incorporated in TREC between 1992 and 1993 and again between 1993 and 1994,and similar advantagesare expected for the testsnow under way in 1995. The statistical approaches have proved to be by far the most potent, outperforming linguistic, cognitive, and other apparently more sophisticated methods (Harman, 19931995).
Ignoring the completely changed conditions under which information retrieval activities are now taking place, forgetting all the accumulated evidence and test data, and acting as if we

were stuck in the nineteenth century with controlled vocabularies, thesaurus control, and all the attendant miseries, will surely not contribute to a proper understanding and appreciation of the modern information sciencefield.
Gerard Salton"
References
Callan, J. P. ( 1994). Passage-level evidence in document retrieval. Praceedings SIGIR `94 (pp. 30 l-3 10). Berlin: Springer Verlag.
Harman, D. K. (Ed.). ( 1993-1995). The First Text Retrieval Conference(TREC l), NIST Special Publication 500-207, National Institute of Standards and Technology, Gaithersburg, MD, March 1993; also The Second TREC Retrieval Conference(TREC 2), NIST Special Publication 500-205, March 1994; also The Third TREC Retrieval Conference (TREC 31, NIST Special Publication 500-225, April 1995.
Kraus, D., Mittendorf, E., & Schauble, P. ( 1994). Improving a basic retrieval method by links and passage level evidence. Text Retrieval Conference, Washington, D.C., November 1994.
Salton,G., Allan, J., Buckley, C., & Singhal, A. ( 1994). Automatic
analysis, theme generation and summarization of machine-readable texts, Science, 264, 142 1- 1428. Salton, G., &Buckley, C. ( 199 1). Global text matching for information retrieval. Science,253, 10 12- 10 15. Salton, G., & Buckley, C. (1993). Approaches to passage retrieval in full text information systems. ProceedingsSIGIR Conferenceon Research and Development in Information Retrieval, Pittsburgh, June 1993.
Rejoinder: A New Horizon for Information Science
Sir:
I am indeed impressed by the results that professor Gerard Salton and coworkers have accomplished in the field of statistical and probabilistic information retrieval (IR), text-summarization and the like. Salton representsan almost classicalparadigm in computer science and IR and his work represents a very straightforward approach to basic problems in IR. Recently his new break-through in IR has been displayed worldwide in the scientific pressas well as in the mass-media. (I read, e.g., an article in "The Economist", where a summary was produced by the statistical method developed by professor Salton).
I therefore regret that our article about domain-analysis

0 1996 John Wiley & Sons, Inc.

* Deceased.

JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE. 47(4):333-335, 1996

CCC 0002~8231/96/040333-03

( Hjorland & Albrechtsen, 1995) has given rise to Dr. Salton's annoyance (Salton, 1995).
The question we raisedwasthe epistemological status of Information Science(IS) and whether the existing theories, paradigms, etc. are a sufficient basis for an IS that tries to gain an independent status in relation to computer scienceand other fields. In my opinion domain-analysis presentsa new, broader and more explicit approach in IS, which will prove itself extremely useful for IS.
First I would like to point out an important agreement between me and Dr. Salton. He writes: "The authors seemto be unaware that in an age of full-text retrieval where millions of full-text documents are often available for processing,the normal retrieval conditions (small collections of document abstractswith little linguistic context) are no longer valid."
Yes, I agreeon this precondition, and our article does not stateotherwise. Theories in IS should not build on restrictions imposed by either the paper-basedpublication systemor by databaseswith limited amounts of data such as typical bibliographical databases,citation indexes, etc. The existenceof fulltext databases,the possibility of making hypermedia links to other records in other databasesand possible value added information to full-text records should be regardedasthe precondition for scientific and theoretical studiesin modem IS. In this regard, there is no conflict betweenDr. Salton's view and mine.
In this ocean of electronic texts, links, and value added information, what is the basic problem of IS?Well this is broadly recognized,I think, asthe facilitation of information transfer to the users(cf. Ingwersen, 1992). Traditional areasof IS include classification, indexing, knowledge representation, information seeking, search logic, and relevancejudgments. All these traditional problems must of coursebe reconsideredin the new reality consisting of full-text retrieval, World Wide Web, etc.
From this perspective, I have reformulated the basic problem of IS ashow to measurethe informational value of dtfirent "subject accesspoints" in databases(or systemsof connected databases). One full-text record consists of elements such as title, abstracts,introduction, methodology, results, conclusion, and references.When is it fruitful to use words from titles as subject accesspoints? When is it fruitful to use the words in abstractsor the words in some section of the complete text record? When is it fruitful to use descriptors and classifications? (That is value added information addedby information professionals.) When do referencesrepresent a useful accesspoint, as utilized in citation indexes?How can the name of the journal in which the paper is published be used in IR? How are single papers connected implicitly or explicitly and how can knowledgeabout these connections be utilized in information seeking? Of course real life information seekingalways involves a combination of many different subject accesspoints. Online IR is really an art, where trained information specialistsuse a lot of skills and talent. A major problem for IS is to formulate more explicit theories and knowledge about how different access points are utilized and combined by competentsearchers-and how competent subject analysts can produce value added information to representationsof documents.
One basic principle in this approach is that no kind of subject accesspoints can be evaluated in isolation, but should be evaluated in the context of the full range of existing access points. For example there is no need to add descriptorsto records if they do not contribute to increasing retrieval effectiveness.Another basic principle is that the measurement or evaluation of single subject accesspoints in naturalistic surroundings

must precedeany systemsdevelopment. You cannot build systems if you do not know the informational value of, say, abstracts or references.And the relative value of such elementsas abstracts,titles, references,etc. forms part of a much broader area than the artificial elements such as descriptors and classification symbols created by information professionals. The foundation of IS therefore lies in types of documents and structures in and between documents. Documents are regarded in their functionality asinformation sourcesto usergroups.
A fundamental question is whether a full-text document is always a good-enough representation of itself. If this was the case,no value added information provided by information specialists would be necessary.At first glance,it seemsobvious that a full-text representation should representan optimal representation of itself. But deeperreflections and empirical studiesindicate that this is not necessarilythe case.For instance, studies with full-text records compared to records indexed by the MEDLINE-thesaurus seemto indicate that the value-added information done by the MEDLINE-staff can, in fact, improve the retrieval effectiveness.I do not regard studies in this field as conclusive yet, but Z think that it is both scientifically and ethically bestto assumethe usefulnessof other professionalpeople's work, until evidenceproves otherwise.
The question whether a text is an optimal representation of itself raisesnew questions such as: What are we using "subject accesspoints" for? What are we trying to identify? What is the "subject" of a document? Is it something objective inherent in the document? Or is it something subjective seenin the documents by the individual user?This question implies deep philosophical questions. But zfyou haveno answerto thesequestions, your judgment of relevanceand henceyour measurementof recall andprecision is unsupported.I have treated thesequestions in Hjorland ( 1992). My philosophical arguments are closely related to the American pragmatic philosophy developed by John Dewey ( 1948) and others.
And now to the usefulnessand limitations of the statistical and probabilistic approach to IR: I think it must alwaysbe necessaryfor a scientific field to consider the potential benefitsand limitations of any single approach. In my opinion, IS has had all too little debateabout its different approaches,and therefore I am now glad to participate in a debateabout this.
Dr. Salton was especiallyannoyed with the sentencein our article "little further improvement in retrieval effectivenesscan be expectedfrom it [statistical and probabilistic approaches]." This was a citation from Ellis'( 1990) conclusion. I used that citation to show that one leading textbook in the field seemsto sharemy view, that the statistical approach has its limitations. However, as Dr. Salton's letter has documented, major advanceshaveindeed beenmade,and our uncommented citation of Ellis'statement on this issueseemsto be premature.
In spite of the documented effectivenessof the statistical approach, there is, however, a need to examine its basic assumptions and limitations. Professor Salton states:". . . there is no better approach to meaning interpretation than by using the large and small contexts now available with full-text in intelligent ways."
Maybe I agree also in this statement. But I would like to present two very different paradigms, which can function as guidelines for intelligent researchersin this regard. The first is the approach used in the fields of "composition studies" (in journals like "Written Communication"), the same approach that I am advocating in domain analysis. The other approach is the more traditional statistical approach.

334 JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE-April 1996

A basic assumption in Domain Analysis is that the domain representsthe unit of study for IS. The type of documents used, the structuresin publications and the terminology applied in the documents all reflectsan adaption to the special needsand conditions of a particular discipline or "`discourse community. " When we shall uselargeand small contexts availablein full-text in an intelligent way. a basic hypothesisis, that the discipline or discoursecommunity representsa major independent variable.'
An important way to study the communication patterns, document types, and information structures in domains is to study the historical developmentof the communication structure in the domain2 An important empirical investigation of abstractingfrom a domain-analytic point of view hasbeendone by Tibbo ( 1993). This work demonstratesthat criteria for developing abstractsshould be domain-specific, not universalistic.
Therefore the major method advocatedby the domain analytic approach is historical, functional, and qualitative analysis of document tyipes,communication patterns, and te,xtarchitectures with the domain or discourse community as functional unit.3 From such qualitative studies,important hypothesesregarding statistical patterns can be produced, and we are closer to our goal regarding the measurement of the informational values of different subject accesspoints in databases.
A good example is the problem of the relative value of citations versustext terms in IR. By studying the development and culture of citing behavior in different domains, we are able to develop a deeperunderstanding, which can be applied in a theory about the informational value of referencesin IR, that is, a theory about the effectivenessof citation indexes as compared to other kinds of systemssuch asdescriptor basedsystems.
The statistical and probabilistic approach to IR has, on the other hand, mostly been concerned with word frequencesand with algorithms where the underlying assumption often seems to be the existenceof a universal structure in texts or databases (the opposite of the basic assumption in domain-analysis). I supposeDr. Salton will agree,that the statistical approach in IS is very different from the proposed historical, functional, and qualitative analysis suggestedabove.
It is well known, that any quantitative analysis always presupposesa good qualitative analysis. I have tried to show, how domain analysis tries to make assumptions that can provide good qualitative analysis. But what method-besides using contexts in "intelligent ways"-can the statistical and probabilistic approach offer to produce fruitful hypothesesabout independent variables?It seemsto me, that the "intelligent behavior" in this approach must be more guided by "trial and error"
'Howevermanydomainscanhaveidenticalinfluencesbecauseof either basicneedsand conditionsare sharedin differentdomainsor becauseof transdisciplinaryinfluencesof ideologicakl inds.
'Also, in order to understandthe real(as opposedto the formal) functionsof documents,it becomesnecessartyo relatedocumenttypologyandstructureto basicepistemological assumptions. It is a wide-
spread assumption, that much published material is not serving scientific or pragmatic progress, but only presentational purposes. Just as it is only interesting to study real-life IR if it is done by competent searchers, it is only interesting to study documentary forms and architectures if they are serving real progress, not just playing science games.
3 Transdisciplinary influences, of course, are also important to
study.

than by any systematicinvestigation of the attributes of the textual structures under investigation.
It is however possible, that this approach either by chance or by insight can discover important statistical relations, that both can be used straightforwardly for effective retrieval and could also contribute with knowledge similar to that sought with domain-analysis. Hopefully the two approachescan supplement eachother in this way.
But I think, that asa paradigm for IS, domain analysisis the most attractive becauseit is broader in the sense,that much more existing researchcan be incorporated in this paradigm. It is easierfor domain analysisto include the statistical approach as one method, than the reverse.Paradigmatic pluralism is of coursefruitful, but paradigms which exclude valuable research are negative. Much researchin IS (and other social sciencesas well) has believed extremely strongly in "technological fixes," and thereby made it difficult for more qualitative oriented approachesto develop a platform. There hasbeena reductionistic tendency in IS-research,which has made it difficult to develop theories about major concepts such as user groups, kinds of knowledge, etc.
A final word about human beings. It seemsto me, that some paradigms in IS try to replace human-based information retrieval (in databases)with algorithms used by computers. Another goal that seemsmore promising to me would be to make IR a conscious,transparent processin which computer and human user interact to produce the most efficient result. If this is not the case,then the algorithms are used by people, who do not know by what criteria the information is selectedor what goals are determining the relevance of the selectedand nonselectedinformation. The selection of information is done, so to speak,behind the back of the users.In this case,people could easily become victims of ideologies instead of conscious,welleducatedpeople,who areresponsiblefor their own information provision and learning. From this perspectiveI also must recommend a further interest in domain analysis.
Birger HjtirIand RqvaI School of Librarianship 6 Birketinget DK-2300 CopenhagenS, Denmark E-mail: bh@db.dk
References
Dewey, J. ( 1948).Reconstructionisn philosophy.Enlarged Edition.
Boston: The Beacon Press. (Original edition published 1920)
Ellis, D. ( 1990). Neil; horizonsin informationretrieval.London: The
Library Association. Hjorland, B. ( 1992). The concept of "subject" in information science.
Journalof Documentation4,8(2), 172-200.
Hjorland, B. & Albrechtsen, H. ( 1995). Toward a new horizon in in-
formation retrieval: Domain analysis. Journalof theAmericanSocietyfor InformationScience4,6,400-425. Ingwersen, P. ( 1992). Informationretrievalinteraction.London: Tay-
lor Graham. Salton, G. ( 1996). A new horizon for information science [Letter to
the editor]. JournaloftheAmericanSocietyforInformationScience,
47, 333.
Tibbo, H. R. ( 1993). Abstractingi,nformationretrievalandthehumanities.Chicago: American Library Association.

JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE-April 1996 335

