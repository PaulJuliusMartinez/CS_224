Towards an overview of spatial up-conversion techniques

Meng Zhao*, Jorge A. Leitao*and Gerard de Haan+*

*Eindhoven University of Technology, The Netherlands 

+Philips Research Laboratories Eindhoven, The Netherlands 

m.zhao@tue.nl

Abstract: The introduction  of  High definition television  (HDTV) asks  for spatial  up-conversion 
techniques  enabling  the  display  of  standard  definition  material  (SDTV).  The  paper  provides  an 
overview  of  some  important  linear  and  non-linear  methods.  We  further  include  a  performance 
evaluation  using  a  Mean  Square  Error  criterion  and  show  relevant  screen  shots  to  allow  for  a 
subjective impression obtained with the described algorithms. 

Keywords: Image enhancement, spatial up-conversion, up-scaling 

1.    Introduction 
 

such 

as 

techniques 

techniques  are 

The  advent  of  HDTV  emphasizes  the  need  for 
spatial  up-conversion 
that  enable 
standard  definition  (SD)  video  material  to  be 
viewed  on  high  definition  (HD)  television  (TV) 
linear 
displays.  Conventional 
interpolation  methods 
bilinear 
interpolation and methods using poly-phase low-
pass  interpolation  filters.  The  former  is  not 
popular  in  television  applications  because  of  its 
low  quality,  but 
in 
commercially  available  ICs,  like  [1].  With  the 
linear methods, the number of pixels in the frame 
is  increased,  but  the  high  frequency  part  of  the 
spectrum  is  not  extended,  i.e.  the  perceived 
sharpness of the image is not increased. In other 
words,  the  quality  of  the  display  is  not  fully 
exploited.  To 
problem,  LTI 
(Luminance Transition Improvement) after linear 
up-conversion 
up-
conversion techniques have been proposed [7]. 
 

and  many 

the 

latter 

is  available 

solve 

this 

non-linear 

The class of non-linear methods can be divided 
into  directional 
interpolation  methods  and 
classification  based  methods.  The 
former 
interpolates  the  pixels  using  edge  information. 
The aim is to avoid interpolation across the edge, 
which  would  cause  the  result  image  to  appear 
blurred.  The  directional  interpolation  methods 
include ELA (Edge-directed Line Averaging) [2], 
which  has  been  designed  mainly 
for  de-
interlacing  purpose,  and  NEDI  (edge-directed 
interpolation) [3], which was intended for image 
scaling.  The  content-based  (or  classification 
include  DRC 1
based) 

interpolation  methods 

(Digital Reality Creation) [4] and RS (Resolution 
Synthesis) [5], which are quite similar techniques 
that differ only in their classification method. We 
have chosen DRC to represent the content-based 
techniques,  because  it  has  been  introduced  in 
television  sets  on 
the  consumer  electronics 
market. 
 

To enable a comparison of the mentioned spatial 
up-conversion methods, we first down-sample the 
input image or the video sequence by a factor of 
four,  and  then  up-scale  it  to  the  original  size. 
Finally, we compare the up-scaled result with the 
original  one,  using  an  objective  quality  metric, 
the MSE (Mean Square Error). 
 

The  remainder  of  the  paper  is  organized  as 
follows. In section  2,  we will  briefly  present the 
evaluated  up-conversion  algorithms.  The  actual 
evaluation  is  given  in  Section  3.  Finally,  in 
section 4, we draw our conclusions. 

2.    Advanced up-conversion algorithms 
 

In this Section, we shall give a brief introduction 
to each non-linear up-conversion techniques to be 
covered in our evaluation. 
 
A. DRC 
 

)+'

+'9LGHR

6LJQDO

/3)

'RZQ
VDPSOLQJ

6'9LGHR6LJQDO

/HDVW6TXDUH

0HWKRG

)6'

$'5&

&ODVVFRGH
/87RI,QWHUSRODWLRQ

FRHIILFLHQW

 

Fig. 1. The learning process in DRC 

1 What we describe as Digital Reality Creation (DRC) is the 
method  revealed  in  US-patent  5,444,487,  [5].  We  believe 

‚ÄúDRC‚Äù is commonly used to refer to this method, although 
the patent does not mention this name. 

Basically, DRC is a data dependent interpolation 
filter  [4].  The  momentary  filter  coefficients, 
during interpolation, depend on the local (block) 
content of the image, which can be classified into 
classes  based  on  the  pattern  of  the  block.  To 
obtain  the  filter  coefficients,  a  learning  process 
should be performed in advance. Shown in Figure 
1,  the  learning  process  employs  both  the  HD-
video  and  the  SD  video  as  the  training  material 
and  uses  the  LMS  (Least  Square  Method) 
algorithm  to  get  the  optimal  coefficients.  The 
training process is computational intensive due to 
the large number of classes. Fortunately it needs 
to  be  performed  only  once.  In  practical  systems, 
classification  of  luminance  blocks  is  realized  by 
using ADRC (Adaptive Dynamic Range Coding) 
[6], which for 1-bit per pixel encoding reduces to: 

4

=

(cid:29)(cid:19)
Ô£±
Ô£≤
(cid:29)(cid:20)
Ô£≥

)
)
<
6' )
)
‚â•

$9

(1) 

$9

6'

Here 
and 

6') is the luminance value of the SD pixel 
$9)
pixels in the  current aperture. 4 is the  encoding 

is  the  average  luminance  value  of  the 

result  of  ADRC.  Other  classification  techniques 
can be thought of, the reason to use ADRC is its 
simple implementation. Using eq. (1), the number 
of classes  decreases  from 
aperture containing 12 pixels shown in Figure 2.  
 

(cid:27) to  212  with  an 

L

L

L

L

L

)

)

)

)

)

)

&

$

'

%

)

)

)

)

)

)

M

M

M

M
 

M

M

M

+,) ). 
) a

Figure 2. Aperture used in content-based interpolation.  
The  white  pixels  are  interpolated  HD  pixels  (

corresponds 

The  black  pixels  are  SD  pixels  (
shorthand  notation  for 
that 
to 
interpolated using 12 SD pixels (
B,  C  and  D  are  interpolated  with  the  same  aperture 
using coefficients from a ‚Äúmirrored‚Äù class. 
 

6') ),  with
(cid:11)(cid:21)(cid:12)(cid:15)(cid:22)
L
M
(cid:12)(cid:12)(cid:22)
) ). Pixels 
) up to 

, etc.  The  HD  pixel  A 
is 

(cid:12)(cid:21)(cid:15)(cid:20)(cid:11)6')
(cid:11)(cid:21)(cid:11)
)+,

+

+

,

+,)

+')

To clarify the use of LMS in the training process, 
let 
be  the  luminance  value  of  the  real  (not 
be  the 
the  up-converted)  HD  pixel  and 
interpolated one, which is the summed weight of 
the 12 SD pixels in the interpolation window. The 
equation used to interpolate pixels on position A 
is: 

=
(cid:11)(cid:21)(cid:15)(cid:20)(cid:12)(cid:21)
N

(cid:12)(cid:12)(cid:22)
(cid:15)(cid:21)(cid:11)M
(cid:12)(cid:22)
+
+
)Z
L
(cid:11)(cid:21)(cid:11)
+
NOZ are  weights.  The  square  error  of  one 
H

=
O
where 
class over a large number of images is: 

(cid:11)(cid:21)(cid:11)L
+,)
‚àë‚àë

(cid:12)(cid:20)(cid:12)(cid:21)
O
+

L)
(cid:15)(cid:11)

M
L
(cid:12)(cid:15)(cid:11)

‚àë

(cid:12)(cid:12)

)

(2) 

(3) 

=
N

(cid:11)

+

+

‚àí

=

M

M

6'

NO











+'

+,

ML


Suppose  we  have  t samples  for  one  class  in  the 
training process, 

The error of the pth interpolation sample will be: 

(cid:11)(cid:21)(cid:11)
L
) S+,
+
‚àë‚àë





M
(cid:11)(cid:21)(cid:12)(cid:15)(cid:22)
)Z

+

(cid:12)(cid:12)(cid:22)
=
(cid:11)(cid:21)(cid:11)
L

+

NO

6'



S

=
N

=

O



=

H
)

S

S+'



=

)
)
‚àí
S+'

)Z
‚àë‚àë
‚àí 
=
N

S+,

NO

=





O



(cid:11)(cid:21)(cid:11)

L

+



S

6'

The total error of this class is: 

(cid:11)(cid:21)(cid:15)(cid:20)(cid:12)(cid:21)
(cid:12)(cid:20)(cid:12)(cid:21)
O
M
N
+
+
+
(cid:12)
(cid:15)(cid:17)(cid:17)(cid:17)(cid:15)(cid:21)(cid:15)(cid:20)
(cid:11)
S =
W

(4) 

(cid:12)(cid:20)(cid:12)(cid:21)
O
(cid:11)(cid:21)(cid:15)(cid:20)(cid:12)(cid:21)
N
M
+
+
+
S =
W
(cid:12)
(cid:11)
(cid:15)(cid:17)(cid:17)(cid:17)(cid:15)(cid:21)(cid:15)(cid:20)

(5) 

H



SH



‚àë
= W
=


S

(6) 

H

S

H to each w

W

S



=

Calculate the first derivative of 
H ‚àë
‚àÇ
(cid:11)(cid:21)
Z
‚àÇ
=

S
(cid:21)
‚àë
= W
=


H
‚àÇ
HZ
(cid:12)
‚àÇ
L
)
(cid:11)(cid:21)(cid:11)
+
N
(cid:11)

N
(cid:11)(cid:21)(cid:15)(cid:20)(cid:12)(cid:21)
+
O
(cid:30)(cid:21)(cid:15)(cid:20)(cid:15)(cid:19)
=
=

6'

NO

NO

S

S

S



O
(cid:12)(cid:20)(cid:12)(cid:21)
M
+
+
(cid:12)(cid:22)(cid:15)(cid:21)(cid:15)(cid:20)(cid:15)(cid:19)





S

NO

TU

6'

;

M
+

(7) 
We  know  that  the  extreme  occurs  when the  first 
derivation is zero. Let: 
(cid:11)(cid:21)(cid:11)
L
)
(cid:11)(cid:21)(cid:15)(cid:20)(cid:12)(cid:21)
N
‚àë
= W
+
+
=
(cid:11)(cid:21)(cid:11)
L
) S
(cid:11)(cid:21)(cid:15)(cid:20)(cid:12)(cid:21)
T
M

S
+
‚ãÖ
+
(cid:11)(cid:21)(cid:11)
L
)
N
M
(cid:11)(cid:21)(cid:15)(cid:20)(cid:12)(cid:21)
+
+
+
) S+'
(cid:11)(cid:21)(cid:12)(cid:15)(cid:22)
(cid:11)(cid:21)(cid:11)
L
M
(cid:12)(cid:12)(cid:22)
‚ãÖ
+
+
(cid:15)(cid:30)(cid:21)(cid:15)(cid:20)(cid:15)(cid:19)
(cid:15)(cid:11)
TN
(cid:12)(cid:22)(cid:15)(cid:21)(cid:15)(cid:20)(cid:15)(cid:19)
UO
=

O
(cid:12)(cid:20)(cid:12)(cid:21)
+
+
(cid:12)(cid:20)(cid:12)(cid:21)
U
+
O
(cid:12)(cid:20)(cid:12)(cid:21)
+

‚àë
= W
=


and: 

<

(8) 

(9) 

+
ON

=

6'

6'



S

S



(10) 









=














(cid:23)


(cid:23)


(cid:23)


(cid:23)

Ô£π
Ô£∫
Ô£∫
Ô£∫
Ô£∫
Ô£∫
Ô£∫
Ô£ª

Ô£Æ
Ô£Ø
Ô£Ø
Ô£Ø
Ô£Ø
Ô£Ø
Ô£Ø
Ô£∞

Ô£π
Ô£∫
Ô£∫
Ô£∫
Ô£∫
Ô£∫
Ô£∫
Ô£ª

Ô£π
Ô£∫
Ô£∫
Ô£∫
Ô£∫
Ô£∫
Ô£∫
Ô£ª

;
;
;
;

;
;
;
;

;
;
;
;

Z
Z
Z
Z

(cid:22)
(cid:22)
(cid:22)
(cid:23)
(cid:22)

<
Ô£Æ
<
Ô£Ø
Ô£Ø
<
Ô£Ø
Ô£Ø
Ô£Ø
<
Ô£Ø
Ô£∞

We get: 
Ô£Æ
Ô£Ø
Ô£Ø
Ô£Ø
Ô£Ø
Ô£Ø
Ô£Ø
Ô£∞
Solving  eq.  (10)  for  all  classes,  we  obtain  the 
coefficients
coefficients, 
calculation using eq (2). 
 
B.    NEDI 
 

NOZ . Once  we  have  all  the  filter 

interpolation  becomes  a  simple 








(cid:23)





The  NEDI  (New  Edge-Directed  interpolation) 
method [3] is a non-iterative orientation-adaptive 
interpolation scheme for natural image sources. It 
aims  at  interpolating  along  edges  rather  than 
across  them  to  prevent  blurring.  This  method 
adapts  the  interpolation  filter  coefficients  to  the 
local image content. NEDI assumes that the edge 
orientation  does  not  change  with  scaling, 
recognizing  the  resolution-invariant  property  of 
edge  orientation.  Therefore,  the  coefficients  can 
be  approximated  from  the  low-resolution  image 
within a local window by using the LMS method. 

L

)

L

)

&

)

)

)

)

L

)

)

)

)

L

L

)

)

)

L

)

$

)

%

)

)

)

L

)

)

)

)

)

)

L

L

)

)

)

)

)

)

L

+

)+, ‚àë‚àë
(cid:11)(cid:21)(cid:12)(cid:15)(cid:20)
(cid:11)(cid:21)(cid:11)
L

(cid:12)(cid:12)(cid:20)
M
+
)Z





+
ON



6'

=

N

=



O



=
(cid:21)(cid:11)
L

+

(cid:21)(cid:15)(cid:21)
N

M

+

(cid:12)(cid:21)
O

(11) 

(12) 

&

HI

HD

M

M

+

+

+

‚àí

+

=

)

Denoting M as the pixel set used to calculate the 
four  weights,  the  MSE  over  set  M  in  the 
optimization can be written as: 
=06(
(cid:11)
)
‚àë

2(cid:12)(cid:12)(cid:21)

(cid:21)(cid:15)(cid:21)

(cid:21)(cid:15)(cid:21)

(cid:21)(cid:11)
L

L
(cid:21)(cid:11)

(cid:12)(cid:21)

ji
,
Which in matrix formulation becomes: 

(13) 

contains the  pixels in  M  (pixel 

(cid:12)(cid:20)(cid:15)(cid:20)(cid:11)6')
(cid:12)(cid:20)(cid:15)(cid:22)(cid:11)6')

06(
&Z\
& ‚àí
(cid:12)(cid:20)(cid:15)(cid:21)(cid:11)6')
(cid:12)(cid:20)(cid:15)(cid:23)(cid:11)6')

Here,  \&
(cid:12)(cid:23)(cid:15)(cid:20)(cid:11)6')
(cid:12)(cid:23)(cid:15)(cid:22)(cid:11)6')
(cid:23) 0√ó
4 diagonal neighbours of each value in  \&
MSE over Z&

to 
and  C  is  a 
matrix whose kth row is composed of the 

To  find  the  minimum  MSE, the  derivation  of 

(cid:12)(cid:23)(cid:15)(cid:21)(cid:11)6')
(cid:12)(cid:23)(cid:15)(cid:23)(cid:11)6')

is calculated: 

to 
to 

to 

.

,

,

,



(14) 

&

06(
‚àÇ
(cid:19)=
Z
‚àÇ
(cid:21)
&\
(cid:19)
&Z
&
 =
+
(cid:11)
&&
(cid:11)
(cid:12)
\&
(cid:12)
&
(cid:11)
(cid:12)
‚àí&& 7

‚àí


7

(cid:21)
=

‚àí
Z
&

7

In  smooth  areas 

ranked,  so  there  is  no  answer  for Z&

(15) 
(16) 
may  not  be  fully 
. Therefore, 
smooth-area  detection  is  performed  prior  to  the 
calculation  and  linear  interpolation  is  used  in 
these areas. 
 
C.   ELA 
 

M M
D

E

F

M

M M

G

H

L

L

L

6'SL[HOJULG
+'SL[HOWREH
LQWHUSRODWHG

 

L

)

)

)

)

)

)

M

M

M

M

M

M M M

M M M

 

 

Figure 4.  The vertical aperture of Modified ELA 

to  calculate 

Figure  3.  Aperture  used 
in  new  edge-directed 
interpolation.  A  is  the  aperture  with  four  SD  pixels 
involved in interpolation. B is the aperture with the SD 
pixels  used 
interpolation 
coefficients.  C  is  the  aperture  that  includes  all  the 
diagonal neighbours of the SD pixels in B. Here,
a shorthand notation for 
 

(cid:12)(cid:21)(cid:15)(cid:20)(cid:11)6')

) is 

, etc. 

four 

the 

NEDI  uses  a 
algorithm 

fourth  order 

interpolation 

from 

is  derived 

(Edge-directed  Line  Averaging) 
The  ELA 
method 
the  de-interlacing 
techniques.  Although  applicable  to  up-scaling,  it 
has not been optimised for this function. The use 
of  the  modified  ELA  [2]  method  is  limited  to  a 
smaller  range  of  edge  orientations.  In  detail,  the 
modified  ELA  uses  a  directional  correlation 
between  the  pixels  (in  white)  in  the  adjacent 
original  scan  lines  to  determine  the  direction  for 
interpolation.  This  is  shown  in  Figure  5.  In  the 

modified  ELA  method,  directions  a to  e are 
detected.  
 

spatial  up-conversion, 

For 
first  edge 
dependently up-scales the SD image vertically to 
obtain an intermediate image 

it 

)

,0

(cid:12)(cid:21)(cid:15)(cid:21)(cid:11)
M
L
+

(17) 

is  up-scaled  horizontally  to 

(cid:20)
)
=
(cid:21)
(cid:20)
)
(cid:21)
,0)
(cid:12)(cid:12)(cid:20)

+

=

6'

,0) :
(cid:21)(cid:12)(cid:15)(cid:20)
O
M
‚àí
M
(cid:21)(cid:12)(cid:15)(cid:20)
+

‚àí
O

K

(cid:12)

K

(cid:12)

6'

(cid:11)(cid:21)(cid:11)
(cid:11)(cid:21)(cid:11)
L

L
+

M
(cid:12)(cid:21)(cid:15)
M
(cid:11)(cid:21)(cid:15)

(cid:20)
(cid:21)
(cid:20)
(cid:21)

)
)

,0

Y

‚àí

+

O
L
(cid:21)(cid:11)
(cid:21)(cid:11)
O
L
‚ÄôRZQ(cid:16)
VDPSOLQJ

Y

,0

Thereafter, 
obtain the HD image: 

)

+,

(cid:11)(cid:21)(cid:15)(cid:21)(cid:11)
L

M

+

+‚Äô(cid:3)9LGHR
6LJQDO

As before, 
of a pixel in the image at position 
Parameters 

)+,
(cid:12)(cid:21)(cid:15)(cid:21)(cid:11)
M
L
K O
O (cid:15)

Y

is the HD luminance value 

[ =&

(cid:12)(cid:21)(cid:15)(cid:21)(cid:11)
L
M

.

depend on the edge orientation. 

3.     Evaluation 
 

To  evaluate  the  described  conversion  methods, 
we  selected  5  SD  video  sequences.  In  order  to 
enable an MSE calculation, for which we need a 
perfect  HD  reference,  we  first  down-sample  the 
video sequence by a factor of 4 and then up-scale 
it to  the  original  size. We compared  the  original 
video  sequences  and  their  corresponding  up-
converted  ones  by  using  the  MSE  criterion. 
Figure 5 depicts the evaluation process. 
 

‚ÄôLIIHUHQW
8S(cid:16)&RQYHUVLRQ
7HFKQLTXHV

+‚Äô(cid:3)9LGHR
6LJQDO

(cid:11)5HFRQVWUXFWHG(cid:12)

+

(18) 

(cid:12)(cid:12)(cid:21)
6‚Äô(cid:3)9LGHR
6LJQDO

&RPSDULVRQ
&RQFOXVLRQ

DQG

Figure 5. Evaluation flowchart of various spatial up-conversion techniques 

 

(cid:11)D(cid:12)(cid:3)/HQQD

(cid:11)F(cid:12)(cid:3)6LHQD

(cid:11)E(cid:12)(cid:3)7RN\R

(cid:11)H(cid:12)(cid:3)%LF\FOH

(cid:11)G(cid:12)(cid:3))RRWEDOO

 

Figure 7.  Images from each test sequences 

A Pre-processing 
 

From the descriptions in Section 2, we conclude 
that  different  up-scaling  methods  result 
in 
different  HD-pixel  grids.  For  instance,  the  result 
of DRC is shifted over 0.5 pixel, while ELA and 
EDDI introduce no such shift. To cope with both 
options  in  a  fair  comparison,  we  produced  two 
copies  of the selected video  sequences.  The  first 
is shifted over 0.25 pixel and the other over 0.75 
pixel. This results in two ‚Äúoriginals‚Äù on different 
grids that have the same picture quality. 
 

Shown in Figure 6, pixels on grid A are original 
HD pixels, the other pixels are interpolated using 
a FIR interpolation filter. Pixels on grid B and C 
are  one  quarter  and  three  quarter  pixel  shifted 
compare  to  A  respectively.  For  DRC,  the  pixels 
are  sitting  on  the  same  grid  as  the  original  after 
the  processing.  For  other  methods,  there  is  half 
pixel shift after the processing. 
 

%

%

$

$

$

%

%

$

$

$

&

&

$

$

$

&

&

Figure 6.  Shift of the HD pixel grid 

 
B.   The down sampling 
 

imaging 

device.  A 

To avoid alias occur during down sampling, the 
first  choice  is  to  use  a  low-pass  anti-alias  pre-
filter  before  decimation.  The  result,  however,  is 
not  an  appropriate  model  for  a  picture  from  a 
low-resolution 
better 
approximation results, applying a Gaussian filter, 
i.e. to simply average the 4 pixels within each HD 
cell  when  emulating  a  SD-cell.  Since  a  camera 
usually  has  an  aperture  correction  filter 
to 
compensate  for  the  roll-off  characteristic  in  the 
high  frequency  part,  it  seems  appropriate  to 
include  a  peaking  filter  in  the  evaluation.  What 
we  used  is  a  cascade  of  the  4-point  averaging 
down-sampling: 

)6'

(cid:21)(cid:11)
L

(cid:21)(cid:15)(cid:20)
M
+
‚àë‚àë





=

=

N



O



(cid:12)(cid:20)
=+
(cid:20)
)
(cid:23)

+'

(cid:11)(cid:21)(cid:11)
L

+

N

(cid:11)(cid:21)(cid:12)(cid:15)

M

+

O

(cid:12)(cid:12)

(19) 

06(

(21) 

(cid:12)(cid:15)(cid:11)
ML)

6'

6'

+
+

(20) 

(cid:12)(cid:15)(cid:20)
M

and a 3-tap peaking filter: 
(cid:12)(cid:15)(cid:11)
ML)
(cid:12)(cid:15)(cid:20)
M
(cid:11)
L)
‚àí=
Œ±
‚àí
(cid:12)(cid:21)(cid:20)(cid:11)
(cid:12)(cid:15)(cid:11)
(cid:11)
L)
ML)
RXW
6'
Œ±
+
Œ±
‚àí
(cid:20)(cid:23)(cid:17)(cid:19)=Œ±
gives the best result according to 
here, 
our  experiment  result.  In  eq.(20)  we  only  define 
the  vertical  peaking  filter,  but  the  same  filter  is 
used  in  the  horizontal  domain.  Down-sampling 
the original HD video with a 7-tap standard low-
pass FIR filter2 is also presented as a reference in 
the evaluation. 
 
C.   The up-conversion and MSE calculation 
 

After up-conversion of the down-sampled video 
with a factor of 4, using the linear and non-linear 
methods,  the  MSE  between  the  original  video 
image(s)  and 
is 
calculated using: 

=

the  up-converted  one(s) 
(cid:20)
‚àë
1
(cid:12)(cid:15)(cid:11)
ML*)

ML*M
(cid:15)(cid:11)
‚àí

L)
(cid:12)(cid:15)(cid:11)

(cid:12)(cid:12)

(cid:11)

)

M

L



and 

are the luminance values of 
the  original  image  and  the  up-converted  one, 
respectively,  while  N represents  the  number  of 
pixels in the image. 
 

The techniques that we evaluated are: 

$ ELOLQHDU(cid:3)LQWHUSRODWLRQ(cid:3)(cid:11)%,(cid:12)(cid:30) 
$ (cid:21)(cid:26)(cid:3)WDSV(cid:3)LQWHUSRODWLRQ(cid:3)ILOWHU(cid:3)(cid:11)),5(cid:12)3;
7KH(cid:3)PRGLILHG(cid:3)(/$(cid:3)(cid:11)(/$(cid:12)(cid:30) 
7KH(cid:3)‚Äô5&(cid:3)(cid:11)&ODVVLILFDWLRQ(cid:3)EDVHG(cid:3)LQWHUSRODWLRQ(cid:12)(cid:30) 

The NEDI (New Edge Directed Interpolation); 

 
D.   Results and comparison 































*DXVVLDQ
),5









%,

),5

(/$

1(',

'5&

Figure 8.  Comparison of spatial up-scaling methods 

using the MSE criterion 

2 This filter was standard Matlab decimation filter and 
had  the  following  coefficients:  -0.0087,  0,  0.2518, 
0.5138, 0.2518, 0, -0.0087. 
3 This filter was standard MatLab up-scaling filter and 
had  the  following  coefficients:  0.0002,  0,  -0.0017,  0, 
0.0077,  0,  -0.0251,  0,  0.0672,  0,  -0.1693,  0,  0.6210, 
1.0,  0.6210,  0,  -0.1693,  0,  0.0672,  0,  -0.0251,  0, 
0.0077, 0, -0.0017, 0, 0.0002. 

due to  erroneous  interpolation  directions.  We 
conclude  that  ELA  seems  unsuitable  for  up-
scaling.  The  result  of  bilinear  interpolation  is 
rather  blurred  compared  to  the  other  methods. 
The  FIR  interpolation  method  visually  performs 
well  in  fine  structured  areas,  but  along  edges, 
overshoots  are  clearly  visible.  The  DRC  and 
NEDI methods yield less overshoot at the edges, 
but are somewhat weaker in fine structured areas.  

4.     Concluding remarks 

IEEE 

We  have  presented  an  overview  of  spatial  up-
scaling  techniques,  including  conventional  linear 
methods,  a  27-taps  FIR-filter,  and  a  bilinear 
interpolator,  and  some  recently  developed  non-
linear  algorithms,  like  ELA,  DRC  and  NEDI. 
From our evaluation, we conclude that NEDI and 
DRC visually perform well on edges, but are not 
as good as a conventional linear FIR-interpolator 
in  fine  structured  areas.  In  terms  of  MSE-score, 
the  FIR-filter  performs  best  of  all  evaluated 
methods, although DRC and NEDI come close. 
 
References 
[1]  GF9320  scaling  processor, preliminary  data 
sheet, Gennum, June 2001. 
[2]  H.  Lee  et.al.,
‚ÄòAdaptive  scan  rate  up-
conversion  system  based  on  human  visual 
characteristics‚Äô. 
trans.  on  Consumer 
Electronics, Vol. 46, No. 4, Nov. 2000, pp. 999-
1006. 
[3]  X.  Li  et.al.,
inter-
polation‚Äô. IEEE trans. on Image Processing, Vol. 
10, No 10, October 2001, pp. 1521-1527.  
[4]  T.  Kondo  et.al., ‚ÄòPicture  conversion  appa-
ratus,  picture  conversion  method, 
learning 
apparatus and learning method‚Äô, Sony corp., US-
patent 6,323,905. 
[5]  C.  B.  Atkins  et.  al., ‚ÄòOptimal  image  scaling 
using  pixel  classification‚Äô,  2001 International 
Conference  on  Image  Processing, Volume  2, 
2001, vol.3, pp864-867. 
[6]  T.  Kondo  et.al.,  ‚ÄòAdaptive  dynamic  range 
encoding  method  and  apparatus‚Äô,  Sony  corp., 
US-patent 5,444,487.  
[7]  P.  Rieder  et.  al., ‚ÄòNew  concept  on  denoising 
and sharpening of video signals‚Äô, IEEE Trans. on 
Consumer  Electronics, vol.47,  No.3,  pp666-671, 
Aug. 2001. 

‚ÄòNew  edge-directed 

We  used  five  test  sequences  for  evaluation. 
There  is  a  stationary  image  with  many  details 
(Lenna),  a  horizontally  moving  sequence  with 
much  vertical  detail  (Tokyo),  a  zooming  scene 
with  low  contrast  detail  (Football),  a  vertically 
moving  image  with  detailed  lettering  and  fine 
structure  (Siena),  and  a  sequence  with  complex 
motion  and  high  contrast  diagonals  (Bicycle). 
Figure 7 shows a picture from each test sequence.  
 

Figure 8 shows a comparison of the algorithms 
using the MSE criterion. All methods show better 
MSE-scores  with  the  down  sampling  using  a 
Gaussian filter and aperture correction. The (long) 
FIR-filter interpolation shows the best MSE-score. 
The  MSE-score  of  NEDI  and  DRC,  is  between 
that  of  the  bi-linear  method  and  the  FIR-
interpolator. The ELA scores clearly worst. 
 

D

E

F

G

H

I

 
Figure 9.  Detailed area of different spatial up-scaling 
(a)  Original  picture,  others  are  up-scaled  using  (b) 
bilinear  interpolation,  (c)  FIR  interpolation  filter,  (d) 
New-edge  Directed 
(f) 
Modified ELA. 
 

Interpolation, 

(e)  DRC, 

To  enable  a  subjective  impression,  Figure  9 
shows the detailed area of an original picture and 
its  up-converted  counterparts  using  different  up-
scaling algorithms.  The modified ELA produces 
clear artefacts, particularly visible in the text area, 

