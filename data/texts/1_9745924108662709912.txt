Fully-Automatic Landmark detection in Skull

X-Ray images

Cheng Chen1, Ching-Wei Wang2,3, Cheng-Ta Huang2, Chung-Hsing Li3,4, and

Guoyan Zheng1

1 Institute for Surgical Technology and Biomechanics, University of Bern,

Switzerland cheng.chen@istb.unibe.ch, guoyan.zheng@ieee.org

2 Graduate Institute of Biomedical Engineering, National Taiwan University of

3 Dental Department, National Defense Medical Center, Taiwan

4 Orthodontics and Pediatric Dentistry Division, Dental Department, Tri-Service

Science and Technology, Taiwan

General Hospital, Taiwan

Abstract. In this paper, we present our new method for fully-automatic
landmark detection on X-ray images. To detect landmarks, we estimate
the displacements from some randomly sampled image patches to the
(unknown) landmark positions, and then we integrate these predictions
via a voting scheme. Diﬀerent from other methods, we jointly estimate
the displacements from all patches together in a data driven way, by con-
sidering not only the training data but also geometric constraints on the
test image. The displacements estimation is formulated as a convex opti-
mization problem that can be solved eﬃciently. We validate our method
on a dataset of skull X-ray image containing 100 training images and 100
test images. We get an average detection error of 2.8 mm.

1

Introduction

In clinical practice, X-ray radiography is widely used for various purposes due to
its convenience and low cost. Detecting key points (landmarks) on X-ray images
beneﬁts many applications. Traditionally, landmark detection is seldom done in
clinical practice due to its diﬃculty. In cases where it is ever done, it is carried out
manually by doctors, which is both time-consuming and error-prone. Therefore,
fully-automatic techniques will immediately make this traditionally useful but
diﬃcult task widely applicable.

In [1], we proposed a new method for this task. We estimate the displacements
from a set of randomly sampled local image patches to the landmark based on
patch appearance, and the individual predictions are then combined in a voting
scheme to produce the predicted landmark position. In previous methods, the
displacement from each patch to the landmark is estimated independently using a
pre-trained model. Our method is fundamentally diﬀerent, as we jointly estimate
the displacements from all patches to landmarks together in a data-driven way.
This joint estimation scheme allows us to exploit the mutual interactions among
the displacements that are being estimated by considering the geometric relations

2

Chen, Wang, Huang, Li, and Zheng

between the patches in the test image. Combining the information from training
data and the geometry constraints, our displacement estimation method achieves
better accuracy.

We tested our method on a dataset of skull X-ray images involving 19 land-
marks. The dataset is devided into 100 training images and 100 test images (with
no overlapping). We get an average detection error of 29 pixels, with 40%, 52%
62% and 78% of landmarks detected within an error less than 2.0mm, 2.5mm,
3.0mm and 4.0mm, respectively.

2 Related Work

In recent literature, there has been a considerable amount of work in landmark
detection. Some methods utilize low-level image features such as gradients and
edges [2]. This type of methods often suﬀers from the large appearance variation
and image noise. To alleviate this problem, some similar methods such as [3, 4]
incorporate the topological constraints in a model-based way.

To overcome the challenge of appearance variation, some machine learning
based methods have been proposed. For example, in [5], a particle ﬁlter-based
approach is ﬁrst used to determine the morphological parameters, and then a
belief propagation based approach is used to extract contours from multiple
calibrated X-ray images. [6] introduce the so-called shape regression machine
to segment in real time the left ventricle endocardium from an echocardiogram
of an apical four chamber view. [7] use marginal space learning for localizing
the heart chambers, and then estimate the 3D shape through learning-based
boundary delineation.

In recent years, random forest (RF) based methods are becoming more and
more popular [8–10]. The basic idea is to estimate the displacement displace-
ments from a set of randomly sampled image patches to the (unknown) land-
mark position by RF regression. The landmark position is estimated by a voting
scheme considering the individual estimations from all the patches. In this pa-
per, we follow the framework of predicting relational displacements from image
patches. However, instead of using RF, our method improves the displacement
prediction by a data-driven approach.

3 Landmark Detection Algorithm

In this section we present our landmark detection algorithm. For more details,
please refer to [1].

3.1 Basic Idea

The overview of our landmark detection framework is given in Fig. 1. Please
note both this paper and [11] use the same framework but diﬀerent detection
algorithms. In the training step, as shown in (a), a rectangular image patch is

Lecture Notes in Computer Science: Authors’ Instructions

3

Fig. 1. Overview of our landmark detection algorithm. During training stage (a)(b), a
set of patches are sampled around the ground-truth landmark position. During testing
stage, given an image, a set of patches are randomly sampled (c), each patch makes
a prediction of the landmark position (d), and then the predictions are aggregated to
produce a response image (e).

randomly sampled around the ground-truth landmark position, with f denot-
ing the visual feature of the patch, and d denoting the displacement from this
patch to the landmark position. In the same way, we randomly sample a number
of patches around the ground-truth landmark position, as shown in (b). The
features and corresponding displacements of all these training patches consti-
tute the training data. Then, in the prediction step, given a new image, we also
randomly sample a number of image patches, as in (c). Since now we do not
know the landmark position, these test patches are sampled everywhere in the
image5. The visual features of these patches will be calculated, and based on
their features, the corresponding displacements with regard to the (unknown)
landmark position can be estimated. In this way, each patch makes a vote on the
landmark prediction as in (d), where each vote contains a position (depicted by
dots) and uncertainty (color-coded). Then, from these votes, we construct the
response image as in (e), which can be viewed as the probability of the landmark
position on every image location.

The crucial part of the procedure presented above is the estimation of dis-

placements for the test patches, which is formally described in the following.

3.2 Notations

Training step. Assume that ˜x ∈ R2 is the ground-truth landmark position. We
randomly sample a number of patches around ˜x. For the kth patch, we denote
˜ck ∈ R2 as its center position, ˜fk ∈ Rdf as its visual feature, and (cid:16)˜dk(cid:17)GT
=
˜x − ˜ck ∈ R2 as its ground-truth (GT) displacement to the landmark. In total, we
sample ˜K patches over all the training images, and we denote ˜F = h˜f1, ..., ˜f ˜Ki ∈
, ...,(cid:16)˜d ˜K(cid:17)i ∈
Rdf × ˜K as the training feature matrix, and (cid:16) ˜D(cid:17)GT
R2× ˜K , as the ground-truth displacement matrix.

= h(cid:16)˜d1(cid:17)GT

5 Or the relevant ROI (region of interest) of the image. See the experiment section for

details of our multi-resolution implementation.

4

Chen, Wang, Huang, Li, and Zheng

Prediction (test) step. Given a new image, we randomly sample K patches,
where ck ∈ R2 and fk ∈ Rdf are the center position and the visual feature of the
kth patch. We denote F = [f1, ..., fk] ∈ Rdf ×K as the test feature matrix.

We want to estimate {dk}k=1...K, the displacement from each patch to the

landmark. If we denote D = [d,..., dK ] ∈ R2×K , our goal is to estimate D.

3.3 Objective Function

First, we construct a compound displacement matrix which contains jointly the
training displacements and the test displacements to be estimated:

ˆD = h ˜D Di = h˜d1, ..., ˜d ˜K , d1, ..., dKi ∈ R2×( ˜K+K)

(1)

The left part (the ﬁrst ˜K columns) of ˆD contains the displacements in the
training images, and the right part (the last K columns) is the displacements
in the test image. Note that we can write ˜D = ˆDP and D = ˆDQ by deﬁning
appropriate (0,1) matrices P and Q which select corresponding columns.

Treating ˆD as a variable, we design an objective with regard to ˆD:

E( ˆD) = Eg( ˆD) + αEf ( ˆD) + βEp( ˆD)

(2)

Please note that although we are ultimately interested in estimating the
displacements of test patches D, our objective function is deﬁned on ˆD, which
is the combination of training and test displacements. In this way we can embed
the relations between training and test data into our objective function. After
we get the optimal ˆD, the optimal D is simply given by D = ˆDQ. Below we
deﬁne each term in the objective function.

Ground-truth Discrepancy Eg( ˆD). The left part of ˆD should be close to the
ground-truth displacements in the training data, which is encoded in (cid:16) ˜D(cid:17)GT
.
Therefore, we want to minimize the Ground-truth Discrepancy:

Eg( ˆD) =

1

2 ˜K (cid:13)(cid:13)(cid:13)

ˆDP − (cid:16) ˜D(cid:17)GT(cid:13)(cid:13)(cid:13)

2

F

(3)

where k.kF is the Frobenius norm.
Feature Propagation Discrepancy Ef ( ˆD). First, we construct a compound
feature matrix ˆF = (cid:2) ˜f f (cid:3) ∈ Rdf ×( ˜K+K). Now, each column of ˆF is the feature of a
(training or test) patch, and the corresponding column of ˆD is the displacement
vector (to all landmarks) of that patch. We denote kcoli( ˆF) − colj( ˆF)kL2 as
the L2 feature distance of a pair of patches (i, j), where coli() denotes the ith
column. From all pairwise distances, we construct a binary aﬃnity matrix S ∈
{0, 1}( ˜K+K)( ˜K+K), where sij = 1 if and only if the ith and the jth patches are
mutually ρ nearest neighbors (ρ = 10 in this paper) in the feature space. Note
that the edges in the aﬃnity matrix might link two training patches, two test
patches, or a training patch and a test patch.

Lecture Notes in Computer Science: Authors’ Instructions

5

For every pair of patches (i, j), if they are similar in the feature space, their
displacements to landmarks should also be similar. We deﬁne the Feature Prop-
agation Discrepancy Ef ( ˆD) as the violation from this assumption:

Ef ( ˆD) =

1

2Pi6=j

X

i6=j

sij (cid:13)(cid:13)(cid:13)

coli( ˆD) − colj( ˆD)(cid:13)(cid:13)(cid:13)

2

L2

(4)

For each pair of patches, Ef introduces a high penalty if the two patches
are similar in the feature space (i.e. sij = 1) but their displacements are very
is large). If we construct M as the (trace

diﬀerent (i.e. (cid:13)(cid:13)(cid:13)

coli( ˆD) − colj( ˆD)(cid:13)(cid:13)(cid:13)L2

normalized) laplacian matrix [12] of S, Ef can be compactly written as:

Ef ( ˆD) = Tr(cid:16) ˆDM ˆD⊤(cid:17)

(5)

In short, this term favors the consistency between feature proximity and dis-
placement proximity. In this way, the ground-truth displacements are propagated
to the test data via the links between training and test patches.

Patch Oﬀset Penalty Ep( ˆD).

i − eK

Each column of D is the displacements from a single patch in the test image
to the landmark position. The subtraction of two columns can be written as
coli(D) − colj(D) = D(eK
is a K dimensional col-
umn vector whose ith element is 1 and all other elements are 0s. it is not diﬃcult
to see that di − dj = cj − ci, because (di, dj) form a triangle with the same
edge cj −ci. Therefore, we impose a penalty Ei−j
,
F
where ¯cj−i = cj − ci. We can include a penalty for each pair (i, j) of columns.
For eﬃciency reasons, we eliminate redundancies and use K − 1 pairs:

(D) = (cid:13)(cid:13)D(eK

j ) = [di − dj], where eK
i

j ) − ¯cj−i(cid:13)(cid:13)

i − eK

2

p

Ep( ˆD) =

1
2K

K−1

X

i=1

Ei−(i+1)

p

(D) =

1

2K (cid:13)(cid:13)(cid:13)

ˆDQU − ¯C(cid:13)(cid:13)(cid:13)

2

F

(6)

where U = (cid:2)eK

1 − eK

2 , ..., eK

K−1 − eK

K(cid:3) and ¯C = (cid:2) ¯c2−1 ... ¯cK−(K−1) (cid:3).

3.4 Optimization

Substituting Eqs. (3),(5) and (6) into Eq. (2), we get the ﬁnal objective function.
We can prove that Eq. (2) is convex, and therefore to ﬁnd the global optimum,
we need to solve the equation:

∂E( ˆD).∂ ˆD = ˆDA + G = 0

(7)

where A = 1
L ˜K
The optimal solution is given by ˆD = −GA−1.

L M + β

PP⊤ + 2α

LK QUU⊤Q⊤, and G = −

P⊤

( ˜D)GT
L ˜K

− β ¯CU⊤Q⊤

LK

.

6

Chen, Wang, Huang, Li, and Zheng

Landmark mean (mm) std. (mm) <2.0mm(%) <2.5mm(%) <3.0mm(%) <4.0mm(%)
AVER.

78.4

43.9

28.1

18.7

54.6

64.2

Table 1. The statistical result of our method on the 100 test images.

3.5 Constructing Response Image

After we ﬁnd the optimum ˆD, we have D = ˆDQ, and {ck + dk}k=1...K will
be the set of votes for the landmark position. We write vk = ck + dk as the
position vote made by the kth patch. For each vote, there is also an uncertainty
Σk, which is calculated as the (diagonal) variance of the training displacements
that are linked to the kth test patch when we calculated the feature propagation
discrepancy Ef ( ˆD) in Section 3.3. The next step is to calculate the probability
of landmark on diﬀerent image locations, from the votes {(vk, Σk)}k=1...K. We
view each vote (vk, Σk) as a Gaussian distribution G(.|µ, Σ) with mean vk and
variance Σk. Then, the probability of landmark at an image coordinate (x, y) is
given by accumulating the contribution of all votes on this image location:

I(x, y) =

K

X

k=1

G ((x, y)|vk, Σk)

(8)

I(x, y) is viewed as an image function which is called response image of the
landmark, as in Fig. 1 (e). And the ﬁnal point estimate of the landmark position
is the image position where the response image gets its maximum value (mode).

4 Experiments

4.1 Data and Implementation details

We validated our method on a dataset of 200 skull X-ray images involving 19
landmarks. The dataset is divided into 100 training images and 100 test images.
The pixel spacing of the images is 0.1 mm/pixel in each dimension.

To improve the eﬃciency, we adopt a multi-scale strategy with two scale
levels. In the ﬁrst level the image is subsampled to its 1/3 size in each dimension,
and the second level operates on the original image. The result of the ﬁrst level is
propagated to the second level as initialization, where the landmarks are detected
by sampling patches only in a limited region around the initial position. At
the ﬁrst level where no initialization is available, the landmarks are detected
by sampling patches all through the image. In this way, we combine the global
detection at the ﬁrst level and local detection at the higher levels, which achieves
high accuracy without exploding the computation time.

In each scale level, we use the same parameters as follows: For each landmark,
we sample ˜K = 2000 training patches and K = 1000 test patches. For the visual
feature of the patches, we use multi-level HoG (Histogram of Oriented Gradient)
feature [13] with block sizes 1 × 1 and 2 × 2. Each block is divided into 2 × 2 cells

Lecture Notes in Computer Science: Authors’ Instructions

7

Fig. 2. Some qualitative result of our method.

and for each cell an 18 dimensional HoG feature is extracted by histogramming
the gradient direction of each pixel. Therefore, our original feature dimension is
df = 360.

4.2 Results

Fig. 2 shows qualitative results on several randomly chosen test images, where
we plot the detected landmark on the image as green dots.

Table 1 shows the statistical result of our method. We can see that we ahieve
an average detecting error as 28.1mm with standard deviation of 18.7mm. The
percentage of detections whose errors are below 2.0mm, 2.5mm, 3.0mm and
4.0mm are 43.9%, 54.6%, 64.2% and 78.4%, respectively.

Note that we detect the 19 landmarks independently of each other. As a
further improvement, we could use some high-level model on top of the output
from our method to regularize the inter-relations between the landmarks, such
as the sparse shape model as in [1], or the MRF based model as in [10].

5 Conclusions

We applied our new method for landmark detection on the dataset of skull X-ray
images. Our method works by jointly estimating the image displacements of test

8

Chen, Wang, Huang, Li, and Zheng

patches using the training data and also the geometric information on the test
image itself. The key contribution is the exploitation of the inter-patch relations
to impose the geometric regularizations on the image displacements that are be-
ing estimated. We formulate our problem as a convex objective function which
can be solved eﬃciently. The validation on the skull X-ray image dataset involv-
ing 19 landmarks shows that we achieve an average detection error of 29.2mm.

References

1. C. Chen, W. Xie, J. Franke, P.A. Grutzner, L.-P. Nolte, G. Zheng, Automatic X-
ray landmark detection and shape segmentation via data-driven joint estimation of
image displacements. Medical Image Analysis, 18(3): 487-499 (2014)

2. Cristinacce, D., Cootes, T.: Automatic feature localization with constrained local

models. Pattern Recognition, 41(19), 3054-3067 (2008)

3. Bergtholdt, M., Kappes, J., Schmidt, S., Schnrr., C.: A study of parts-based object
class detection using complete graphs. International Journal of Computer Vision 87,
93-117 (2010)

4. Schmidt, S., Kappes, J., Bergtholdt, M., Pekar, V., Dries, S., Bystrov, D., Schnrr,
C.: Spine detection and labeling using a parts-based graphical model, in: IPMI, pp.
122-133 (2007)

5. Dong, X., Zheng, G.:. Automatic extraction of proximal femur contours from cali-
brated x-ray images using 3d statistical models: an in vitro study. The International
Journal of Medical Robotics and Computer Assisted Surgery 5, 213-222 (2009).

6. Zhou, S.K., Comaniciu, D.: Shape regression machine, in: IPMI, pp. 13-25 (2007).
7. Zheng, Y., Barbu, A., Georgescu, B., Scheuering, M., Comaniciu, D.: Four-chamber
heart modeling and automatic segmentation of 3-D cardiac CT volumes using
marginal space learning and steerable features. IEEE T. Med. Imaging, 27(11),
1668-1681 (2008)

8. Criminisi, A., Shotton, J., Robertson, D., Konukoglu, E.: Regression forests for eﬃ-
cient anatomy detection and localization in CT studies. In: proceedings of MICCAI
2010 workshop in Medical Computer Vision: recognition techniques and applications
in medical imaging, pp. 106-117 (2010)

9. Lindner, C., Thiagarajah, S., Wilkinson, J.M., Wallis, G.A., Cootes, T.F.: Fully au-
tomatic segmentation of the proximal femur using random forest regression voting.
IEEE Trans. Med. Imaging 32, 1462-1472 (2013).

10. Donner, R., Menze, B.H., Bischof, H., Langs, G.: Global localization of 3d anatomi-
cal structures by pre-ﬁltered hough forests and discrete optimization. Medical Image
Analysis, 17(8): 1304-1314 (2013).

11. Chu, C., Chen, C., Wang, C-W., Huang, C-T., Li, C-H, Nolte, LP, Zheng, G.:
Fully Automatic Cephalometric X-Ray Landmark Detection Using Random Forest
Regression and Sparse shape composition. submitted to Automatic Cephalometric
X-ray Landmark Detection Challenge 2014.

12. Kokiopoulou, E., Chen, J., Saad, Y.: Trace optimization and eigenproblems in di-
mension reduction methods. In: Numerical Linear Algebra with Applications, 18(3),
565-602 (2011)

13. Dalal, N., Triggs, B., Histograms of oriented gradients for human detection. In:

CVPR (2005)

