Correcting sample selection bias in maximum entropy density estimation

Miroslav Dud´ik, Robert E. Schapire Princeton University
Department of Computer Science 35 Olden St, Princeton, NJ 08544 {mdudik,schapire}@princeton.edu

Steven J. Phillips AT&T Labs - Research 180 Park Ave, Florham Park, NJ 07932
phillips@research.att.com

Abstract
We study the problem of maximum entropy density estimation in the presence of known sample selection bias. We propose three bias correction approaches. The first one takes advantage of unbiased sufficient statistics which can be obtained from biased samples. The second one estimates the biased distribution and then factors the bias out. The third one approximates the second by only using samples from the sampling distribution. We provide guarantees for the first two approaches and evaluate the performance of all three approaches in synthetic experiments and on real data from species habitat modeling, where maxent has been successfully applied and where sample selection bias is a significant problem.
1 Introduction
We study the problem of estimating a probability distribution, particularly in the context of species habitat modeling. It is very common in distribution modeling to assume access to independent samples from the distribution being estimated. In practice, this assumption is violated for various reasons. For example, habitat modeling is typically based on known occurrence locations derived from collections in natural history museums and herbariums as well as biological surveys [1, 2, 3]. Here, the goal is to predict the species' distribution as a function of climatic and other environmental variables. To achieve this in a statistically sound manner using current methods, it is necessary to assume that the sampling distribution and species distributions are not correlated. In fact, however, most sampling is done in locations that are easier to access, such as areas close to towns, roads, airports or waterways [4]. Furthermore, the independence assumption may not hold since roads and waterways are often correlated with topography and vegetation which influence species distributions. New unbiased sampling may be expensive, so much can be gained by using the extensive existing biased data, especially since it is becoming freely available online [5].
Although the available data may have been collected in a biased manner, we usually have some information available about the nature of the bias. For instance, in the case of habitat modeling, some factors influencing the sampling distribution are well known, such as distance from roads, towns, etc. In addition, a list of visited sites may be available and viewed as a sample of the sampling distribution itself. If such a list is not available, the set of sites where any species from a large group has been observed may be a reasonable approximation of all visited locations.
In this paper, we study probability density estimation under sample selection bias. We

assume that the sampling distribution (or an approximation) is known during training, but we require that unbiased models not use any knowledge of sample selection bias during testing. This requirement is vital for habitat modeling where models are often applied to a different region or under different climatic conditions. To our knowledge this is the first work addressing sample selection bias in a statistically sound manner and in a setup suitable for species habitat modeling from presence-only data.
We propose three approaches that incorporate sample selection bias in a common density estimation technique based on the principle of maximum entropy (maxent). Maxent with 1-regularization has been successfully used to model geographic distributions of species under the assumption that samples are unbiased [3]. We review 1-regularized maxent with unbiased data in Section 2, and give details of the new approaches in Section 3.
Our three approaches make simple modifications to unbiased maxent and achieve analogous provable performance guarantees. The first approach uses a bias correction technique similar to that of Zadrozny et al. [6, 7] to obtain unbiased confidence intervals from biased samples as required by our version of maxent. We prove that, as in the unbiased case, this produces models whose log loss approaches that of the best possible Gibbs distribution (with increasing sample size).
In contrast, the second approach we propose first estimates the biased distribution and then factors the bias out. When the target distribution is a Gibbs distribution, the solution again approaches the log loss of the target distribution. When the target distribution is not Gibbs, we demonstrate that the second approach need not produce the optimal Gibbs distribution (with respect to log loss) even in the limit of infinitely many samples. However, we prove that it produces models that are almost as good as the best Gibbs distribution according to a certain Bregman divergence that depends on the selection bias. In addition, we observe good empirical performance for moderate sample sizes. The third approach is an approximation of the second approach which uses samples from the sampling distribution instead of the distribution itself.
One of the challenges in studying methods for correcting sample selection bias is that unbiased data sets, though not required during training, are needed as test sets to evaluate performance. Unbiased data sets are difficult to obtain -- this is the very reason why we study this problem! Thus, it is almost inevitable that synthetic data must be used. In Section 4, we describe experiments evaluating performance of the three methods. We use both fully synthetic data, as well as a biological dataset consisting of a biased training set and an independently collected reasonably unbiased test set.
Related work. Sample selection bias also arises in econometrics where it stems from factors such as attrition, nonresponse and self selection [8, 9, 10]. It has been extensively studied in the context of linear regression after Heckman's seminal paper [8] in which the bias is first estimated and then a transform of the estimate is used as an additional regressor.
In the machine learning community, sample selection bias has been recently considered for classification problems by Zadrozny [6]. Here the goal is to learn a decision rule from a biased sample. The problem is closely related to cost-sensitive learning [11, 7] and the same techniques such as resampling or differential weighting of samples apply.
However, the methods of the previous two approaches do not apply directly to density estimation where the setup is "unconditional", i.e. there is no dependent variable, or, in the classification terminology, we only have access to positive examples, and the cost function (log loss) is unbounded. In addition, in the case of modeling species habitats, we face the challenge of sample sizes that are very small (2­100) by machine learning standards.
2 Maxent setup
In this section, we describe the setup for unbiased maximum entropy density estimation and review performance guarantees. We use a relaxed formulation which will yield an 1-regularization term in our objective function.

The goal is to estimate an unknown target distribution  over a known sample space X based on samples x1, . . . , xm  X . We assume that samples are independently distributed according to  and denote the empirical distribution by ~(x) = |{1  i  m : xi = x}|/m. The structure of the problem is specified by real valued functions fj : X  R, j = 1, . . . , n, called features and by a distribution q0 representing a default estimate. We assume that features capture all the relevant information available for the problem at hand
and q0 is the distribution we would choose if we were given no samples. The distribution q0 is most often assumed uniform.
For a limited number of samples, we expect that ~ will be a poor estimate of  under
any reasonable distance measure. However, empirical averages of features will not be too
different from their expectations with respect to . Let p[f ] denote the expectation of a function f (x) when x is chosen randomly according to distribution p. We would like to find a distribution p which satisfies

|p[fj] - ~[fj]|  j for all 1  j  n,

(1)

for some estimates j of deviations of empirical averages from their expectations. Usually there will be infinitely many distributions satisfying these constraints. For the case when the default distribution q0 is uniform, the maximum entropy principle tells us to choose the distribution of maximum entropy satisfying these constraints. In general, we should minimize the relative entropy from q0. This corresponds to choosing the distribution that satisfies the constraints (1) but imposes as little additional information as possible when compared with q0. Allowing for asymmetric constraints, we obtain the formulation

min RE(p q0) subject to 1  j  n : aj  p[fj]  bj.
p

(2)

Here,   RX is the simplex of probability distributions and RE(p q) is the relative

entropy (or Kullback-Leibler divergence) from q to p, an information theoretic measure of

difference between the two distributions. It is non-negative, equal to zero only when the

two distributions are identical, and convex in its arguments.

Problem (2) is a convex program. Using Lagrange multipliers, we obtain that the solu-

tion takes the form

q(x) = q0(x)e·f(x)/Z

(3)

where Z = x q0(x)e·f(x) is the normalization constant. Distributions q of the form (3) will be referred to as q0-Gibbs or just Gibbs when no ambiguity arises.
Instead of solving (2) directly, we solve its dual:

min
Rn

log

Z

-

1 2

j

(bj

+

aj )j

+

1 2

j (bj - aj )|j | .

(4)

We can choose from a range of general convex optimization techniques or use some of the algorithms in [12]. For the symmetric case when

[aj, bj] = ~[fj] - j, ~[fj] + j ,

(5)

the dual becomes

min -~[log q] +
Rn

j j |j | .

(6)

The first term is the empirical log loss (negative log likelihood), the second term is an 1regularization. Small values of log loss mean a good fit to the data. This is balanced by

regularization forcing simpler models and hence preventing overfitting.

When all the primal constraints are satisfied by the target distribution  then the solution

q^ of the dual is guaranteed to be not much worse an approximation of  than the best Gibbs distribution q. More precisely:

Theorem 1 (Performance guarantees, Theorem 1 of [12]). Assume that the distribution  satisfies the primal constraints (2). Let q^ be the solution of the dual (4). Then for an arbitrary Gibbs distribution q = q
RE( q^)  RE( q) + j (bj - aj)|j |.

Input: finite domain X

features f1, . . . , fn where fj : X  [0, 1]

default estimate q0

regularization parameter  > 0

sampling distribution s

samples x1, . . . , xm  X

Output: q`^ approx´imating the target distribution Let 0 = / ^ m · min {fs[1/s], (max 1/~s - ^min 1/s)/2}
[c0, d0] = fs[1/s] - 0, fs[1/s] + 0  min 1/s, max 1/s]

For j = 1`, . . ., n: ´ j = / ^ m · min {fs[fj/s], (max fj/~s - ^min fj/s)/2} [cj, dj] = ^fs[fj/s] - j~, fs^[fj/s] + j  min fj/s, max fj/s] [aj , bj ] = cj /d0, dj /c0  min fj , max fj ]

Solve the dual (4)

Algorithm 1: DEBIASAVERAGES.

Table 1: Example 1. Comparison of distributions q and q minimizing RE( q ) and RE(s qs).

x f (x) (x) s(x) s(x) q(x) qs(x) q(x)
1 (0, 0) 0.4 0.4 0.64 0.25 0.544 0.34 2 (0, 1) 0.1 0.4 0.16 0.25 0.256 0.16 3 (1, 0) 0.1 0.1 0.04 0.25 0.136 0.34 4 (1, 1) 0.4 0.1 0.16 0.25 0.064 0.16

When features are bounded between 0 and 1, the symmetric box constraints (5) with

j = O( (log n)/m) are satisfied with high probability by Hoeffding's inequality and the union bound. Then the relative entropy from q^ to  will not be worse than the relative

entropy from any Gibbs distribution q to  by more than O(  1 In practice, we set  j = / m · min {~[fj], max[fj]}

(log n)/m).

(7)

where  is a tuned constant, ~[fj] is the sample deviation of fj, and max[fj] is an upper bound on the standard deviation, such as (maxx fj(x) - minx fj(x))/2. We refer to this
algorithm for unbiased data as UNBIASEDMAXENT.

3 Maxent with sample selection bias

In the biased case, the goal is to estimate the target distribution , but samples do not come
directly from . For nonnegative functions p1, p2 defined on X , let p1p2 denote the distribution obtained by multiplying weights p1(x) and p2(x) at every point and renormalizing:

p1p2(x) =

p1(x)p2(x) x p1(x)p2(x

)

.

Samples x1, . . . , xm come from the biased distribution s where s is the sampling distribution. This setup corresponds to the situation when an event being observed occurs at the point x with probability (x) while we perform an independent observation with probability s(x). The probability of observing an event at x given that we observe an event is then equal to s(x). The empirical distribution of m samples drawn from s will be denoted by s. We assume that s is known (principal assumption, see introduction) and strictly
positive (technical assumption).

Approach I: Debiasing Averages. In our first approach, we use the same algorithm as for the unbiased case but employ a different method to obtain confidence intervals [aj, bj]. Since we do not have direct access to samples from , we use a version of the Bias Correction Theorem of Zadrozny [6] to convert expectations with respect to s to expectations with respect to .
Theorem 2 (Bias Correction Theorem [6], Translation Theorem [7]).

s[f /s] s[1/s] = [f ].

Hence, it suffices to give confidence intervals for s[f /s] and s[1/s] to obtain confidence intervals for [f ].

Corollary 3. Assume that for some sample-derived bounds cj, dj, 0  j  n, with high probability 0 < c0  s[1/s]  d0 and 0  cj  s[fj/s]  dj for all 1  j  n. Then with at least the same probability cj/d0  [fj]  dj/c0 for all 1  j  n.
If s is bounded away from 0 then Chernoff bounds may be used to determine cj, dj. Corollary 3 and Theorem 1 then yield guarantees that this method's performance converges,
with increasing sample sizes, to that of the "best" Gibbs distribution. In practice, confidence intervals [cj, dj] may be determined using expressions analo-
gous to (5) and (7) for random variables fj/s, 1/s and the empirical distribution s. After first restricting the confidence intervals in a natural fashion, this yields Algorithm 1. Alter-
natively, we could use bootstrap or other types of estimates for the confidence intervals.

Approach II: Factoring Bias Out. The second algorithm does not approximate  di-
rectly, but uses maxent to estimate the distribution s and then converts this estimate into
an approximation of . If the default estimate of  is q0, then the default estimate of s is q0s. Applying unbiased maxent to the empirical distribution s with the default q0s, we obtain a q0s-Gibbs distribution q0se^·f approximating s. We factor out s to obtain q0e^·f as an estimate of . This yields the algorithm FACTORBIASOUT.
This approach corresponds to 1-regularized maximum likelihood estimation of  by q0-Gibbs distributions. When  itself is q0-Gibbs then the distribution s is q0s-Gibbs. Performance guarantees for unbiased maxent imply that estimates of s converge to s as
the number of samples increases. Now, if infx s(x) > 0 (which is the case for finite X ) then estimates of  obtained by factoring out s converge to  as well.
When  is not q0-Gibbs then s is not q0s-Gibbs either. We approximate  by a q0-Gibbs distribution q^ = q^ which, with an increasing number of samples, minimizes RE(s qs) rather than RE( q). Our next example shows that these two minimiz-
ers may be different.

Example 1. Consider the space X = {1, 2, 3, 4} with two features f1, f2. Features f1, f2, target distribution , sampling distribution s and the biased distribution s are given in Table 1. We use the uniform distribution as a default estimate. The minimizer of RE( q) is the unique uniform-Gibbs distribution q such that q[f ] = [f ]. Similarly, the minimizer qs of RE(s qs) is the unique s-Gibbs distribution for which qs[f ] = s[f ]. Solving for these exactly, we find that q and q are as given in Table 1, and that these two
distributions differ.

Even though FACTORBIASOUT does not minimize RE( q), we can show that it

minimizes a different Bregman divergence. More precisely, it minimizes a Bregman di-

vergence between certain projections of the two distributions. Bregman divergences gen-

eralize some common distance measures such as relative entropy or the squared Euclidean

distance, and enjoy many of the same favorable properties. The Bregman divergence asso-

ciated with a convex function F is defined as DF (u v) = F (u)-F (v)-F (v)·(u-v).

Proposition 4. Define F : RX+  R as F (u) = is a convex function and for all p1, p2  , RE(p1s

px2ss()x)=u(xD)Flo(gp1u(xp).2)T, hwenherFe

p1(x) = p1(x)/ x s(x)p1(x) and p2 (x) = p2(x)/ x s(x)p2(x) are projections of

p1, p2 along lines tp, t  R onto the hyperplane x s(x)p(x) = 1.

Approach III: Approximating FACTORBIASOUT. As mentioned in the introduction,
knowing the sampling distribution s exactly is unrealistic. However, we often have access to samples from s. In this approach we assume that s is unknown but that, in addition to samples x1, . . . , xm from s, we are also given a separate set of samples x(1), x(2), . . . , x(N) from s. We use the algorithm FACTORBIASOUT with the sampling distribution s replaced by the corresponding empirical distribution s~.
To simplify the algorithm, we note that instead of using q0s~ as a default estimate for s, it suffices to replace the sample space X by X  = x(1), x(2), . . . , x(N) and use q0

relative entropy to target

2.5

target=
1
RE( ||u)=4.5

2

target= 2.2
2
RE( ||u)=5.0

target=
3
RE( ||u)=3.3

123

1.5 2

2

1.5 10

1 100 1000 10

1.8 100 1000 10

100 1000

number of training samples (m)

unbiased maxent debias averages factor bias out

approximate factor bias out 1,000 samples 10,000 samples

Figure 1: Learning curves for synthetic experiments. We use u to denote the uniform distribution. For the sampling distribution s, RE(s u) = 0.8. Performance is measured in terms of relative entropy to the target distribution as a function of an increasing number of training samples. The number of
samples is plotted on a log scale.

restricted to X  as a default. The last step of factoring out s~ is equivalent to using ^ returned for space X  on the entire space X .
When the sampling distribution s is correlated with feature values, X  might not cover
all feature ranges. In that case, reprojecting on X may yield poor estimates outside of these ranges. We therefore do "clamping", restricting values fj(x) to their ranges over X  and capping values of the exponent ^ · f (x) at its maximum over X . The resulting algorithm
is called APPROXFACTORBIASOUT.

4 Experiments

Conducting real data experiments to evaluate bias correction techniques is difficult, because bias is typically unknown and samples from unbiased distributions are not available. Therefore, synthetic experiments are often a necessity for precise evaluation. Nevertheless, in addition to synthetic experiments, we were also able to conduct experiments with real-world data for habitat modeling.

Synthetic experiments. In synthetic experiments, we generated three target uniform-

Gibbs distributions 1, 2, 3 over a domain X of size 10,000. These distributions were

derived from 65 features indexed as fi, 0  i  9 and fij, 0  i  j  9. Values

fi(x) were chosen independently and uniformly in [0, 1], and we set fij(x) = fi(x)fj(x).

Fixing these features, we generated weights for each distribution. Weights i and ii were

generated jointly to capture a range of different behaviors for values of fi in the range [0, 1].

Let US denote a random variable uniform over the set S. Each instance of US corre-

sponds to a new independent variable. We set ii = U{-1,0,1}U[1,5] and i to be iiU[-3,1]

if ii = 0, and U{-1,1}U[2,10] otherwise. Weights ij, i < j were chosen to create cor-

relations between fi's that would be observable, but not strong enough to dominate i's

and ii's. We set ij = -0.5 or 0 or 0.5 with respective probabilities 0.05, 0.9 and 0.05.

In maxent, we used a subset of features specifying target distributions and some irrelevant

features. 0i

5W(reeulesveadntfefaetautruersesf)ia, n0dfii(x)

9 =

and their U[0,1] for

squares fii, where fi(x) = fi(x) for 6  i  9 (irrelevant features). Once

generated, we used the same set of features in all experiments. We generated a sampling

distribution s correlated with target distributions. More specifically, s was a Gibbs distrib-

ution generated from features fi(s), 0  i  5 and their squares fi(is), where fi(s)(x) = U[0,1] for 0  i  1 and fi(s) = fi+2 for 2  i  5. We used weights i(s) = 0 and (iis) = -1.
For every target distribution, we evaluated the performance of UNBIASEDMAXENT,

DEBIASAVERAGES, FACTORBIASOUT and APPROXFACTORBIASOUT with 1,000 and

10,000 samples from the sampling distribution. The performance was evaluated in terms

of relative entropy to the target distribution. We used training sets of sizes 10 to 1000. We

considered five randomly generated training sets and took the average performance over

these five sets for settings of  from the range [0.05, 4.64]. We report results for the best ,

chosen separately for each average. The rationale behind this approach is that we want to

Table 2: Results of real data experiments. Average performance of unbiased maxent and three bias correction approaches over all species in six regions. The uniform distribution would receive the log loss of 14.2 and AUC of 0.5. Results of bias correction approaches are italicized if they are significantly worse and set in boldface if they are significantly better than those of the unbiased maxent according to a paired t-test at the level of significance 5%.

average log loss

average AUC

awt can nsw nz sa swi awt can nsw nz sa swi

unbiased maxent 13.78 12.89 13.40 13.77 13.14 12.81 0.69 0.58 0.71 0.72 0.78 0.81

debias averages 13.92 13.10 13.88 14.31 14.10 13.59 0.67 0.64 0.65 0.67 0.68 0.78

factor bias out 13.90 13.13 14.06 14.20 13.66 13.46 0.71 0.69 0.72 0.72 0.78 0.83

apx. factor bias out 13.89 13.40 14.19 14.07 13.62 13.41 0.72 0.72 0.73 0.73 0.78 0.84

explore the potential performance of each method. Figure 1 shows the results at the optimal  as a function of an increasing number of sam-
ples. FACTORBIASOUT is always better than UNBIASEDMAXENT. DEBIASAVERAGES is worse than UNBIASEDMAXENT for small sample sizes, but as the number of training samples increases, it soon outperforms UNBIASEDMAXENT and eventually also outperforms FACTORBIASOUT. APPROXFACTORBIASOUT improves as the number of samples from the sampling distribution increases from 1,000 to 10,000, but both versions of APPROXFACTORBIASOUT perform worse than UNBIASEDMAXENT for the distribution 2.
Real data experiments. In this set of experiments, we evaluated maxent in the task of estimating species habitats. The sample space is a geographic region divided into a grid of cells and samples are known occurrence localities -- cells where a given species was observed. Every cell is described by a set of environmental variables, which may be categorical, such as vegetation type, or continuous, such as altitude or annual precipitation. Features are real-valued functions derived from environmental variables. We used binary indicator features for different values of categorical variables and binary threshold features for continuous variables. The latter are equal to one when the value of a variable is greater than a fixed threshold and zero otherwise.
Species sample locations and environmental variables were all produced and used as part of the "Testing alternative methodologies for modeling species' ecological niches and predicting geographic distributions" Working Group at the National Center for Ecological Analysis and Synthesis (NCEAS). The working group compared modeling methods across a variety of species and regions. The training set contained presence-only data from unplanned surveys or incidental records, including those from museums and herbariums. The test set contained presence-absence data from rigorously planned independent surveys.
We compared performance of our bias correction approaches with that of the unbiased maxent which was among the top methods in the NCEAS comparison [13]. We used the full dataset consisting of 226 species in 6 regions with 2­5822 training presences per species (233 on average) and 102­19120 test presences/absences. For more details see [13].
We treated training occurrence locations for all species in each region as sampling distribution samples and used them directly in APPROXFACTORBIASOUT. In order to apply DEBIASAVERAGES and FACTORBIASOUT, we estimated the sampling distribution using unbiased maxent. Sampling distribution estimation is also the first step of [6]. In contrast with that work, however, our experiments do not use the sampling distribution estimate during evaluation and hence do not depend on its quality.
The resulting distributions were evaluated on test presences according to the log loss and on test presences and absences according to the area under an ROC curve (AUC) [14]. AUC quantifies how well the predicted distribution ranks test presences above test absences. Its value is equal to the probability that a randomly chosen presence will be ranked above a randomly chosen absence. The uniformly random prediction receives AUC of 0.5 while a perfect prediction receives AUC of 1.0.
In Table 2 we show performance of our three approaches compared with the unbiased maxent. All three algorithms yield on average a worse log loss than the unbiased maxent. This can perhaps be attributed to the imperfect estimate of the sampling distribution or to

the sampling distribution being zero over large portions of the sample space. In contrast, when the performance is measured in terms of AUC, FACTORBIASOUT and APPROXFACTORBIASOUT yield on average the same or better AUC as UNBIASEDMAXENT in all six regions. Improvements in regions awt, can and swi are dramatic enough so that both of these methods perform better than any method evaluated in [13].
5 Conclusions
We have proposed three approaches that incorporate information about sample selection bias in maxent and demonstrated their utility in synthetic and real data experiments. Experiments also raise several questions that merit further research: DEBIASAVERAGES has the strongest performance guarantees, but it performs the worst in real data experiments and catches up with other methods only for large sample sizes in synthetic experiments. This may be due to poor estimates of unbiased confidence intervals and could be possibly improved using a different estimation method. FACTORBIASOUT and APPROXFACTORBIASOUT improve over UNBIASEDMAXENT in terms of AUC over real data, but are worse in terms of log loss. This disagreement suggests that methods which aim to optimize AUC directly could be more successful in species modeling, possibly incorporating some concepts from FACTORBIASOUT and APPROXFACTORBIASOUT. APPROXFACTORBIASOUT performs the best on real world data, possibly due to the direct use of samples from the sampling distribution rather than a sampling distribution estimate. However, this method comes without performance guarantees and does not exploit the knowledge of the full sample space. Proving performance guarantees for APPROXFACTORBIASOUT remains open for future research.
Acknowledgments
This material is based upon work supported by NSF under grant 0325463. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of NSF. The NCEAS data was kindly shared with us by the members of the "Testing alternative methodologies for modeling species' ecological niches and predicting geographic distributions" Working Group, which was supported by the National Center for Ecological Analysis and Synthesis, a Center funded by NSF (grant DEB0072909), the University of California and the Santa Barbara campus.
References
[1] Jane Elith. Quantitative methods for modeling species habitat: Comparative performance and an application to Australian plants. In Scott Ferson and Mark Burgman, editors, Quantitative Methods for Conservation Biology, pages 39­58. Springer-Verlag, 2002.
[2] A. Guisan and N. E. Zimmerman. Predictive habitat distribution models in ecology. Ecological Modelling, 135:147­186, 2000.
[3] Steven J. Phillips, Miroslav Dud´ik, and Robert E. Schapire. A maximum entropy approach to species distribution modeling. In Proceedings of the Twenty-First International Conference on Machine Learning, 2004.
[4] S. Reddy and L. M. Da´valos. Geographical sampling bias and its implications for conservation priorities in Africa. Journal of Biogeography, 30:1719­1727, 2003.
[5] Barbara R. Stein and John Wieczorek. Mammals of the world: MaNIS as an example of data integration in a distributed network environment. Biodiversity Informatics, 1(1):14­22, 2004.
[6] Bianca Zadrozny. Learning and evaluating classifiers under sample selection bias. In Proceedings of the Twenty-First International Conference on Machine Learning, 2004.
[7] Bianca Zadrozny, John Langford, and Naoki Abe. Cost-sensitive learning by cost-proportionate example weighting. In Proceedings of the Third IEEE International Conference on Data Mining, 2003.
[8] James J. Heckman. Sample selection bias as a specification error. Econometrica, 47(1):153­161, 1979. [9] Robert M. Groves. Survey Errors and Survey Costs. Wiley, 1989. [10] Roderick J. Little and Donald B. Rubin. Statistical Analysis with Missing Data. Wiley, second edition, 2002. [11] Charles Elkan. The foundations of cost-sensitive learning. In Proceedings of the Seventeenth International
Joint Conference on Artificial Intelligence, 2001. [12] Miroslav Dud´ik, Steven J. Phillips, and Robert E. Schapire. Performance guarantees for regularized maxi-
mum entropy density estimation. In 17th Annual Conference on Learning Theory, 2004. [13] J. Elith, C. Graham, and NCEAS working group. Comparing methodologies for modeling species' distribu-
tions from presence-only data. In preparation. [14] J. A. Hanley and B. S. McNeil. The meaning and use of the area under a receiver operating characteristic
(ROC) curve. Radiology, 143:29­36, 1982.

