Session 17 Psychology and Artificial Intelligence

ACTIVE SEMANTIC NETWORKS AS A MODEL OF HUMAN MEMORY1
David E. Rumelhart Donald A. Norman
Department of Psychology U n i v e r s i t y of C a l i f o r n i a , San Diego
La J o l l a , C a l i f o r n i a 92037

Abstract
A g e n e r a l system to s i m u l a t e human c o g n i t i v e p r o cesses is d e s c r i b e d . The f o u r - p a r t system comprises a nodespace to store the network s t r u c t u r e ; a supervisor; a t r a n s i t i o n network p a r s e r ; and an i n t e r p r e t e r . The method by which noun phrases operate and the process for the determiner "the" is presented. An analysis of v e r b s t r u c t u r e s i l l u s t r a t e s how n e t w o r k s t r u c t u r e s can be constructed from p r i m i t i v e verb d e f i n i t i o n s that get a t the u n d e r l y i n g s t r u c t u r e s o f p a r t i c u l a r v e r b s . The paper concludes with an i l l u s t r a t i o n of a problem in question-asking.

A Model of Human Memory

We have constructed a large general simulation of human language and l o n g - t e r m memory on t h e premise t h a t t h e s t u d y o f t h e i n t e r - r e l a t i o n s h i p s among p s y c h o l o g i c a l processes w i l l l e a d t o more i n s i g h t i n t o human c o g n i t i o n and memory. The general implementation is bas i c a l l y complete, and a v a r i e t y of users are s t a r t i n g to study specific psychological tasks (language understanding; children's development of language; p r i m i t i v e v e r b s t r u c t u r e ; r e a d i n g ; i n f e r e n c e ; game p l a y i n g - - G o and Gomoku; v i s u a l r e p r e s e n t a t i o n and memory; l e a r n i n g ; and q u e s t i o n a n s w e r i n g ) . I t i s s t i l l too e a r l y t o r e port on the results of the psychological investigation.. Therefore, t h i s paper is a progress report on the system and the u n d e r l y i n g p s y c h o l o g i c a l p r i n c i p l e s .
The m a j o r g u i d e l i n e s have come f r o m o u r a t t e m p t s to r e p r e s e n t l o n g - t e r m memory s t r u c t u r e s . We know t h a t people rapidly forget the details about the surface structure of an experience but r e t a i n the meaning or interpretation of that experience indefinitely. We a l so know t h a t r e t r i e v a l of an e x p e r i e n c e from memory is usually a reconstruction which is heavily biased by the person's general knowledge of the world. Thus, general world knowledge should i n t e r a c t with s p e c i f i c event knowledge in such a way t h a t d i s t i n c t i o n between the two i s not p o s s i b l e . The r e p r e s e n t a t i o n should a l l o w p a r a p h r a s e . F i n a l l y , t h e l i m i t a t i o n s o f human w o r k i n g s t o r a g e ( o r s h o r t - t e r m memory) p r o b a b l y comprise a f u n damental p r o p e r t y of the system, one t h a t should be viewed as an e s s e n t i a l , p o s i t i v e component, not as simply a performance l i m i t a t i o n .

The Computer System

The basic system c o n s i s t s e s s e n t i a l l y o f f o u r

f i x e d components: 1) a nodespace in which our network

structures are stored; 2) a supervisor which allows us

d i r e c t access to various portions of the nodespace; 3)

a parser which converts strings of words i n t o network

structures; 4) an interpreter which processes sections

of the nodespace and c a r r i e s out any s t r a t e g i e s which

were s t o r e d in t h a t p o r t i o n of t h e nodespace. The sys-

tem i s w r i t t e n i n ALGOL o n t h e B u r r o u g h s 6700 a t t h e

u n i v e r s i t y o f C a l i f o r n i a , San D i e g o .

The s i m u l a t i o n s

a r e done i n o u r own E n g l i s h - l i k e l a n g u a g e , w i t h a l l

statements entered through the p a r s e r . The language is

c a l l e d SOL ( f o r S e m a n t i c O p e r a t i n g L a n g u a g e -- p r o n o u n c e d

" s o u l " ) and i t i s s p e c i f i c a l l y designed f o r manipulat-

ing and t r a v e r s i n g the network s t r u c t u r e s of the data

b a s e . Because we wish many d i f f e r e n t p s y c h o l o g i c a l

simulations to be handled by the one system, we have

made i t r e a s o n a b l y g e n e r a l and r e a d i l y e x t e n d a b l e s o t h a t any of the psychological hypotheses under study can b e s i m u l a t e d and t e s t e d i n i t s own s p e c i a l i z e d mini-world.
The Representation of A c t i o n s and Concepts. The representation to be described here is presented in more d e t a i l and w i t h more j u s t i f i c a t i o n in the papers by Rumelhart, Lindsay & Norman3 and Norman4. B a s i c a l l y , we use a network representation w i t h nodes connected to other nodes by l a b e l e d , d i r e c t e d r e l a t i o n s . Because each r e l a t i o n also has an i n v e r s e , the network is bidirectional.
Events are specified in a similar way, except that a c t i o n s r e q u i r e arguments. Thus, the node t h a t r e p r e s e n t s a n a c t i o n may have o b l i g a t o r y r e l a t i o n s l e a d i n g from i t , specifying such things as the agent, l o c a t i o n , and o b j e c t of t h a t a c t i o n .
Most a c t i o n s and concepts in the network have a s i n g l e primary node (or type node) t h a t encodes i t s d e f i n i t i o n , and numerous secondary nodes (or token nodes) that represent s p e c i f i c instances of the primary one. Almost a l l encodings of s p e c i f i c scenes are done by means of secondary nodes.
The b a s i c u n i t in t h e memory space is t h e scenario: an action that consists of events, agents, locations, and o b j e c t s . To i l l u s t r a t e the r e p r e s e n t a t i o n a l system, consider the sentence
Peter put the package on the t a b l e . F i g u r e 1 shows a p o s s i b l e simple encoding f o r t h i s sent e n c e w h i c h i n c l u d e s some o f t h e u n d e r l y i n g s t r u c t u r e s of the action.
Figure 1. Peter put the package on the t a b l e .
The SOL Language
The p a r s i n g process is based on t h r e e independently motivated principles. F i r s t , the parsing procedures are represented as an augmented recursive t r a n s i t i o n n e t w o r k ( f o l l o w i n g t h e work o f Woods and K a p l a n 5 * 6 ' 7 ) . Second, the parser is based around a "case grammar" ( a f t e r F i l l m o r e 8 ) and has "case frames" and "argument c o n s t r a i n t s " a s s o c i a t e d w i t h many l e x i c a l i t e m s . (Here some o f t h e methods s u g g e s t e d b y Schank9 can b e u s e d . ) T h i r d , the parsing is based on the idea that it is the t a s k o f each noun phrase t o f i n d i t s own r e f e r e n t i n memory i f i t e x i s t s o r e l s e t o c r e a t e a new s t r u c t u r e in the data base. Thus, c e r t a i n l e x i c a l items such as determiners, a d j e c t i v e s , and pronouns are defined by the strategies for finding the proper referent.
Argument Frames. Associated with every predicate word is an argument frame which i n d i c a t e s which and how many arguments must e x i s t . For example, a s s o c i a t e d w i t h t h e v e r b move m i g h t b e t h e f o l l o w i n g s e t o f arguments; 1) a causal mover ( c a l l e d here an AGENT); 2 ) a moved o b j e c t ( O B J ) ; 3 ) a n i n i t i a l l o c a t i o n (FROMLOC); 4) a t e r m i n a l l o c a t i o n (T0-L0C); 5) a means of moving (METHOD); and 6) a t i m e of o c c u r r e n c e (AT-TIME). We denote the argument frame as f o l l o w s :
AGENT X MOVES Y (FR0M-L0C Ll T0-L0C L2 METHOD M AT-TIME T ) .
Those arguments enclosed in parentheses are taken to be optional; the others are required. Associated with each case name ( e . g . , FROM-LOC o r METHOD) i s a l i s t o f prepositions which can occur at the surface level to i n d i c a t e or mark t h a t argument. Each l a b e l a l s o is

450

associated with a set of semantic characteristics which can be i n t e r r o g a t e d during the parse. The p r e p o s i t i o n s and the semantic c h a r a c t e r i s t i c s can be used together to disambiguate which of the variety of concepts a given noun phrase is r e p r e s e n t i n g .
Certain verbs, p a r t i c u l a r l y those t a l k i n g about ideas, sometimes take whole sentences as arguments. Such arguments are r e f e r r e d to in our system as prepo s i t i o n a l arguments (PROPOSITION). Thus, the argument frame f o r one sense of the verb make (as in the sentence "Freddy made h i s brother come home") takes a p r o p o s i t i o n a l argument and has the argument frame
AGENT X MAKE PROPOSITION Y (METHOD M AT-TIME T)
where Y stands f o r some transformed version of an ent i r e sentence.
At every -point during the parse the goal is to f i n d and c o r r e c t l y f i l l the argument s l o t s o f the predi c a t e word in q u e s t i o n . If some arguments do not f i t i n t o the frame of the sense of the predicate word in q u e s t i o n , a new sense of the predicate word is t r i e d u n t i l e i t h e r a f i t occurs, or no more senses e x i s t ( i n which case, the parse f a i l s ) .
Operators. One important class of words in our language analysis is the class we c a l l operators. Operators are nouns t h a t take arguments ( u s u a l l y prepo s i t i o n a l phrases) and thus have associated case frames. Operators can be verb based nouns such as d e s t r u c t i o n in the destruction of the c i t y by the enemy--destruct i o n is an operator w i t h i t s two arguments f i l l e d by the f o l l o w i n g noun phrases. An operator is also a r e l a t i o n a l noun such as f a t h e r , as in the sentence " B i l l is the father of Henry." Here, father is analyzed as an operator w i t h one argument. The existence of case frames f o r these nouns as w e l l as verbs reduces substantially the ambiguity of prepositional modification.
Disambiguating the Referent
One of the major problems in the analysis of n a t u r a l language is determining the exact referents of a phrase. Most of the complexities of such words as the come from the d i f f i c u l t i e s of determining j u s t what concept is being r e f e r r e d t o . In the SOL system the parser automatically invokes the procedural definition of the which, in turn, performs an active search through the data base to determine the r e f e r e n t as each noun phrase is analyzed. We i l l u s t r a t e here how t h i s is done by going through the s t r a t e g i e s t h a t comprise the procedural d e f i n i t i o n for the. In rough form, the process is t h i s : f i r s t , if the phrase is an operator, then it contains the procedures f o r i t s own disambiguation which should be performed before doing anything else. If that is not the case, then we determine whether the object being referred to is unique within the data base, for if it i s , no particular problem e x i s t s . If these two s t r a t e g i e s f a i l , then we see whether or not immediate context h e l p s , and if t h a t f a i l s , we look to see whether or not there is a r e l a t i v e clause t h a t can do the j o b . Now look at t h i s in detail.
Operators. If the unknown phrase is an operator, then it is necessary to determine whether or not to perform the operation or to refer to the value of the operation. Thus, w i t h the phrase the father of John the operator f a t h e r has not been evaluated, so f i r s t we execute the routine f o r father (passing John to it as an argument) and then r e t u r n to the parser w i t h the r e s u l t of t h a t operation (presumably, the name of the person who is John's f a t h e r ) . If f a t h e r is being used in i t s nominal sense, however, as in "I t o l d the father to give the toothbrush to the daughter," then we are referring to the value that a previous execution of the operator had returned.
Unique Instances. If a given concept is unique to the data base, then it can be unambiguously found when-

ever r e f e r r e d to w i t h a determiner. Thus, if the memory system knows of only one ocean, to t e l l it "The sun set over the ocean" is completely unambiguous, not because the system is i n t e l l i g e n t , but rather because it doesn't know enough to be confused. T e l l it about the existence of a second ocean (or a second sun) and t h i s strategy w i l l not work (but the f o l l o w i n g ones m i g h t ) .
Foregrounding. Chafe1" suggests t h a t many problems in disambiguation are handled by context in a manner that he calls "foregrounding." If the recent cont e x t has been about "Fred's k i t c h e n , " then the objects in t h a t p a r t i c u l a r kitchen are foregrounded even though they have never been mentioned s p e c i f i c a l l y . Foreground establishes l o c a l context. In our system each concept t h a t can be brought to the foreground has associated w i t h it a s p e c i f i c l i s t of items. As new sentences pass through the parser, they i n i t i a t e the appropriate foreground l i s t s .
Note t h a t foreground has several h i e r a r c h i c a l levels, for the context includes the general overall t o p i c under d i s c u s s i o n , the s p e c i f i c d e t a i l s , and the environmental setting of the speakers. Thus, in this paper we could now t a l k of " t h i s conference" or " t h i s parser," both of which would be disambiguated by foreg r o u n d - l i k e o p e r a t i o n s , but each would be at d i f f e r e n t levels.
Short-term Memory. We can also look back in short-term memory to determine if any of the recent sentences help disambiguate the r e f e r e n t . At the moment, we look back over the l a s t f i v e sentences. Event u a l l y , we intend to have a more reasonable s i m u l a t i o n of human short-term memory processes, so t h a t only t o p ics that could reasonably be expected s t i l l to remain in a c t i v e short-term memory could be disambiguated t h i s way.
Search. I f a l l this f a i l s , i t i s s t i l l possible t h a t an i n t e l l i g e n t search among the concepts discussed r e c e n t l y (or foregrounded recently) could disambiguate the r e f e r e n t . This s t r a t e g y has not yet been implemented, p r i m a r i l y because i t s use depends upon the operation of a search routine that is not yet f u l l y opera t i o n a l . (The search r o u t i n e is a simultaneous breadthf i r s t search emanating from as many nodes as are s p e c i f i e d , r e t u r n i n g w i t h a path that l i n k s a l l the nodes in the search space. That path is evaluated for i t s l o g i cal p r o p e r t i e s and the search process is e i t h e r t e r m i nated or continued.)
Clauses. A common method of disambiguation is by the use of clauses, as in the phrase the g i r l (whom) I saw in the park. This method of disambiguation is c l e a r l y an important part of normal English, It has been deleted from the e x i s t i n g the routines because the search routines do not yet work. But it is an import a n t enough process to warrant f u r t h e r discussion here.
Consider the sentence "I see the g i r l w i t h the t e l e s c o p e . " As it now stands the sentence is incomp l e t e and, t h e r e f o r e , ambiguous: we need some c o n t e x t . Suppose t h a t the f o l l o w i n g information is known by the system.
Jane, Mary, Cynthia, and Helen are g i r l s . Mary has a telescope. These data are represented in the l e f t part of Figure 2.
Figure 2.
The analysis of the sentence "I see the g i r l w i t h the telescope" is simple u n t i l we reach the phrase the g i r l . Thus, we can recognize I a s the subject of the verb see. (The model has only one person w i t h whom it converses, namely you. The change in designation of the subject to the case r e l a t i o n of agent occurs w i t h the construction of the deep parse ana construction of a permanent memory segment.) The analysis of the is complex because a l l the strategies discussed so f a r would f a i l . We need to look at the clause w i t h the

451

telescope. A search of the data base reveals that only one g i r l possesses a telescope; now we have d i s ambiguated the referent (see Figure 2).
A d i f f e r e n t r e s u l t would occur had the contextual information in the data base been the f o l l o w i n g .
Mary is a g i r l . I got a telescope on Tuesday. The r e s u l t i n g analysis is shown in Figure 3.

Figure 3.
The major d i f f e r e n c e between the analyses shown in Figures 2 and 3 is that in the l a t t e r the phrase w i t h the telescope is n e i t h e r needed to help disambiguate the referent for the g i r l nor is it consistent w i t h the known i n f o r m a t i o n about Mary. Hence, the r e f e r e n t program completes i t s a c t i o n w i t h one phrase l e f t unanaly2ed. When c o n t r o l returns to the parser, t h i s phrase i s s t i l l l e f t . The parser then checks i t against the possible frame f o r the verb see and, in t h i s case, finds that it can be used as the instrument of seeing. Again, the sentence is analyzed with no d i f f i c u l t y and w i t h no r e c o g n i t i o n by the parser t h a t an a l t e r n a t i v e analysis was p o s s i b l e .

Defining Verbs

At this point the general description of the sys-

tem is complete. One more s p e c i f i c point is a p p r o p r i -

ate to discuss here, however. The basic premise un-

d e r l y i n g the l i n g u i s t i c analysis is that we can repre-

sent the meaning of verbs as network structures b u i l t

from a l i m i t e d set of semantic p r i m i t i v e s . Here we

wish to i l l u s t r a t e one analysis of verbs and ' t h e i r un-

d e r l y i n g p r i m i t i v e s , both to show how we believe the

l i n g u i s t i c s t r u c t u r e s should be represented and also

to demonstrate several features of the SOL language.

At least three d i f f e r e n t aspects of verb meanings

can be d i s t i n g u i s h e d : s t a t e s ; changes of s t a t e s ; and

causes of these changes. The s t a t i v e component of a

verb conveys t h a t f i x e d r e l a t i o n s h i p which holds among

i t s arguments f o r a s p e c i f i e d period of t i m e . The

change component of a verb t e l l s t h a t a change in

s t a t e has occurred. The causative component communi-

cates the source o f , or reason f o r , the change. These

d i f f e r e n t verb components are not a l l present in a l l

verbs, but a l l components may appear in a s i n g l e l e x i -

cal item.

In the remainder of t h i s section we show how we

represent these various semantic components and how we

can express the d e f i n i t i o n s of p a r t i c u l a r l e x i c a l

items in such a way that the p r i m i t i v e r e p r e s e n t a t i o n

f o r t h a t item is automatically computed whenever it appears in a sentence.11

S t a t i y e s . The simplest semantic component of

verbs is the s t a t i v e component. This component merely

communicates the information that a p a r t i c u l a r state

of the world holds from some i n i t i a l time to some f i n a l

time. The simple l o c a t i v e is an example of a verb

which seems to have only s t a t i v e components. For ex-

ample ;

A stadium was located in the park from

1956 u n t i l 1963.

(1)

Sentence (1) presumably communicates nothing more than that a p a r t i c u l a r r e l a t i o n s h i p held between a stadium and a park f o r some p e r i o d of t i m e . We represent t h i s meaning by an underlying l o c a t i v e p r i m i t i v e c a l l e d *LOC (the names of our p r i m i t i v e predicates are p r e ceded w i t h a s t e r i s k s in order to d i f f e r e n t i a t e them from surface lexical items). Figure 4 i l l u s t r a t e s the network representation we give to sentence (1).

Figure 4,

We want to define *LOC and locate in such a way t h a t when the meaning of locate is computed ( i . e . , the

d e f i n i t i o n is executed), we have the s t r u c t u r e given in Figure 4 generated in the nodespace and associated w i t h sentence (1)- To accomplish t h a t , we f i r s t define *LOC so t h a t it generates the appropriate s t r u c t u r e . Then we define locate in terms of *LOC. F i r s t the d e f i n i t i o n of *LOC:

Define as predicate *LOC. X *LOC AT-LOC L (FROM-TIME T1 TO-TIME T2). Return with newtoken f o r "*LOC" "SUBJ" X
"AT-LOC" L "FROM-TIME" Tl "TO-TIME" T2.

In this d e f i n i t i o n , the i n i t i a l line calls the special d e f i n i n g mode of the parser which sets up the basic node s t r u c t u r e f o r the d e f i n i t i o n of a new concept. It also accepts the sentences that follow as instructions f o r processes which are executed each time the newly defined s t r u c t u r e is a c t u a l l y used. The term p r e d i c a t e is the s y n t a c t i c class to which *LOC is being assigned. This class includes a l l r e l a t i o n a l terms which can stand as the main r e l a t i o n a l term of a sentence. The second l i n e of the d e f i n i t i o n gives the argument frame for the d e f i n i t i o n . In t h i s example, the structure t h a t *L0C returns is a newly constructed token node (secondary node) f o r the p r i m i t i v e w i t h the appropriate argument values inserted in place.
Now we can define the s t a t i v e sense of the verb locate:
Define as predicate LOCATE.
X LOCATE AT-LOC L (PROM-TIME Tl TO-TIME T2). Iswhen X *LOC at L from T1 to T2.

(Other senses of l o c a t e can also be d e f i n e d , but they are not shown in t h i s example.) Note here t h a t when the d e f i n i t i o n of locate is invoked, a statement i n v o l v i n g *LOC is asserted. Whenever t h i s happens, the d e f i n i t i o n of *LOC is invoked and a s t r u c t u r e s i m i l a r to that in Figure 4 is generated. This structure is then passed back through the d e f i n i t i o n of locate and in t h i s case returned hack to be associated w i t h the surface p r o p o s i t i o n from which it was invoked. Thus, the s t r u c t u r e generated by *L0C becomes associated w i t h the use of the verb l o c a t e . The term is when is an act i o n of SOL which c a r r i e s out the d e t a i l s of passing back the newly constructed s t r u c t u r e s .
Change-of-States. The next simplest type of verb component is t h a t of the change of s t a t e where no part i c u l a r causative component is s p e c i f i e d or i m p l i e d . For example:

The t r a i n moved out of the s t a t i o n at 3 o'clock.

C2)

In t h i s sentence the subject, t r a i n , is the object of moved, not the causative agent. L e t t i n g "CHANGE he the underlying p r i m i t i v e i n d i c a t i n g change o f s t a t e , w e i l l u s t r a t e the network structure f o r sentence (2) in Figure 5.

Figure S.

We want to define *CHANGE in such a way t h a t it constructs s t r u c t u r e s l i k e those shown in Figure 5. The features of these s t r u c t u r e s a r e : 1) i n d i c a t e t h a t the former s t a t e (FROM-STATE) terminated at the time of the change; 2) i n d i c a t e t h a t the f i n a l s t a t e (TO-STATE) was i n i t i a t e d at the time of the change; 3) construct and r e t u r n w i t h a new token node f o r change w i t h each of the arguments f i l l e d with the appropriate structures. The SOL d e f i n i t i o n of "CHANGE is t h i s :
Define *CHANGE as operator. *CHANGE FROM-STATE S1 TO-STATE S2 AT-TIME T. Understand t h a t S1 ended at T. Understand that S2 started at T. Return w i t h newtoken f o r "*CHANGE" "FROM-
STATE" SI "TO-STATE" S2 "AT-TIME" T.
We are now ready to define the i n t r a n s i t i v e ( i . e . , non-causative) sense of the verb move. We c a l l t h i s

452

sense M0VE1 to d i s t i n g u i s h it from the general sense of move which contains a causative component. The noncausative sense simply indicates a change from one l o c a t i v e s t a t e to another one. The SOL d e f i n i t i o n f o r M0VE1 is t h i s :

Define as predicate M0VE1.
X M0VE1 (FROM-LOC L1 TO-LOC L2 AT-TIME T ) . Iswhen a "CHANGE from the s t a t e t h a t X
is located at L1 to the state that X is located at L2 occurs at T.

Note t h a t when t h i s d e f i n i t i o n i s evaluated, i t i n vokes *LOC twice (through the two uses of locate) and passes the s t r u c t u r e s b u i l t by *L0C to *CHANGE where the f i n a l structure of the form in Figure 5 is put together and then associated w i t h the current invocation of MOVE.
Causatives. The p r o t o t y p i c a l causal verb i s , of course, the verb cause i t s e l f . The complexity of the causal component of verbs stems from the f a c t t h a t there are at least three qualitatively different sorts of causes of events. As an i l l u s t r a t i o n , consider the following five sentences:

The cowboy caused Ambrose to wake by putting water on him.

(3a)

The cowboy caused Ambrose to wake w i t h

a bucket of water.

(3b)

The cowboy caused Ambrose to wake.

(3c)

The water caused Ambrose to wake.

(3d)

Ambrose was awakened by water being

put on him.

(3e)

Sentence (3a) i l l u s t r a t e s the s p e c i f i c a t i o n of a l l

three types of causes: 1) the agentive cause (the cow-

boy); 2) the instrumental cause (the w a t e r ) ; 3) the

method (the p u t t i n g of the w a t e r ) . Sentences (3b)-

(3e) i l l u s t r a t e some of the surface forms in which

these causes can appear. We hold the basic underlying

model of causatives to be t h a t "someone does something

w i t h some i n s t r u m e n t . " If the event is f u l l y speci-

f i e d , then that event is taken to be the cause; other-

wise a dummy a c t , *D0, is i n s e r t e d i n t o the s t r u c t u r e .

Figure 6A-E gives the network representations f o r the

sentences (3a)-(3e).

Figure 6A-E

Note in 6A t h a t the structure f o r put (from Figure 1) is the event causing Ambrose to wake. When the event is not known it is replaced by *D0 with the agent or instrument properly f i l l e d i n .
We are now in a p o s i t i o n to define cause in such a way t h a t the proper causative s t r u c t u r e w i l l be generated whenever the d e f i n i t i o n of cause is executed:
Define as predicate CAUSE. AGENT X CAUSE PROPOSITION Y (METHOD M
INSTRUMENT I AT-TIME T ) . If M is specified,
understand that M started at T, evaluate M, c a l l M "ACT", else call(newtoken f o r " D 0 " "AGENT" X
"INSTRUMENT" I) ACT. Understand that Y started at T. Evaluate Y. Return w i t h a newtoken f o r "*CAUSE"
"EVENT" ACT "RESULT" Y.
In t h i s d e f i n i t i o n we f i r s t check to see whether the method is s p e c i f i e d ; if so, we say t h a t it was i n i t i ated at the time of the cause, compute the s t r u c t u r e associated w i t h the method (by evaluating the procedure MJ, and save t h a t s t r u c t u r e in a v a r i a b l e c a l l e d ACT. In case the method is u n s p e c i f i e d , we b u i l d a

dummy a c t i o n and s t o r e it in ACT. We then compute the structure f o r Y, the caused event (by evaluating the procedure for Y). Using the predicate for the p r i m i t i v e sense of cause, we now l i n k the causative event to the resultant event. Finally, the procedure returns with a structure that represents the entire definition.
Now t h a t we have defined the p r i m i t i v e s f o r the three basic types of components, we can use these as building blocks to define ever broader classes of verbs with increasingly natural d e f i n i t i o n s . We can, f o r example, define the verb MOVE as it appears on the surface. The SOL d e f i n i t i o n of MOVE is t h i s :
Define as predicate MOVE. (AGENT X) MOVES Y (FROM-LOC L1 TO-LOC L2
METHOD M AT-TIME T ) . If X is not specified,
iswhen Y move! from L1 to L2 at T, else
iswhen X caused Y to movel from L1 to L2 by M at T.
Here move is defined only in terms of the i n t r a n s i t i v e move (MOVE1) and CAUSE. S i m i l a r l y , we can define the verb put in terms of MOVE so t h a t the s t r u c t u r e i l l u s trated in Figure 1 is produced:
Define as predicate PUT. ASENT X PUTS Y AT-LOC L (AT-TIME T ) . Iswhen X moves Y to L at T.
Note that these d e f i n i t i o n s do more than simply r e w r i t e one verb in terms of another. The important point about the e n t i r e memory model is the type of r e presentational structure that is constructed with the network. With these verb definitions, the primitives b u i l d new s t r u c t u r e s and modify o l d i n f o r m a t i o n . Thus, in the d e f i n i t i o n of MOVE, the l a s t l i n e performs the processes f o r CAUSE and also the processes defined f o r M0VE1. CAUSE both b u i l d s a s t r u c t u r e f o r the causal f a c t o r s and also performs whatever processes are r e p r e sented by M, the method. The process f o r M is passed as an argument down from the o r i g i n a l sentence t h a t was entered through the parser, through the definitional s t r u c t u r e f o r MOVE, and f i n a l l y to the d e f i n i t i o n a l s t r u c t u r e f o r CAUSE. There it is f i n a l l y executed, b u i l d i n g whatever network s t r u c t u r e the method M represents.

The Three Drugstores Problem

In t h i s section we give an example of one problem being analyzed by our research group. A major feature of the way t h a t a person views the events of the world is in terms of t h e i r causal f a c t o r s . That i s , we tend to d i s b e l i e v e that an event could simply happen by its e l f ; r a t h e r , we tend to believe that an event must have a cause. The tendency to give causal reasons f o r events is important because it a f f e c t s the ways in which people make use of i n f o r m a t i o n . To i l l u s t r a t e the point, we analyze the three drugstores problem.
The basic problem before us was eloquently posed by Abelson and Reich. We paraphrase t h e i r v e r s i o n of the problem in t h i s way:

Suppose an i n d i v i d u a l says a sentence such as,

"I went to three d r u g s t o r e s . "

(4)

A response based on syntax only might be,

"How d i d you go to three drugstores?"

(5)

A response based on some semantics might be,

"What useful things d i d you buy in three

drugstores?"

(6)

But the most n a t u r a l response ought to be,

"How come the f i r s t two drugstores d i d n ' t

have what you wanted?"

(7)

453

Solving the Drugstore Problem. Just what must the required processes look l i k e to be able to solve the drugstore problem? To solve the f i r s t few levels a l l t h a t is needed is a pattern-match program t h a t examines the s t r u c t u r e of the verb of the sentence and compares the allowable arguments w i t h those a c t u a l l y presented. Thus, in the sentence, "I went to a d r u g s t o r e , " we see that the to-location is provided but not the from-locat i o n , the method, or the time. Thus, it is r e a l l y a simple matter to construct questions like (5).
To be more i n t e l l i g e n t a basic d e c i s i o n must be made: Should the missing i n f o r m a t i o n be requested? The answer is u s u a l l y no. In normal conversation informat i o n is omitted e i t h e r because it is assumed to be p r o vided by the preceding or f o l l o w i n g context or because i t i s unimportant t o the conversation. The p a t t e r n match routines (inside a procedure c a l l e d comprehend) f i l l in information by examining the structure of preceding sentences. Sometimes the i n f o r m a t i o n in p r i o r sentences might be appropriate to l a t e r ones, and sometimes the information given in the present sentence might f i l l in missing arguments from previous sentences. When missing arguments are n o t i c e d , an attempt is made to answer the i m p l i c i t question provided by t h e i r absence through an examination of the data base. In add i t i o n , the present input is examined to see whether it can f i l l arguments missing in the data base being constructed from the conversation.
So f a r , we have simply i n v e s t i g a t e d a simple means for f i l l i n g out the syntactic pattern for verbs, albeit w i t h some s o p h i s t i c a t i o n in determining when to ask f o r mors i n f o r m a t i o n . The next step is more complex. Suppose we wish to determine why someone has gone to the drugstore. Again, we should not simply have to ask why, but rather determine the general reasons f o r going to the s t o r e s . For t h i s p o i n t the comprehend r o u t i n e must be i n t e l l i g e n t enough to examine a more general data base. Now a f a i r amount of inference is r e q u i r e d : we need to match the basic paradigm w i t h the s p e c i f i c information given by the parsed sentence. This is not easy when one considers t h a t many d i f f e r e n t paradigms w i l l probably be s t o r e d . If the sentence had been, "John went to a shoestore," then the same analysis should c l e a r l y not y i e l d the query, "What d i d John buy at the shoestore?" The comprehend r o u t i n e must be f l e x i b l e enough to solve t h i s part of the problem by i t s e l f . A large amount of world knowledge is needed to solve the general problem.
This b r i e f analysis shows t h a t in order to have i n t e l l i g e n t conversation it is necessary to be able to generate i n t e r n a l questions and t h e i r answers, Whenever i n f o r m a t i o n is missing some attempt must be made to f i l l in the gap, sometimes by asking appropriate questions, but usually by internal problem solving. In general, i n f o r m a t i o n should not be requested by means of a quest i o n unless there is some actual need f o r it at the moment. Moreover, it would appear that the information should be asked from the very highest level down. Thus, the f i r s t question asked should r e f e r to the motive and results of the operations being described. Only l a t e r should s p e c i f i c d e t a i l s of the method be asked.
In the implementation of the memory model system at the time of t h i s w r i t i n g , a l l the l e v e l s of analysis can not yet be performed. Basically, the implementation is complete up to the level of the sophisticated internal answering of questions. Thus, it has been an easy matt e r to implement a question answering routine to ask questions like the following for the input sentence: How d i d John go to the drugstore? What d i d he do a f t e r wards? With whom d i d he go? At the moment, the basic r o u t i n e s to ask such questions as "What d i d he buy at the drugstore?" are close to operation, but the cons t r u c t i o n of the system t h a t can ask the question o r i g i n a l l y posed, "How come the f i r s t two drugstores d i d n ' t have what you wanted?" s t i l l remains some distance away.
The memory representation provides a r i c h e n v i r o n -

merit f o r s i m u l a t i n g human c o g n i t i v e processes. The major ideas have been implemented, y i e l d i n g an a c t i v e network representation with an English parser that a l lows i n t e r a c t i o n w i t h the network and ready e x t e n d a b i l i t y . Actual simulations of human c o g n i t i v e tasks have j u s t begun, and although work is in progress in a v a r i ety of areas, no large system has yet been completed. However, f o r a d e s c r i p t i o n of the use of t h i s system in human problem) s o l v i n g , see the paper by Eisenstadt and Kareev.

454

FIGURE 1 455

456

FIGURE 5 457

