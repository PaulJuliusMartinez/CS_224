Symbolic Heuristic Search Value Iteration for Factored POMDPs

Hyeong Seop Sim and Kee-Eung Kim and Jin Hyung Kim

Department of Computer Science, Korea Advanced Institute of Science and Technology

Daejeon, Korea

Du-Seong Chang and Myoung-Wan Koo

HCI Research Department, KT

Seoul, Korea

Abstract

We propose Symbolic heuristic search value iteration
(Symbolic HSVI) algorithm, which extends the heuris-
tic search value iteration (HSVI) algorithm in order to
handle factored partially observable Markov decision
processes (factored POMDPs). The idea is to use al-
gebraic decision diagrams (ADDs) for compactly rep-
resenting the problem itself and all the relevant inter-
mediate computation results in the algorithm. We lever-
age Symbolic Perseus for computing the lower bound
of the optimal value function using ADD operators, and
provide a novel ADD-based procedure for computing
the upper bound. Experiments on a number of standard
factored POMDP problems show that we can achieve an
order of magnitude improvement in performance over
previously proposed algorithms.

Partially observable Markov decision processes (POMDPs)
are widely used for modeling stochastic sequential deci-
sion problems with noisy observations. However, when we
model real-world problems, we often need a compact rep-
resentation since the model may result in a very large num-
ber of states when using the ﬂat, table-based representation.
Factored POMDPs (Boutilier & Poole 1996) are one type of
such compact representation.

Given a factored POMDP, we have to design an algo-
rithm that does not explicitly enumerate all the states in the
model. For this purpose, it has gained popularity over the
years to use the algebraic decision diagram (ADD) represen-
tation (Bahar et al. 1993) of all the vectors and matrices used
in conventional POMDP algorithms. Hansen & Feng (2000)
extended the Incremental Pruning algorithm (Cassandra,
Littman, & Zhang 1997) to use ADDs. More recently,
Poupart (2005) proposed the Symbolic Perseus algorithm,
which is a point-based value iteration using ADDs. Sym-
bolic Perseus was the primary motivation for our work to
design a symbolic version of heuristic search value iteration
(HSVI) algorithm (Smith & Simmons 2004; 2005) to handle
factored POMDPs by using ADDs in a similar manner.

HSVI is also a point-based value iteration algorithm that
recursively explores important belief points for approximat-
ing the optimal value function. For this purpose, HSVI com-
putes both the lower as well as the upper bound of the value

Copyright c(cid:13) 2008, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

Procedure: π = HSVI(ǫ)

Initialize V⊕ and V⊖
while V⊕(b0) − V⊖(b0) > ǫ do

explore(b0, V⊕, V⊖)

end while

Procedure: explore(b, V⊕, V⊖)

if V⊕(b) − V⊖(b) ≤ ǫγ−t then

return

end if
a∗ ← argmaxa QV⊕(b, a)
z∗ ← argmaxz P (z|b, a∗)

explore(τ (b, a∗, z∗), V⊕, V⊖)
V⊖ ← V⊖ ∪ backup(b, V⊖)
V⊕ ← V⊕ ∪ {(b, HV⊕(b))}

·[V⊕(τ (b, a∗, z)) − V⊖(τ (b, a∗, z)) − ǫγ−t−1]

Procedure: α = backup(b, V⊖)

αa,z ← argmaxα⊖∈V⊖(α⊖ · τ (b, a, z))

αa(s) ← R(s, a) + γPz,s′ αa,z(s′)O(s′, a, z)T (s, a, s′)

α ← argmaxαa (αa · b)

Figure 1: Top level pseudo-code of HSVI

function in each recursive exploration. Our proposed al-
gorithm (hereafter Symbolic HSVI) uses ADD operators to
compute the upper and lower bound without explicitly enu-
merating the states and observations of the POMDP. We de-
scribe the implementation of core procedures and the exper-
imental results on a number of benchmark factored POMDP
problems.

Overview of POMDPs and HSVI

POMDPs model stochastic control problems with partially
observable states. A POMDP is speciﬁed as a tuple
hS, A, Z, T, O, R, b0i: S is the set of states (s is a state);
A is the set of actions (a is an action); Z is the set of ob-
servations (z is an observation); T (s, a, s′) is the transition
probability of changing to state s′ from state s by executing
action a; O(s, a, z) is the observation probability of observ-
ing z after executing action a and reaching in state s; R(s, a)
is the immediate reward of executing action a in state s; b0
is the initial belief, which is the starting probability distribu-

Proceedings of the Twenty-Third AAAI Conference on Artificial Intelligence (2008)1088Procedure: V⊕(b)

V interior

⊕

αcorner
⊕ = [αcorner
V corner
(b) ← b · αcorner
for (bi, vi) ∈ V interior

⊕

⊕

⊕

do

= {(bi, vi)|bi is an interior point of the belief

simplex, and vi is the upper bound value at bi}
⊕ (s0), . . . , αcorner

⊕ (sn)]

Figure 2: The sawtooth upper bound

Figure 3: Pseudo-code for the sawtooth upper bound

φ ← min{b(s)/bi(s)|s ∈ S, bi(s) > 0}
(b) + φ(vi − bi · αcorner
⊕(b) ← V corner
V i
⊕ )

⊕

end for
V⊕(b) = mini V i

⊕(b)

tion on the states at the initial time step. Since the state is
hidden, POMDP algorithms often make use of belief, which
is the probability distribution b over the current states, for
computing the policy π that maximizes the long-term dis-

t=0 γtR(st, at)|b, π].

counted reward V π(b) = E [P∞

In the following subsections, we brieﬂy overview the
HSVI algorithm (a point-based POMDP algorithm) for the
comprehensibility of presentation. We limit our discussion
to the improved version of HSVI, namely HSVI2, which we
used as the basis for Symbolic HSVI. For more details, we
refer the readers to (Smith & Simmons 2004) for the original
version of HSVI, and (Smith & Simmons 2005) for HSVI2.
The outline of HSVI is shown in Figure 1.

Bound initialization
HSVI computes the initial lower bound by evaluating the
value of blind policies of form “always execute action a”.
The evaluation of each blind policy is carried out by Markov
decision process (MDP) policy evaluation:

αa

⊖,t+1(s) = R(s, a) + γPs′ T (s, a, s′)αa

⊖,t(s′)
The initial lower bound is given by the set of all αa
each action a: V⊖ = {αa

⊖|a ∈ A}.

(1)
⊖’s for

For computing the initial upper bound, HSVI uses the fast

informed bound method (Hauskrecht 2000):
αa

⊕,t+1(s) = R(s, a)

(2)

+ γPz maxa′ Ps′ T (s, a, s′)O(s′, a, z)αa′

⊕,t(s′)
Alternatively, the initial upper bound can be obtained by
computing the value function of fully observable MDP, as
in the original version of HSVI:

αa

⊕,t+1(s) = R(s, a) + γXs′

T (s, a, s′) max

a′

αa′
⊕,t(s′) (3)

Once αa

⊕ (s) = maxa αa

⊕’s are computed for each action a, the upper
bound should be given by the set of all belief simplex cor-
ner points for each state s and their corresponding upper
bound value αcorner
⊕(s). Hence, V⊕ =
⊕(s))|s ∈ S} where es is the unit vector with
{(es, maxa αa
the s-th element es(s) = 1. However, as we will ex-
plain shortly, the initial upper bound is stored as a vector
αcorner
⊕ = [αcorner
⊕ (sn)] in order to differenti-
ate between the interior belief points (b(s) < 1, ∀s) and the
corner belief points (e.g., b = es).

⊕ (s0), . . . , αcorner

Upper and lower bound update
HSVI uses the set of α-vectors for representing the lower
bound, as with the case of most POMDP algorithms. The
lower bound is updated by the backup operation, which is
the standard point-based Bellman update as given in Fig-
ure 1; τ (b, a, z) is the successor of belief point b, which will
be deﬁned in the next section.

The upper bound is represented as the set of pairs
(b, V⊕(b)), so that V⊕(b) is guaranteed to be always greater
than or equal to the true optimal value at belief point b.
Given such set of pairs, the upper bound is deﬁned by the
convex hull of V⊕(b)’s. Although it requires linear program-
ming to ﬁnd the exact value for the upper bound, HSVI in-
stead uses the approximation of the estimate for the upper
bound suggested by (Hauskrecht 2000). The idea is shown
in Figure 2. Suppose that two belief points b1 and b2 are
known to have upper bound values v1 and v2, respectively.
Instead of computing the convex hull formed by v1, v2,
and αcorner
⊕ ’s, HSVI uses the sawtooth-shaped upper bound
shown as the thick solid line. To compute the upper bound
value at a new belief point b, we compute the value predicted
by one interior belief point and the corner points. For exam-
ple, if the interior belief point is b1, the predicted value is
given by

⊕(b) = b1 ·αcorner
V 1

⊕ +min(cid:20) b(s0)

b1(s0)

,

b(s1)

b1(s1)(cid:21) (v1 −b1 ·αcorner

⊕ )

following the formula for the proportional difference. We
repeat for b2, and the ﬁnal upper bound value predicted from
the sawtooth bound is

V⊕(b) = min[V 1

⊕(b), V 2

⊕(b)]

Figure 3 shows the pseudo-code for computing the upper
bound value based on the sawtooth bound.

The upper bound at belief point b is updated by operator

H, deﬁned as

QV⊕(b, a) =Xs

R(s, a)b(s)+γXz

HV⊕(b) = maxa QV⊕ (b, a)

P (z|b, a)V⊕(τ (b, a, z))

(4)

where P (z|b, a) = Ps′ O(s′, a, z)Ps b(s)T (s, a, s′)
Belief point exploration
Given the current upper and lower bounds of the optimal
value (V⊕ and V⊖) and the belief point b, HSVI uses the

1089Figure 4: Calculating the successors of belief point and computing αa(S, Z). Since the whole ADD is too large to show in this
paper, we show how the relevant operations are done on only one abstract observation (charge = zero).

following heuristic to explore the belief points (i.e., select a
belief point among successors of b). First, HSVI computes
the upper bound for the value of executing action a in belief
point b, which we denote as QV⊕ (b, a) given in Equation 4,
and selects action a∗ that yields the maximum upper bound
value. Second, HSVI selects an observation z∗ so that the
difference of bounds is greatest at the successor belief point
b′ = τ (b, a∗, z∗) deﬁned as

where C is a normalizing constant so that Ps′ b′(s′) = 1.

b′(s′) = C · O(s′, a∗, z∗)Ps b(s)T (s, a∗, s′)
Symbolic HSVI for Factored POMDPs

POMDP problems are traditionally represented in terms of
matrices and vectors. However, real-world problems often
exhibit large numbers of states and observations, and hence
it is impractical to use such “ﬂat” representation. Factored
POMDPs (Boutilier & Poole 1996) use factored representa-
tion of states and observations by introducing state and ob-
servation variables. The idea is to compactly represent the
transition probabilities, the observation probabilities, and
the rewards in terms of these variables. We use ADDs (Ba-
har et al. 1993) to represent the problem, as well as all the
relevant intermediate computation results used in the algo-
rithm. For details on using ADDs in other POMDP algo-
rithms, we refer the readers to (Hansen & Feng 2000) for
the Incremental Pruning algorithm and (Poupart 2005) for
the Perseus algorithm.

In this section, we explain our Symbolic HSVI algorithm,
which extends HSVI algorithm to handle factored POMDPs.
We will use the following notations for the ease of presenta-
tion: S for the set of state variables for the current time step,
S ′ for the set of state variables for the next time step, and
Z for the set of observation variables. We explicitly attach
the variables to notations to signify the fact that a vector or a
matrix is represented as an ADD, e.g., b(S) is a belief point
represented as an ADD. Some of the ADD operators used

frequently in the algorithm are the product (·), sum (+), and

existential abstraction (PS).
Bound initialization
The initializations of the lower and upper bounds are carried
out using SPUDD (Hoey et al. 1999). Speciﬁcally, assum-
ing an ADD representation for the αa
⊖,t(S), we use ADD
product, existential abstraction, and sum operators for com-
puting the lower bound in Equation 1:

αa

⊖,t(S ′)

⊖,t+1(S) = Ra(S) + γPS ′ Ta(S, S ′)αa

Similarly, we can compute the upper bound by fast informed
bound method in Equation 2 using ADD product, existential
abstraction, sum, and max operators:
αa

⊕,t+1(S) = Ra(S)

+ γXZ

max

a′ XS ′

Ta(S, S ′)Oa′ (S ′, Z)αa′

⊕,t(S ′)

However, as noted in (Smith & Simmons 2005), fast in-
formed bound does not signiﬁcantly increase the perfor-
mance of HSVI. We observed the same trend in Symbolic
HSVI, so instead we implemented the fully observable MDP
bound in Equation 3:
αa

⊕,t+1(S) = maxa(cid:2)Ra(S) + γPS ′ Ta(S, S ′)αa
Upper and lower bound update
As with other ADD-based POMDP algorithms, Symbolic
HSVI uses ADDs to represent α-vectors. The evalua-
tion of lower bound at a belief point b(S) is done by

⊕,t(S ′)(cid:3)

maxα⊖(S)∈V⊖ PS b(S)α⊖(S) which involves ADD prod-

uct and existential abstraction operators.

In order to establish the backup operator for updating the
lower bound, we ﬁrst compute the ADD of all successors
from the current belief point b(S) by executing action a:

τ (b(S), a, Z) = PS Ta(S, S ′)Oa(S ′, Z)b(S)
PS,S ′ Ta(S, S ′)Oa(S ′, Z)b(S)

1090Procedure: V⊕(b(S))

V interior

⊕

= {(bi(S), vi)|bi(S) is an interior point of the

belief simplex, and vi is the upper bound value
at bi(S)}

⊕ (S) = upper bound from the initialization step

⊕(b(S)) ← PS b(S)αcorner

αcorner
V 0
for (bi(S), vi) ∈ V interior
φ ← min{b(S)/bi(S)}
⊕(b(S)) ← V 0
V i

⊕

⊕ (S)
do

end for
V⊕(b) = mini V i

⊕(b)

⊕(b(S)) + φ(vi −PS bi(S)αcorner

⊕ (S))

Figure 5: Using ADDs for the sawtooth upper bound

where the fraction is ADD division operator. Note that
τ (b(S), a, Z) will contain observation variables in the di-
agram, hence it is effectively partitioning the observation
space into a set of abstract observations that lead to the same
successor from b(S). Figure 4 shows an example of comput-
ing such successor ADD representing τ (b0(S), nothing, Z)
for the coffee delivery problem (Poupart 2005).

Next, for each abstract observation z and the associated
successor (which is also a belief point represented as ADD),
we compute

αa,z(S) ← argmaxα⊖∈V⊖(PS α⊖(S)τ (b(S), a, z))

using the ADD product and existential abstraction operators.
The results are combined to yield αa(S, Z), the ADD repre-
senting αa,z for all observations (see the rightmost decision
diagram in Figure 4). We ﬁnally compute

αa(S) → Ra(S) + γPS ′,Z Ta(S, S ′)Oa(S, Z)αa(S ′, Z)
α(S) ← argmaxαa(S) (PS αa(S)b(S))

using appropriate ADD operators.

The evaluation of the upper bound value at belief point
b(S) is also done using ADD operators. Note that we use
ADD division operator to compute the minimum of belief
proportions (φ) without explicitly enumerating the states
(Figure 5).

The upper bound update operator H (Equation 4) is com-
puted using ADDs similarly as in the backup operator: We
ﬁrst compute τ (b(S), a, Z) to obtain the successors of b(S)
and the associated abstract observations, and evaluate the
upper bound values. The results are combined to yield
V⊕(τ (b(S), a, Z)), an ADD with observation variables as
intermediate nodes and upper bound values as leaf nodes.
Once this is done, we compute

QV⊕(b(S), a) = PS Ra(S)b(S)

HV⊕(b(S)) = maxa QV⊕(b(S), a)

+ γPZ P (Z|b(S), a)V⊕(τ (b(S), a, Z))
where P (Z|b(S), a) = PS ′ Oa(S ′, Z)PS b(S)Ta(S, S ′).
Belief point exploration
Given the aforementioned ADD-based procedures for com-
puting QV⊕ (b(S), a), V⊕(b(S)), and V⊖(b(S)), we can se-
lect action a∗ in a straight-forward way:

a∗ = argmaxa QV⊕(b(S), a)

In order
to select τ (b(S), a∗, z∗), we ﬁrst compute
τ (b(S), a∗, Z), which is an ADD representing all possible
successors from b(S) by executing action a∗ and the asso-
ciated abstract observations. For each successor b′(S), we
compute V⊕(b′(S)) and V⊖(b′(S)), and calculate the excess
uncertainty V⊕(b′(S)) − V⊖(b′(S)) − ǫγ−t−1 . The succes-
sor that maximizes the excess uncertainty weighted by the
probability of the associated abstract observation is selected
for the recursive exploration.

Additional performance optimization
HSVI additionally employs a number of techniques to speed
up the algorithm. We mention two noteworthy techniques
that are also used in symbolic HSVI: (1) HSVI caches the
value of QV⊕(b, a) for each explored belief point b in or-
der to avoid re-computation of Equation 4 in the later ex-
ploration. For example, if a1 had the greatest upper bound
and a2 had the second, if the updated QV⊕(b, a1) is greater
than cached QV⊕(b, a2), there is no need to re-compute
QV⊕(b, a2) for determining action; (2) HSVI aggressively
prunes α-vectors by combining passive bounded pruning
and pairwise pruning (Smith 2007).

Symbolic HSVI also adopts the factored belief approxi-
mation technique (Boyen & Koller 1998) used in symbolic
Perseus; since the size of the ADD for the belief point can
quickly become very large as recursive exploration depth
increases, Symbolic HSVI breaks the correlations between
state variables and represents the belief point as a product
of independent marginals. This approximation technique
has an additional beneﬁt when we compute the upper bound
value; we can obtain φ by calculating the product of the min-
imum of belief marginal ratios, instead of using the ADD
division operator. For example, if we assume Boolean state
variables,

φ ← Ys∈S

min(cid:20) b(s)

bi(s)

,

b(s)

bi(s)(cid:21)

where s represents the state variable s being true, and s be-
ing false.

Experiments

In this section, we report the experimental results of Sym-
bolic HSVI on the following benchmark factored POMDP
problems: Tiger (Kaelbling, Littman, & Cassandra 1998),
Coffee Delivery and Handwashing (Poupart 2005), and n-
City Ticketing (Williams, Poupart, & Young 2005) spoken
dialogue management problem 1 with varying error rates of
speech recognition pe = {0.0, 0.1, 0.2}.

We compared the performance of Symbolic HSVI with
the following POMDP algorithms: Perseus (Spaan & Vlas-
sis 2005), HSVI (Smith & Simmons 2005) with the same set
of performance optimizations used in Symbolic HSVI, and
Symbolic Perseus (Poupart 2005). Since Perseus and HSVI
cannot handle factored POMDPs, we prepared the equiva-
lent ﬂat versions for some of the problems (n-City Ticket-
ing problems). In addition, since Symbolic HSVI was im-

1The original problem gives the penalty of 10 when issuing a

wrong ticket, but here we give the penalty of 100.

1091Problem & Size (|S|/|A|/|Z|; |S|/|Z|)
R

Time

[ǫR]
|Γ|

37.00
36.87

76.44
78.42

0.07
0.03
0.13
0.06

6.28
6.28
6.23
6.23

3.3
0.7

4.9
1.3
3.6
1.0

6.5
1.4
4.8
1.7

3.7
1.6
6.7
1.6

[±1.41]
52
50

80.0
15.7

[±0.42]
5
5
5
5

Tiger (2/2/2; 1/1)
Perseus
HSVI
Symbolic Perseus
Symbolic HSVI
Coffee Delivery (432/10/6; 7/2)
Symbolic Perseus
Symbolic HSVI
Handwashing (180/6/6; 4/1)
[±4.19]
14
Symbolic Perseus
Symbolic HSVI
27
2-City Ticketing, pe= 0.0 (397/10/11; 5/1) [±0.016]
Perseus
4
4
HSVI
4
Symbolic Perseus
Symbolic HSVI
4
2-City Ticketing, pe= 0.1 (397/10/11; 5/1) [±0.078]
9
Perseus
5
HSVI
7
Symbolic Perseus
Symbolic HSVI
5
2-City Ticketing, pe= 0.2 (397/10/11; 5/1)
[±0.18]
8
Perseus
12
HSVI
11
Symbolic Perseus
Symbolic HSVI
25
3-City Ticketing, pe= 0.0 (1945/16/18; 5/1) [±0.023]
16
Perseus
18
HSVI
Symbolic Perseus
14
Symbolic HSVI
13
3-City Ticketing, pe= 0.1 (1945/16/18; 5/1) [±0.13]
93
Perseus
HSVI
258
101
Symbolic Perseus
Symbolic HSVI
145
3-City Ticketing, pe= 0.2 (1945/16/18; 5/1) [±0.24]
Perseus
150
626
HSVI
163
Symbolic Perseus
Symbolic HSVI
200

1260.1
1072.9
707.1
10.5

115.9
55.6
48.1
0.9

637.4
227.3
221.3
5.7

6.06
6.04
6.12
6.02

5.22
5.30
5.25
5.30

8.74
8.74
8.74
8.74

7.41
7.47
7.46
7.39

6.92
6.95
6.77
6.81

8.09
8.09
8.09
8.09

Figure 6: Performance comparison results of Symbolic
HSVI on factored POMDP problems. For the n-City Tick-
eting problems, we prepared the equivalent ﬂat versions in
order to test Perseus and HSVI. R is the average cumulative
reward of 3000 simulations, T is the execution time in sec-
onds until convergence, and |Γ| is the number of α-vectors
in the ﬁnal result.

plemented in Java, for fair comparisons, we re-implemented
other POMDP algorithms in Java using the published source
code of each algorithm. All the performance evaluation is
done on a Linux platform with the Intel Xeon 2.33GHz CPU
and 8GB memory. Figure 6 shows the performance compar-
ison results.

The execution times of the algorithms were gathered in
the following way: for HSVI algorithms, we executed mul-
tiple times with various goal widths (ǫ) and obtained an
estimate of the policy quality (cumulative reward) through
simulations. When the estimate is within 95% conﬁdence
interval of the optimal, we stopped the algorithm and mea-
sured the execution time. For Perseus algorithms, we contin-
ued execution until the value function difference was within
0.001, and measured the shortest execution time by varying
the number of initial belief points. Figure 7 shows the solu-
tion quality versus wallclock time for four of the problems.
In summary, Symbolic HSVI was able to achieve the same
level of solution quality as other algorithms, while signiﬁ-
cantly reducing the execution time. The speedup was most
distinct in large problems, speciﬁcally the 3-City Ticket-
ing problems, where Symbolic HSVI was, on average, 68x
faster than HSVI, 121x faster than Perseus, and 53x faster
than Symbolic Perseus.

Conclusion and Future Work

In this paper, we proposed Symbolic HSVI, an extension
of the HSVI algorithm to handle factored POMDPs by us-
ing ADDs. Experiments on a number of benchmark prob-
lems show that Symbolic HSVI is able to achieve an order
of magnitude speedup over previously proposed POMDP al-
gorithms in large POMDPs with factored representations.

Symbolic HSVI leverages existing techniques for using
ADDs to update the lower bound, and provides a novel
ADD-based procedure for computing the upper bound. The
upper bound computation in Symbolic HSVI is particu-
larly efﬁcient when assuming the sawtooth approximation
method and factored belief points. By combining the belief
point exploration strategy of HSVI and the efﬁcient repre-
sentation of ADDs, Symbolic HSVI scales better to larger
problems.

We are currently working on applying Symbolic HSVI
to real-world scale dialogue management problems repre-
sented as factored POMDPs. They are similar to the n-City
Ticketing problems in the task objectives (i.e., gather infor-
mation from noisy observations), however the state dynam-
ics are obtained from a real corpus.

Symbolic HSVI could also be extended to handle fac-
tored action space representations. Using variables for the
factored representation of action space has been previously
studied for MDPs (Boutilier, Dean, & Hanks 1999) but not
yet in sufﬁcient depth for POMDPs. The ADD-based proce-
dures in this paper for computing the upper and lower bound
could be easily extended to factored action space as well.

Acknowledgments

This work was supported in part by the Korea Science and
Engineering Foundation (KOSEF) grant (R01-2007-000-

1092Coffee Delivery

15.7s

80.0s

Symbolic HSVI
Symbolic Perseus

101
2−City Ticketing, pe=0.2

102

1.6s

3.7s

6.7s

 

103

 

Symbolic HSVI
Symbolic Perseus
HSVI
Perseus

100

101

102

103

90

80

70

60

50

40

 

30
10−1

10

5

0

−5

−10

−15

−20

 
100

Handwashing

 

0.7s

3.3s

Symbolic HSVI
Symbolic Perseus

100

101

102

3−City Ticketing, pe=0.2

103

 

10.5s

707.1s 1072.9s

1260.1s

Symbolic HSVI
Symbolic Perseus
HSVI
Perseus

101

102

103

104

40

30

20

10

0

−10

−20

 
100

10

5

0

−5

−10

−15

 

10−1

Figure 7: Solution quality versus wallclock time

21090-0) funded by the Korea government (MOST)

References

Bahar, R. I.; Frohm, E. A.; Gaona, C. M.; Hachtel, G. D.;
Macii, E.; Pardo, A.; and Somenzi, F. 1993. Algebraic
decision diagrams and their applications. In Proceedings
of IEEE/ACM International Conference on CAD-1993.
Boutilier, C., and Poole, D. 1996. Computing optimal
policies for partially observable decision processes using
compact representations. In Proceedings of AAAI-1996.
Boutilier, C.; Dean, T.; and Hanks, S. 1999. Decision-
theoretic planning: Structural assumptions and computa-
tional leverage. Journal of Artiﬁcial Intelligence Research
11.
Boyen, X., and Koller, D. 1998. Tractable inference for
complex stochastic processes. In Proceedings of UAI-1998.
Cassandra, A.; Littman, M. L.; and Zhang, N. L. 1997.
Incremental pruning: A simple, fast, exact method for par-
tially observable Markov decision processes. In Proceed-
ings of UAI-1997.
Hansen, E. A., and Feng, Z. 2000. Dynamic programming
for POMDPs using a factored state representation. In Pro-
ceedings of AIPS-2000.
Hauskrecht, M. 2000. Value-function approximations for
partially observable Markov decision processes. Journal of
Artiﬁcial Intelligence Research 13.

Hoey, J.; St-Aubin, R.; Hu, A.; and Boutilier, C. 1999.
SPUDD: Stochastic planning using decision diagrams. In
Proceedings of UAI-1999.
Kaelbling, L. P.; Littman, M. L.; and Cassandra, A. R.
1998. Planning and acting in partially observable stochas-
tic domains. Artiﬁcial Intelligence 101.
Poupart, P. 2005. Exploiting Structure to Efﬁciently Solve
Large Scale Partially Observable Markov Decision Pro-
cesses. Ph.D. Dissertation, University of Toronto.
Smith, T., and Simmons, R. 2004. Heuristic search value
iteration for POMDPs. In Proceedings of UAI-2004.
Smith, T., and Simmons, R. 2005. Point-based POMDP al-
gorithms: Improved analysis and implementation. In Pro-
ceedings of UAI-2005.
Smith, T. 2007. Probabilistic Planning for Robotic Explo-
ration. Ph.D. Dissertation, Carnegie Mellon University.
Spaan, M. T. J., and Vlassis, N. 2005. Perseus: Random-
ized point-based value iteration for POMDPs. Journal of
Artiﬁcial Intelligence Research 24.
Williams, J. D.; Poupart, P.; and Young, S. 2005. Factored
partially observable Markov decision processes for dia-
logue management. In Proceedings of IJCAI-2005 Work-
shop on Knowledge and Reasoning in Practical Dialogue
Systems.

1093