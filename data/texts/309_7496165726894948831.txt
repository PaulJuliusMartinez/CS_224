iInterdisciplinaw
ISystems Reseaich lnterdisziplin8re
47
.. I ,

Takeo Kanade
Computer recognition of humanfaces
1977 Birkhauser Verlag, Basel und Stuttgart

I
ISR 47
Intordisciplinrry Systems Resorrch Intordiuipliniire Systemforschung

ABSTRACT
Pictures o f human faces are successfully analyzed by a computer program w h i c h extracts face-feature p o i n t s , such as nose, m o u t h , eyes and so on. The program was tested w i t h more t h a n 800 photographs. Emphasis i s p u t on the flexible picture analysis scheme with feedback w h i c h was f i r s t enployed i n the picture analysis program with remarkable success. The program consists o f a collection of rather simple subroutines, each of which works on the specific part o f the picture, and elaborate combination o f them w i t h backup procedures makes t h e whole process flexible and adaptive. An experiment on face identification of 20 people was also conducted.
T h i s is a p a r t of the author's doctorial thesis submitted t o Department of I n f o n a t i o n Science, Kyoto University, Kyoto, Japan
".i n November 1973. The thesis t i t l e was I' Picture Processing System
by Computer Complex and Recognition of Human Faces
i

CIP-Kuraiielaufnahme der Deurschen Bibliothek
Kinad.. Taka0
-Computer recognition ofhuman faces 1 A ~ f l-
Basel Stuttgan Birkhauser 1977 (Interdisciplinan/ systems research. 4 7 ) ISBN 3-7643-0957-1
AI1 rights resewed No pan of this publication may be reproduced. stored in a retrieval system or transmnted,in any form or by any means. electronic. mechanical photocopying. recording or otherwise. wnhout the prior permisslon
ofthe copyright owner
Birkhauser Verlag Basel 1977

.

TABLE OF CONTENTS

ABSTRACT . . . . . . . . . . . . . . . . . . . . . . . . . . . . ACKNOWLEDGMENTS . . . . . . . . . . . . . . . . . . . . . . . . TABLE OF CONTENTS . . . . . . . . . . . . . . . . . . . . . . .

i ii iii

CHAPTER
1-1 1-2

I INTRODUCTION
. . .P i c t u r e Analysis and Recognition .New Aspects Relatedworks . . . . . . . . . . . . . . . . . . . .

1 4

CHAPTER 11 ANALYSIS OF HUMAN-FACE PICTURES

11-1 Introduction . . . . . . . . . . . . . . . . . . . . .

9

.11-2 The Problem Human Face as Object o f P i c t u r e A n a l y s i s 10

. . . . . . .11-3 O u t l i n e and Features o f Analysis Method

11

11-3-1 Outline o f Analysis . . . . . . . . . . . . . . 11

11-3-2 F l e x i b l e P i c t u r e Analysis Scheme w i t h Feedback 14

11-4 Complete Description of Analysis . . . . . . . . . . . 15

11-4-1 11-4-2 11-4-3 11-4-4

Input of Picture . . . . . . . . . .
Line Extraction by Laplacian Operator
. . . . . . . . . .Analysis Program . . .Backup Procedures w i t h Feedback

....

....

....

....

....

15 17 21 30

11-5 Results of Analysis . . . . . . . . . . . . . . . . . 33

11-5-1 11-5-2

. .Sumnary of Results
Examples and Discussions

.

..

..

..

..

..

..

..

..

..

..

..

34 35

CHAPTER 111 IDENTIFICKTION OF HUMAN FACES
111-1 Introduction . . . . . . . . . . . . . . . . . . . . . 111-2 The Problems . . . . . . . . . . . . . . . . . . . . .

47 47

iii

......

ACKNOWLEDGMENTS
I would like to express my sincere appreciation to
Professor Toshiyuki Sakai f o r his adequate guidance and encouragement to enable this thesis to be cmpleted.
I am also grateful to Professor Makoto Nagao f o r
having had enlightening discussions with me.
In addition, I should extend my thanks to hundreds of people, the photographs o f whose faces supplied
indispensable data used in my research. Constant encouragement and editorial assistance
given by Yukiko Kubo are worth mentioning with my thanks.
ii

CHAPTER I
INTRODUCTION

P i c t u r e processing by computer has found i t s a p p l i c a t i o n i n

v a r i o u s f i e l d s . Character r e c o g n i t i o n has shown the most p r a c t i c a l

success. Furthermore, t h e techniques span much more s o p h i s t i c a t e d

a p p l i c a t i o n s such as i n t e r p r e t a t i o n o f biomedical images and X-ray

f i l m s , measurement o f images i n nuclear physics, processing o f a l a r g e

volume o f p i c t o r i a l data sent from t h e s a t e l l i t e s , etc.

The p a r t i c u l a r problem a t t a c k e d i n t h i s t h e s i s i s computer

a n a l y s i s and i d e n t i f i c a t i o n of human faces. P i c t u r e s of human faces

are successfully analyzed by a computer program which e x t r a c t s face-

feature p o i n t s , such as nose, mouth, eyes, and so on.

The program

was t e s t e d w i t h more than 800 photographs The research has been

done w i t h main enphasis on t h e method o f how t o i n c o r p o r a t e t h e p i c t u r e

s t r u c t u r e s i n t o the p i c t u r e a n l y s i s program. The success o f t h e

prosram i s due t o theemploymentof a f l e x i b l e p i c t u r e a n a l y s i s scheme

w i t h feedbacks, which w i l l be described i n the next chapter.

An

experiment on f a c e i d e n t i f i c a t i o n of 20 people was a l s o conducted.

-1-1. P i c t u r e A n a l y s i s and R e c o g n i t i o n New Aspects
When shown t h e p i c t u r e s of the human face o f Fig. 1-1. we can i m n e d i a t e l y t e l l t h e p o s i t i o n s of t h e nose, mouth and eyes; and more-
l

e

111-3 Computer Extraction of Face Features . . . . . . . . . 49

111-3-1 111-3-2

Data Set Two-Stage

....
Process

..

..

.. .. ..

..

..

..

..

..

..

.. .. .. ..

49 49

111-3-3 111-3-4

Sampling of Description

Finer Image Data . .
of Extraction Process

..

..

..

..

..

..

..

51 54

111-4 Facial Parameters . . . . . . . . . . . . . . . . . . 57

111-5 Identification Test . . . . . . . . . . . . . . . . . 61

CHAPTER
IV-1 IV-2 IV-3

IV CONCLUSION
Sumnary of This Thesis . . . . . . . . . . . . . . . 65 Picture Structure and Analysis Kethod . . . . . . . . 66 Picture Analysis and Problem Solving . . . . . . . . . 70

REFERENCES . . . . . . . . . . . . . . . . . . . . . . . . . . 73

APPENDIX A APPENDIX B
APPENDIX C

COMPARISON OF LINE-DETECTION OPERATORS . . . . . . 75
SUPPLEMENTARY EXAMPLES OF RESULTS OF ANALYSIS
OF CHAPTER I 1 . . . . . . . . . . . . . . . . . . 77
RESULTS OF FACE-FEATURE EXTRACTION OF CHAPTER I 1 1 . 81

iv

l y , completely new aspects appear. I n the case of p r i n t e d characters, one can assume the standard
pattern. Thus processing usually involves matching w i t h the standard pattern or feature mtrsurements a t predetermined points, and decisions about the existence of features are based on the combinational logic.
On the other hand, i n processing complex natural images such as facesc the situation i s further complicated. There i s such a wide variety i n the i n p u t images t h a t the measurement o f features must be
-adaptive t o each individual image and relative to other feature mea-
surements. I n a d d i t i o n t o these low-level processings so t o speak
-" local" processing the system needs decision algorithm of higher --level i t should be referred t o as "global" recognition ; i t has
t o interpret the structures of the picture. The picture analysis program for human-face photographs. develop-
ed i n this thesis, shows some of these new aspects of advanced picture processing. I t employs a new flexible analysis scheme which elaboratel y combines local processing w i t h global recognition. Backup procedures with feedback and retrial play a very important role in i t . Since the variety of pictures t o be treated i s enormous, fixed analys i s algorithms are not very powerful. The process must be flexible and adaptive i n the sense t h a t the analysis in a certain portion of a picture i s carried out repeatedly w i t h a change of parameters until i t gives a satisfactory result. If the analysis f a i l s . i t s cause i s examined i n detail t o f i n d out the p a r t where the analysis must be performed once more. The flexibility of the human-face analysis program results certainly from these. backup procedures.
T h i s i s one of the f i r s t works t h a t actually implement such a flexible analysis scheme i n the picture analysis program. The detail will be described i n CHAPTEFI I I .
In CHAPTER 111, computer identification of 20 people by their faces i s attempted, using two pictures for each person. A set of facial parameters i s calculated f o r each picture on the basis of fea-
3

over, we can say that both pictures surely portray the same person. Picture analysis and recognition by computer concerns itself with this
type of two-dimensional image processing. In this thesis, I selected human-face pictures as objects of processing.
Character recognition by machine has been investigated very intensively as one of the most fundamental problems with practical value. Today computer processing of visual images has come to deal with more sophisticated problems: scene analysis in robot projects, biomedical or meteorological image interpretation, recognition of faces or fingerprints, etc.
It might be considered that recognition of faces or other natural scenes would be only a little more complex than characters, but actual-
Figure 1-1 Pictures of human face.
2

. 1,
concerned w i t h both the human and the computer's ability of human-face
identification(Hannon 171 , Goldstein, Harmon and Lesk[5] ). After two
Prel iminary experhentt they constructed an interactive system for
.human- face 1dent i f ieat ion (Go1dstei n , Harmon and' Lesk 163)
A human operator i s given a photograph of one member o f the population. He describes this target face t o the computer using rather
subjective "features' 1i ke long ears , wide-set eyes, etc. The comput-
e r searches through the population t o retrieve the "target" on the basis of this subjectively assigned feature judgment. In this way the system takes advantage both of the human's superiority in describing
features and of the machine's superiority i n making decisions based on
.accurate know1 edge of population s t a t i s t i c s
Those works mentioned above do not deal with human faces as the object o f picture processing, and the problem o f automatic feature extraction from a picture of the face has been l e f t open for further research.
The f i r s t serious work in this direction i s perhaps one by Kelly[lO], which i s most closely related t o the work reported here. He uses five measurements from a picture of the entire body such as h e i g h t , width of shoulders, etc. and five measurements from a close-up of the head such as w i d t h of the head, distance between eyes, etc. His program could identify about ten persons whose photographs were taken i n a standardized manner. Various methods are used i n recognizi n g each part of the picture: subtraction, edge detection, template m a t c h i n g , and dynamic threshold setting. All of these methods are applied heuristically i n a goal-directed manner.
Much more intensive study i s reported in this thesis. Only a picture of the face i s used. Accurate feature points are located i n i t , from which the measurements on facial parameters are derived. Though the general flow of processing resembles t h a t o f Kelly, an important and clear difference exists in the picture analysis program. The analysis program i s n o t a straight-line program t h a t processes an
5

.
ture points located by the picture analysis program. In the identification t e s t , 15 out of 20 people were correctly identified. This result i s compared w i t h the case i n which a human operator locates the feature points, and i t i s demonstrated t h a t c a p u t e r measurement i s almost as good as human measurement. The two-stage process employed i n the computer feature extraction includes a "distant" feedback t h a t involves both high-level decision and low-level processing.
1-2. Related Works
A tremendous number of papers have been published on pictorial pattern recognition or picture processing: for instance, see Nagy[14] and Rosenfeld[l7].
I n spite of the f a c t t h a t i t is a matter o f everyday practice t o recognize faces, machine recognition of human faces has not been a t tempted so often as recognition of characters or other picture interpretation tasks.
The work begun by Bledsoe(Chan and Bledsoe[3], Bledsoe[Z]) i s the f i r s t important a t t e m p t . I t is a hybrid man-machine system: a human operator locates the feature p o i n t s of the face projected on the RAND tablet, and the computer classifies the face on the basis o f those fiducial marks. The parameters employed are normalized distances and ratios among such points as eye corners, mouth corners, nose t i p , head top, etc.
Kaya and Kobayashi [9] discussed in the lnformation theoretic terms the number of faces t h a t can be identified by this k i n d of paramet t i za ti on.
Recently, Harmon and h i s associates did a systematic research
4

ponents a r e detected in r a t h e r a top-down manner d i r e c t e d by the mode? of the face unbeddcd I n the program.
7

input p i c t u r e i n a predetermined order, but i t employs a f l e x i b l e p i c t u r e a n a l y s i s scheme w i t h feedback. The success o f t h e program has shown t h a t the scheme i s v e r y powerful f o r processing o f complex p i c tures.
Before K e l l y ' s work, Sakai, Nagao and F u j i b a y a s h i [ l B ] have w r i t ten a program for finding faces i n photographs by template-matching method. They f i r s t produce a b i n a r y p i c t u r e which contains t h e edges of t h e i n p u t p i c t u r e . A template f o r a human f a c e i s d i v i d e d i n t o several subtemplates each o f which corresponds t o t h e head l i n e , fore-
head, eyes, nose or mouth. Those subternplates a r e matched w i t h the
edge p i c t u r e . A s e t of p o i n t s w i t h h i g h matching o u t p u t whose mutual s p a t i a l r e l a t i o n s h i p i s reasonable assure t h e existence of a f a c e .
F i s c h l e r and Elschlager[4] describe a sophisticated method f o r detecting the global structure by a set o f local template matchings. Suppose t h a t an o b j e c t (e.g., a face) i s composed o f several components (e.g., eyes, nose, mouth, etc.) which must s a t i s f y some s p a t i a l r e l a t i o n s h i p s i n order t o be recognized as such. A p l a u s i b l e model o f t h i s i s a s e t o f mass p o i n t s which a r e m u t u a l l y connected by springs: t h e degree o f r e l a t i o n s h i p between two components i s represented by " s p r i n g constant" o f the s p r i n g t h a t connects them, and the e x t e n t t o which t h e r e l a t i o n s h i p i s n o t s a t i s f i e d i s regarded as " s t r e t c h i n g the spring" . The evaluation f u n c t i o n combines both the degree o f l o c a l matching o f each component and t h e cost of s t r e t c h i n g t h e springs. Given an i n p u t image, t h e l o c a t i o n s o f components are determined such that the evaluation function I s minimal by using a k i n d o f dynamic programing. They applied t h i s method t o t h e problem of locating feature points i n a face.
These two methods have some p a r a l l e l i s m i n t h e i r nature and may be e f f e c t i v e t o d e t e c t an o b j e c t i n a scene; but they appear t o be tirne-consuming, and y i e l d o n l y approximate l o c a t i o n s of components.
The method employed i n t h i s t h e s i s i s completely d i f f e r e n t . The com-
6

CHAPTER I1
ANALYSIS OF HUMAN-FACE PICTURES
11-1. Introduction
I n p i c t u r e processing and scene a n a l y s i s by computer, compared w i t h c h a r a c t e r r e c o g n i t i o n , we a r e confronted w i t h much more complicated pattern variations and noise behavior. Therefore i t i s necessary
t h a t t h e processing should t a k e advantage o f s t r u c t u r a l or contextual
information about object patterns i n order t o achieve good r e s u l t s . I n t h i s chapter, t h e problem o f p i c t u r e a n a l y s i s o f human faces
i s presented as an example of automatic a n a l y s i s o f complex p i c t u r e s . A computer program f o r i t has been developed: given a photograph o f t h e human face, t h e program e x t r a c t s f e a t u r e p o i n t s such as t h e eyes, mouth, nose, and c h i n . A f l e x i b l e p i c t u r e a n a l y s i s scheme w i t h feedback i s successfully employed i n t h e program.
F i r s t , the significance of the problem i s b r i e f l y described.
Then t h e computer a n a l y s i s procedure f o r human faces i s o u t l i n e d and t h e f l e x i b l e p i c t u r e a n a l y s i s scheme w i t h feedback i s introduced. A complete d e s c r i p t i o n of t h e a n a l y s i s w i l l be g i v e n i n 11-4. More than 800 photographs have been processed by t h e program and the results are presented. This chapter principally treats picture analys i s . The problem of f a c e - i d e n t i f i c a t i o n u s i n g t h e l o c a t e d f e a t u r e p o i n t s w i l l be discussed i n CHAPTER 111.
S

.. c

as i s also the case w i t h my work reported here.

. .I

11- 3. Outline and Features of Analysis Method
T h i s section outlines the analysis method of human-face photographs to give a general view o f the program. Then is explained the picture analysis scheme with feedback, which i s employed i n the program.
11- 3- 1. Outline of Analysis
Fig. 2- 1 i s the block diagram illustrating the flow o f analysis. Main body of the analysis program was written i n t h e NEAC 2200/200 assembler language.

TV camera

Digitized gray-level

on-line mode Lap1acian
operator

Binary picture
Extraction of face features

Figure 2-1 Block diagram of analysis of human-face photographs.
11

-11-2. The Problem Human Face as Object of Picture Analysis
Human faces are very interesting as an object of picture analysis for severa 1 reasons : ( 1 ) They are not a r t i f i c i a l , and not as simple as cubes or pyramids which have been used i n the visual scene analysis of hand-eye projects. 2 ) A face has many component substructures: eyes, nose, m o u t h , c h i n and so on, which can be recognized a s such only in the proper "context of the face". ( 3 ) These components are distributed in the face w i t h i n a certain permissible range, whose mutural relations can be correctly grasped by the concept of picture structure. ( 4 ) Lines i n a face are very d i f f i c u l t t o define, d i f f i c u l t t o extract and are n o t straight, a l l of which make the problem of interest. ( 5 ) The variety of human faces i s a s large as the human family.
Pictures of human faces contain many essential problems t o be i n vestigated i n the field of picture processing. How far the sutomatic analysis procedure can go i n t o detail and can categorize the human faces has interested me.
What we are g o i n g t o deal w i t h are photographs of one full face w i t h no glasses or beard. We assume t h a t the face in a photograph may have t i l t , forward inclination, or backward bent t o certain degrees, b u t is n o t turned t o the side. The prrblem i n this chapter is, given a photograph of the human face, t o locate the face-feature points i n order t o characterize the face.This kind of problem i s referred t o as feature extraction i n pattern recognition, and is regarded as most
d i f f i c u l t and important. In the attempts a t cunputer recognition of
faces made by Bledsoe[i], Kaya and Kobayashi [ 9 ] , and Goldstein, Harmon and Lesk[6] , the feature extraction was due t o human-operator's abili-
t y t o extract or describe features o f the face. In contrast, the works by Sakai, Nagao and Fujibayashi[l8], Kelly[lOj and Fischler and Elschlager [43 are attempts t o automate thi-s feature extraction process,
10

Figure 2-3
Typical stouencc of the
analysis steps.
( a ) top Of head
( b ) cheeks and sides of face
( c ) nose, mouth, and chin
( d ) chin contour (e) face-side lines ( f ) nose 1ines (9) eyes ( h ) face axis

components. These steps are shown i n Fig. 2-3 f r m ( a ) t o ( h ) .There are several backup procedures w i t h feedback among them, hence some analys i s steps m i g h t be tried more t h a n once. Various picture processing techniques are used i n the analysis program.

=.
-=

- -*-.=_- - I -

? :. ..T- .T

.- ..

.. ..

. .r e--I .-- =-"
. -.... ..--.L=

:-

* - -. .. -*. . . %

-: r i

7

.. . %. e.., Y

e

t

.-

-- - k . t - '

#

i

,.?-

-L

.. - . ,- . --: i - . .i-~ . . . . = x-

-. . =- -=+=
% I_
- -.

As a final result, more t h a n
thirty feature points are located in the binary picture as shown i n Fig. 2-4.
Once these feature points are
located , much more prec i se features
can be measured by returning again t o the original photograph. The
method and significance of this refinement process will be discussed in CHAPTER 111.

Figure 2- 4
Result of feature extraction.

13

(a) Original photog raph
Figure 2-2

(b) Printout o f the digit- (c) Binary

a1 gray-level picture

picture

Picture input and line extraction.
The dark horizontal line in the upper part is due to the burn in the CRT surface of the FSS used for digitization.

A photograph (or a real view) of the face is converted to a digital array of 140 x 208 picture elements, each having a gray level o f 5 bits (i.e., 32 levels), by means of a flying spot scanner or a TV camera. F i g . 2-2(a) is an original photograph, and Fig. 2-2(b) is the gray-level picture digitized by the FSS. The program can work in either on-line or off-line mode. In on-line mode, .the digitized picture i s fed directly into the analysis program, and in off-line mode, it is stored once on a magnetic tape for later use.
The binary picture of Fig. 2-2(c) is obtained by applying a Laplacian operator (i .e. two-dimensional secondary differentiation) on the gray-level picture and thresholding the result at a proper level. This binary picture represents contour portions where brightness changes significantly. The analysis program which locates facefeature points works on this binary picture.
The analysis steps are first to find the approximate position of the face, and then to go into detail on the positions of face

12

times w i t h a change of parmeters u n t i l i t gives a satisfactory result. I do n o t claim thrt this scheme i s completely new. Similar ideas
may have been suggested by several authors. I G l i e v e , however, t h a t this i s one o f the f f r s t works that actually implement the scheme w i t h feedback and show I t s powerfulness I n the picture analysis.
This a n a l y s i s scheme has the following excellent properties:
( 1 1 Inevitably the analysis proceeds i n a top-down goal-directed
manner, which makes the analysis efficient because the necessary local operations a r e applied on only the relevant portions estimated by the process. ( 2 ) The analysis algorithm which is t o be prepared for each step can be f a i r l y simple, because i t knows what to look f o r and can be repeatedly performed on the most probable area w i t h improved parameter values using the feedback process. Unlike the straight- line scheme, errors a t each step are not accumulated, b u t will be disclosed i n the succeeding steps and recovered by the backup procedures. T h i s i s one of the most important features. ( 3 ) The economy of memory and processing time f o r the analysis is great i f a flexible scanning device i s available which samples only the significant parts. This advantage i s fully taken i n the extracti o n of precise locations of feature points, which will be described i n CHAPTER 111.
1 1 - 4 . Complete Description o f Analysis
This section describes i n detail the flow o f analysis t h a t i s illustrated i n F i g . 2- 1; from i n p u t o f picture t h r o u g h final result.
11- 4- 1. I n p u t of Picture
A picture (or a real view) of a face i s f i r s t transfonned i n t o a
15

I 1 - 3 - 2 . F l e x i b l e P i c t u r e A n a l y s i s Scheme w i t h Feedback

The d i s t i n g u i s h i n g f e a t u r e o f t h e program i s t h a t subroutines
d i v i d e d i n t o blocks, each f o r d e t e c t i n g a p a r t o f t h e face, a r e combined i n t o action not only by making use o f t h e contextual information of a face. b u t a l s o by emp o y i n g backup procedures w i t h feedback.
As shown i n F i g . 2-5, each s t e p o f a n a l y s i s c o n s i s t s of t h r e e parts: p r e d i c t i o n , d e t e c t on, and evaluation. The r e s u l t i s evaluated for the purpose of knowing whether t h e program can proceed t o the n e x t step. Ifan u n s a t i s f a c t o r y r e s u l t I s y i e l d e d . i t s cause i s examined t o f i n d o u t the step where t h e analysis must be performed again. There are two cases o f feedback. D i r e c t feedback i s used t o modify the parameters of t h e analysis step j u s t executed. The other i s a feedback t o former steps. I t takes p l a c e when t h e imperfection o f the r e s u l t i s disclosed during t h e succeeding a n a l y s i s i n the form
o f an unsatisfactory evaluation; u s u a l l y t h e e v a l u a t i o n c r i t e r i a are n o t so severe, and so sometimes t h e process may have gone t o t h e next
step even though the a n a l y s i s a t one step i s n o t p e r f e c t . I n t h i s way, t h e t o t a l process of a n a l y s i s becmes f l e x i b l e and adaptive. The a n a l y s i s i n a c e r t a i n p o r t i o n o f a p i c t u r e may be performed several

+1Prediction

modification

+Former steps
. J
Discard a p a r t of r e s u l t s so
-b f a r obtained i

. ..
When a TV camera 1s used as an i n p u t device, the human operator a d j u s t s the camera watching a monitor TV, so t h a t the object face may be seen a t the appropriate position w i t h the appropriate size. The video level I s also adjusted manually. The whole frame consisting of 240 x 300 picture elements i s completely digitized and then i t i s edited i n t o an array of 140 x 208 by software.
The picture digitized i n these ways i s either fed i n t o the face analysis program in on-line mode, or stored on the magnetic tape i n the d a t a collection stage of off-line analysis.
11- 4- 2. Line Extraction by Laplacian Operator
The next step of processing is t o extract lines and contours from t h e picture. The operator illustrated in F i g . 2-8 is applied t o the d i g i t a l picture of F i g . :-7, and then thresholding the result a t a proper threshold value produces the binary picture shown in F i g . 2- 9. This binary picture represents contour portions where brightness changes significantly. I t preserves the structural information of the original gray-level p i c t u r e and yet far easier t o deal w i t h because of the binary values. A l l t h e succeeding analysis i s performed upon t h i s binary picture. The threshold value is fixed to 30.
A s t o edge or contour detection, a number of papers have appear-
ed: for a survey, see 1131 t h a t contains a large number of references.
The operator used here i s fundamentally a digital Laplacian operator (two-dimensional secondary differentiation). Let I (x*y) be a function t h a t represents a gray-level picture. The Laplacian i s defined as:
The simplest digital version of this Laplacian i s
17

d i g i t a l a r r a y by means o f a f l y i n g - s p o t scanner(FSS) o r a TV camera.
When t h e FSS i s used, t h e standard m a t e r i a l i s a photograph i n which l i e s a f u l l face of about 2 an. The photograph i s scanned by the
f l e x i b l e scanning program described i n [a], and d i g i t i z e d t o an
a r r a y of 140 x 208 elements, each o f 5 b i t s o f b r i g h t n e s s i n f o r m a t i o n ( i . e . 32 l e v e l s ) . As shown i n F i g . 2-6, a 5 x 5 r e c t a n g l e spot i s used and sampling i s made a t e v e r y 3 p o i n t s . The f a c e i n t h e d i g i t i z e d p i c t u r e i s t y p i c a l l y o f s i z e 80 x 80 % 100 x 10n. The necessar y t i m e f o r i n p u t i s about 5 seconds. F i g . 2-7 shows a l i n e p r i n t e r output of a d i g i t i z e d p i c t u r e w i t h various characters superimposed t o approximate the gray levels.
The reason why t h e i n p u t d i g i t i z a t i o n i s rough sampling by a rather large-sized spot i s that extreme details are not necessary i n the next line- extraction process: averaging e f f e c t o f a large spot suppresses high-frequency noise and thus prevents e x t r a unimportant l i n e s i n a face from being extracted.
Since the scanning program o f the FSS i s h i g h l y f l e x i b l e , approp r i a t e comnands of an human o p e r a t o r a l l o w v a r i o u s k i n d s o f photographs t o be d i g i t i z e d i n t o the standard format: f i n e scanning f o r a s m a l l e r sized phot:graph and coarse scanning f o r a l a r g e r - s i z e d one; f u r t h e r more i n the case of a photograph i n which there are several people, t h e scan and i n p u t of one p a r t i c u l a r face can be performed very e a s i l y .
Figure 2 4
Scanning by a f l y i n g s p o t scanner. The s p o t s i z e i s 5 x 5, and the sampling i n t e r v a l i s 3.
16

Figure 2-10 ( a ) Robert2 operator; and (b) Maximum o f differences.
For comparison, three operators for edge detection including the Laplacian of Fig. 3-8 were applied on the same set of pictures; the other two are the f i r s t derivative of Robertz[l6] (see Fig. 2-10(a)) and the maximum of differences (see Fig. 2-10(b)) for 3 x 3 window. The results are presented i n F i g . 2-11 and APPENDIX A contains supplementary data. They show the superiority of the Laplacian operator I used. I t can detect slow b u t apparent changes i n brightness as well as sharp edges, because i t takes broader area i n t o account. Furthermore, i t is observable t h a t the different values o f threshold do not yield any significant difference i n the resultant binary pictures.
A very efficient program of the Laplacian operator has been coded, by t a k i n g maximum advantage of variable-length word and implicit addressing of NEAC 2200/200, though the computer i s not so fast: 2-usec memory-cycle time f o r a 6-bit character. I t takes only 14 seconds t o convert from Fig. 2- 7 t o Fig. 2-9.
Any a d d i t i o n a l operations such as t h i n n i n g , elimination of isolated points, etc. are n o t performed on the binary picture. The reason i s t h a t significance of line elements may vary f r o m position t o posit i o n , or i n other words may depend on the "context": a set of line elements foming a long line may mean the contour o f the face or meaningless edges i n the background; a group of isolated points may come from noise or show the existence of low-contrast edges around the chin. The "context" information is used positively i n the picture analysis
program.
19

Figure 2-7 Digital gray-level picture of a face.

Figure 2-8 Operator for line extraction. This i s fundamentally a Laplacian operator.

wherelI. .}denotes the d i g i t a l array 'J
t o represent I ( x , y ) . From t h i s equation i t can be seen t h a t the operator of F i g . 2-8 combines differential operation w i t h averagi n g : i . e . , f i r s t averaging operation i s perfomd on 3 x 3 subarea, then differential operation regarding each subarea as one picture element in the equation ( 2 - 2 ) . This operator was demonstrated i n S a k a i , Nagao and Kidode[ 161 t o work very successfully
for line extraction of human-face pictures.

r - * =-i=-z 1.=---
---s

gi - ii!

-.

-- . -.
-2 p+js1 T

Figure 2-9 Binary picture.

18

!I-J-3. A n a l y s i s Program
F i g . 2-12 fllustrrtcs t h e general f l o w o f a n a l y s i s : I t shows t h e
l o g i c a l connection o f subroutines i n t h e a n a l y s i s pmgram o f humanface P i c t u r e s . I n general, t h e a n a l y s i s steps proceed fran easy t o d i f f i c u l t , and from grasping approximate information t o d e t e c t i n g a c c u r a t e p o s i t i o n s o f eyes, nose, mouth and so on. Each s u b r o u t i n e shown by t h e square box t r i e s t o d e t e c t each component (e.g., eye) s a t i s f y i n g s p e c i f i c conditions (e.g., l o c a t i o n , s i z e and shape) i n t h e predicted region. A t y p i c a l sequence o f analysis steps i s f r m ( a ) t o ( h ) as shown i n F i g . 2- 2.
There are several backup procedures w i t h feedback interwoven
among t h e a n a l y s i s steps. According t o whether one step succeeds o r
f a i l s i n t h e f e a t u r e detection, which subroutine t o be executed next i s determined, and various parameters i n t h e program a r e modified.
The main p a r t o f backup procedures w i l l be described i n t h e next sub-
section 11-4-4.
Figure 2-12 General flow o f analysis program.
21

,. .
Figure 2-11 Comparison of 1 ine-detection opera tors.
(a 1 Gray-1 eve1
picture (b) Laplacian
opera tor
(b-1) e 25 (b-2) e = 35
(c) Robertt operator
(c-1) e = z (c-2) e = 4
(d) Maximum of differences
(d-1) e 2 (d-2) e = 4
20

.A fundamental useful technique of picture processing used
t h r o u g h o u t the program ISan 'integral projection". As shown in
F i g . 2-13, a s l i t o f proper width and l e n g t h i s placed i n a picture. A histogram Is obtalne4 along the length of the s l i t by counting the
number of clesnentr - 8 . I n the direction o f the'width. This i s called an integral projection (curve) of the s l i t . If the s l i t i s applied within a suitable area with the proper direction and width, the integral projection t e l l s reliably the position of a component in the picture even in the presence of noise.
Now, the analysis steps will be described i n detail.
1 ) T o p of Head A horizontal s l i t i s moved down from the t o p of the picture. The
f i r s t position with sufficient o u t p u t i s presumed as the top o f the head H. This p o s i t i o n i s used only for setting the starting point of s l i t application in the next step, and therefore i t need n o t be so precisely determined.
2 ) Sides of Face a t Cheeks Starting from the p o i n t of a certain distance below H, a horizon-
t a l s l i t o f w i d t h h i s applied successively, shifting downward with h/2 overlap as in Fig. 2-14. Fig. 2-14(a) shows three successive outputs. When the s l i t crosses the cheeks, i t s integral projection displays characteristic patterns like the lowest one of the three i n F i g . 2 - 1 4 ( a ) : two long clearances and one or two peaks sandwiched by them. The two long clearances are the cheeks. and the outputs a t these positions in the upper s l i t s show the eyes or sometimes the effect of glasses. Thus we can determine the l e f t and r i g h t sides of the face as the l e f t and right ends of these two vacant portions.
They are indicated by L and R in Fig. Z-14. Since we need to know these positions only approximately, the width h o f the s l i t is s e t
rather large so t h a t i t can pick up t h i n line portions. Here we set h = 10.
23

Figure 2-13
Integral projection o f a slit.

slit

.---._--__r._H -
--
-_

..-

(a) Integral projection of a horizontal slit
EYES

Figure 2-14 Detection o f the face sides, nose, mouth, and chin by the application of s l i t s .
22

p 1+ I
1
Figure 2- 15 Types o f peaks.
l i t t l e . And then matching i s tried again. If there i s no match even t h e n , this step i s a failure, and the backup procedure will work t o reactivate the step 2).
4 ) C h i n Contour and Smoothinp I n o b t a i n i n g the c h i n contour, a method like tracing i t fran one
o f i t s ends would probably lead i n the wrong direction because o f the existence of line s p l i t s and extra lines, even if an elaborate means
such as line extension i s employed. Such a method i s substantially based on the local decision, i.e., 'line connectivity. Since we have already known, a t least approximately, the face sides L and R, the nose N, the upper l i p M and the c h i n C , we can limit the search area
for the chin contour. As shown in Fig. 2-17, the search area i s de-
termined by L, R, C , M and N. Nineteen radial lines are drawn downward from M i n every 10 degrees. These lines are expected t o cross the c h i n contour i n the predicted area a t nearly r i g h t angles, if the
25

c

Erroneous detection of L and R i n t h i s step will cause the suc-
ceeding step 3 ) or 4 ) to f a i l i n detecting the expected canponents, and thus the analysis will come back to this step again t o obtain the correct positions of L and R. (See example(1) of 11-4-4)

3 ) Vertical Positions of Nose, Mouth and Chin A vertical s l i t of width LR/4 is placed a t the center of L and R
as shown in F i g . 2-14. A nose, a mouth and a c h i n are probably in i t i f L and R are approximately correct and i f the face does not t i l t or turn a great deal. I t i s observed t h a t i n the integral projection curve of the s l i t the peaks appear which correspond t o the nose, mouth and chin. Fig. 2 - 1 4 ( b ) i s one of the typical curves. The integral projection curve i s then coded i n t o a compact fonn by using the symbols f o r the types of the peak and i t s length, as shown in Fig. 2-15. The integral projection of Fig. 2-14(b) is coded as follows:

R (17 ) B (8) * M ( S ) * B ( 3 ) - M ( 3)-B( 10)*M(4 )

(2-3)

Before c o d i n g , the curve is smoothed so t h a t small gaps or noisy peaks

are eliminated.

The form of this curve changes widely depending on the face and

existence of face inclination, shadow, mustache, wrinkles and so on.

A t present, nine typical curves are prepared as standard types. They

are a l s o coded in the same manner and stored i n t h e table. The table

i s shown in Fig. 2-16 with the explanation of how i t i s read. In a

word, each standard type specifies mutual posftiondl relations of the

nose, mouth and chin. The table can be extended simply by adding the

new types. The integral projection of the i n p u t picture i s compared

w i t h the standard types. If i t matches w i t h only one type, the verti-

cal positions of the lower end o f the nose N, the upper l i p M and the

point of the chin C are obtained.

For instance, the integral

projection(2-3) of Fig. 2-14(b) matches TYPE 3. If there are more

t h a n one match, the matching c r i t e r i a of the standard types are chang-

ed w i t h a l i t t l e more rigidity. I n case there is no match, the match-

ing criteria are slightly relaxed, or the vertical s l i t is shifted a

24

.. I.
positions of L , R , C , m N are correct. A s l i t is placed along
each r a d i a l l l n e rnd ( t s lntwral projection is examined. A contour P o i n t B f s detectcd 4s the peak marest t o M w i t h i n the specified area. The sequence ~f 8 ' s thus obtained for nineteen radial lines i s smoothed. The lfcnlt inporcd on the search area and the smoothing enable this step to wold mistaking long wrinkles or neck lines for a p a r t of the chin contour.
In the B p o i n t detection, B is not determined on the radial line
whose incidental integral projection contains no conspicuous peak
w i t h i n the search area. In case B's cannot be determined on three consecutive radial lines, the contour detection is judged unsuccessful.
The program activates the backup procedure. The cause i s investigated and a n appropriate recovery action will be taken. (See examples ( 2 ) and ( 3 ) of 11- 4- 4)
Figure 2-17 Extraction of chin contour. The search area is established
and a s l i t is placed
along each r a d i a l 1ine.
5 ) Nose End Points and Cheek Areas As i s shown i n Fig. 2-18, by successive application of horizontal
s l i t s starting from N, we can trace upward the nose as well as the l e f t and r i g h t face sides u p t o approximately the eye position. Both ends o f the nose, P and Q. are located. Then the l e f t and r i g h t cheek
areas are determined as those which are enclosed by the nose lines and face-side 1ines.
27

TIPi 1
npr z
-
nPi 3
-
nn 4
-
mr 5
nvt 6
~
nPi 7
Figure 2-1E Standard types of integral projections.
26

....-a..-_..---..._.._.......-...--........~.............-:...-............... .e..

.....0.0..0..............................................I...........:..I

I *.
......*.*...............0..............

.e*.

1-I (b) Fusion ...............

Fl(a) Predicted rectang 1 e ..0........e...
( d ) Component o f
FIthe maximum area ......................

( c ) Shrinking

1-1t.
: II
.....*..*...:...IIII
....--...........................*.*..........

*-:.**.0..?~0....?......e-.:.:...-:.0......--...&...-...?.-..:.:.................................................-......0............0.0....................

H...

u..

( e ) Extended component

( f ) Rectangle t h a t circumscribes the component, and i t s center

Figure 2-19 Determination o f eye center.

29

6 ) Eye Positions Examination of the vertical and horizontal integral projections
of the cheek areas gives the rectangles containing the eyes. Fig. 2-18 i l l u s t r a t e s the method: f i r s t , vertical sumnation i s done between the face side and the nose side, and then horizontal s m a t i o n in the zone obtained from the vertical sumnation. As in t h e case of Fig. 2-19(a), the rectangle may contain a part of the eyebrow, the nose or the face-side line. Even a p a r t of the eye may l i e outside of i t . The following operations determine the position of the eye precisely: f i r s t , the operations of fusion and shrinking[17) are executed i n the rectangle cut o u t of the picture t o eliminate gaps and hollows
which often appear in the eye area(Fig. 2-19(b), ( c ) ) . The connected component of the maximum area i s then identified and singled o u t in
the rectangle(Fig. 2-1?(d)). The parts which are outside the rectangle, b u t w P - c h are connected t o this component, are joined, and the fusion a n d shrinking are performed a g a i n on this extended component ( F i g . 2-19(e)). The position, the size, and the shape o f the component are examined whether they satisfy certain conditions which the locations and properties of feature points so f a r obtained impose.
iI
a 2 :,Be:
horizontal integral pmjecti on
Figure 2-18 Cheek areas and rectangles which
contain the eye.
28

Figure 2-20 Misrecognition of L and R.

Figure 2-21 Mis recogni t i on o f
N, M, and C.

failures in B detection occur around the misrecognized C in a synnnet-
rical manner. When t h i s i s found, the backup mechanism forces the program t o go back to the step 3) t o re-examine the positions of N, M and C.
( 3 ) When the chin contour i s unsatisfactorily located. I n the detection of chin contour a t the step 4 ) , there often
exists a short break in the contour, or the real contour l i n e partiall y s t i c k s out of the search area. Then the complete contour i s not detenined. Usually i n t h i s case, however, either half of the contour i s obtained correctly. Thus, as shown i n Fig. 2-22, for the radial line whose B was not obtained, a prediction point B' i s detenined there by utilizing the symnetrical property with respect to the vertical axis. The same routine for chin-contour detection i s again executed w i t h the narrouer search region around B' and w i t h the bwer threshold for peak detection. By this process i t m i g h t be possible t o detect the t h i n portion of the contour which was undetectable i n the first trial.
31

I f they do, the eye center is determined as the center of the rectangle w h i c h circumscribes the component(Fig. 2-19(f)). I n t h i s way, the l e f t a n d r i g h t eye centers, S and T, are obtained.
T h i s concludes a whole analysis procedure. As the final result a l l the feature points extracted are printed out on the lineprinter as was shown i n Fig. 2- 4.
11-4-4. Backup Procedures w i t h Feedback
I n the process of face analysis described above, errors may occur i n various steps. To manage them, several backup procedures w i t h feedback were introduced. I n the following descriptions are demonstrated a few typical examples.
( 1 ) When face sides, L and R , a r e incorrectly located. L and R are usually determined a t the step 2) by detecting the
existence of two wide areas of the cheeks on both sides of the nose. The method i s very simple, arid therefore sometimes they are misrecognited,especially i n a woman's face like Fig. 2-20. When the analysis proceeds t o the next step 3 ) , where a vertical s l i t i s applied t o f i n d the nose, m o u t h and chin, the integral pmjection curve differs markedly from w h a t i s expected. Thus the analysis f a i l s there. The program
goes back t o the step 2 ) once more, and t r i e s t o find out another possibility for L and R. Fig. 2-20 is an example i n which the correct
results were obtained i n the second t r i a l . We could determine these positions correctly i n this way f o r many pictures for which the analys i s was f i r s t unsuccessful.
( 2 ) When the nose(N1, muth(M) and c h i n ( C ) are incorrectly located. There are cases where N, M and C are determined in the step 3)
as upward shifted positions as i n Fig. 2-21. This trouble i s discovered as failures i n detecting the chin contour a t the step 4 ) . Usually
30

I

I.

Other than t h e examples mentioned above, t h e r e a r e many minor feedbacks. Compound feedback may also occur. For instance, t h e f a i l -
u r e i n t h e chin- contour d e t e c t i o n a c t i v a t e s t h e s t e p 4 ) . whose f a i l u r e ,
then. makes t h e program go back t o t h e s t e p 3 ) .
I t i s notable t h a t t h i s t r i a l - a n d - e r r o r process with t h e feedback mechanism allowed each a n a l y s i s s t e p t o be simple. The once-and-fora l l process would have required t h a t each step be h i g h l y elaborate and r e l i a b l e , i n order t o avoid delivering erroneous r e s u l t s t o the succeeding steps.
I n many steps, simple p a t t e r n matching methods have been employed. It should be mentioned that pattern matching applied to the r e s t r i c t e d r e g i o n i n a p i c t u r e has a p o s i t i v e meaning i n c o n t r a s t t o t h a t applied t o t h e whole p i c t u r e . A successful match means t h a t what was expected exists i n the predicted region. It increases the r e l i a b i l i t y o f the a n a l y s i s r e s u l t s so f a r o b t a i n e d and used f o r p r e d i c t i o n as w e l l as adding t h e new r e s u l t . On t h e o t h e r hand, f a i l u r e i n matching may
r e q u i r e t h a t some of t h e program parameters be m o d i f i e d or t h a t a feed-
back procedure be a c t i v a t e d f o r c o r r e c t i o n s and r e t r i a l s .
11-5. Results o f Analysis
. About 800 p i c t u r e s o f human faces have been processed by t h e program described above. Most p i c t u r e s (688) o f t h i s l a r g e data s e t were obtained i n d i g i t a l form a t t h e World F a i r '70 OSAKA i n 1970. Nippon E l e c t r i c Company r a n an a t t r a c t i o n named "Computer Physiognomy":
a person s i t s before a Pi camera, t h e p i c t u r e o f h i s f a c e i s d i g i t i z e d
and fed i n t o t h e computer, a simple program e x t r a c t s l i n e s and locates a few f e a t u r e p o i n t s ( t h e method i s the same as t h a t described i n [ l o ] ) and, f i n a l l y , h i s face i s c l a s s i f i e d i n t o one o f seven categories,
33

..

Figure 2-22
Failure in detecting chin-contour points.

(4) When a wrong face-side line results i n a wrong prediction area of the eye.
As shown in Fig. 2-23, one of the face-side lines that are determined in the step 5) may extend to the wrong direction, which results
in a wrong prediction area of the eye. Thus, at the next step 6) the component expected to be the eye does not satisfy the necessary condition. Then a new prediction area is established from the position of the other eye, and the determination o f this eye position is tried
again. The face-side line is also corrected by tracing it downward
from the correct eye position.

-- - - - ---- -- - -..-..................""....

........."......-.-.I-

__I__
new pre

d

i

c

t

i

o

n

%-

eye corners

area

-^..,
-......:...^='............-............-.............................:.2-..+..^......
,='. 3... ."t.C. ..
. --"-LLm-_-..-.....................3.-.

:=.

. -I-
-- -p 4=e-== *-7

---- -f-..

m 'first

-=

J prediction

-== area * =9

1 ine wrong
.

Figure 2-23 Wrong prediction area o f the eye.

32

CbtegorY of
faces
full face with no glasses o r beard
f u l l face with
glasses

nukr
of facet
610
17

correct msultr
2

step i n which the e r m r or

~ r r o r unrecovered fat lure occurred or un-

7:?Zzd face

chin

nose

sides chin contour eyes width

62 5 14 17 19 1

75 4 4 2 65

face with turn
or tilt

19

63

16 4 3 3 5 1

f a c t with beard,
and others

27

21

12 4

11

i

Table 2- 1 Sumnary o f r e s u l t s o f a n a l y s i s

11-5-2. Examples and Discussions
(1 ) Two s e t s o f examples F i g . 2-24 and Fig. 2- 25 present two complete sets of examples.
I n each f i g u r e , p a r t ( a ) i s t h e o r i g i n a l photograph and p a r t ( b ) shows t h e g r a y - l e v e l r e p r e s e n t a t i o n of t h e d i g i t i z e d p i c t u r e on t h e l i n e p r i n t e r . Part(c) gives the binary picture i n which the extracted fea-
t u r e p o i n t s a r e i n d i c a t e d by dots. To v e r i f y how well t h e program
located the feature points, t h e i r coordinates are marked on the enTarged o r i g i n a l photograph as shown i n p a r t ( d ) .
F i g . 2- 26 shows t h e p i c t u r e i n which the same s e t o f f e a t u r e p o i n t s i s l o c a t e d by human. Comparison of Fig. 2-24(d) w i t h F i g . 2-26 shows t h a t the computer e x t r a c t i o n i s c o n s i d e r a b l y good. Most r e s u l t s of p i c t u r e s in t h e group(a) which a r e judged as c o r r e c t are o f this quality.
35

each of which i s represented by a very famous person. Though the program was not very reliable, the attraction i t s e l f was very successf,,l. A l o t of people participated i n i t , a number of whose faces were stored on ten magnetic tapes. They include faces of young and old, males and females, w i t h glasses and hats, and faces w i t h a t u r n , t i l t or inclination to a slight degree. I t i s of great interest t o see how the program works w i t h them. The rest of the d a t a Set comprises pictures I took f o r the purpose of investigating the Perfomance and 1imitation of the program.
11-5-1. Summary of Results
The results are sumnarized i n Table 2- 1. The input faces were categorized i n t o four groups:
( a ) f u l l face w i t h no glasses o r beard (b) full face w i t h glasses (c) face w i t h t u r n or t i l t ( d ) face w i t h beard, and others The f i r s t category corresponds t o the faces which were assumed for the i n p u t of the program. The result of analysis was judged either "correct I' or I' i nco r rect" by human i nspect ion. "Incorrect" includes erroneous results and unrecovered failures. In the case of incorrect results, the step i n which the error o r unrecovered failure took place i s examined. For pictures of the group(a), 608 pictures out of 670 were successfully analyzed, g i v i n g a l l of the face-feature points correctly. f o r about 200 of them the analysis failed halfway once or twice, b u t the feedback mechanism including diagnosis, correction, and r e t r i -
al , made recovery possible.
As i s seen i n Table 2- 1, the program works f a i r l y well also on pictures of groups ( b ) , ( c ) and ( d ) -which do not satisfy the presumed constraints.
34

..

.
(C) (4
Figure 2-24 Result of the analysis : example 1.

i

37

The locations of the feature points obtained i n the binary picture may c o n t a i n small errors: eye centers l i e a b i t on the outer side; face-side lines are apt to shift a l i t t l e t o the darker side. These phenomena stem from the property o f the Laplacian operat o r used i n the line extraction. The Laplacian operator, as i s easily seen, produces a b i g positive o u t p u t when i t is on the darker side of the edge i n the original picture. Thus, i n the binary picture w h i c h i s obtained by thresholding the differential picture, lines appear on the darker side of the real edge, rather than just on the r i g h t position.
I n the next chapter, more precise locations are obtained by returning t o the original picture, for the purpose of face identification.
( 2 ) Face w i t h f a c i a l lines or extra shadow F a c i a l lines a n d extra shadow i n the face often result i n trouble-
some line segments i n the binary picture, hence failure or error of the analysis. I n F i g . 2- 27, the correct result i s obtained because the search of the c h i n contour was limited t o a small area based on the implicit model of the face. In the case of F i g . 2- 28, the program was deceived by t h e several parallel line segments near the m o u t h and was not able t o detect the face-side line.
( 3 ) Face w i t h glasses I n the case of faces w i t h glasses, the program usually f a i l s i n
the step of eye detection or gives erroneous eye positions, b u t t h i s i s only natural because the program was not taught t h a t people may wear glasses! !; all the other results, however, are ustially correct. F i g , 2-29 i l l u s t r a t e s an example.
( 4 ) Face w i t h mustache I n the face w i t h mustache, thick line segments appear between
mouth and nose a s shown i n f i g . 2-30, and the nose (P and Q indicate the nose ends) i s often located below the r i g h t position.
36

Figure 2-26 Photograph w i t h feature points located by human.
Figure 2-27 Face w i t h facial lines : example 1. 39

.. ..
(c) (4
Figure 2-25 Result of the analysis : example 2. 38

-i ' . ,

.. . .

+

.-
Figure 2-30 Face with mustache.

Figure 2-31 Face w i t h turn or tilt : example 1.
41

Figure 2-28 Face with f a c i a l lines : example 2.
Figure 2-29 Face with glasses. 40

"
Figure 2-35 Picture o f low contrast.

_ _. :- er ..--. _..

- -.

.-- .

( b ) Digitized picture by the beam (00)

(c) Binary picture: the chin contour is not detected.

43

..
- .-... - ... -,

Figure 2-32 Face with turn or t i l t : example 2.

is--
Figure 2-33 Face with sparse
.. chi n-contour segments

-t 4
-. e - . & i#
Figure 2-34 Noisy picture.

42

( 7 ) Noisy pictures
A l o t of noisy points exist i n the picture of Fig. 2-34. However,
they d i d not produce any effect on the analysis result, thanks t o the use of integral projection and the predictive nature of the program. The operation o f eliminating a m a l l isolated segments beforehand may seem preferable, but sparse segments are often meaningfull as i n the case of F i g . 2- 33.
(8) Picture of low contrast I n the case of pictures of low contrast around the c h i n , there i s
no c h i n contour detected i n the binary picture. Fig. 2-35 i s atypical exarrple. I n this case, the beam-intensity control of the flying-spot scanner[8] i s very useful; i t changes the relation o f input p i c t u r e density v s . o u t p u t digital valueas shown i n Fig. 2 - 3  ( ~ ) . Fig. 2 - 3 5 j b ) was sampled by the beam ( 0 0 ) . The use of the beam (10) increases the contrast o f the middle range in the d i g i t a l picture as shown i n F i g . 2 - 3 6 ( a ) . Therefore, i n F i g . 2-36(b) the chin contour appears i n the binary picture and the analysis program can detect i t .
(9) Size variation The program i t s e l f i s able t o accept the size variation of face
u p t o 15 z 20%. I t may be readily extended so t h a t larger variations are acceptable, by making combined use of the flexible scanning program of FSS ( Kanade[8]). Suppose a face in the input picture i s too small, The program will f a i l i n the f i r s t step of detecting the face sides L and R , b u t the size o f the face can be estimated. Based on the estimation, finer scanning with a smaller spot size will probably produce a digital picture in which the face i s of the acceptable size.
APPENDIX 6 contains supplementary examples. Much more examples would be necessary t o completely show the excellent properties of the
45

r h r b o f pray of Input p i c t u n

(a) Digitized picture of Fig. 3-35(a) by the beam (10)

( b ) Result of the analysis

( c ) Four kinds of
beam: (OCj , (01) ,
(10). and (11)

Figure 3-36 Effect o f beam-intensity control

( 5 ) Face with t u r n or t i l t Fig. 2-31 and F i g . 2-32 show the faces t h a t involve a small
extent of t u r n and t i l t . Though the results are fairly good, the positions of mouth, nose ends and eye rectangle have some errors because no explicit compensation is made for the t u r n and t i l t .
( 6 ) Case of sparse chin-contour segments F i g . 2-33 illustrates the case i n which the feedback process w i t h
adaptive threshold setting i n the chin-contour detection made i t possible t o detect a set of sparse line segments as forming the chin contour.
44

CHAPTER 111
IDENTIFICATION OF HUMAN FACES
111-1. Introduction
The r e c o g n i t i o n of a f a c e i s one o f t h e most c m o n human e x p e r i ences, and y e t i t i s v e r y d i f f i c u l t t o e x p l a i n how t h i s i s done. L i t t l e research has been r e p o r t e d on machine i d e n t i f i c a t i o n of faces. T h i s c h a p t e r describes an attempt a t face i d e n t i f i c a t i o n of 20 people by computer.
Main emphasis i s put on computer e x t r a c t i o n o f face features from t h e p i c t u r e . The i d e n t i f i c a t i o n t e s t o f faces was conducted mainly t o v e r i f y the results of the feature- finding algorithms, as w e l l as t o attempt an automatic v i s u a l i d e n t i f i c a t i o n o f people. Therefore t h e method employed i s r a t h e r standard and straightforward: the picture i s f i r s t analyzed t o locate feature points; then, facial parameters are calculated; a weighted Euclidian distance defined on these parameters i s used t o measure t h e s i m i l a r i t y o f faces.
111-2. The Problems
To automate t h e i d e n t i f i c a t i o n o f human faces, t h r e e problems arise as i n other pattern-recognit i o n tasks:
47

program, but the successful results of analysis Of more t h a n 800 pictures have demonstrated that the flexible picture analysis Scheme w i t h feedback which was employed in the program 1s very Powerful for dealing w i t h complex pictures.
46

such points as eye corners,muth extremities, n o s t r i l s , and chin t o p . These facial landnarks are located by computer picture processing. Decision-making uses a simple Euclidian distance defined on the feature parameters.
111-3. Computer Extraction o f Face Features
111-3-1. Data Set
Machine identification o f 20 people by their faces was attempted. They were a l l young people, 17 males and 3 females, without glasses, mustache or beard. Pictures of the subjects were taken i n two series, i . e . , two pictures for each person. The f i r s t and second pictures o f the same person were taken in a different place w i t h a time interv a l of one month. Thus, a collection of 40 photographs of a full face was used i n the experiment. No special arrangements on lighting and other photographic conditions were made, except for asking the subject t o t u r n a full face. The films were processed i n a normal way, and positive prints w i t h an appropriate size were produced t o f i t w i t h the opaque-material head of the flying-spot scanner.
111- 3- 2. Two-Stage Process
Computer picture processing i s carried out t o locate face-feature points i n the face, such as eye corners, nostrils, c h i n contour and so on. As shown i n F i g . 3-1, the whole process consists of two stages. The f i r s t stage i s exactly the process described i n CHAPTER 11: the
49

( 1 ) Selection of effective features to identify faces About face-features, a few works have been reported. Bledsoe[2]
and Kaya and Kobayashi[9] used geometrical parametrization on the basis of coordinates of facial landmarks, whereas Goldstein, Harmon and Lesk[6] used subjective descriptors of features such as face shape, hair texture and lip thickness.
(2) Machine extraction of those features Computer processing o f human-face pictures for feature extraction
has rarely been studied. Face-identification systems so far developed
are man-machine system, in which feature extraction is perfoned more or less by human. In Kelly's work[lO], only five measurements are drawn from the face, and it seems that measurements in the body picture, e.g., height and width of shoulders, play more important roles in his identification test.
(3) Decision-making based on the feature measurements This is related to learning machines in pattern recognition.
Many elaborate alogrithms to derive the optimal decision rule have been proposed. Actually, however, in such a complex problem as the identification of faces, the set of selected features mainly determines the performance of identification. In fact, Bledsoe and Kelly used a rather simple weighted Euclidian distance. In the tasks of suspect-face-file search and fingerprint-file search, it i s more reliable and useful to find a small subset in which the target is surely included than to try to identify the best match in the file. The rank-ordering process devised in [6] provides quick reduction of target population.
At present the problems (1) and (3) are not of our major concern, though they are of interest. Computer extraction of facial features
is our principal purpose. In this thesis, the geanetrical parametrization was used to characterize a face; distances and angles among
48

Figure 3-2 Result o f the f i r s t stage o f processing.
111-3- 3. Sampling of F i n e r Image D a t a
The f i r s t t h i n g t o do i s t o o b t a i n f i n e r image data of the confined p o r t i o n s . From the feature p o i n t s obtained i n the f i r s t stage, four small r e g i o n s are s e t t l e d as shown i n F i g . 3-3. They correspond t o t h e r i g h t eye, l e f t eye, nose and mouth. This time, the scanning i s made w i t h t h e h i g h e s t r e s o l u t i o n , i.e., spot s i z e = 1 x 1 ( p o i n t s p o t ) and sampling s t e p = 1. The " best" beam i n t e n s i t y i s s e l e c t e d t o o b t a i n t h e d e t a i l s . Four kinds o f beam i n t e n s i t y a r e a v a i l a b l e as was mentioned i n CWPER I1 (see Fig. 2-36(c)). The best beam i n t e n s i t y t o be used f o r each r e g i o n i s determined as f o l l o w s . Take t h e nose r e g i o n f o r instance. Fig. 3-4(a) shows t h e histogram of gray levels contained i n the correspondfng region of the d i g i t a l p i c t u r e which was scanned by t h e beam i n t e n s i t y (00) and used i n t h e
51

whole p i c t u r e i s scanned t o produce a Wit d i g i t a l p i c t u r e of 140 x 208 elements; t h e sampling i s made a t every 3 addressable p o i n t s by a 5 x 5 s p o t by means o f t h e f l e x i b l e scann ng program of the f l y i n g - s p o t scanner; then t h e secondary d i f f e r e n t a t i o n and thresholdi n g y i e l d a binary picture, i n which t h e p i c t r e analysis program locates a Set of f a c i a l landmarks; an example o f the processing r e s u l t of t h e f i r s t stage i s shown i n Fig. 3-2.
The coarse scanning by a r e l a t i v e l y l a r g e spot has eased t h e succeeding d i f f e r e n t i a l o p e r a t i o n and f e a t u r e - f i n d i n g algorithms o f the f i r s t stage, but, f o r the purpose o f face- identification, the accuracy i s i n s u f f i c i e n t . Once t h e l o c a t i o n s of eyes, mouth, nose, e t c . a r e known, a t l e a s t approximately, one can r e t u r n t o t h e o r i g i n a l p i c t u r e t o e x t r a c t more accurate i n f o r m a t i o n by confining the processi n g t o smaller regions and scanning w i t h h i g h e r r e s o l u t i o n . This refinement process i s t h e second stage, which w i l l be described i n t h e f o l l o w i n g two subsections.

Binary picture Extraction of 4 f a c i a l landmarks

First stage
L

on t h e confined r e g ions

T+
Fine image data o f

specific parts

Second

P r e c i s e 1ocat ion

stage

J.o f f e a t u r e p o i n t s
rd

F i g u r e 3-1 Two-stage process f o r computer measurement of features o f human-face photographs.

50

(a) Right eye

(b) Left eye

( c ) Nose

(d) k u t h

Figure 3-5 Printouts o f detailed image data.

, f i r s t stage (see Fig. 3-5(c)). The histogram indicates t h a t the
shades of gray i n the region range from 8 t o 26. Thus the beam
intensity (10) will provide the best detail, because the middle range i s digitized i n t o 32 levels, and the darker and brighter ranges saturate t o the lowest value 0 and the highest value 31, respectively. I n f a c t , as shown i n Fig. 3-4(b) the new histogram of the detailed image data of the nose region (Fig. 3-5(c)) proves the effect of t h i s beam selection: the whole digital range i s used effectively.
I n t h i s way, the best beam intensity i s selected for each region: (00) f o r t h e region o f wfde-range intensity, (01) for dark region, (10) for medium, and (11) for bright. Fig. 3-5 shows the printouts
53

Figure 3-3

Four regions t o be

sampled i n the second

stage.

They are

determined by the

positions of S , 1,

P, Q, and M.

Size of the regions:

--Eye --Nose
-- .k u t h

70 x 40 80 x 50 105 x 50

frequency
(a 1

Figure 3-4

frequency
(b)
Histogram o f gray levels.

52

.

( a ) Elimination of irrelevant portions

( b ) Determination o f eye rectangle

Figure 3-6 Detection of eye comers

The operations shown in Fig. 3-6 can locate the eye corners precisely. The f i r s t operation i s t o erase the connected canponents
w h i c h cross the frame edge and l i e outside of the circumscribed
rectangle of the right eye S1S2S3S4 t h a t has been determined i n the f i r s t stage (Fig. 3 - 6 ( a ) ) . This operation eliminates the portions t h a t correspond t o eyebrow, nose line, and h a i r . The circumscribed rectangle of the remaining components, A1A2A3A4 is determined ( F i g . 3-6(b)); i t indicates the precise location o f the eye.
The same operation i s performed on the left-eye region. The result i s illustrated i n Fig. 3-7; the four vertexes are displayed
i n the gray-level digital picture.

( 2 ) Nose
I n the nose region, the two nostrils are the features t h a t can be consistently obtained, because they appear extremely dark.
Two small areas are fixed, i n which the l e f t and right nostrils
may be contained, respectively. P-tile method i s applied on each area t o determine the threshold t h a t singles out the nostril from the background: the threshold value is the minimum T such t h a t the number of points which are darker t h a n T exceeds a predeternined number P = 45. Points t h a t are darker than T are located, and the fusion of distance 1 is perforned on i t . The center of gravity o f the maximum component i n each area i s computed as the center of the nostril.

55

of the detailed image data (upper) and those of the corresponding regions In the picture used i n the f i r s t stage (lower). I t can be
seen t h a t the upper pictures contain more details. This re-scanning process can be regarded as a k i n d of visual actomnodation i n both position and 1ight intensity; the conditions of image-data sampl i n g are adapted t o the individual portions.
111-3-4. Description of Extraction Processes
After acquisition of the finer image d a t a , the next processing i s t o extract more precise infonation from each region. This time, all the operations used are very straight and simple: thresholding, differentiation, integral projection, and so on. Such simple operations suffice t o get the facial details, because the program knows w h a t part of the face i t i s looking a t and what properties i t deals w i t h . Moreover i t should be noted t h a t this two-stage process could reduce the memory and time which m i g h t have been wasted for processing unnecessarily fine image data of irrelevant portions.
( 1 ) Eye F i g . 3-5(a) i s the gray-level representation of image array i n
w h i c h the r i g h t eye i s contained. For each picture element I i j , the f i rst derivative
i s computed. Fig. 3-6(a) shows the binary picture in which the ( i , j )
element has 1 i f d1. .>e or 0 i f dI. .a.The value of e is set 15 in
1J 13 this experiment.
54

.

F i g . 3-8 i l l . u s t r a t e s t h i s process. Fig. 3-9 shows t h e r e s u l t s : t h e centers of n o s t r i l s are displayed i n the picture.
13) Mouth
L i p t h i c k n e s s and t h e shape of mouths a r e v e r y d i s t i n c t i v e features of people, but It i s n o t easy t o e x t r a c t them w i t h consis-
tency. Therefore,in the mouth region, o n l y the p o s i t i o n and breadth o f the mouth are used.
The l i p s occupy a r e l a t i v e l y dark and oblong area i n t h e mouth r e g i o n as can be seen i n F i g . 3-5(d). As shown i n F i g . 3-10, t h e v e r t i c a l i n t e g r a l p r o j e c t i o n i s f i r s t c a l c u l a t e d . The deepest v a l l e y V corresponds t o t h e dark p o r t i o n where t h e upper and l o w e r l i p s meet. It shows t h e v e r t i c a l p o s i t i o n o f t h e mouth. Next, along t h i s h o r i z o n t a l l i n e , a narrow band i s e s t a b l i s h e d as shown i n F i g . 3-10. From t h e h o r i z o n t a l p r o j e c t i o n o f t h i s band, t h e breadth can be d e t e r mined by detecting the darker part; the d e t a i l i s explained i n Fig. 3-10. The l e f t and r i g h t e x t r e m i t i e s o f t h e mouth l o c a t e d i n t h i s way a r e d i s p l a y e d i n t h e p i c t u r e o f F i g . 3-11.
This completes t h e second stage of t h e processing. A l l t h e f a c i a l f e a t u r e p o i n t s which have been e x t r a c t e d i n t h e f i r s t and second stages a r e used t o calculate f a c i a l parameters.
Examples o f t h e processing r e s u l t s a r e presented i n APPENDIX C. They a r e a p a r t o f 40 p i c t u r e s used i n t h e i d e n t i f i c a t i o n experiment.

111-4. Facial Parameters

...,A s e t o f s i x t e e n f a c i a l parameters X = (x,, x2,

x16) shown

i n F i g . 3-12 i s calculated. They a l l a r e r a t i o s o f d i s t a n c e and area,

and angles t o compensate f o r t h e v a r i n g s i z e of p i c t u r e s . I n order

57

, Figure 3-7 Eye comers.

-. ..........................

......................

-- ---.-..-................ ---_--....-.......-...

1 g-/&
______...__.__._

C
---- -
i
..-

.

( a ) P-tile method and fusion

(b) Centers o f gravity o f maximum components

F i g u r e 3-8 Detection o f nostrils.

Figure 3-9 Centers o f nostrils.
5

.I

over t h e whole s e t of data. That i s , yi means how f a r t h e parameter

value x i i s f r o m t h e mean mi= E[xi]. normalized by t h e standard devia-

t i o n oi. y i takes a p o s i t i v e value i f xi i s g r e a t e r t h a n t h e mean and

....negative if s m a l l e r t h a n t h e mean.

v e c t o r y = (y1. y2.

yls).

Thus a p i c t u r e i s expressed by a

On t h e o t h e r hand. t h e same s e t o f f a c i a l parameters i s measured

by human hand i n t h e enlarged photograph o f t h e f a c e u s i n g a m i l l i m e -

t e r scale and a transparent millimeter g r i d . The normalization i s

a l s o performed. T h i s i s done t o compare t h e f e a t u r e measurements by

computer w i t h those by human. H e r e a f t e r , t h e s u p e r s c r i p t E o r h i s

p u t on t h e parameter v a r i a b l e yi when i t i s necessary t o i n d i c a t e

whether i t i s o b t a i n e d by computer o r by human.

x1 = AB/OC x2 = ST/AB
x3 = NC/OC curvature o f the
'4 = 'top o f t h e c h i n
x5 = (AEGC+AFCH)/(S~+S~)

st sy : hatched areas
F i g u r e 3- 12 Facia1 parameters. 59

to eliminate the differences of dimension and scale among the components of X , the vector X i s normalized according to the following

where mi

-0: E[(xi m i ) ' ] ; and E[-] stands for the average

Figure 3-10 Determination of mouth extremities.
58

111-5. Identification Test
The phase of identification t e s t of faces was r u n separately from the phase of picture processing. The whole collection of 40 pictures was processed, and a l l the parameter measurements were obtained both by computer and by hand. The resultant nonalized vectors tYC and 2 Yh for t = 1 40 were recorded on a magnetic tape.
The experiment was r u n as follows. The collection o f 40 pictures was divided i n t o two sets of equal size. The f i r s t set t h a t comprises 20 pictures, one picture for each person, i s the reference s e t R, or the s e t o f known individuals. The remaining 20 pictures are used as the t e s t s e t T o r the s e t of unknown individuals. Now the problem is: given a picture i n the t e s t set T , find the picture of the same person i n the reference set R.
We chose a simple distance

a s a measure of similarity between the pictures Y and Y ' . Therefore,

Feature measurement
r
Computer
Human

123
;
10 9 10 10
15 13 13 12

Table 3-2

The number of people who were correctly identified when a l l the parameters were used. A better performance i s obtained
.when ineffective parameters are omitted
i n deci s ion-ma k ing

Before going to identification experiment, the effectiveness or repeatability of parameter values has been examined in the following way. P i c k u p a picture t Y . Let z Y ' be the other picture of the same person. Then

i s hopefully the minimum of the set

but this i s not always the case. Let zUi be the zri-th smallest of
Table 3-1 tabulates the average ai and standard deviation Bi of

re. over the whole collection o f pictures, i.e.,
1c

ai = E[Zri]

(3-5)

'I

' 1 '1 't

&'

'#

'7

'#

'#

'10 'H ' I J ' J l ' J 4 ' l b 'I# h * r @ Q e

0: 12.2 15.6 16.9 1 6 . 1 1 S . 1 1 6 . 1 15.0 13.7 13.7 17.1 11.0 10.7 12.7 17.3 10.) IO.) 1 4 . 1 8: 9 . 7 9.6 9 . 5 10.1 1 0 4 I I . 3 10.8 1 1 . 0 10.1 9.9 7.7 1.1 0.0 10.9 0.6 0.5

a: 10.2 10.1 1 4 . 1 11.0 l 7 . Y 12.0 11.9 19.1 12.2 9.3 15.3 11.7 11.4 9.0 13.6 10.5 12.7 0: I 1 1 8 10.0 10.5 8.8 1 . 2 9.0 9.7 0.5 7.0 10.5 0.9 9.4 7.9 10.0 0 . 1

Table 3-1 Repeatability o f parameter values.

The upper and lower rows correspond to, respectively, measurements by computer and by hand. It can be said from the table that the reliability of individual parameters i s not very high. The accuracy of computer extraction i s slightly inferior to that o f human extraction.
60

-
w h e n given a Picture k T in the t e s t s e t , the answer i s the picture Y i n the reference set such t h a t
(3-7)
3,The identification t e s t was carried out f o r K = 1 , 2, 3.
Table 3-2 summ-izes the results. The correct identification i s
45 2, 75%.
Better results are obtained when ineffective parameters are not used i n calculating the distance. The parameters, the sun of whose ai and Bi i s large, are regarded as ineffective.* In the cmputer extraction, yg, y6 and ylB are discarded and in the human extraction, y5, y8 and yIl. Therefore only thirteen parameters are used. The results of identification t e s t are presented i n Table 3-3 (computer extraction) and Table 3-4 (human extraction). The entry number stands f o r the rank of the real target picture: "1" means t h a t the correct i n d i v i d u a l i s identified. I n both tables, 15 out of 20 people are correctly identified in the best cases.
From t h i s limited experiment i t i s difficult t o judge whether a f u l l y automatic identification of faces is feasible or not, but the experiment has shown t h a t the computer is certainly capable of extracting f a c i a l features t h a t can be used for face identification of people, almost as reliably as a person.
*This criterion may be justified as follows. Suppose Iri follows
a normal distribution N(ai, B i ) . Then Ci = ai + Bi is the rank below
w h i c h 84% of cases f a l l .
3

f 32

Average Nunbcr
-Of1dent 1f 1 Ic a t i o n

1.0 1.8 1.5 1.8
9 12 14 1s
II1

Table 3-3
Results of identification t e s t ; feature measurement by computer.

Table 3-4
Resul ts o f i d e n t i f i c a t i o n
t e s t ; feature measurement
by human.

2

CHAPTER IV
CONCLUSION
IV-1. Surrrnary of This Thesis
T h i s thesis has been devoted t o the descriptions of computer analysis a n d identification of human faces. I t can be sumnarized as
follows:
( 1 ) I n CHAPTER 11, the analysis o f human-face photographs has been performed as a task of pictorial information processing. Given a photograph of the face, the analysis program can locate facial feature points, such as eye corners, nose, mouth, chin contour and so o n . More t h a n 800 pictures were successfully processed by the program.
( 2 ) The flexible picture analysis scheme was presented and employed i n the analysis program of human face. I t consists of a collect i o n of rather simple subroutines, each of which works on the specific part of the picture, and elaborate combination of them w i t h feedback interwoven makes the whole process flexible a n d adaptive. The face-analysis program dereloped in t h i s thesis is one o f the f i r s t ones t h a t implement this type of analysis scheme w i t h feedback for picture analysis. Excellent properties of the program as well as successful resultsof the analysis have proved t h a t t h i s manner of organizing programs i s very promising t o the analysis of complex pictures.
65

e

area of black portions i n a character. A decision r u l e that divides t h e f e a t u r e space i n t o subspaces assigns an unknown p a t t e r n t o one of p r e d e f i n e d classes. Many a l g o r i t h m s have been proposed f o r c o n s t r u c t i n g t h e optimal decision r u l e s . But i n t h i s method, as i s o f t e n pointed out, the choice o f features i s more c r u c i a l than the decision r u l e .
I n extracting features from a picture, two-dimensional Fourier
transforms and histograms o f g r a y l e v e l s may be useful, for example, i n d i s t i n g u i s h i n g c o r n f i e l d s from woods i n a e r i a l photographs, b u t i n cases where t h e s t r u c t u r e of t h e p a t t e r n i s o f more concern, they
do n o t work s a t i s f a c t o r i l y . Therefore, i t becomes e s s e n t i a l t o prov i d e the computer with the s t r u c t u r a l information o f patterns.
N o t i c i n g the analogy between t h e s t r u c t u r e o f patterns and t h e syntax of languages, Kirsch1111, Narasimhan[lS], and o t h e r s began t o t a k e the s o - c a l l e d l i n g u i s t i c approach. As shown i n Fig.4- 1, t h e input pattern i s f i r s t represented i n a s t r i n g o f primitive elements which are e x t r a c t e d i n a r a t h e r microscopic way. Then a s y n t a c t i c analysis i s performed on t h e s t r i n g i n order t o decide whether t h e
g i v e n p a t t e r n i s i n t h e p a r t i c u l a r c l a s s or n o t . T h i s approach could
be s u c c e s s f u l l y a p p l i e d t o l i n e - l i k e p a t t e r n s , such as handwritten characters, t r a c k s o f bubble-chamber photographs, and chromosome p i c tures, achieving more f l e x i b i l i t y than t h e template-matching method o r the method based on the s t a t i s t i c a l decision theory.

Primitive

input

element

p a ttern- e x t r a c t ion

string

Syntactic c
analysis
Gramnir(Structure)

Figure 4-1

Introduction of structure in the liguistic approach; t h i s scheme i s n o t s a t i s f a c t o r y
f o r complex pictures.

7

.

c
( 3 ) In CHAPTER 111. visual identification of people by their faces was tested. 15 out o f 20 people were correctly identified relying solely on measurements obtained by a computer. This is the first success of machine identification of human-face photographs,
( 4 ) Though simple, the two-stage process employed in extracting precise features has a significant meaning. It is an example of distant feedback: high-level decision affects and controls input
sampl i ng stage .
I V - 2 . Picture Structure and Analysis Method
This section provides a discussion on the generalized concept o f the method used f o r processing human-face photographs.
Several methods of pattern recognition so far developed are first discussed briefly from the point o f manipulating the picture structure.
The techniques of correlation in two dimensions can be used f o r pattern recognition. Prepared a file of standard objects, a given scene i s correlated with each member o f the file and it i s concluded that it most resembles that object which gives the maximum correlation. This type of approach is often termed "template matching" and it has an advantage that high-speed computation of correlation may be carried out by means of optical devices. Although straightforward in concept, the template-matching method, we know, is less potent for recognizing patterns with large variations, because it i s sensitive to translation, magnification, brightness, contrast and orientation.
Statistical pattern recognition is another important approach. The pattern is treated as a multi-dimensional vector in the feature space, the components of which denote individual observations, e.g., the

only in the context of a face; in fact, many other components show the shape o f the eye in the picture. This means that the search for the component with the shape of the eye should be done in the region in which the eye i s expected to exist.
The scheme of Fig. 4-2 which I employed is better for this pur-
pose: first the region in which a particular part (e.g. head top) is predicted to exist i s detennined by taking full advantage of a prim: knowledge about the object class of pictures and of the global but
sometimes not so precise information extracted from the input picture. Then the component with specific properties is detected in it. A s a
result, the information about the picture under processing is reinforced and this can be used, in turn, for determining where to look f o r the next part. Iteration o f these processes leads to the acquisition o f information enough to describe the given picture.
Procedures of detecting parts are divided into subroutines and they operate on the estimated search area under given constraints. Each procedure can take advantage of the fact that it knows what to look for and where to look at. For rough and tentative estimation of

a prioln: know1 edge
of the object class
of pi ctui-es

i npu t picture

i nfoTtomtaatl i on picture
TT
1

components with specified propert ies

(success) (failure)

reinforcement

I

i correction, retrial

Figure 4-2 Generalized concept of the picture analysis scheme employed in this thesis.

.

The linguistic approach presents certain difficulties in its a p plication. In addition to the difficulty in describing a two-dimensional image in the string form, the method suffers from the fact that the stage of primitive-element extraction does not know what element
is meaningful and what is noise because it is separated from the stage of syntactic analysis. Another reason for this is that primitive ele-
ments are usually line segments and arcs: they are neither subparts nor substructures of the picture, but only convenient units of processing. Recently a method appeared which uses a description of the picture in t e n s of properties of regions (e.g. circular) and relations between them (e.9. adjacent), instead of lines[l]. It may have the same kind of disadvantages unless the relational structures of objects which are stored do not direct the process of pictorial analysis of a given scene.
In order to overcome this difficulty, Shaw[2C] proposed a topdown goal-directed syntax analyzer. It "parses" the picture in the analogous manner to a classical top-down string parser: the grammar is explicitly used to direct the analysis and to control the calls on picture processing routines for primitive elements. Unfortunately the relation the analyzer uses is only the head-and-tail concatenation, thus limiting its applicability.
Now, let's discuss the significance of the method I employed in anlyzing pictures of human faces. Some difficulties would be en-
countered i f the linguistic approach were taken for hurnan-face analysis. Suppose that small line segments, arcs and the like are selected as the primitives. Then the resultant rules for composing a face would be intolerably complicated and awkward. Moreover, a lot of noisy line segments unrelated to the face structure, perhaps from wrinkles and hair style, would be annoying. Thus it is more convenient to consider a face to be composed of larger substructures such as eyes, nose, mouth and so on, having the relatively macro-positional relations. Recall that the eyes, for instance, are recognized as such
68

prepared. t h e mnber of which works on the specified r e g i o n a n d yields certain results when given a set of d a t a i t needs; the routines are called i n t o a c t i o n i n the appropriate sequence w i t h retrial a n d feedback interwoven.
This scheme, when advanced, leads t o the view t h a t a pictureanalysis program should be a problem-solving program: t h a t i s , the analysis does n o t proceed i n a predetermined order, but the program decides the best sequence o f analysis steps depending on individual i n p u t pictures, on the basis of a priori knowledge and evidence so f a r gathered a b o u t the given i n p u t . The program selects from a collection of routines one t h a t i s expected t o give the most reliable result. The selected routine i s executed and the total information about the i n p u t increases. I n this way, the program reaches the goal of describi n g the given picture. I n i t s process, the several aspects of problemsolving techniques will appear inevitably, such as evaluation of intermediate results, subgoal setting, backtracking and so on. The problem o f data structure i s the most essential in this method, and one possible approach i s discussed by Nagao[12].
The problem of computer picture processing has many different phases. Sometimes, a single transformation performed upon the whole picture may suffice the purpose, among them uniform enhancement or smoothing. When i t comes t o analysis or understanding of the picture, the problem will involve much deeper aspects; structure, knowledge, and problem solving. The results of t h i s thesis suggest t h a t , rather t h a n individual techniques of picture processing, i t i s more essential t o combine them i n a proper manner based on the context and structure of t h e picture. The work reported here will serve t o advance picture processing i n t h a t direction.
71

search areas. procedures insensitive t o noise are used which might not

be so accurate, b u t once t h e search areas f o r s p e c i f i c components are

established, accurate procedures are employed which determine the ex-

a c t p r o p e r t i e s of t h e components, and which sometimes incorporate

ad hoc methods. Ift h e program f a i l s tr! d e t e c t t h e component s a t i s f y -

ing the specified conditions i n the predicted area, i t diagnoses the

cause, and

modify t h e program parameters, or may go back t o t h e

former steps. T h i s k i n d o f feedback mechanism makes t h e whole pro-

cess very f l e x i b l e . Note t h a t i t also s i m p l i f i e s each step of analysis:

p e r f e c t r e s u l t s need not t o beobtained i n t h e once-and-for-all process-

i n g , f o r t h e e r r o r s , when detected a t l a t e r steps, can be recovered.

The feedback may i n v o l v e t h e i n p u t scanning o f t h e p i c t u r e t o

o b t a i n more proper image data. A simple example i s t h e two-stage pro-

cess described i n t h e f i r s t p a r t o f CHAPTER I 1 1 f o r e x t r a c t i n g p r e c i s e

f e a t u r e s of t h e face. This " d i s t a n t " feedback prevents waste of memo-

ry and time f o r t r e a t i n g unnecessarily f i n e image data.

The scheme described above resembles somewhat t h e top-down goal-

directed syntax 2nalyzer o f Shawl201 i n t h a t both employ "detection-

a f t e r - p r e d i c t i o n " process. I n our scheme, however, ( 1 ) u priori

s t r u c t u r a l i n f o r m a t i o n about p a t t e r n s i s embedded i n t h e procedures,

therefore, ( 2 ) the next p a r t t o be looked f o r and i t s search area are

determined by taking i n t o account a broader context than the local

h e a d - t a i l connection i n Shawls analyzer, and ( 3 ) m o d i f i c a t i o n of t h e

program parameters and backtracking can be performed more f l e x i b l y .

I n c o n t r a s t t o Shawls approach i t may be a more problem-dependent

scheme.

I V - 3 . Picture Analysis and Problem Solving
The p i c t u r e a n a l y s i s scheme used i n t h e a n a l y s i s o f human-face pictures i s fundamentally as follows: a c o l l e c t i o n o f routines i s
70

REFERENCES

[ 1 ] H. G. Barrow and R. J. Popplestone: "Relational Descriptions in Picture Processing", in Machine IntelZigence 6, Michie(ed. ),
pp. 377-395.

[ 2 ] W.W.Bledsoe:" Man-Machine Facial Recognition ' I , Panoramic Research Inc., Palo Alto, Cal., Rep. PRI:22 Aug. 1966.

[3j

H.Chan and W.W,Bledsoe:" Some Preliminary Results

A"

,MaPna-nMoarcahmiinceReFsaeciaarlchReIcnoc.gniPtailoon

System; Alto,

Cal., Yay 1965.

[ C j Y.A.Fischler and R.A.Elschlager:" The Representation and Yatching of Pictorial Structures ",Lockheed Palo Alto Research Lab. Lockheed Missiles & Space Company, Inc. Cal., LMSC-D243781, Sept. 1971.

[ 5 1 A.:.Goldstein, L.I!.Harmon and A.B.Lesk:" Identification o f Human
Faces " , ?roc. L E E , Vol.59, p.748, 1971.
[E3 A. J . Go1dstei n, L .D.Harmon and A . 6. Les k: I' Man-Machine Interaction
in Human-Face Identification ' I , BeZ! Sys. Tech. J., Vol.51, ~ 0 . 2 ,pp.399-427, Feb. 1972.

[ 7 ] L.D.Hanon:"Some Aspects o f Recognition o f Human Faces", in
? a t t e r n Recognitior i r , SiologicaZ and Technica 2 Systems, O.J.Gruesser(ed. ), New York Springer.

[: T.Kanade:" Picture Processing System by Computer Complex and Recognition of Human Faces 'I, Doctorial Dissertation,
Deoartrnect of Conouter Science Kyoto University Kyoto Japan
( T h i s isthe original version o f this book.)

[F; Y.Kaya and K.Kobayashi : " A Basic Study on Human Face Recognition", i n 'roritlers of -=cttern .?ecoGnition, S.Watanabe(ed.), p.265, 1972.
[ l o ] M.D.Kelly:"Visual Identification o f People by Computer", Stanford Artificial Intelligence Project Memo AI-130, July 1970.
[ l l ] R.A.Kirsch:"Computer Interpretation o f English Text and Picture Patterns", I&E Trms., Vol .EC-13, pp.363-376, Aug. 1964.

73

APPENDIX A COMPARISON OF LINE-DETECTION OPERATORS

Example 1
(a) Gray-level picture
(b) Laplacian opera tor ( F i g . 3-8)
(b-1) e = 25 (b-2) e = 35
(c) Robertz operator ( F i g . 3-10(a))
( ~ - 1 )e = 4
(c-2) 5 = 2
( d ) flaxirnum o f
differences (Fig. 3-10(b))
(d-1) 8 = 4 (d-2) 8 = 2

75

c
M.Nagao:"Picture Recognition and Data Structure", in C m p k t c Zr,-u;es, p.48, North-Holland, 1972. M.Haaao and T.Kanade:"Edge and Line Extraction in Pattern Recognition", FMC. Inst. n e e t . corn. -8. Japan, V01.55, No.12, pp.1618-1627, Dec. 1972 ( in Japanese ). G.Nagy:"State of the Art in Pattern Recognition", A s s . IEEE, vOl.56, NO.5, pp.836-862, May 1968. R.Narasimhan:"Label ing Schemata and Syntactic Descriptions of Pictures", I n f o r m t i o n and ContmZ, Vol.7, pp.151-179, 1964. L.G.Robertz:"Machine Perception of Three-dimensional So1 ids" , in Optical and nectro-DpticaI I n f o m a t i o n m c e s s i n g . pp.159-197, Cambridge, Mass. MIT Press, 1965. A.Rosenfe1d: Picture Processing by Caputep, Academic Press, New York, 1969, p.141. T.Sakai, M.Nagao and S.Fujibayashi:"Line Extraction and Pattern
Detection in a Photograph", Pottern Recognition, Vol .1 , p.233,
March 1969.
-T.Sakai, M.Nagao and M.Kidode:"Processing o f Multi-Leveled
Pictures by Computer The Case o f Photographs o f Human Face -'I, Jour. I n a t . Elect. C m . Ehqt-6, Japan, A b s t m c t s , Vol.54, No.6, p.27, June 1971. A.C.Shaw:"Parsing o f Graph-Representable Pictures", J. ACh!, V01.17, No.3, pp.453-481, July 1970.
74

APPENDIX B
SL'FPLECENTARY EXAMPLES OF RESULTS OF ANALYSIS OF CHAPTER I 1

.

i
1. Simple Case
77

..
Example 2 (a) Gray-level
picture (b) Laplacian
operator (Fig. 3-8) (b-1) 8 = 25
(b-2) e = 35
(c) Robert2 operator (Fig. 3-10(a))
(c-1) e = 4
(c-2) e = 2 (d) Maximrm of
differences (Fig. 3-10(b)) (d-1) (3 = 4 (d-2) 8 = 2

r-----. -. -. -. -. -. -. -. -. ---- .-
4. Face with f a c i a l l i n e s
t
..+- =.=
5. Face with glasses; eye centers happened t o be obtained 79

2. Chin contour with breaks
-- - 3. Separated eye components
78

APPENDIX C
RESLLTS OF FACE-FEATURE EXTRACTION OF CHAPTER I 1 1

This appendix contains 10 sets of pictures

( 2 s e t s x 5 persons) t o show the r e s u l t s o f

face-feature extraction described i n CHAPTER 111.

They a r e a part of 40 pictures used i n the

experiment of face identification. Each set

compr i ses

: ( i ) a digitized gray-level

p i c t u r e ; ( i i ) a b i n a r y picture i n which the

feature points located i n the f i r s t stage of

analysis a r e marked a s d o t s ; and ( i i i ) pictures

displaying the r i g h t eye corners, l e f t eye

corners, n o s t r i l s and m o u t h extremities, which

are located i n t h e second stage of analysis.

81

c
-. . . 1.
6. Woman's face
7 . Sparse chin contour 80

-"' . 83

e--
- 82

NAKE
.I
....-. .

.

85

L
NAKl
.. ---. . _
84

ON02 87

ON01 86

UEYP 89

L

-. . .

KONl

90

91

AUTHOR INDEX
Barrow, H. G . , 73
Bledsoe, W. W . , 4 , 10, 48, 73
Chan, H., 4 , 73
E l s c h l a g e r , F,. A . , , 10, 73
F i s c h l e r , M. A . , 6 , 10, 73
Fujibayashi, S . , 6 , 10, 74
Goldstein, A. J . , 5, 10, 48. 73
Harmon, L. D., 4 , 5 , 10, 48, 73
Kanade, T., 45, 73, 74
Kaya, Y . , 4, 10, 48, 73
K e l l y , M. D., 5 , 10, 48, 73 Kidode, M., 18, 74
Kirsh, R. A . , 67, 73 Kobayashi, K. 4 , 10, 48, 73
Lesk, A . E., 5 , 10, 48, 73
Nagac, Y . , 6, 10, 18, 71, 74 Nagy, G . , 4 , 74 Narashimhan, R . , 67, 74
.Popplestone, R . J , 73
Roberts, L. G., 19, 74

Rosenfeld, A,, 4. 74
Sakai, T., 6, 10, 18, 74 Shaw, A. C., 68, 70, 74

93

SUBJECT INDEX
a n a l y s i s steps, 23 cheek areas, 27 c h i n contour, 25 eye p o s i t i o n s , 28 nose end p o i n t s , 27 sides of face a t cheeks, 23 t o p o f head, 23 v e r t i c a l p o s i t i o n s of nose, mouth, and chin, 24
backup procedures, 30 b i n a r y p i c t u r e , 12
coarse scanning, 50 context, 69 c o r r e l a t i o n , 66
d e t a i l e d image data, 53 d i f f e r e n t ia1 o p e r a t i on, 18
f i r s t d e r i v a t i v e , 19, 54 second d e r i v a t i v e , 17 distance, 61
f a c i a l parameters, 57 feature extraction, 10 feedback, 14, 70 fine feature extraction
eye, 54 eye corners, 55 mouth, 57 nose, 55
nostrils, 55
f i n e scanning, 50
94

f l o w of a n a l y s i s , 21
flying- spot scanner, 16 fusion, 28
geometrical parametrization, 48 goal- directed, 15, 68
i d e n t i f i c a t i o n of human faces, 47 i d e n t i f i c a t i o n t e s t , 61 i n p u t of p i c t u r e , 15 i n t e g r a l p r o j e c t i o n , 23
Laplacian operator, 12, 17 l i n e extraction, 17 l i n g u i s t i c approach, 67
maximum of differences, 19
p a t t e r n matching, 33 p i c t u r e analysis, 1, 70 p i c t u r e a n a l y s i s scheme w i t h feedback, 14 p i c t u r e structure, 66 problem s o l v i n g , 70 P - t i l e method, 55
r e p e a t a b i l i t y of parameter values, 60
r e s u l t of analysis, 33
case of sparse chin- contour segments, 44
face w i t h f a c i a l l i n e s or e x t r a shadow, 36 f a c e w i t h glasses, 36 face w i t h mustache, 36 face w i t h turn or tilt, 44
p i c t u r e o f low c o n t r a s t , 45 size variation, 45
95

result of analysis(continued) sumnary table, 34 two sets of examples, 35
Roberts operator, 19 sequence of analysis steps 13 shrinking, 28 smoothing, 27 statistical pattern recogn tion, 66 syntactic analysis, 67 template matching, 66 top-down, 15, 68 trial-and-error process, 33 TV camera, 17 two-stage process, 49 visual accomnodation, 54
96

-.
hterdisciplinary Systems Research Birkhauser Verlag, Basel und Stuttgart

ISR 1 - . II--.. Menschlicher Xonformtrarr wernal ten - a m Computer simuhen
ISR 2
v".a.-.. ->Joe.
Welrmodelle J U d~am Prufstand
ISR 3 C u JI Sc-ooeoecx 0.r Beitrag k o m p h r u Stadt-
srmulationsmod.lle (vom Forrester Typl zur Analyse und Prognose goQstadrischar System.

- ISR 15 I . . " :I r)'3
Hierarchic Rcognition of Tumors #nChosr Radiographs
ISR 16
-dmCS I? LOW
Autonutic Coding: Choim of SCr~wmS
ISR 17
Rrharo young Suiation by ChiMnn: An Anificial I n t e l l i g e m Analysis of
a Piagotion T u k

ISR 28 Eetan I?ath.Ndgel Alt8rnatiw Entwicklungsmoglichhairon d u Lwrpiowimch.h in der 8RD
ISR 29 Harry Wechskr Autonutic &tation of Rib Contours hlClk.1 R d - M s
ISR 30
Alfred V a s A W - I W U t O M l V S . dsS
SP~WUM n n = c h 4 ~ i ~ m w d r

ISR 4
c C p Cr' V4 6JckharUr iEOrJri
-Industrial Robots Robots indus-
-triels Indusrri8roborer

tSR 5
h,.C :--
Entscheidungstheorie

- - -_- ISR 6-,-I7,

3"

Konfiik tlosung durch Vermittlung

Computersimulation rwischen.

staatlrcher Krisen

ISR 7

A,----

,a.-',:

Sysremanalyse der Selbsrrefleiion

- ISF:a
- r - -.3 Czrrr3.:
A f k r i b k ? Efficienr Computer System ro Answer Human Ouestions

=ISR 9
G .-a,: 'relCarne'
Lernsn und Morivarron als relevenrg*sreuene Dltenverartuitung

ISG 10
-L
_ c -.CZ
Shape Grammars and their Uses

-Ic;R 1 1

- ^-._ . :a.

'6 ~

;'der i

Applrcatrons of Fuzzy Sets t o System

Analysts

ISR 12 - E d * . _ 4p r
Syncare. samanriQue at a~iomattque
d'un Ianpagede pogrammarion SimPh

ISR 13
-.-_7-,3f > ' r , , Pictorialand FonnaIAsprcts of shop..
Shape Grammars and Aesrhetic
Srstems

ISR 14 d e r g n r e r .a- cer Sever
Mathematischo Auswahlfunk tionen und pesellschaftliche Entsetmidungen

ISR 18 Helmut M a w Computusimulation mif dmn Oialog-
udahran SIMA 8 d 1 KOWeDtiOn

ISR 19 Bd 2 Dokumentar~on

ISR 20

Hau-Li Bossei Saiomon Klaczkoi

Vomer: Mu!rer :  m o r s )

Spl8m

in the social Scienns

ISR 2 1 Ehclesaro B ~ U W8 Gemard Fehl fnrsg / Systemtheorre und Systemtwhnik in dsr Rawnplanung

ISR 22
E)e%ara*' Ne*ai.d
Computer Analysis of Scenes of Sdimensional Curved Objects

ISR 23
tfenrv M Daws Computar Repsenfarion of the Stareochunisny of Otyanic Moluulas

ISR 24 Beroneim Boosr Klaus Krcke.
Der0 'H'S7 &fothO#WtiSiDrUngder &inzdwissen-
rehaften

ISR 2 5 C:aus W Germrcrt Alternatiwn in der Forschungs. und
Entwicklungspditik ein8s Unter-
&mens

ISR 26 Hans-Paw Schwelei Numuische Optimiuung yon Com-
putuMo&llen mittals der Evolutions-
m#t89i8

ISR 27 Hermanr: Urarimann Newistischa Optimiuung yon Simule
tiO?lSmod.llM mit dam Ruof-Somrch Algorithmus

ISR 31
D e f e r bwc
Ein Computmnohlf der Vadluhrung zwischen Wohn- und Naherholungsp b k t s n d u Rogion Hannovar

ISR 32

Erns BiUerer I Mchel Cuenwi Saomor

Kbuao

Ovdapping Tn&ncies i n Opwrations

h S 8 8 d t . sVSt8mS

and

cVb.m8&S

ISR 33 G Mrrrhew Bopham 1 Mkhae,
J ShdDifO IEdirors,
h g h l OMAction i n Forwgn Policy

ISR 34 Ronald H A i k m Combinatwd Connoctivities in Soual S p t a m s

ISR 35
Moscneh Mresse MOSIM -.in Simulationskonzept briorend aut PL I I

ISR 361 3 1 I 3 0 Hsrrmur Bossel IEdtrorI Conc8pts and tools of Compurar-
Assisrad Policy Anolysrs
Volume I: &sic Conceprs Volume 2: Causal Systams Analysts Volume 3.Cognitive Syrtams
In8lysrs

ISR 39 Ro!f Pfedfer
K ~ k n w t i s c h oA ~ l v s 8okonomischer
rM.kmmokllo lu die Bundesrapublik
butschland

ISR 40
D a d Canlecd Smirn PYGMALION: A Compurer Program to
Mod.landStimuJata Cmative Thought

ISR 41
&rearan N m a u s Computersimulation tangfristiger U-Itbelastung dumh
Mi-=9m9

r1
T h i s book describos tho first oxtensivo study on automatic pictorial recognition Of human facos by cornputor. Tho proc.duro of picture analysis is b r s d on 8 novol floxible picturo analysis schomo with feedback. Tho program rocognitcrr face f u t u r e points such as nose mouth. .yes. and so on, and thon computos tho fmcial paramotor values to be usod to charactoriro tho fa-. Tho work will intorost resoarchon in pattarn r q n i t i o n . anificial intelligence. r n d image processing, and also those concernd with computer application to humrn idontifimtion.
e Computer-G&ennungrnenrch1ich.r Gesichtsrs Diose8 Buch borchreibt dio em. broitoro Untorruchung iibor automatische Erkennung yon Bildaufnahmen monrchlichor Gerichter durch einen Computor. 08s dargortollto Veriahron fiir dio Bildrnalyse b u t auf sin flexibtos &hem8 mit Riickkopplung. 00s Progmmm wkennt mlcho charakterinischon ~ i c h t w l o m o n t wo io N8so. Mund. Augen, usw. und errochnot anrchli..und dio Koordinrtonwerte dorsotben, urn d r r Gosicht LU konrueichn.n. Mosm Buch irt fiir Fachlouto der Formorkennung dor kiinrtlichon Intolligont und der Bildverarboitung von 1ntore.w mwio fiir dioionigon, dio sich m i l der Montifikrtion von Mmnrchon boschiiftigon.
ISBN 3-7643-0957-1

