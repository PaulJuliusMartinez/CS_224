Constraint Hierarchies

and Logic Programming

Alan Borning, Michael Maher,

Amy Martindale, and Molly Wilson

Technical Report 88-11-10

Computer Science Department

University of Washington

November 1988

Abstract. Constraint Logic Programming (CLP) is a general scheme for extending logic pro-

gramming to include constraints. It is parameterized by D, the domain of the constraints. However,

CLP(D) languages, as well as most other constraint systems, only allow the programmer to specify

constraints that must hold. In many applications, such as interactive graphics, page layout, and

decision support, one needs to express preferences as well as strict requirements.

If we wish to

make full use of the constraint paradigm, we need ways to represent these defaults and preferences

declaratively, as constraints, rather than encoding them in the procedural parts of the language. We

describe a scheme for extending CLP(D) to include both required and preferential constraints, with

an arbitrary number of strengths of preference. We present some of the theory of such languages,

and an algorithm for executing them. To test our ideas, we have implemented an interpreter for an

instance of this language scheme with D equal to the reals. We describe our interpreter, and outline

some examples of using this language.

Authors' addresses:

Alan Borning, Amy Martindale, and Molly Wilson

Michael Maher

Computer Science Department, FR-35

IBM T.J. Watson Research Center

University of Washington

P.O. Box 704

Seattle, Washington 98195

Yorktown Heights, New York 10598

internet: borning@cs.washington.edu

mjm@ibm.com

amy@cs.washington.edu

molly@cs.washington.edu

1

Introduction

Recently there has been considerable research on extending logic programming to include constraints.

This extension signicantly increases the expressiveness of such languages. Constraint Logic Pro-

gramming [16] is a general scheme for such extensions, and is parameterized by D, the domain of

the constraints. The language that arises from a xed set of constraints over D can be denoted by

CLP(D). In place of unication (which can be viewed as testing the satisability of equations over

the Herbrand universe), constraints are accumulated and tested for satisability over D, using tech-

niques appropriate to the domain. Several such languages have now been implemented, including

Prolog III [5], CLP(R) [14, 17] and CHIP [7]. The formal semantics of such languages dier mainly

in the choice of underlying domain and constraints, as was shown formally in [16]. It was also shown

that for every language that can be obtained from the CLP scheme for solution-compact domains D,

numerous desirable properties of the declarative and operational semantics hold|properties that had

been considered characteristic of logic programming. In particular, CLP languages have coincident

logical, xedpoint, and operational semantics.

Independent of logic programming, constraints have proven useful for a variety of applications, in-

cluding geometric layout, physical simulations, user interface design, document formatting, algorithm

animation, and design and analysis of mechanical devices and electrical circuits. (See for example

[2, 3, 8, 13, 21, 22, 24, 27, 29, 33, 34, 35, 36], and [23] for a survey.) Many such applications require

some notion of defaults and preferences. If we wish to make full use of the constraint paradigm,

we need ways to represent these defaults and preferences declaratively, as constraints, rather than

encoding them in the procedural parts of the language.

Consider an interactive graphics example from our own work on ThingLab [2]. Suppose we have

a line with a point constrained to lie at its midpoint (Figure 1). If we pick up one end of the line

with the mouse and move it about, the constraint will ensure that the midpoint relation remains

satised. However, without some notion of defaults and the ability to specify preferences, the other

end of the line could ail wildly about the screen, without violating the midpoint constraint. To

prevent this, we want to specify that parts of the gure should remain stationary unless otherwise

required to move. There is a further problem, however. Given the discussion so far, we might also

have the midpoint remain stationary, with the line pivoting about it. This isn't what most users

expect; they want the endpoint of the line to be less movable than the midpoint. Early versions

of ThingLab implemented these defaults in an ad hoc fashion as part of the constraint satisfaction

algorithm. Later, to allow such defaults and preferences to be specied explicitly and declaratively,

we devised a theory of constraint hierarchies [1], which allows a user to specify not only constraints

that must hold, but also weaker constraints at an arbitrary number of strengths. The constraint

hierarchy scheme is parameterized by a comparator C that allows us to compare dierent possible

solutions to the hierarchy and select the best ones. We have also implemented several algorithms

for satisfying such hierarchies within ThingLab [1, 12].

Defaults and preferences arise naturally when trying to use constraint logic programming for interac-

tive graphics, as well as for other applications, for example, decision support systems. On the other

Figure 1: Moving an endpoint of a midpoint line

1

hand, some of our interactive graphics applications require such general programming language ca-

pabilities as conditionals and recursion, which are already elegantly provided by logic programming.

We are thus led to an integration of CLP and constraint hierarchies. The result, described in this

paper, is a Hierarchical Constraint Logic Programming scheme HCLP(D; C ), parameterized both by

the domain D of the constraints and by the comparator C . In addition to the benets listed above,

the integration allows us to build on CLP's rm theoretical foundation.

In the remainder of the paper, we rst present a theory of constraint hierarchies, which extends

and modies our previous theory for use in a logic programming framework. We then describe

HCLP(D; C ), give examples of its use, and describe a formal semantics for this family of languages.

We also present an algorithm for solving HCLP programs. This algorithm is general for the domain

D of constraints, but specic to a particular comparator LP B. (LP B is the locally-predicate-better

comparator, which will be dened in Section 2.) We also describe a prototype implementation of

of HCLP(R; LP B), where R is the domain of real numbers. Finally we discuss some directions for

future research.

2 Constraint Hierarchies

The domain D determines the constraint predicate symbols 

of the language. A constraint is of

D

the form p(t

; : : : ; t

) where p is an n-ary symbol in 

and each t

is a term. A label led constraint

1

n

D

i

is a constraint labelled with a strength, written sc, where s is a strength and c is a constraint.

In HCLP programs we give user-denable symbolic names to the dierent strengths of constraints.

In both the HCLP theory and in the implementation, we then map each of these names onto the

integers 0 : : : n, where n is the number of non-required levels. Strength 0 is always reserved for

required constraints.

A constraint hierarchy is a multiset of labelled constraints. Given a constraint hierarchy H , let C

0

denote the required constraints in H , with their labels removed. In the same way, we dene the sets

C

; : : : ; C

for levels 1 : : : n. Note that for all i; j in 0 : : : n, if i < j then the constraints in C

are

1

n

i

stronger (more preferred) than those in C

.

j

A solution to a constraint hierarchy H will consist of a valuation for the free variables in H , i.e.,

a function that maps the free variables in H to elements in the domain D. We wish to dene the

set S of all solutions to H . Clearly, each valuation in S must be such that after it is applied all the

required constraints hold. In addition, we want each valuation in S to be such that it satises the

non-required constraints as well as possible, respecting their relative strengths. To formalize this

desire, we rst dene the set S

of valuations such that all the C

constraints hold. Then, using S

,

0

0

0

we dene the desired set S by eliminating all potential valuations that are worse than some other

potential valuation using the comparator better.

S

= f j 8c 2 C

c holdsg

0

0

S = f j  2 S

^ 8 2 S

:better (; ; H )g

0

0

(In the denition c denotes the result of applying the valuation  to c.)

2

There are many plausible candidates for comparators. We insist that better be irreexive and

transitive:

88H :better (; ; H )

888 8H better (; ; H ) ^ better (;  ; H ) ! better (;  ; H )

From irreexivity and transitivity it immediately follows that:

888H better (; ; H ) ! :better (; ; H ):

Note that, in general, better will not provide a total ordering|there may exist  and  such that 

is not better than  and  is not better than .

We insist that better respect the hierarchy|if there is some valuation in S that completely satises

all the constraints through level k, then all valuations in S must satisfy all the constraints through

level k:

if 9 2 S ^ 9k 2 0 : : : n such that

8i 2 1 : : : k 8p 2 C

p holds

i

then 8 2 S 8i 2 1 : : : k 8p 2 C

p holds

i

We now dene several dierent comparators. In the denitions we will need an error function e(c)

that returns a non-negative real number indicating how nearly constraint c is satised for a valuation

. This function must have the property that e(c) = 0 if and only if c holds. For any domain D,

we can use the trivial error function that returns 0 if the constraint is satised and 1 if it is not. For

a domain that is a metric space, we can instead use its metric in computing the error: for example,

the error for X = Y would be the distance between X and Y . (See Section 7.3 for more information

on this topic.)

The rst of the comparators, local ly-better, considers each constraint in H individually.

Denition. A valuation  is local ly-better than another valuation  if, for each of the constraints

through some level k   1, the error after applying  is equal to that after applying , and at level k

the error is strictly less for at least one constraint and less than or equal for all the rest.

local ly-better (; ; H ) 

9k 2 1 : : : n such that

8i 2 1 : : : k   1 8p 2 C

e(p) = e(p)

i

^ 9q 2 C

e(q) < e(q)

k

^ 8r 2 C

e(r)  e(r)

k

Next, we dene a schema global ly-better for global comparators. The schema is parameterized by a

function g that combines the errors of all the constraints C

at a given level.

i

3

Denition. A valuation  is global ly-better than another valuation  if, for each level through some

level k   1, the combined errors of the constraints after applying  is equal to that after applying ,

and at level k it is strictly less.

global ly-better (; ; H; g) 

9k 2 1 : : : n such that

8i 2 1 : : : k   1 g(; C

) = g(; C

)

i

i

^ g(; C

) < g(; C

)

k

k

Using global-better, we now dene three global comparators, using dierent combining functions g.

Denition. A valuation  is weighted-sum-better than another valuation  if, for each level through

some level k   1, the weighted sum of the errors of the constraints after applying  is equal to that

after applying , and at level k it is strictly less.

In the formula, the weight for constraint p is

denoted by w

. Each weight is a positive real number.

p

weighted-sum-better (; ; H )  global ly-better (; ; H; g)

where g( ; C ) 

w

e(p )

p

X

p2C

Denition. A valuation  is worst-case-better than another valuation  if, for each level through

some level k   1, the maximum of the weighted errors of each constraint after applying  is equal to

that after applying , and at level k the maximum is strictly less.

worst-case-better (; ; H )  global ly-better (; ; H; g)

where g( ; C )  max fw

e(p ) j p 2 C g

p

Denition. A valuation  is least-squares-better than another valuation  if, for each level through

some level k   1, the weighted sum of the squares of the errors of the constraints after applying  is

equal to that after applying , and at level k it is strictly less.

least-squares-better (; ; H )  global ly-better (; ; H; g)

where g( ; C ) 

w

e(p )

p

X

2

p2C

Finally, we dene an important special case of local ly-better, namely local ly-predicate-better, and of

weighted-sum-better, namely unsatised-count-better.

Denition. A valuation  is local ly-predicate-better than another valuation  if each of the con-

straints through some level k that holds after applying  also holds after applying , and if there is

4

at least one constraint at level k that holds after applying  and that does not hold after applying

. To formalize this denition, we simply dene local ly-predicate-better to be equal to local ly-better

using the trivial error function that returns 0 if the constraint is satised and 1 if it is not.

Denition. A valuation  is unsatised-count-better than another valuation  if, for each level

through some level k   1, the number of unsatised constraints after applying  is equal to that

after applying , and at level k the number is strictly less. Again, we formalize this by dening

unsatised-count-better to be equal to weighted-sum-better using the trivial error function and all

weights equal to 1. (It is also equal to least-squares-better with these same specializations.)

There are a number of interesting relations that hold among the comparators.

Proposition: 888H local ly-better (; ; H ) ! least-squares-better (; ; H )

Corollary: Let S

denote the solutions for a hierarchy H using the local ly-better comparator, and

LB

S

that for least-squares-better. Then S

 S

.

LSB

LSB

LB

Proposition: 888H local ly-better (; ; H ) ! weighted-sum-better (; ; H )

Corollary: Let S

denote the solutions for a hierarchy H for weighted-sum-better. Then

WSB

S

 S

.

WSB

LB

The proofs are similar to those given in [1].

The converse of each of the propositions and corollaries does not hold: for example, least-squares-

better does not imply local ly-better.

We end this section with a few comments on the comparators. The denitions of the global com-

parators include weights on the constraints. For the local comparators, adding weights would be

futile, since the result would be the same with or without the weights. The global comparators

weighted-sum-better, worst-case-better, and least-squares-better are derived from the standard sta-

tistical measures of deviation L

-norm, L

-norm, and L

-norm respectively. The local ly-better

1

1

2

comparator is derived from the concept of a vector minimum (or pareto-optimal point, or nondom-

inated feasible solution) in multiob jective linear programming problems [28]. Finally, the standard

linear programming problem of minimizing an ob jective function sub ject to a set of linear inequality

conditions can be easily expressed as a constraint hierarchy. The linear inequality conditions are

represented as required constraints, and the ob jective function translates to a default constraint that

the value of the ob jective function be zero.

3 Constraints in Logic Programming

In standard logic programming (as exemplied by Prolog), rules are of the form

p(t) :   q

(t); : : : ; q

(t):

1

m

where p; q

; : : : ; q

are predicate symbols, and t denotes a list of terms. In CLP, rules are of the

1

m

form

p(t) :   q

(t); : : : ; q

(t); c

(t); : : : ; c

(t):

1

m

1

n

where p; q

; : : : ; q

are as before, and c

; : : : ; c

are constraints. Operationally, we can think of

1

m

1

n

executing the Prolog part of the program in the usual way, accumulating constraints on logic variables

as we go, and either verifying that the constraints are solvable or else backtracking if they are not.

The program can terminate with substitutions being found for all variables in the input, or with

5

some constrained variables still unbound, in which case the output would include the remaining

constraints on these variables.

In HCLP, rules are of the form

p(t) :   q

(t); : : : ; q

(t); s

c

(t); : : : ; s

c

(t):

1

m

1

1

n

n

where s

indicates the strength of the corresponding constraint c

. Symbolic names are given to

i

i

the dierent strengths of constraints. The user denes an arbitrary number of names and their

corresponding strengths. One strength, the \required" strength, is special, in that the constraints

it labels must be satised. The other strengths all denote non-required constraints. If the s

are

i

all required, then clearly the program is equivalent to the same program in standard CLP with the

strengths omitted.

Operationally, goals are satised as in CLP, temporarily ignoring the non-required constraints. When

a goal is determined to be satisable, all non-required constraints in that goal are then added to

the current constraint hierarchy. After a goal has been successfully reduced, there may still be non-

ground variables in the solution. The hierarchy of non-required constraints is solved, using a method

determined by the comparator C , thus further rening the values of these variables. Additional

answers may be produced by backtracking. As with CLP, constraints can be used multi-directionally,

and the scheme can accomodate collections of constraints that cannot be solved by simple forward

propagation methods. (For example, our current implementation can handle simultaneous linear

equations.)

4 HCLP Examples

The following example is illustrative of a wide class of interactive graphics programs. We have a

horizontal line displayed on the screen, and we are moving one endpoint with the mouse (Figure 2).

There is a required constraint that the line be horizontal, a preference that one endpoint of the line

follow the mouse, and a weaker preference that the endpoints of the line remain xed. This weak

preference gives stability to the line as it is moved, so that, for example, it doesn't suddenly triple

in length as we move the endpoint by some small distance.

The HCLP(R; C ) rule below expresses the desired update behavior. It takes as arguments terms

representing the old and new states of the horizontal line, and a third term that is the x-y distance

by which one endpoint should be moved. Any or all of the terms may contain variables. However,

in typical use in an interactive graphics application, the old state of the line and the displacement

would be ground, while the new state of the line would be a variable, whose value would be computed

as a result of satisfying the constraints.

Figure 2: Moving an endpoint of a horizontal line

6

/* set up symbolic names for constraint strengths */

levels([require, strong, prefer, default, weak]).

move_horiz_end2(line_segment(OldX1,OldY1,OldX2,OldY2),

line_segment(NewX1,NewY1,NewX2,NewY2),

delta(DX,DY)) :-

require OldY1 = OldY2, require NewY1 = NewY2,

prefer OldX2 + DX = NewX2, prefer OldY2 + DY = NewY2,

default OldX1 = NewX1, default OldY1 = NewY1,

default OldX2 = NewX2, default OldY2 = NewY2.

Suppose now we anchor the other end of the horizontal line, so that this other end becomes dicult

to move. (We'll use a strong preference rather than a required constraint, so that the anchor can

be moved if needed by using an even stronger mouse constraint.) Since in this version the anchor

constraints are stronger than the mouse constraints, now the line will stretch in the x direction,

following the mouse, but its y position will remain constant. In other words, the mouse constraint

on the new x value of end2 will be satised, but the mouse constraint on the new y value will be

overridden by the stronger constraint that it be the same as the old y value. (See Figure 3.)

move_horiz_end2_anchor_end1(line_segment(OldX1,OldY1,OldX2,OldY2),

line_segment(NewX1,NewY1,NewX2,NewY2),

Displacement) :-

move_horiz_end2(line_segment(OldX1,OldY1,OldX2,OldY2),

line_segment(NewX1,NewY1,NewX2,NewY2),

Displacement),

strong OldX1 = NewX1, strong OldY1 = NewY1.

In a similar manner, we can (without any hard thinking required) translate all of the ThingLab

examples given in [2] into HCLP. For the more complex examples, the HCLP code becomes tediously

long. However (as with ThingLab), we envision such code being written automatically by the

interactive graphics application, rather than by a person. For cases when a programmer is writing

code, we have also designed (but not yet implemented) a pre-processor to support a notion of ob jects

in HCLP. Using the pre-processor, the move horiz end2 example would be written as follows:

move_horiz_end2(Old,New,Displacement) :-

horizontal(Old), horizontal(New),

prefer Old end2 + Displacement = New end2,

default Old = New.

horizontal(L) :-

line(L),

required L end1 y = L end2 y.

Figure 3: Moving an endpoint of an anchored horizontal line

7

The pre-processor supports data abstraction, so that for example the move horiz end2 predicate

can be used with any terms Old and New that satisfy the horizontal predicate. A series of ac-

cess messages is translated into a series of goals; for example, L end1 y becomes end1(L,Temp1),

y(Temp1,Temp2). The pre-processor also supports user-dened constraints, such as the point addi-

tion and equality constraints in the rst rule.

If we could do nothing beyond expressing previously implemented interactive graphics examples in

HCLP, of course, the current research would not be of great interest. However, since we have the

full power of logic programming available, we can do considerably more. For example, we have been

investigating the use of lters as a technique for the declarative construction of user interfaces. In

the lter browser described in [9], the screen view of some source ob ject is constructed by passing

the ob ject through a series of lters to produce the nal image. Each lter is represented as a

constraint relating its input and output. Thus the view is updated if the source changed. Further,

since the constraints are bidirectional, we can edit the image to make some change to the source.

ThingLab supported such lter networks for xed topologies, but it was dicult to make the shape

of the network depend on the data. Such dynamically congured constraint networks are needed,

for instance, if we want to view a tree, applying a sublter to each node in the tree to produce its

screen image. Such a tree-viewing lter is simple to write in HCLP|we write a recursive view tree

rule that sets up a node-viewing lter for each corresponding nodes in the source and view trees.

view_tree(Source,Image) :-

view_node(Source,Image),

view_subtrees(Source,Image).

view_subtrees(Source,Image) :-

leaf(Source), leaf(Image).

view_subtrees(Source,Image) :-

left(Source,LS), right(Source,RS).

left(Image,LI), right(Image,RI),

view_tree(LS,LI), view_tree(RS,RI).

view_node(SourceNode,ImageNode) :- ...

5 HCLP Theory

5.1 Denitions

We assume the existence of a structure D, which determines the function symbols  and the con-

straint predicate symbols 

of the language. 

must include =. The set of predicate symbols to

D

D

be dened by the program is denoted by 

and is assumed to be disjoint from 

. In this section

U

D

we develop some of the theory of HCLP(D; C ). Although many of these results are analogs of results

for CLP, some analogs do not hold for HCLP, for reasons discussed below.

An atom is of the form p(t

; : : : ; t

) where p is an n-ary symbol in 

and each t

is a term. A

1

n

U

i

primitive constraint is of the form p(t

; : : : ; t

) where p is an n-ary symbol in 

and each t

is a

1

n

D

i

term. In this paper a constraint is a primitive constraint. However the results of this section extend

to larger classes of constraints, as in [25]. We write P j=

Q if Q holds in every model of P that has

D

8

the same universe as D and assigns the same meaning to function symbols and constraint predicate

symbols as D. We use (9) to denote existential closure. A conjunction of constraints C is said to

be consistent (or satisable) if there are values (from D) for the free variables y such that every

constraint is true in D, that is, ; j=

9yC .

D

A variable renaming is an invertible substitution, that is, a substitution  such that for some

substitution 

,   

= 

  = " (" is the identity substitution). A variant of a syntactic

 1

 1

 1

ob ject is the result of applying a variable renaming to that ob ject. By a new variant we will refer

to a variant that has no variables in common with the current context. The equivalence relation 

is dened by A  A

i A and A

are variants of each other.

0

0

As previously discussed, an HCLP rule takes the form

p(t) :   q

(t); : : : ; q

(t); s

c

(t); : : : ; s

c

(t)

1

m

1

1

n

n

where t is a list of terms, p(t); q

(t); : : : ; q

(t) are atoms and s

c

(t); : : : ; s

c

(t) are labelled con-

1

m

1

1

n

n

straints. We can view a rule logically as

8x p(t)   q

(t) ^ : : : ^ q

(t) ^ c

(t) ^ : : : ^ c

(t)

1

m

1

n

where x is a list of the free variables in t.

(Note that the labels have been removed from the

constraints.) In fact, the logical semantics we will give uses only required constraints, but we take

this view of a rule to compare with other possible logical semantics.

An HCLP(D; C ) program is a collection of rules. A goal takes the form < G; H > where G is a

multiset of atoms and H is a constraint hierarchy. We let B be the set of goals modulo variable

renaming. Instead of working directly with elements of B , it suces to work with new variants of a

member of the equivalence class. This observation allows us to express some denitions in a simpler

way.

5.2 Formal Semantics of HCLP

The formal operational semantics of HCLP is very close to the operational semantics for logic pro-

gramming languages. In this section we dene the operational semantics and examine its relationship

to declarative semantics of HCLP.

A derivation for a program P and initial goal G

is a (nite or innite) sequence of goals fG

g.

0

i

Consecutive goals are related in the following manner: for some A

2 G where G

= < G; H

>, and

0

0

0

i

some variant A   H; B

; : : : ; B

of a rule of P where A and A

have the same predicate symbol,

1

n

G

= < (G   fA

g) [ fB

; : : : ; B

g; H

[ fA = A

g [ H >

i+1

1

n

0

0

0

where fA = A

g denotes the set of required constraints obtained by equating each argument of A

0

with the corresponding argument of A

. A

is said to be selected at step i. A computation rule

0

0

determines (uniquely) for every goal in a derivation which atom in that goal is selected.

Intuitively, an atom A

in a goal G

is being matched against a rule in the database whose head

i

0

is A. Required constraints are established between the corresponding arguments in A

and A, and

0

are added to the hierarchy for the next goal. (This corresponds to the unication step in standard

Prolog interpreters.) Then, A

is removed from the next goal, and the rules and constraints in the

0

body of A are added.

9

A derivation is innite unless, for some goal in the derivation, there is no next goal. There are two

cases. A derivation is successful if some G

takes the form < ;; H >. In this case H is called the nal

i

constraint hierarchy. The second case occurs when the derivation is nitely failed. A derivation is

nitely failed if no (variant of the) head of a rule of P unies with the selected atom. A goal is nitely

failed for a given computation rule if every derivation of that goal according to the computation rule

is nitely failed. A computation rule is fair if every atom that appears in the derivation is chosen

at some step. We assume in our work that a fair computation rule is used. Such rules are maximal

for detecting nite failure.

Recall that B denotes the set of goals modulo variable renaming. For a program P we dene the

success set SS , the nite failure set F F (both subsets of B ), and the function T

, which maps a set

P

of goals I to the set of all goals that can be obtained by one-step deductions from I .

SS = f< G; H >j< G; ; > succeeds with nal hierarchy H g

F F = f< G; H >j< G; H > is nitely failed g

T

: }(B ) ! }(B )

(}(B ) denotes the power set of B .) T

is dened as follows: for I  B ,

P

P

T

(I ) = f< G; H >j

P

G = fp

(s

); : : : ; p

(s

)g

1

1

n

n

for j = 1; : : : ; n there is a new variant of a rule of P;

p

(t

) :   H

; p

(t

); : : : ; p

(t

)

j

j

j

j;1

j;1

j;n(j )

j;n(j )

< fp

(r

); : : : ; p

(r

)g; H

>2 I

j;1

j;1

j;n(j)

j;n(j )

0

j

0

S

n(j )

F

= H

[ fp

(s

) = p

(t

)g [ H

[

fp

(t

) = p

(r

)g;

j

j

j

j

j

j

j;k

j;k

j;k

j;k

j

k=1

H = F

[ : : : [ F

;

1

n

and the collection of required constraints in H is consistent g

Let T

" ! =

T

(;) and T

# ! =

T

(B ):

P

P

n=0

P

n=0

P

S

T

1

1

n

n

It is straightforward to show that T

is continuous on the complete lattice of subsets of B under the

P

inclusion ordering. Consequently T

has a least xedpoint, which is equal to T

" !. This gives a

P

P

xedpoint characterization of the successful goals for a program and the nal constraint hierarchies

they compute.

Proposition: SS is the least xedpoint of T

.

P

As described above, a solution to a constraint hierarchy is a valuation. v is a computed solution for

< G; H

> i < G; H

> has a successful derivation with nal constraint hierarchy H , and v is a

0

0

solution of H .

Our next result is a soundness result for the computation of solutions. We extend it to give a

logical criterion for the existence of a computed solution. This can be viewed as a soundness and

completeness result for successful derivations. However, there is no direct converse of part (a) of the

theorem, that is, there is no corresponding completeness result. We use P

to denote the program

0

P with non-required constraints omitted.

Theorem:

(a) If v is a computed solution for < G; H > then P

j=

v(G ^ C

).

0

D

0

(b) < G; H > has a computed solution i P

j=

(9)(G ^ C

).

0

D

0

10

To see why there is no corresponding completeness result, consider the goal < p(X ); ; > for the

program P

p(X) :- strong prefer X=0.

Then P

is simply p(X). If we take v to be the valuation that assigns 2 to X then P

j=

v(p(X ))

0

0

D

but the computed solution will assign 0 to X . The incompleteness here is due to using P

rather

0

than P . However using P has even worse problems|a computed solution may not be sound. For

example the program Q

p(X) :- strong prefer X=0, weak prefer X6=0.

is logically a tautology (with respect to D). Hence although the computed solution would assign 0

to X we do not have Q j=

p(0). The simplicity of this example can suggest some obvious possible

D

remedies. However these do not work on other examples. Ultimately, the problem lies in attempting

to characterize the solutions of a constraint hierarchy logically when they are dened in a manner

that is essentially meta-logical.

In the above theorem we have a combined soundness and completeness result for successful deriva-

tions.

In the theorem below we show that there is also soundness and completeness for nitely

failed computations. We also have a characterization of the nite failure set in terms of the

function T

. A theory D is a satisfaction-complete theory for D if D is a model of D, and

P

0

for any conjunction of allowed constraints C with free variables y, D j= 9y C i ; j=

9y C , and

D

D j= :9y C i ; j=

:9y C . We write P

* for the Clark-completion [4, 18] (sometimes called the

D

0

IFF-denition) of a logic program P

.

0

Theorem: Let D be a satisfaction-complete theory for D.

(a) F F = B   T

# !

P

0

(b) < G; H > is nitely failed by the program P i P

*; D j= :(G ^ C

).

0

0

This is not simply the complement of (b) of the previous theorem, since there are also goals with

innite derivations, i.e. goals that have no computed solutions but are not nitely failed. There

are further results|which we will not state formally here|that associate the ground nite failure

set with the greatest xedpoint of T

, and that can give a characterization of nite failure using D

P

0

instead of D, provided D is solution-compact and the program is canonical [16].

6 An Algorithm for Interpreting HCLP Programs

In this section we sketch an algorithm for interpreting HCLP(D; LP B) programs. A complete

description is given in Appendix A.

In addition, we have written a proof of correctness for the

algorithm, which we plan to publish separately [37]. The algorithm works for any constraint domain

D, but is specic to the locally-predicate-better comparator.

The algorithm has two phases. In the rst phase, the algorithm attempts to reduce a goal using only

predicates and required constraints, while building up a hierarchy of non-required constraints. We

assume the existence of a CLP(D) interpreter for interpreting the predicates and required constraints

during this phase. In the second phase, the hierarchy of constraints is solved to further rene the

values of the remaining unbound variables, resulting in an answer. An answer consists of bindings

for some (possibly all) of the variables in the initial goal, and constraints on the remaining variables.

Additional answers are produced by backtracking.

Each answer represents one or more locally-predicate-better solutions to the constraint hierarchy.

11

For example, the answer x=2 represents the single valuation that maps x to 2, while the answer

y>5 represents an innite set of valuations, with each member of the set mapping y onto a dierent

number greater than 5. We make this distinction between answers and solutions since, on the one

hand, we obviously want our algorithm to return y>5 rather than an innite number of solutions.

On the other hand, since solutions are mappings from variables to particular elements in the domain,

it is easier to dene the comparators that let us decide whether one solution is better than another.

During its second phase, the algorithm uses a recursive procedure Solve. Each invocation of Solve

represents a node in an implicit search tree of possible non-required constraints to satisfy next.

A number of data structures are maintained by each invocation of Solve, including Answer (a set

of unlabelled constraints that represents the answer computed so far), and Untried (a multiset

of labelled constraints that have not yet been dealt with). Let s be the strongest strength of

the constraints in Untried. For each constraint c in Untried with strength s, Solve adds c to the

current answer, renes Untried by removing constraints that either have become unsatisable by the

assumption that c holds or that are implied by the current answer, and then recursively calls itself

with the remaining untried constraints. The base case is reached when the hierarchy is empty.

Each leaf in the implicit tree represents an answer to the goal. Upon request, the algorithm will

backtrack to nd alternate answers. These can arise in two ways. First, it is possible that the

constraint hierarchy produced by the current choices of rules has more than one answer. Second, it

is also possible that a goal can be satised in more than one way at the rule level: by using dierent

rules to solve a goal, a new constraint hierarchy may be obtained. All answers to the current

hierarchy are given before an attempt is made to resatisfy the goal. There is a unique computation

tree associated with every answer, but the answers themselves are not always unique.

Here is a trivial example in HCLP(R; LP B) to illustrate the algorithm's behavior upon backtracking.

banana(X) :- artichoke(X), weak_prefer X>6.

artichoke(X) :- strong_prefer X=1.

artichoke(X) :- required X>0, required X<10, weak_prefer X<4.

The rst answer to ?-banana(A) would be produced by selecting the rst of the artichoke clauses,

yielding the hierarchy strong prefer A=1, weak prefer A>6. There is a single answer to this

hierarchy, namely A=1. Upon backtracking, the second artichoke clause is selected, resulting in the

hierarchy required A>0, required A<10, weak prefer A<4, weak prefer A>6. This hierar-

chy has two answers. The rst is A>0, A<4. Upon backtracking the second and nal answer A>6,

A<10 would then be found.

To test our ideas, we have written an interpreter for HCLP(R; LP B) in CLP(R). The rst phase

is accomplished via a meta-interpreter. As with most Prolog meta-interpreters, it accepts a goal

and either satises it immediately, or looks up the goal in the rule base, reduces it to subgoals, and

recursively solves the subgoals. Required constraints are passed on to the CLP(R) solver immedi-

ately, while non-required constraints are simply pushed onto a stack. Non-required constraints that

are part of the body of some rule are only added to the stack if that rule (minus the non-required

constraints) succeeds. Upon completion of this phase, variable bindings and required constraints

are maintained within the environment, and the stack of non-required constraints is passed as a

constraint hierarchy to the second phase.

The implementation of the second phase is a straightforward incorporation of the above algorithm

into CLP(R). The search tree described above is built implicitly by the interpreter, and alternate

answers are returned upon backtracking. The stack of constraints is represented as a at Prolog

list. The non-required constraints that have already become true or unsatisable due to bindings

established by required constraints are removed from this list. The list is then sorted by the levels of

12

the constraints. (The order in which answers to the hierarchy are found is dependent on the order

of the constraints at a given level. However, all such answers are equally valid.) This second phase

takes advantage of Prolog's backtracking capabilities to try various combinations of constraints.

The interpreter is small (2 pages of CLP(R) code) and clean. We haven't concerned ourselves yet

with eciency, and the second phase of the interpreter is slow.

7 Future Work

The work described in this paper is recent, and there are a number of promising avenues for explo-

ration. A few of these are outlined below.

7.1 Dierent Ways of Selecting Among Answers

The HCLP theory is parameterized by the comparator C , but the current algorithm is specic to

local ly-predicate-better. For applications involving domains that are metric spaces, the use of an

error function based on the metric can restrict the set of solutions in a useful way; we want to devise

algorithms for such cases. For example, consider the program

p(X) :- strong prefer X3, weak prefer X=0.

Local ly-predicate-better yields the answer X3. (Since the weaker X=0 constraint can't be satised,

it is ignored completely.) In contrast, local ly-better using the standard distance metric for the reals

yields the answer X=3, in which the weaker constraint is satised as well as possible.

There are many applications in which it would be useful to place strengths on predicates as well as

on constraints. For example, to express a preference (but not a requirement) that a given window

be displayed on the screen, one could simply write default member(Window,DisplayedWindows).

Finally, our theory as described above selects among all the solutions arising from a single choice of

HCLP rules, but doesn't try to select among solutions arising from alternate choices of rules. As a

trivial but pathological example, consider the following program:

f(X) :- strong_prefer X>3, g(X).

g(5).

g(1).

Given the goal f(A), HCLP would rst return the answer A=5, and on backtracking A=1, since these

answers arise from dierent choices of the rule for g, even though the strong prefer X>3 constraint

is satised for one answer and not the other.

The problem of programming an options trading analysis system (OTAS) [15] provides some realistic

examples of where it would be useful to compare solutions arising from alternate choices of rules.

If this were supported, HCLP would have some clear advantages as a language for implementing

such systems. Option-based investment strategies can be tailored to t the prole of a specic

investor and to take into account currently prevailing market conditions. Mathematical models of

market behavior dene the parameters that are used to express the characteristics of those strategies.

Typically these strategies are described in OTAS by sets of constraints on selected parameters. For

instance, one might wish to consider positions that are delta-neutral and theta-positive and which

are centered within 2.5 points of the current stock price, with a margin requirement of at most

13

$1000.00 and a maximum potential return greater than the interest on the margin plus initial debit

plus commission. In the framework of OTAS, a query to generate positions that t this description

would contain the set of constraints:

Delta=0, Theta > 0,

abs(Midpoint-Stockprice) <= 2.5,

Margin <= 1000,

Return > Margin*Interest+Debit+Commission.

It is possible that, given the current market conditions, there will be few or no solutions. To

avoid the situation where an exhaustive search through all available positions fails, because none

of the positions satisfy all the constraints, we can weaken the strength of the previously required

constraints. The more important a constraint, the greater the strength it is given. In the above

example we could choose

strong Delta=0, strong Theta > 0,

prefer abs(Midpoint-Stockprice) <= 2.5,

default Margin <= 1000,

strong Return > Margin*Interest+Debit+Commission.

Now solutions will consist of option positions that all satisfy the highest level constraints and that

may or may not satisfy the others. They can be ranked, with better solutions satisfying more higher

level constraints. (This form of better is unsatised-count-better.) This ranking corresponds to their

closeness to the desired class of positions, and can be used to avoid examining positions which are

furthest from this class.

7.2 Ob jects with State

Interactive graphics applications naturally give rise to a notion of ob jects whose state changes over

time. Currently we handle this in a straightforward fashion by representing ob jects as terms, and by

using predicates that take as arguments the old and new states of the ob jects being acted upon. This

has the advantage of simplicity, but the disadvantage that one must pass along all the ob jects that

one wishes to update. (The same requirement for complete information about ob ject connectivity

was present, and satised, in ThingLab, so currently we don't regard this as a ma jor stumbling

block for our intended applications.)

Another technique for representing ob jects, used in e.g. Concurrent Prolog [32] and Vulcan [19], is

to represent an ob ject as a process that consumes messages, recursively calling itself with the next

state of the ob ject as an argument. It appears that this technique could be used in HCLP as well,

if HCLP were suitably extended (for example, with concurrency, a commit operator, and read-only

annotations). An additional complication with using perpetual processes to represent ob jects is that

we would need to modify the HCLP semantics to allow answers to be extracted incrementally, based

on the constraint hierarchy obtained at a given point in the execution of a process, rather than

only when it terminates. (Otherwise it would be dicult, for example, to display the state of the

horizontal line as we moved it about!) For example, here is one of the rules that dene the behavior

of a a horizontal line ob ject (namely one for receiving the move end2 message), written in the CP

style:

14

horizontal( [move_end2(DX,DY)|NewHorizontal] , OldX1,OldY1,OldX2,OldY2 ) :-

require OldY1 = OldY2, require NewY1 = NewY2,

prefer OldX2 + DX = NewX2, prefer OldY2 + DY = NewY2,

default OldX1 = NewX1, default OldY1 = NewY1,

default OldX2 = NewX2, default OldY2 = NewY2.

horizontal(NewHorizontal?,NewX1,NewY1,NewX2,NewY2).

A nal technique that we are investigating is to represent an ob ject as a binary predicate that relates

times and ob ject states. As the computation progresses, more and more information becomes known

about the ob ject at dierent times, but information is never retracted.

Experience with using HCLP in applications will determine whether our current simple model for

ob jects is adequate, or whether a process or other model is more appropriate.

7.3 Using Non-Standard Analysis

There are a number of problems that arise in the combined presence of inequality constraints and

error functions based on distance metrics. For example, what should be the error function for the

constraint X > Y , where X and Y are reals? One would like the error to be small when X is close

to Y , so an obvious candidate is that the error be 0 if X > Y , otherwise Y   X . This isn't correct,

however, since it gives an error of 0 when X = Y .

A related problem concerns the existence and non-existence of solutions. If the set of solutions S

0

for the required constraints is non-empty, we would want the set of solutions S for the hierarchy be

non-empty as well. However, consider the hierarchy require N>0, prefer N=0. Suppose the error

for X = Y is the distance between X and Y . Suppose also that the error for X > Y is such that,

if X 6> Y , the error is smaller if X and Y are closer. Then the solution set S will be empty, even

though S

is not. To prove this, suppose S is non-empty. Let v be a member of S . Then v will map

0

N to some positive number p, since the required constraint must be satised. But the valuation

mapping N to p=2 is better than v, and so v can't be in S . Hence S is empty.

1

To resolve such problems, we are investigating the use of non-standard analysis [6, 20, 31]. Using

non-standard analysis, we would dene the the error for X > Y to be  if X and Y are equal, for

some innitesimally small number . Similarly, a solution to the hierarchy require N>0, prefer

N=0 would be a valuation that maps N to an innitesimal.

2

7.4 Relation to Nonmonotonic Logic

The articial intelligence literature includes a substantial body of literature on nonmonotonic rea-

soning (see e.g. [10, 26, 30]). Some of the high-level goals of this work overlap strongly with those of

our own, but once one moves to the actual details of the formalisms, there are distinct dierences.

Thus another direction for future research will be to elucidate the relation between the formalisms.

Typically, in nonmonotonic logics one can state default rules of inference that allow an inference to

be made if and only if it would be consistent to do so. This allows fact that cannot be proved from

If S

is non-empty and nite, however, then S will be non-empty as well. See [1] for a proof.

0

1

2

A little care is needed in writing the comparator, lest we wind up in the same situation as before, where for any

possible valuation, a better one exists. The innitesimals still obey the axioms of real arithmetic, so that  +  6= ;

hence in fact there are an innite number of innitesimals. However, if the comparator ignores innitesimal dierences

in non-zero errors, we can achieve the desired behavior. Thus, in the example above, the solution set S would consist

of all valuations that map N to a positive innitesimal.

15

rst-order principles, but that are consistent with what is already inferred, to be added to one's

knowledge base. Reiter and Etherington, for example, allow the use of inference rules of the form

A(x) : B

(x); : : : ; B

(x)

1

m

w(x)

Informally, we can read this as \if A(x) holds, and if it is consistent to believe B

(x); : : : ; B

(x),

1

m

then conclude w(x)." Reiter and Etherington also identify a useful subset of these inference rules,

namely normal defaults, in which m = 1 and B

(x) = w(x).

1

HCLP programs are clearly nonmonotonic: given a default constraint on a variable X , the addition of

a stronger constraint might result in completely dierent permissible valuations for X . (In contrast,

in standard CLP, the addition of a constraint on X could result in fewer permissible valuations for

it, but not in completely dierent ones.)

One of the specic problems addressed by nonmonotonic logics is the frame problem. Consider a

system for planning robot actions. We need to reason about the state of the world after the robot

has performed some action. We would like to deduce that properties of the world will be the same

after the action as they were before, unless there is reason to believe otherwise. However, it isn't

possible to express this in standard rst-order logic except by a laborious enumeration of specialized

facts about each combination of possible robot actions and properties. Nonmonotonic logics do let

us state such rules in a general way.

Constraint hierarchies also provide a solution for the frame problem in the particular context of

interactive graphics. In the midpoint line example described in the introduction, for example, the

default stay constraints express the fact that we want parts of the gure to remain stationary unless

there is reason for them to move.

There are, however, dierences between nonmonotonic logics and constraint hierarchies. For exam-

ple, a common problem with nonmonotonic logics is that there are multiple extensions for a given

set of axioms and inference rules, without a clear way of choosing among the extensions. For in-

stance, to handle the midpoint line example using nonmonotonic logic, we might have a default rule

stating that points remain xed if it is consistent to so believe. However, this rule doesn't allow

us to select among the dierent possible extensions in which dierent points stay xed. Similarly,

it isn't clear that stronger preferences, e.g. that a point follow the mouse, can be expressed in a

nonmonotonic logic in such a way that the appropriate extension is chosen. In HCLP, however, the

ability to express constraints at varying strengths means that less desirable extensions will be ruled

out. Although there are some applications, such as inheritance hierarchies, where the default rules of

a default logic can be manipulated to eliminate extensions, the addition of new rules often requires

rewriting of the old ones because information about exceptions is encoded explicitly into the rules

[11]. In HCLP, preferences can be expressed simply by the strength given to a constraint. Adding

new constraints may require reordering of existing ones if all the stronger levels are being used, but

the constraints themselves can stay the same.

On the other hand, it isn't possible to translate default rules into HCLP, since we currently do not

allow strengths to be applied to predicates. We do believe that a variant of HCLP that allowed

strengths on predicates and on the heads of rules could express normal defaults. (We still need to

prove this conjecture, however.) Such a variant might provide a convenient means for eliminating

less preferable extensions, since HCLP provides defaults of multiple strengths.

16

Acknowledgements. Thanks for many useful discussions, and comments on drafts of this

paper, to Greg Barnes, Alan Bundy, Rob Duisberg, Bjorn Freeman-Benson, Joxan Jaar, Ken Kahn,

Catherine Lassez, Jean-Louis Lassez, David Maier, Geo Phipps, Vijay Saraswat, Peter Stuckey,

and Dan Weld. Bjorn Freeman-Benson devised a tree-search algorithm for satisfying constraint

hierarchies, from which the algorithm described in this paper was derived. Catherine Lassez provided

the OTAS example in Section 7. The work on non-standard analysis is being done jointly with Dan

Weld. This research was sponsored in part by the National Science Foundation under Grant No.

IST{8604923, by the Washington Technology Center under Grant No. 09-1054, by fellowships from

Apple Computer for Molly Wilson and Amy Martindale, by IBM (for Michael Maher), and by Rank

Xerox (for Alan Borning while a visiting scientist at Rank Xerox EuroPARC during summer 1988).

17

A An Algorithm for Interpreting HCLP Programs

PROCEDURE Interpret(Goal,Program);

VAR Succeeded : Boolean;

Answer : Set of Constraints;

Untried, Satised, Unsatised : Hierarchy;

C1 : Constraint;

BEGIN

( Make a cal l to CLP and get an answer to the predicates and required constraints using the standard

CLP machinery. Also return the hierarchy of non-required constraints in the variable Untried. The

repeat loop causes the CLP engine to backtrack, producing alternate answers. )

LOOP

CLP(Goal,Program,Succeeded,Answer,Untried);

IF NOT Succeeded THEN

Output \no more answers";

RETURN;

END; ( IF )

FOR each constraint C1 in Untried DO

IF Answer implies C1 is false THEN

add C1 to Unsatised;

remove C1 from Untried;

ELSIF Answer implies C1 THEN

add C1 to Satised;

remove C1 from Untried;

ELSE

( Answer says nothing about C1. C1 remains in Untried )

END; ( IF )

END; ( FOR )

( Make the cal l to the constraint hierarchy solver. If Answer is empty, then the solver wil l output

the empty set as an answer and then return. )

Solve(Answer,Satised,Untried,Unsatised);

END; ( LOOP )

END Interpret.

PROCEDURE Solve(CurrentAnswer : Set of Constraints;

Satised, Untried, Unsatised : Hierarchy);

VAR S : Set of Constraints;

C1, C2 : Constraint;

NewAnswer : Set of Contraints;

NewSatised, NewUntried, NewUnsatised : Hierarchy;

18

BEGIN

( If al l the constraints have been tried, then we have an answer )

IF Untried is empty THEN

Output CurrentAnswer;

RETURN;

END;

( Explore al l answers starting with the strongest constraints )

S:= set of all constraints at the strongest level in Untried;

FOR each constraint C1 in S DO

( Note that C1 is consistent with the current answer since it is not in Unsatised. Cal l constraint

solver to combine the current answer and C1. We assume that the constraint solver is powerful

enough either to return a new set of constraints or to fail if there are no substitutions that satisfy

the constraints in the CurrentAnswer and C1. )

NewSatised:= Satised;

NewUntried:= Untried;

NewUnsatised:= Unsatised;

NewAnswer:= ConstraintSolver(CurrentAnswer,C1);

( Now update Satised and Unsatised lists. Note that C1 wil l be removed from the list of Untried

constraints and put in the list of Satised constraints. Any constraint that is not satised by the new

answer wil l be one at a level equal to or weaker than C1, because of the way S is chosen. So we stil l

have a valid answer. )

FOR each constraint C2 in Untried DO

IF NewAnswer implies C2 is false THEN

add C2 to NewUnsatised;

remove C2 from NewUntried;

ELSIF NewAnswer implies C2 THEN

add C2 to NewSatised;

remove C2 from NewUntried;

ELSE

( NewAnswer says nothing about C2. C2 remains in NewUntried )

END;

END; ( FOR )

( Make recursive cal l. This cal l to Solve creates a new node in the implicit search tree. Each C2 in

Untried can be seen as labeling an edge to a child of the current node. )

Solve(NewAnswer,NewSatised,NewUntried,NewUnsatised);

( Re-initialize hierarchies )

END; ( FOR )

END Solve.

19

References

[1] Alan Borning, Robert Duisberg, Bjorn Freeman-Benson, Axel Kramer, and Michael Woolf.

Constraint Hierarchies. In Proceedings of the 1987 ACM Conference on Object-Oriented Pro-

gramming Systems, Languages, and Applications, pages 48{60. ACM, October 1987.

[2] Alan H. Borning. The Programming Language Aspects of ThingLab, A Constraint-Oriented

Simulation Laboratory. ACM Transactions on Programming Languages and Systems, 3(4):353{

387, October 1981.

[3] Alan H. Borning and Robert A. Duisberg. Constraint-Based Tools for Building User Interfaces.

ACM Transactions on Graphics, 5(4), October 1986.

[4] K. L. Clark. Negation as Failure. In H. Gallaire and J. Minker, editors, Logic and Databases,

pages 293{322. Plenum Press, New York, 1978.

[5] Alain Colmerauer. An Introduction to Prolog III. Draft, Groupe Intelligence Articielle, Uni-

versite Aix-Marseille II, November 1987.

[6] M. Davis and R. Hersh. Nonstandard Analysis. Scientic American, June 1972.

[7] M. Dincbas, P. Van Hentenryck, H. Simonis, A. Aggoun, T. Graf, and F. Bertheir. The Con-

straint Logic Programming Language CHIP. Draft, European Computer-Industry Research

Center, Munich, West Germany.

[8] Robert A. Duisberg. Constraint-Based Animation: The Implementation of Temporal Con-

straints in the Animus System. PhD thesis, University of Washington, 1986. Published as U.W.

Computer Science Department Technical Report No. 86-09-01.

[9] Raimund Ege, David Maier, and Alan Borning. The Filter Browser|Dening Interfaces Graph-

ically. In Proceedings of the European Conference on Object-Oriented Programming, pages 155{

165, Paris, June 1987. Association Francaise pour la Cybernetique

Economique et Technique.



[10] David W. Etherington. Formalizing Nonmonotonic Reasoning Systems. Articial Intel ligence,

31(1):41{85, January 1987.

[11] David W. Etherington and Raymond Reiter. On Inheritance Hierarchies With Exceptions. In

Proceedings AAAI-83, 1983.

[12] Bjorn Freeman-Benson and John Maloney. The DeltaBlue Algorithm: An Incremental Con-

straint Hierarchy Solver. In Proceedings of the Eighth Annual IEEE Phoenix Conference on

Computers and Communications, Scottsdale, Arizona, March 1989. IEEE. To appear.

[13] James A. Gosling. Algebraic Constraints. PhD thesis, Carnegie-Mellon University, May 1983.

Published as CMU Computer Science Department tech report CMU-CS-83-132.

[14] N. Heintze, J. Jaar, S. Michaylov, P. Stuckey, and R. Yap. The CLP(<) Programmer's Manual.

Technical report, Computer Science Dept, Monash University, 1987.

[15] T. Huynh and C. Lassez. A CLP(<) Options Trading Analysis System. In Proceedings of 5th

International Conference and Symposium of Logic Programming, pages 59{69, 1988.

[16] J. Jaar and J-L. Lassez. Constraint Logic Programming. In Proceedings of the 14th ACM

Principles of Programming Languages Conference, Munich, January 1987. ACM.

[17] J. Jaar and S. Michaylov. Methodology and Implementation of a CLP System. In Proceedings

of the 4th International Conference on Logic Programming, 1987.

[18] Joxan Jaar, Jean-Louis Lassez, and Michael J. Maher. A Logic Programming Language

Scheme. In D. DeGroot and G. Lindstrom, editors, Logic Programming: Relations, Functions

and Equations. Prentice-Hall, 1986.

20

[19] Kenneth Kahn, Eric Tribble, Mark Miller, and Daniel Bobrow. Ob jects in Concurrent Logic

Programming Languages. In Proceedings of the 1986 ACM Conference on Object-Oriented Pro-

gramming Systems, Languages and Applications, pages 242{257, Portland, Oregon, September

1986. ACM.

[20] J. Keisler. Foundations of Innitessimal Calculus. Prindle, Webber and Schmidt, Inc., Boston,

1976.

[21] M. Konopasek and S. Jayaraman. The TK!Solver Book. Osborne/McGraw-Hill, Berkeley, CA,

1984.

[22] William Leler. Specication and Generation of Constraint Satisfaction Systems Using Aug-

mented Term Rewriting. PhD thesis, University of North Carolina at Chapel Hill, 1986.

[23] William Leler. Constraint Programming Languages. Addison-Wesley, 1987.

[24] David Levitt. Machine Tongues X: Constraint Languages. Computer Music Journal, 8(1):9{21,

Spring 1984.

[25] Michael J. Maher. Logic Semantics for a Class of Committed-choice Programs. In Proceed-

ings of the Fourth International Conference on Logic Programming, pages 858{876, Melbourne,

Australia, May 1987. ICALP.

[26] John McCarthy. Circumscription|A Form of Non-Monotonic Reasoning. Articial Intel ligence,

13(1,2):27{39, April 1980.

[27] Sanjay Mittal, Clive L. Dym, and Mahesh Morjaria. PRIDE: An Expert System for the Design

of Paper Handling Systems. Computer, pages 102{114, July 1986.

[28] Katta G. Murty. Linear Programming. Wiley, 1983.

[29] Greg Nelson. Juno, A Constraint-Based Graphics System. In B.A. Barsky, editor, SIGGRAPH

'85 Conference Proceedings, pages 235{243, San Francisco, July 1985. ACM.

[30] Raymond Reiter. A Logic for Default Reasoning. Articial Intel ligence, 13(1,2):81{132, April

1980.

[31] A. Robinson. Non-Standard Analysis. North-Holland Publishing Company, Amsterdam, 1966.

[32] Ehud Shapiro. Concurrent Prolog: A Progress Report. IEEE Computer, 19(8):44{58, August

1986.

[33] Guy L. Steele Jr. The Denition and Implementation of a Computer Programming Language

Based on Constraints. PhD thesis, MIT, August 1980. Published as MIT-AI TR 595, August

1980.

[34] Gerald J. Sussman and Guy L. Steele Jr. CONSTRAINTS|A Language for Expressing Almost-

Hierarchical Descriptions. Articial Intel ligence, 14(1):1{39, January 1980.

[35] Ivan Sutherland. Sketchpad: A Man-Machine Graphical Communication System. In Proceedings

of the Spring Joint Computer Conference. IFIPS, 1963.

[36] Christopher J. van Wyk. A High-level Language for Specifying Pictures. ACM Transactions

on Graphics, 1(2), April 1982.

[37] Molly Wilson. A Proof of Correctness of an Algorithm for Executing Constraint Hierarchy

Logic Programs. To be submitted for publication, 1989.

21

